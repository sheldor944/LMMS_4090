The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-11-28 08:38:54[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-28 08:38:54[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-28 08:38:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-28 08:38:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-28 08:38:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-28 08:38:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-28 08:38:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-28 08:38:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-28 08:38:55[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/300_run_LV/selected_dbfp_longvideobench_blip_k16_alpha1.0_sup2.0_temporal_20251128_083849_results'}[0m
[32m2025-11-28 08:38:55[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-28 08:38:55[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/300_run_LV/selected_dbfp_longvideobench_blip_k16_alpha1.0_sup2.0_temporal_20251128_083849_results'}[0m
[32m2025-11-28 08:38:55[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-28 08:38:55[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-28 08:38:55[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
OpenCLIP not installed
OpenCLIP not installed
force sample: False
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
force sample: False
Rank 0:  Loaded LLaVA model: ../LLaVA-NeXT-Video-7B-Qwen2
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:07,  2.64s/it]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:03<00:09,  3.00s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:04,  2.43s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:05<00:05,  2.76s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:07<00:02,  2.38s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  1.89s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  2.09s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:08<00:02,  2.65s/it]Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 300 examples [00:00, 28112.59 examples/s]
[32m2025-11-28 08:39:08[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 1 (local rank 1)[0m
[32m2025-11-28 08:39:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank1-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-28 08:39:08[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 1...[0m
  0%|          | 0/150 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 6413.24it/s]
[32m2025-11-28 08:39:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 150[0m
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09<00:00,  2.02s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09<00:00,  2.29s/it]
Rank 0:  Model Class: LlavaQwenForCausalLM
[32m2025-11-28 08:39:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36m__init__[0m:[36m215[0m - [1mUsing 2 devices with data parallelism[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 0 (local rank 0)[0m
[32m2025-11-28 08:39:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank0-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 0...[0m
  0%|          | 0/150 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 6910.35it/s]
[32m2025-11-28 08:39:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 150[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/150 [00:00<?, ?it/s][32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pJI5ZU6wxqg.mp4[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pJI5ZU6wxqg.mp4[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pJI5ZU6wxqg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=1[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bUaFXONIXzM.mp4[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bUaFXONIXzM.mp4[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bUaFXONIXzM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=0[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a foam paper cup containing three drinks, one of the drinks has a raised milk cap in a creamy yellow color. Where else has this drink appeared?
A. In the kitchen
B. In the fridge
C. In an amusement park
D. In the hand of a woman without a ring holding a green straw
E. In a Starbucks store
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   1%|          | 1/150 [00:03<08:00,  3.23s/it][32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7135100078221430058.mp4[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7135100078221430058.mp4[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7135100078221430058.mp4 | Selected 5 frames[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=2[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a lush tree on the screen. Beside it, there is a small wooden house. A man wearing a hat and dressed in yellow and black clothing is looking towards the camera while riding an electric vehicle. Some people are chatting by the roadside. What happens after a white car passes through the screen?
A. A white car appears
B. An elderly person holding a palm fan appears
C. A little girl with a backpack appears
D. A large truck appears
E. A person wearing a helmet appears riding a motorcycle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6999997457392307457.mp4[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6999997457392307457.mp4[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6999997457392307457.mp4 | Selected 10 frames[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=3[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 08:39:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white table, there is a white plate with strawberries on it. A person is holding a strawberry with their left hand, and holding a knife above the strawberry with their right hand. After saying 'Welcome back to episode 5 of my healthy snack series,' what happens to the strawberry?
A. The strawberry is cut into small pieces
B. The strawberry is cut in half
C. The strawberry is covered in yellow powder
D. Blueberry sauce is added to the strawberry
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   1%|‚ñè         | 2/150 [00:03<04:21,  1.76s/it][32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mld0TnA2jEs.mp4[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mld0TnA2jEs.mp4[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mld0TnA2jEs.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=4[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a long-haired girl wearing a white top is sitting on the ground, holding a blue wrapped gift. After the subtitle says 'I hope he doesn't mind,' what does she do?
A. She puts the gift under the bed.
B. She puts the gift into the cabinet.
C. She puts the gift into a courier box.
D. She puts the gift into the car's trunk.
E. She puts the gift into a paper bag.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=5[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a red short-sleeve shirt is sitting on a sofa with his hands folded. There is a laptop on the left side of the sofa and a pillow on the right side. Behind the sofa is an open kitchen with brown cabinets. When the subtitle 'a very desirable property now let's talk' appears, what objects are present in this scene?
A. a black thread
B. an umbrella
C. a potted plant
D. a watch
E. a necklace
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:   2%|‚ñè         | 3/150 [00:06<05:23,  2.20s/it][32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mYotOV3Q51g.mp4[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mYotOV3Q51g.mp4[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mYotOV3Q51g.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=6[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:39:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a canyon, the walls on both sides are covered with green plants. There is a small stream below, with several stones on the left side and a golden-haired person on the right. In front of the camera is a man wearing a red headscarf and holding a black backpack. When the subtitle 'gonna weather proof my stuff like this' appears, what action does this man take?
A. Pats the black backpack
B. Raises his thumb
C. Opens the backpack
D. Puts down the backpack
E. Take off the headscarf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Sy2unO22PUE.mp4[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Sy2unO22PUE.mp4[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Sy2unO22PUE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=7[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen, a man wearing a mask and short sleeves is serving coffee to two seated people. The woman on the left is wearing a denim jacket, and the man on the right is wearing a red short-sleeved shirt and a hat. What did the woman on the left do the first time she appeared?
A. Shaking hands
B. Hugging
C. Raising her phone
D. Lying down
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:   3%|‚ñé         | 4/150 [00:09<05:43,  2.35s/it][32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bqQTWdk1DAM.mp4[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bqQTWdk1DAM.mp4[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bqQTWdk1DAM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=8[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A cartoon character is standing at the end of a corridor in a room. The cartoon character is wearing a green uniform, a green hat, and black shoes. The corridor has doors on both sides arranged in an orderly manner. When the subtitle 'around a corner he was suddenly within' appears, what change occurs in the posture of this character in the green uniform?
A. From standing to leaning back
B. From standing to kneeling
C. From standing to bending over
D. From standing to crawling
E. From standing to lying on the side
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zVudr8cxHRE.mp4[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zVudr8cxHRE.mp4[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zVudr8cxHRE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=9[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A short-haired man wearing a blue shirt is standing on the street, with a pocket on each side of the chest of the blue shirt. Behind the man is a commercial street with duty-free shops and restaurants. What is the first food the man eats after entering the restaurant?
A. fried noodles
B. steamed bread
C. soup dumplings
D. canned chive dumplings
E. fritters
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:   3%|‚ñé         | 5/150 [00:12<06:19,  2.62s/it][32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7268771669123042562.mp4[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7268771669123042562.mp4[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7268771669123042562.mp4 | Selected 12 frames[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=10[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 08:39:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the amusement park at night, there is a woman standing with her hair covered, holding a camera. Behind her, there is an amusement facility with yellow lights. What color clothes is the woman holding the camera wearing?
A. blue
B. pink
C. white
D. green
E. purple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:   4%|‚ñç         | 6/150 [00:13<05:13,  2.18s/it][32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mkqgTAe2_O4.mp4[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mkqgTAe2_O4.mp4[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mkqgTAe2_O4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=12[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are two men in a room. The man on the left is wearing a yellow shirt, a hat backwards, and a watch on his left hand. The man on the right is wearing a shirt with red flowers and green leaves and has a bracelet on his left hand. When the subtitle mentions "interested enough to join us but first," what change happens to the man wearing the shirt with red flowers and green leaves?
A. He takes off his bracelet
B. He changes into a black short-sleeved shirt
C. He changes into a white long-sleeved shirt
D. He changes into a black jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7262938043315686664.mp4[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7262938043315686664.mp4[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7262938043315686664.mp4 | Selected 15 frames[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=11[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 08:39:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a classroom with many wooden desks and chairs, there is a woman wearing a black dress and has black hair standing. The woman is surrounded by many children. With which of the following subtitles did the woman in the black dress appear together?
A. "the truth of the matter. Call on your friend and sneak into the teacher's house. The three have"
B. "against the wall."
C. "living room"
D. "The three of them had to hide behind the sofa."
E. "Unexpectedly, a few people even entered the room, discovering the previous teacher leaning"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2edlqFUTDVc.mp4[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2edlqFUTDVc.mp4[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2edlqFUTDVc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=13[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the distance of the battlefield is a broken white building, with an archway on the left side of the building. A soldier wearing a green uniform and helmet is shooting, while another soldier without a helmet is wounded and leaning in the corner. There is a rifle to the left side of the wounded soldier. What objects are present in this scene?
A. Doctor in a white coat
B. Military green aircraft
C. White horse
D. Broken iron pillar
E. Stacked lumber
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   5%|‚ñç         | 7/150 [00:16<05:32,  2.33s/it][32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ysRFFN5nzqE.mp4[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ysRFFN5nzqE.mp4[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ysRFFN5nzqE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=14[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue and white sky, in front of a short house backdrop, on the far right side stand two figures wearing olive-colored clothes and belts, one of whom is holding a scythe. Which of the figures on the grass in the bottom left corner is simultaneously opening a scroll?
A. Two small figures wearing black helmets
B. Two small figures wearing white helmets
C. Two small figures wearing green helmets
D. Two small figures wearing black helmets
E. Two small figures wearing yellow helmets
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jJGbXCCU5yc.mp4[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jJGbXCCU5yc.mp4[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jJGbXCCU5yc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=15[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x43cb2900] mmco: unref short failure
[32m2025-11-28 08:39:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a rectangular wooden board hanging on a wall, a woman with long black hair, wearing a black leather jacket, is sitting in front of a table with a water cup and a flat panel. What is the color of the water cup on the table when the subtitle says 'to Melissa miracle calm and I'll see you'?
A. yellow
B. white
C. blue
D. black
E. red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   5%|‚ñå         | 8/150 [00:19<05:52,  2.48s/it][32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = L-XGTMusZvc.mp4[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/L-XGTMusZvc.mp4[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: L-XGTMusZvc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=16[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the Google logo, there is a white box below it, and text continuously appears in it. What is the complete text that appears in the white box?
A. lucky
B. google flights
C. google flight
D. google search
E. search
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rwL_XPw46zQ.mp4[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rwL_XPw46zQ.mp4[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rwL_XPw46zQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=17[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the gray background, there is a paragraph made up of black and white English words in the middle. There are four circular white icons on the top and bottom of the screen respectively. What happens after the subtitle 'close air support force, the 8th Air Corps' appears?
A. Explosion occurs around the ship
B. Explosion occurs on the ground
C. Fighter jet is hit by artillery
D. Fighter jet crashes into the sea
E. Personnel on the tank are injured by explosion
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   6%|‚ñå         | 9/150 [00:21<05:44,  2.44s/it][32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = n24n_20Kwe4.mp4[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/n24n_20Kwe4.mp4[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: n24n_20Kwe4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=18[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan. Then, a section of a gun appears with a hand holding a handgun and shooting at the section. Finally, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun.
B. First, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan. Then, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Finally, a section of a gun appears with a hand holding a handgun and shooting at the section.
C. First, a section of a gun appears with a hand holding a handgun and shooting at the section. Then, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Finally, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan.
D. First, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Then, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan. Finally, a section of a gun appears with a hand holding a handgun and shooting at the section.
E. First, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Then, a section of a gun appears with a hand holding a handgun and shooting at the section. Finally, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7326709884102216965.mp4[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7326709884102216965.mp4[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7326709884102216965.mp4 | Selected 6 frames[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=19[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-28 08:39:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a half-open brown door, some flowers painted on the white wall, and a girl standing in the doorway. She has two ponytails and is wearing a red inner clothing with a purple fur coat. When the subtitle 'appeared she must have been hiding when' appears, what happens to the girl?
A. Holds a doll and smiles at the camera
B. Holds a doll and shows a fearful expression
C. Holds a pillow and squats down
D. Holds a doll and squats down
E. Looks at a kitten nearby
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   7%|‚ñã         | 10/150 [00:24<05:49,  2.50s/it][32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6THwql5c6w.mp4[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6THwql5c6w.mp4[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6THwql5c6w.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=20[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a black-haired woman wearing a backless yellow floral dress with her back to the camera, facing a white curtain. What other objects are present in this scene?
A. life preserver
B. green bedspread
C. dinghy
D. sailboat
E. cradle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9WjElCiDpzM.mp4[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9WjElCiDpzM.mp4[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9WjElCiDpzM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=21[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the top of the screen, there are three flags, with the American flag in the middle. A person in a black suit is speaking in front of a microphone in the center. After the captions mention 'punching domo in toner mau 9 term,' what appears on the screen?
A. Stars
B. Sun
C. Moon
D. A piece of white paper
E. Satellite map
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   7%|‚ñã         | 11/150 [00:26<05:40,  2.45s/it][32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z6Hx_BAZeUw.mp4[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z6Hx_BAZeUw.mp4[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z6Hx_BAZeUw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=22[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, the braided-haired woman holding a book opens it to a page where the left side shows a long branch with some people on it, and the right side is blue. Then, the dark-skinned woman on the white sofa lifts a book with the cover marked 'EXTRA YARN'. Finally, the dark-skinned woman on the white sofa holds a colored pencil in each hand.
B. First, the dark-skinned woman on the white sofa holds a colored pencil in each hand. Then, she lifts a book with the cover marked 'EXTRA YARN'. Lastly, the braided-haired woman holds a book, opens it to a page where the left side shows a long branch with some people on it, and the right side is blue.
C. First, a dark-skinned woman sitting on a white sofa lifts a book with the cover marked 'EXTRA YARN'. Then, a woman with braided hair holding a book opens to a page with a long branch on the left side with some people on it. The right side of the page is blue. Finally, the dark-skinned woman on the white sofa holds a colored pencil in each hand.
D. First, a dark-skinned woman sitting on a white sofa lifts a book with the cover marked 'EXTRA YARN'. Then, the same woman on the white sofa holds a colored pencil in each hand. Lastly, the braided-haired woman holds a book, opens it, and the left page shows a long branch with some people on it, while the right page is blue.
E. First, the braided-haired woman holding a book opens it to a page where the left side shows a long branch with some people on it, and the right side is blue. Then, the dark-skinned woman on the white sofa holds a colored pencil in each hand. Lastly, the dark-skinned woman on the white sofa lifts a book with the cover marked 'EXTRA YARN'.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fZBC3nmvJb8.mp4[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fZBC3nmvJb8.mp4[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fZBC3nmvJb8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=23[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a white PPT background with the title 'Exceptions to the Octet Rule'. Below the title, the content 'XeF4' is displayed. There is a pink frame underneath, and to the right, there is a figure composed of green and pink elements with black letters inside. On the left, there is a split screen showing two women. In the split screen, a woman with black straight hair, wearing a denim jacket, is speaking. After she clasps her hands, what action does this woman take?
A. The woman takes out a notebook
B. The woman starts making a phone call
C. The woman raises a cup
D. The woman picks up a pen
E. The woman spreads her hands open
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   8%|‚ñä         | 12/150 [00:28<05:37,  2.45s/it][32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZfapKqwklG4.mp4[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZfapKqwklG4.mp4[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZfapKqwklG4.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=24[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:39:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the phrase 'forbidden instead they were welcome to' was mentioned, what action did the man in the red and purple striped clothes do in the old, broken room?
A. Got up from the bed and ran
B. Ate
C. Covered his ears with both hands
D. Picked up a cup and drank water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   9%|‚ñä         | 13/150 [00:30<04:59,  2.18s/it][32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7309241426028596523.mp4[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7309241426028596523.mp4[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7309241426028596523.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=26[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a black drawing board in the screen, there is a white design. In the distance, a plastic box filled with items is placed on the desk. In the lower right corner, a hand is holding a drawing pen and adjusting a color palette. What object is sliding down at this moment?
A. black canvas
B. white pigment
C. drawing pen
D. color palette
E. easel
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _7sd4fjnmvc.mp4[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_7sd4fjnmvc.mp4[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _7sd4fjnmvc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=25[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the dark night, there is an old man wearing a hat, one hand holding a flickering candle, one hand on the door, and watching a man and a woman. In which scenes has the old man in the hat appeared?
A. A crowded street
B. Sitting in a room with a glowing light bulb
C. Lying in a room with a flickering candle
D. Sitting in a room with a flickering candle
E. Sitting in a carriage
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lN3WnXMaE0o.mp4[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lN3WnXMaE0o.mp4[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lN3WnXMaE0o.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=27[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow table, there is a yellow cutting board with a piece of chicken breast on it. A person wearing a glove on the left hand has the left hand placed on the chicken breast, while holding a knife with the right hand on the chicken breast. When mentioning 'Only these ingredients and my family loves it,' what is this person doing?
A. This person is frying chicken breast
B. This person is frying a steak
C. This person is cutting chicken breast
D. This person is washing chicken breast
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   9%|‚ñâ         | 14/150 [00:34<05:56,  2.62s/it][32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = cc0T2vtuJtc.mp4[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/cc0T2vtuJtc.mp4[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: cc0T2vtuJtc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=28[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the right side of the screen, there are three soldiers holding shield banners with olive patterns, armed with spears and swords. On the left side, there is a person dressed in red clothes with black hair. What object first appeared on the screen after the subtitle 'creating a ruckus that echoed throughout' appeared?
A. A person with yellow hair holding a waterskin
B. Three soldiers with green shield banners and white-haired with long swords
C. A person dressed in a red robe with black hair
D. Three baskets
E. A soldier holding a red shield banner wearing a helmet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z-1lgAXOEc8.mp4[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z-1lgAXOEc8.mp4[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z-1lgAXOEc8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=29[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a white plate in the middle of the screen with food on it, and a hand wearing a black glove is placed above the food. When the subtitle mentions 'I'd be happy to improve my channel!', what other object can be seen on the screen?
A. spoon
B. pot
C. red seasoning
D. fork
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  10%|‚ñà         | 15/150 [00:36<05:55,  2.63s/it][32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bXRuqcmTIuk.mp4[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bXRuqcmTIuk.mp4[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bXRuqcmTIuk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=30[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a blonde woman wearing a black tank top and a man with curly hair wearing a black T-shirt. They are talking in front of a mirror, with a black column and a thick tree behind them. There are also two white cars parked by the roadside. In which scene does the woman in the gold tank top appear?
A. On the stairs in front of a red building with black handrails.
B. On the stairs in front of a red building with white handrails.
C. On the stairs in front of a red building with gray handrails.
D. On the stairs in front of a red building with yellow handrails.
E. On the stairs in front of a red building with orange handrails.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = athabNMGceo.mp4[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/athabNMGceo.mp4[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: athabNMGceo.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=31[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a long-haired woman in a black long-sleeved dress is sitting by a desk, with a short-haired man in a black long-sleeved shirt standing beside her. There is a laptop on the desk. Behind them, there is a white door, and two paintings are hanging on the right side. On the desk, which subtitles have appeared together with the laptop?
A. At night, Joe and Maric who are still unaware of what is going on, sneak into the school
B. After the visit, the two decide to take a rest and clean themselves up. The tension
C. Back at the bar, Chucky who also went to Evergreen with Joe is closing his own research
D. Here we learn that young Joe had a bit of enemies because he was a bully
E. The two try looking up the school on the internet but the website is inaccessible
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  11%|‚ñà         | 16/150 [00:39<06:13,  2.79s/it][32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sWfcgeDth_w.mp4[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sWfcgeDth_w.mp4[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sWfcgeDth_w.mp4 | Selected 9 frames[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=32[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 08:39:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[h264 @ 0x430c5940] mmco: unref short failure
[h264 @ 0x430c5940] mmco: unref short failure
[32m2025-11-28 08:39:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The scene shows a lady sitting in a yellow flower field looking ahead, with a mountain peak in the distance. Yellow flowers bloom on a hillside. The lady has brown hair and is wearing a long-sleeved outfit. When 'Not the least of which, is' is mentioned, what object is not present in the scene?
A. Snowy mountain
B. Green long-sleeved outfit
C. Blue sky
D. Brown long-sleeved outfit
E. Yellow flowers of yellow flower clusters
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  11%|‚ñà‚ñè        | 17/150 [00:41<05:12,  2.35s/it][32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dE5iWeCVpGI.mp4[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dE5iWeCVpGI.mp4[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dE5iWeCVpGI.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=34[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, a man wearing black-framed glasses and a white short-sleeve shirt with a small bird pattern is explaining. Which of the following animals evolved hindgut fermentation?
A. Ostrich
B. Rabbit
C. Kangaroo
D. Whale
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSeq-nVSY_E.mp4[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSeq-nVSY_E.mp4[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSeq-nVSY_E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=33[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a black stage, there are many black frames; behind the frames, people are standing, while in front of the frames, someone is performing. There is a woman dressed in a red suspenders with black leggings. What is she doing when the subtitle 'I know that there is a leader for us the' appears?
A. Kneeling on one knee with both hands on the ground
B. Standing and singing, with her right hand raised
C. On both knees with both hands on the ground
D. On both knees with one hand on the ground
E. Kneeling on one knee with both arms open
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  12%|‚ñà‚ñè        | 18/150 [00:43<05:12,  2.36s/it][32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAcbasjxljY.mp4[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAcbasjxljY.mp4[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAcbasjxljY.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=36[0m
[32m2025-11-28 08:39:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white background PPT, the top left corner has the black English text '1st Pass: Contrastive Loss'. Which captions appear at the same time as the blue background icon with English text 'image Encoder' inside the dashed box in the middle of the screen?
A. 'you're going to get a very low value for'
B. 'you turn on the cross attention switch'
C. 'and when they're like further apart'
D. 'going to get a very high value for pi'
E. 'pi and then what you're going to do is'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LlqsCCa6y58.mp4[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LlqsCCa6y58.mp4[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LlqsCCa6y58.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=35[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene where the words 'wanna make a meaningful connection' in white English letters are written at the top left corner, there is a man with long curly hair standing in the room, wearing a black outfit with a white heart pattern. What is this man doing?
A. Dancing
B. Playing on a computer
C. Listening to music
D. Watching TV
E. Looking at a phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  13%|‚ñà‚ñé        | 19/150 [00:46<05:12,  2.38s/it][32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5zbV24vyO44.mp4[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5zbV24vyO44.mp4[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5zbV24vyO44.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=38[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black and white scene, a person is bending over, with a white skull next to them. In the distance, there are many mounds of earth. When the subtitle mentions "American modernism her art reflects the diverse Landscapes of her homes from Wisconsin to New York", what does this person do?
A. Grabs a handful of sand
B. Picks up the skull from the ground
C. Dusts off the ash from their body
D. Picks up clothes from the ground
E. Raises their hand to block the wind and sand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7194857776877817094.mp4[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7194857776877817094.mp4[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7194857776877817094.mp4 | Selected 7 frames[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=37[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-28 08:39:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the person, in a room with green plants, holding chopsticks and picking up food from the round plate on the table in front, and then putting it into their mouth?
A. A black-haired woman wearing a black top
B. A black-haired man wearing a white top
C. A black-haired woman wearing a white top
D. A white-haired woman wearing a black top
E. A black-haired woman wearing a purple top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7275653401025826050.mp4[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7275653401025826050.mp4[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7275653401025826050.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=39[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:39:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner of the screen, there's a frame with a blue background wall, and on the wall, there are black clothes and a bag hanging, along with a man with short black hair. After this man says 'by a thousand samples of the test set,' what does he do next?
A. Touches the brain with a hand
B. One hand extends with the index finger pointing upwards
C. Both hands extend with index fingers pointing upwards
D. Both hands spread outwards
E. One hand touches the forehead
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:39:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  13%|‚ñà‚ñé        | 20/150 [00:48<05:22,  2.48s/it][32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eJr-y6UXnRE.mp4[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eJr-y6UXnRE.mp4[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eJr-y6UXnRE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=40[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:39:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a sunny outdoor setting, a fire truck stands nearby along with a firefighter whose skin is dark. In which of the following scenes has this dark-skinned firefighter appeared before?
A. In front of a burning house
B. Inside a garbage truck loaded with trash
C. Outside a forest on fire
D. In a rainy park
E. On a golden sandy beach
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = crmV4OduHYA.mp4[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/crmV4OduHYA.mp4[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: crmV4OduHYA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=41[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the color of the first piece of clothing shown in the video?
A. white
B. purple
C. red
D. olive
E. black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  14%|‚ñà‚ñç        | 21/150 [00:51<05:40,  2.64s/it][32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UN3ICsfqKEY.mp4[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UN3ICsfqKEY.mp4[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UN3ICsfqKEY.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=42[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some people are sitting face-to-face at a long table outdoors, wearing name tags around their necks and smiling at each other. What happened earlier in the video?
A. A woman in a brick-red suit jacket is sitting and talking in front of a camera.
B. In the upper right corner of the screen, a man in a red short-sleeve shirt is explaining the PPT shown on the screen.
C. A man in a black shirt and a woman in a white coat with a grey inner lining are sitting in front of a camera, with the woman lifting her legs.
D. In the upper right corner of the screen, a man in a red short-sleeve shirt is pointing to a picture on the screen.
E. A man in a black shirt and a woman in a white coat with a grey inner lining are sitting in front of a mural and having a conversation.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hg2Q_O5b9w4.mp4[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hg2Q_O5b9w4.mp4[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hg2Q_O5b9w4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=43[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
White clouds drift in the blue sky. A long-haired girl, wearing a red short-sleeve shirt and a reversed baseball cap, falls onto the ground. Beside her is a skateboard. What items are present in this scene?
A. A gray baseball cap
B. A black baseball cap
C. A gray short-sleeve shirt
D. A green skateboard
E. A red baseball cap
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  15%|‚ñà‚ñç        | 22/150 [00:54<05:39,  2.65s/it][32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tdA5atpqaAc.mp4[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tdA5atpqaAc.mp4[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tdA5atpqaAc.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=44[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:40:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top-right corner of the brown cutting board, there are several pieces of already-cut meat. On the left side of the cutting board, there is uncut meat on a metal plate. In the middle of the screen, a person is holding a pair of tongs. What is this person doing?
A. Placing the tongs on the cutting board
B. Placing the meat from the metal plate onto the cutting board
C. Using the tongs to grab vegetables
D. Placing the cut meat from the cutting board onto the metal plate
E. Putting the tongs into a bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  15%|‚ñà‚ñå        | 23/150 [00:55<04:49,  2.28s/it][32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PCPQToF10IM.mp4[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PCPQToF10IM.mp4[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PCPQToF10IM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=46[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT slide with a white background, there is a group of words enclosed in a rounded rectangle at the bottom. In the middle, there is a doodle composed of letters in blue parentheses, blue, and green. What change occurs to the doodle when the subtitle 'that if I put in this representation' appears?
A. Moved to the far left
B. Entirely turned black
C. Covered by a yellow overlay
D. Moved to the far right
E. Enlarged
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aoxy2e7j9Bc.mp4[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aoxy2e7j9Bc.mp4[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aoxy2e7j9Bc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=45[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man outdoors wearing a black hat and dressed in black clothes has his hands in his pockets, looking at a child in front of him wearing a jacket. After the subtitle mentions 'fixed during their Journey with Odo', who is the character that appears in the video?
A. A child with black hair wearing a jacket
B. A bald man wearing a green coat
C. A woman wearing a yellow headscarf and green coat
D. A man with an afro wearing black clothes
E. A woman with blonde hair sitting in a wheelchair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  16%|‚ñà‚ñå        | 24/150 [00:58<05:06,  2.43s/it][32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7359951777845775648.mp4[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7359951777845775648.mp4[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7359951777845775648.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=48[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the forest with green trees and grass on both sides, there is a clear stream in the middle, and above the stream, there is a bridge with a white railing. What object can be seen on the screen at this moment?
A. child
B. puppy
C. bird
D. goldfish
E. rock
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TlaX2iIYZD4.mp4[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TlaX2iIYZD4.mp4[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TlaX2iIYZD4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=47[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a line of English text at the top of the PPT in the video, with some chemical formulas written below it. On the right side, there are two women in video frames. The woman in the lower right is sitting in front of a mirror with her head down, while the woman in the upper right with long black straight hair is wearing a black and white checkered coat and a dark red inner garment, facing the mirror. When the subtitle 'one and it‚Äòs not of that I what I want' appears, what is the color of the chair that the woman in the lower right is sitting on?
A. Black
B. Off-white
C. Yellow
D. Olive
E. Green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WaiGdRYD36k.mp4[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WaiGdRYD36k.mp4[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WaiGdRYD36k.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=49[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the first item placed in the shopping cart in the video?
A. A box of blueberries
B. A net of tangerines
C. A bag of carrots
D. A bag of nuts
E. A box of cherry tomatoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  17%|‚ñà‚ñã        | 25/150 [01:03<06:22,  3.06s/it][32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yXXhrMqfMlk.mp4[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yXXhrMqfMlk.mp4[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yXXhrMqfMlk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=50[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen is a long-haired woman wearing a checkered coat over a black shirt, and there is a bright lamp on the wall behind her. When the subtitle mentions 'strategically on how to get the job done,' what object appears on the wall?
A. A pendant lamp
B. A potted plant
C. A painting
D. A mobile phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SO3czkzeFjw.mp4[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SO3czkzeFjw.mp4[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SO3czkzeFjw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=51[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dimly lit room, a man wearing a duckbill hat and colorful clothes is reaching out with both hands, with 'TRAVELWITHMAX.ORG' written above his head. When the subtitle mentions 'that should have all the information you', what object is present in this scene?
A. a pair of headphones
B. a decorative lamp emitting white light
C. a decorative lamp emitting purple light
D. a bracelet
E. a decorative lamp emitting red light
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  17%|‚ñà‚ñã        | 26/150 [01:05<06:06,  2.96s/it][32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mkqgTAe2_O4.mp4[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mkqgTAe2_O4.mp4[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mkqgTAe2_O4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=52[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of events is correct?
A. First, the video shows a boy in a blue shirt crossing over a tree trunk in a forest. Then, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing a book bag, walks up the stairs. Finally, in a bedroom, a book bag placed on the bed is shown being zipped up. The boy then wears the book bag and walks out of the room.
B. First, a book bag placed on the bed in a bedroom is shown being zipped up. Then, a boy puts on the book bag and walks out of the room. Next, the video shows a room with yellow and white walls with a staircase inside it. The boy, still wearing the book bag, walks up the stairs. Finally, the video shows a boy in a blue shirt crossing over a tree trunk in a forest.
C. First, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing a book bag, walks up the stairs. Then, the video shows a book bag placed on the bed in a bedroom being zipped up. The boy then wears the book bag and walks out of the room. Finally, the video shows a boy in a blue shirt crossing over a tree trunk in a forest.
D. First, the video shows a boy in a blue shirt crossing over a tree trunk in a forest. Then, the video shows a book bag placed on the bed in a bedroom being zipped up. The boy then wears the book bag and walks out of the room. Finally, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing the book bag, walks up the stairs.
E. First, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing a book bag, walks up the stairs. Then, the video shows a boy in a blue shirt crossing over a tree trunk in a forest. Finally, in a bedroom, the video shows a book bag placed on the bed being zipped up. The boy then wears the book bag and walks out of the room.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Dkm35G5kkcc.mp4[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Dkm35G5kkcc.mp4[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Dkm35G5kkcc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=53[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman, dressed as ordinary people, are holding shovels and digging soil. The man is wearing a hat, and the woman is wearing a headscarf. There are two soldiers in blue uniforms with black hats holding guns nearby. In the distance, there are some green plants. What is present in this scene?
A. A photographer wearing a hat
B. Skirts
C. Advancing cannons
D. NP-News-Programers
E. Various colored horses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  18%|‚ñà‚ñä        | 27/150 [01:08<05:44,  2.80s/it][32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kLuqCtnKr_8.mp4[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kLuqCtnKr_8.mp4[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kLuqCtnKr_8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=54[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face. Next, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Finally, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping.
B. First, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping. Next, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face. Finally, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine.
C. First, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping. Next, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Finally, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face.
D. First, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Then, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping. Finally, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face.
E. First, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Next, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face. Finally, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pGEF7Tme3Tk.mp4[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pGEF7Tme3Tk.mp4[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pGEF7Tme3Tk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=55[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a mountain lush with greenery and overlooking a vast blue ocean, a girl dressed in a black suspenders and donning golden long hair smiles slightly at the mirror, what does she do next?
A. Faces the mirror, bends at the waist, and laughs heartily
B. Turns her back to the mirror and faces the ocean
C. Turns her back to the mirror and extends both arms
D. Faces the mirror and extends both hands
E. Faces the mirror and extends one hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  19%|‚ñà‚ñä        | 28/150 [01:10<05:28,  2.69s/it][32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CGngv8vTQOs.mp4[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CGngv8vTQOs.mp4[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CGngv8vTQOs.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=56[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the white cabinet, there is a man with short hair and wearing a black short-sleeved shirt. He is holding a chickpea in his left hand with both hands raised. When he appears alongside the subtitle 'pork ragu or i‚Äôm gonna do some romesco,' what changes occur to him?
A. The chickpea in his hand turns into pork.
B. The chickpea in his hand turns into an egg.
C. The chickpea in his hand turns into a glass of milk.
D. The chickpea in his hand turns into a bluebonnet.
E. The chickpea in his hand turns into a kitchen knife.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7324761016909188358.mp4[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7324761016909188358.mp4[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7324761016909188358.mp4 | Selected 5 frames[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=57[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the sky, there is a blue beam of light in the distance, green grass below, deep blue waters, and a gray rocket flying upwards, with blue flames shooting out below it. On either side of the rocket are red-topped cylinders. What are the cylinders doing?
A. Breaking into pieces
B. Flying out to the right
C. Emitting blue flames
D. Spinning downwards
E. Flying out to the left
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  19%|‚ñà‚ñâ        | 29/150 [01:13<05:26,  2.70s/it][32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jdbG9gmg_SA.mp4[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jdbG9gmg_SA.mp4[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jdbG9gmg_SA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=58[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman wearing a yellow coat with a ponytail. She is holding a mobile phone in her right hand and raises it to her ear. Which object does not appear in the video?
A. Yellow coat
B. Ring
C. Swimming pool
D. Mobile phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UMFy3keSk-s.mp4[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UMFy3keSk-s.mp4[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UMFy3keSk-s.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=59[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x435cbec0] mmco: unref short failure
[32m2025-11-28 08:40:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, it's near dusk with many people raising their hands and cheering wildly; then, it's in sunny weather with many people queuing; lastly, it's in the evening with many people camping.
B. First, it's in the evening with many people camping; then, it's near dusk with many people raising their hands and cheering wildly; lastly, it's in sunny weather with many people queuing.
C. First, it's in the evening with many people camping; then, it's in sunny weather with many people queuing; lastly, it's near dusk with many people raising their hands and cheering wildly.
D. First, it's in sunny weather with many people queuing; then, it's in the evening with many people camping; lastly, it's near dusk with many people raising their hands and cheering wildly.
E. First, it's in sunny weather with many people queuing; then, it's near dusk with many people raising their hands and cheering wildly; lastly, it's in the evening with many people camping.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  20%|‚ñà‚ñà        | 30/150 [01:16<05:41,  2.84s/it][32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dCscvoOX2as.mp4[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dCscvoOX2as.mp4[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dCscvoOX2as.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=60[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white walls, there is a brown wardrobe and a black television. A man in a pink short-sleeve shirt is sitting in the room. Which objects are present in the room with white walls?
A. A blue hat
B. A blue curtain
C. A black chair
D. A black and grey backpack
E. A white bed
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = V0h7rJShw0g.mp4[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/V0h7rJShw0g.mp4[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: V0h7rJShw0g.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=61[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:40:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a small car, a woman sitting in the driver's seat wearing a pink fleece jacket with her left hand fully opened upwards, what is she doing?
A. She turns her head to wave at a pedestrian
B. She turns her head to look at the rearview mirror
C. She looks at the mirror and is talking
D. She closes her eyes to rest
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qjY9kmveQAk.mp4[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qjY9kmveQAk.mp4[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qjY9kmveQAk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=63[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the evening, when the lights of distant buildings are bright, a man with short hair, wearing a black shirt, stands outside. On his chest, there's a white inscription 'ALLAS SEA POOL'. Who is the first person that appears behind this man after this scene?
A. A man wearing a black long-sleeved shirt and black shorts
B. A man wearing black long pants with no shirt
C. A man wearing black shorts with no shirt
D. A man wearing white shorts with no shirt
E. A man wearing a khaki short-sleeved shirt and black shorts
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  21%|‚ñà‚ñà        | 31/150 [01:20<05:59,  3.02s/it][32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = FnKDgC9aNu0.mp4[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/FnKDgC9aNu0.mp4[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: FnKDgC9aNu0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=62[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a train, a person wearing a green military uniform and a green face mask is making a phone call. What other items appear on this train?
A. Biscuit
B. Flower
C. Gun
D. Piano
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2zZSMnGLGao.mp4[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2zZSMnGLGao.mp4[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2zZSMnGLGao.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=65[0m
[32m2025-11-28 08:40:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, three men are sitting. In the top right corner of the screen, there is a square picture. When the subtitle 'doomed doomed attempt ah they don't know' appears, what objects are present on the screen?
A. A blue shirt
B. A red arrow
C. A purple backpack
D. A black chair
E. A white short sleeve
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  21%|‚ñà‚ñà‚ñè       | 32/150 [01:22<05:41,  2.90s/it][32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 22iOyzE8Ec0.mp4[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/22iOyzE8Ec0.mp4[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 22iOyzE8Ec0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=64[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a green plant in the background, a woman with long hair draped over her shoulders is holding a yellow book with a square cover featuring cartoon characters. What is this woman doing?
A. Throwing the book into the trash can
B. Turning the back of the book towards the camera
C. Picking up another book with a blue cover
D. Watering the plant
E. Holding the book facing the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pJI5ZU6wxqg.mp4[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pJI5ZU6wxqg.mp4[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pJI5ZU6wxqg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=67[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a purple background, there is a man with long black hair standing. He is clasping his hands together in front of him. In the upper right corner of the screen, there are bold subtitles in white and blue. What action does he take afterwards?
A. He tilts his head and supports his cheek with one hand.
B. He squats down to tie his shoelaces.
C. He bends down to pick something up.
D. He spreads his hands open, palms facing outward.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 33/150 [01:25<05:34,  2.86s/it][32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kbRtl58u_kk.mp4[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kbRtl58u_kk.mp4[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kbRtl58u_kk.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=66[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:40:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a rotating fan hanging. When the screen displays white subtitles saying 'i watch all ur vedeo', what is a short-haired man wearing a green short-sleeved shirt doing?
A. He is preparing to change clothes.
B. He is preparing to turn off the fan.
C. He is touching his own hair.
D. He is looking at the electric fan.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  23%|‚ñà‚ñà‚ñé       | 34/150 [01:26<04:28,  2.31s/it][32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WmrwQMFZLqI.mp4[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WmrwQMFZLqI.mp4[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WmrwQMFZLqI.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=68[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, floodwaters are surging, and some vehicles are driving through the water. A woman with long hair, wearing a red jacket and a white undershirt, is holding an umbrella. Beside her is a young boy in a blue short-sleeved shirt and a cyclist in a blue raincoat. After the woman and the young boy brush past the cyclist in the blue raincoat, what happens?
A. A tall man is carrying a young girl
B. Two women are holding an umbrella, walking forward in the water
C. An elderly person is being carried by a rescue team member
D. A rescue dog appears
E. A woman wearing a red hat is moving forward in the water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7MemY9jOmuk.mp4[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7MemY9jOmuk.mp4[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7MemY9jOmuk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=69[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a person wearing a black apron with the word 'TASTY' on it. They are wearing a ring on their left hand which is resting on a dough. There is a wooden board on the table. What is the shape of the dough in the video?
A. Square
B. Oval
C. Round
D. Triangular
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  23%|‚ñà‚ñà‚ñé       | 35/150 [01:28<04:25,  2.31s/it][32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ysRFFN5nzqE.mp4[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ysRFFN5nzqE.mp4[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ysRFFN5nzqE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=70[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left, there is a topless man covering his head, while behind him stands a uniformed armed personnel wearing a mask. On the right, there is a woman sitting on a black sofa, dressed in black and white striped clothing. In which subtitles does the topless man appear?
A. in
B. the two Mexican uh criminal groups at
C. moment
D. between cartel and
E. where we have a set of policies across
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OUeE8nCKWGA.mp4[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OUeE8nCKWGA.mp4[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OUeE8nCKWGA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=71[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the rightmost side of the white screen, from top to bottom, there are two person frames. The top one is a black-haired woman sitting in front of a desk, and the bottom one is a woman wearing glasses. When the subtitle says 'get a little bit technical which you,' what type of clothing is the woman wearing glasses at the bottom wearing?
A. T-shirt
B. Leather jacket
C. Sweater
D. Swimsuit
E. Suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  24%|‚ñà‚ñà‚ñç       | 36/150 [01:31<04:32,  2.39s/it][32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = akoJDx23QWU.mp4[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/akoJDx23QWU.mp4[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: akoJDx23QWU.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=72[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:40:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman are sitting in front of a red background. The man has black hair and is wearing black clothes, while the woman has brown hair and is wearing off-white clothes. In front of them is a long black table with some items on it. When the camera zooms in and the man raises one of his arms, what change happens to the woman next to him?
A. An 'omg' icon appears on the woman's face
B. A bowtie icon appears on the woman's face
C. A sad face icon appears on the woman's face
D. A small cat icon appears on the woman's face
E. A smiley face icon appears on the woman's face
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  25%|‚ñà‚ñà‚ñç       | 37/150 [01:32<04:02,  2.15s/it][32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = BtaVRhoLpC0.mp4[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/BtaVRhoLpC0.mp4[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: BtaVRhoLpC0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=74[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white background, there is a man with short hair wearing a short-sleeved T-shirt, sitting in front of a mirror. What is he doing at this moment?
A. Raised both hands upwards
B. Shaking head
C. Stood up
D. Crying
E. Hands clasped together
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XJ6REZOXsvM.mp4[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XJ6REZOXsvM.mp4[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XJ6REZOXsvM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=73[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a building, there is a person wearing a white shirt and a black suit jacket. There are many microphones in front of this person. What is this person doing?
A. This person is taking a walk
B. This person is answering reporters' questions
C. This person is eating
D. This person is chatting with friends
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  25%|‚ñà‚ñà‚ñå       | 38/150 [01:35<04:19,  2.31s/it][32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gURB1JwPfJw.mp4[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gURB1JwPfJw.mp4[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gURB1JwPfJw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=76[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with slightly dim lighting, there stands a woman with long hair, wearing blue clothes. She is looking at a square screen in front of her and is touching the screen with her hand. On the screen, there is a man. Not far from them, there is a lit lamp. What is the color of the man's clothes on the screen?
A. white
B. yellow
C. purple
D. olive
E. pink
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = j7kxn5CsHnw.mp4[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/j7kxn5CsHnw.mp4[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: j7kxn5CsHnw.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=75[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:40:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white background PPT, there's a black English question at the top. In the middle of the screen, there's one black arrow and three blue arrows. At the bottom, there are chemical element symbols written inside a black lined border. In the lower right corner, within a circular frame, there's a video screen of a long-haired woman wearing a white coat with black inner clothing. What is this woman doing when the subtitle 'that's a good thing you get it now yeah' appears?
A. Yawning
B. Raising both hands and smiling with thumbs up
C. Resting her face on one hand
D. Making a peace sign at the camera
E. Tucking her hair behind her ear
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  26%|‚ñà‚ñà‚ñå       | 39/150 [01:38<04:19,  2.34s/it][32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7318074908645264645.mp4[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7318074908645264645.mp4[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7318074908645264645.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=78[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A silver plate was placed on the wooden table, which contained some nuts and fragments of pastries like buns. A hand was holding a red wooden spoon picking up some pastry fragments. What subtitles appeared along with this red wooden spoon?
A. Meat buns were once popular in the USA and the UK
B. The situation in the UK is the same
C. They ultimately lost green onions
D. Sharing some information about meat buns
E. Music
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -iCLYpeghJs.mp4[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-iCLYpeghJs.mp4[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -iCLYpeghJs.mp4 | Selected 12 frames[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=77[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 08:40:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A light-colored building is located on the left side of the screen, with exquisite carvings on its walls. At the entrance at the front of the building, a red UNIQLO sign is hanging. The entrance area is surrounded by a crowd of pedestrians. After the camera finishes filming the entrance of UNIQLO, what does it film next?
A. It films the scene inside the UNIQLO store.
B. It films the art museum next door.
C. It films the library next door.
D. It films the hotel next door.
E. It films the restaurant next door.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 40/150 [01:39<03:37,  1.98s/it][32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7203120578537049386.mp4[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7203120578537049386.mp4[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7203120578537049386.mp4 | Selected 6 frames[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=80[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-28 08:40:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white tiled wallpaper with icy and sweet candy circles, there are two men standing side by side, one wearing short sleeves and the other holding a remote control wearing long sleeves. When the phrase 'tlicking topping motion is that how you' is mentioned, how are their clothes described?
A. The man on the left is wearing light red short sleeves, and the man on the right is wearing a white long sleeve.
B. The man on the right is wearing light yellow short sleeves, and the man on the left is wearing a black long sleeve.
C. The man on the right is wearing light red short sleeves, and the man on the left is wearing a black long sleeve.
D. The man on the left is wearing light red short sleeves, and the man on the right is wearing a black long sleeve.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Uy_o-WCq2Cc.mp4[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Uy_o-WCq2Cc.mp4[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Uy_o-WCq2Cc.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=79[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences in the video is correct?
A. First, flipping the menu on a wooden table in a dining room, then showing a phone to a mirror in a car, and finally showing a black shopping bag to a mirror in a shopping mall.
B. First, showing a black shopping bag to a mirror in a shopping mall, then showing a phone to a mirror in a car, and finally flipping the menu on a wooden table in a dining room.
C. First, showing a phone to a mirror in a car, then showing a black shopping bag to a mirror in a shopping mall, and finally flipping the menu on a wooden table in a dining room.
D. First, flipping the menu on a wooden table in a dining room, then showing a black shopping bag to a mirror in a shopping mall, and finally showing a phone to a mirror in a car.
E. First, showing a phone to a mirror in a car, then flipping the menu on a wooden table in a dining room, and finally showing a black shopping bag to a mirror in a shopping mall.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 41/150 [01:40<03:00,  1.66s/it][32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d8H7hgQY9ew.mp4[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d8H7hgQY9ew.mp4[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d8H7hgQY9ew.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=82[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The scene shows a very large space with gray-white walls and gray tiles on the floor. There are a few people standing by the wall and four long tables on the ground. A woman in black clothing is sitting in front of one of the tables. In which other scene does this woman appear?
A. In a place with all white walls and gray tiles on the floor, with a piece of paper on the table
B. In front of a table in a spacious square
C. In a square
D. In a forest
E. In a seat in a movie theater
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zda-T6wrEhs.mp4[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zda-T6wrEhs.mp4[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zda-T6wrEhs.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=81[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a news scene, a woman with short hair wearing red clothes and a black inner shirt with earrings is smiling. Behind her, there's a large screen displaying the letters 'cna' and a red triangular line, along with some red and black characters. When the ticker below her scrolls to 'Australia's energy giants to face annual earnings slump on bleak,' what event occurred?
A. She shook hands with another man
B. She put on glasses
C. She nodded
D. She stood up from her chair
E. She hugged a man next to her
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 42/150 [01:43<03:41,  2.05s/it][32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7254803496900267266.mp4[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7254803496900267266.mp4[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7254803496900267266.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=84[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:40:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the woman, who is wearing half-rimmed glasses, a white coat, and light blue jeans, doing in the vegetable-filled garden in the video?
A. Crossing both hands
B. Using one hand to stroke her hair
C. Holding her hair with both hands
D. Placing one hand on her knee
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0rWA-p4p5IM.mp4[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0rWA-p4p5IM.mp4[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0rWA-p4p5IM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=83[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a car with black seats, there are four people sitting in a row. One of them is a man wearing a black shirt. He rests his right hand on the shoulder of the woman next to him. When the subtitle 'She didn't want to harm the flowers of her country' appears, what hairstyle does the man in the black shirt have?
A. Short hair
B. Pigtails
C. Long hair
D. Bald
E. Shoulder-length curls
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  29%|‚ñà‚ñà‚ñä       | 43/150 [01:44<03:24,  1.91s/it][32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vpKtHB8x0js.mp4[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vpKtHB8x0js.mp4[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vpKtHB8x0js.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=86[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white surface, there is a small silver bowl with a piece of cake inside it. A person, whose face is not visible, is using a tool to take the cake out of the bowl. Where does the cake appear?
A. In a teacup
B. In a red bag
C. On a silver plate
D. In a bucket with alcohol
E. On a black plate
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lnCPn8gX3FU.mp4[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lnCPn8gX3FU.mp4[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lnCPn8gX3FU.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=85[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:40:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a restaurant, what is the man wearing a white shirt and a gray patterned jacket doing, standing to the right of a black-haired girl with Liu Hai hairstyle in white clothes?
A. Hugging the girl
B. Pulling the girl next to him and looking at her
C. Pinching the girl's cheek
D. Kissing
E. Touching the girl's head
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAcbasjxljY.mp4[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAcbasjxljY.mp4[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAcbasjxljY.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=87[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Before the subtitle says, 'she quickly hides inside a dead tree with James. The latter wants her to return to,' what does the woman in a blue top do?
A. She is swimming in the water
B. She assists a person in walking
C. She is combing her hair
D. She wakes up a man lying on the ground
E. She is applying lipstick
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:40:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  29%|‚ñà‚ñà‚ñâ       | 44/150 [01:47<03:49,  2.17s/it][32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yqejTvYILlA.mp4[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yqejTvYILlA.mp4[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yqejTvYILlA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=88[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:40:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with walls covered in pictures and a world map hanging, what is a man wearing a white beard and a gray shirt doing?
A. Holding a rabbit
B. Holding a squirrel
C. Holding a sheep
D. Holding a small dog
E. Holding a cat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lzAESaVqix0.mp4[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lzAESaVqix0.mp4[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lzAESaVqix0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=89[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Outside the window where there is a shelf, in the distance, there are many people sitting and eating. Nearby, from left to right, there are a woman with blonde hair, a man wearing a hat and drinking, and a short-haired white man looking into a mirror. After the black man finishes drinking, what action does he perform?
A. Falls to the ground
B. Puts the bottle on the table
C. Stands up
D. Takes out a piece of chewing gum
E. Eats a mouthful of bread
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  30%|‚ñà‚ñà‚ñà       | 45/150 [01:50<04:14,  2.42s/it][32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _hODR1cR9lo.mp4[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_hODR1cR9lo.mp4[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _hODR1cR9lo.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=90[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:41:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[h264 @ 0x4312ed40] mmco: unref short failure
[h264 @ 0x4312ed40] mmco: unref short failure
[32m2025-11-28 08:41:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, there is a woman with yellow hair, wearing a brown coat, a pair of necklaces, and glasses. With which of the following subtitles did she appear together?
A. "I like to wear it when I sleep"
B. "which i am wearing right now and i have"
C. "This style is particularly comfortable to wear"
D. "There are a lot of people who like to wear this"
E. "I really like this style"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  31%|‚ñà‚ñà‚ñà       | 46/150 [01:52<03:48,  2.19s/it][32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7197144530024500485.mp4[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7197144530024500485.mp4[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7197144530024500485.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=92[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:41:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Standing on the left side of a black screen, a man in a red short-sleeved shirt is hit by another man in a red and white striped shirt on the right side of the screen. After being slapped, what did the man in the red short-sleeved shirt do?
A. Fell to the ground
B. Kneeled down on the ground
C. Grabbed someone else
D. Turned around and bent down
E. Jumped up
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JLBsG65WoVU.mp4[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JLBsG65WoVU.mp4[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JLBsG65WoVU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=91[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Where else have we seen the man in black clothes standing indoors beside a large floor-to-ceiling window with a black frame, through which we can see the view of tall buildings outside?
A. Inside the hotel lobby
B. On the street downstairs
C. On the couch in the mall
D. Beside the transparent glass wall on the rooftop under the blue sky
E. Inside the coffee shop
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 47/150 [01:53<03:27,  2.01s/it][32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iJgh2dnudIU.mp4[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iJgh2dnudIU.mp4[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iJgh2dnudIU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=94[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a screen with a white background, there are three headshot photos of people and their information. Below these, there is a headshot photo of one person and their information. On the right side of the screen, there is a male wearing a blue striped shirt. Which object appears on the screen?
A. A round photo of a man wearing a black suit
B. A rectangular photo of a man wearing a black suit
C. A rectangular photo of a man wearing a white shirt
D. A round photo of a man wearing a black shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AHeq99pojLo.mp4[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AHeq99pojLo.mp4[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AHeq99pojLo.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=93[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:41:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Next to a refrigerator covered in many pictures, there is a woman with purple hair wearing a green top. Her hands are open with the palms facing upwards. What items are behind her to the left?
A. Green and gray boards
B. A pot and some knives
C. Tea cup
D. Water faucet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 48/150 [01:55<03:33,  2.09s/it][32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7267884432420277506.mp4[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7267884432420277506.mp4[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7267884432420277506.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=96[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top left corner of the black background, there is a picture where many people are sitting together. In the middle of the black background, a man wearing an orange shirt makes a 'Yay' hand gesture. What action did the man do after that?
A. Touched his nose
B. Put his hands on his head
C. Touched his ear
D. Clasped his hands together
E. Crossed his hands in front of his chest
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8Qe03WDCrB4.mp4[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8Qe03WDCrB4.mp4[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8Qe03WDCrB4.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=95[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:41:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a group of people, young and old, male and female, gathered in front of a building watching a performance on a stage. What object exists in this scene?
A. Basketball
B. Olive
C. Soccer ball
D. Ping pong ball
E. Balloon
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JhlzvoqKOc8.mp4[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JhlzvoqKOc8.mp4[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JhlzvoqKOc8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=97[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with the white text 'to partner in the firm', there is a man wearing a blue shirt who is resting his hand on the shoulder of another man beside him. What kind of beard does the man in the blue shirt have?
A. Mountain goat beard
B. Connected beard
C. Eight-character beard
D. One-character beard
E. Shaving beard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 49/150 [01:58<03:49,  2.28s/it][32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = M7YSCIkUaNw.mp4[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/M7YSCIkUaNw.mp4[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: M7YSCIkUaNw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=98[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two people are standing on a grass field. On the far left is a man wearing a denim jacket, and on the far right is a blonde woman in a white top. When the subtitles say 'As the days pass, the group forgets all their miseries and has the best time of their lives,' what action does this woman perform?
A. She picks up a gun
B. She picks up a shield
C. She picks up a flower
D. She picks up a dagger
E. She picks up a sword
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HeRS3nwySI8.mp4[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HeRS3nwySI8.mp4[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HeRS3nwySI8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=99[0m
[32m2025-11-28 08:41:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Walking through rows of shelves in a dazzling shop, ahead are humanoid figures with long white beards and plant decorations. The shelves on the right are filled with red and white Christmas toys. After the subtitle 'really happy' appears, what item appears on the screen?
A. A burning white candle
B. A little girl
C. A courier paper box
D. Santa Claus mug
E. Two books
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 50/150 [02:00<03:45,  2.26s/it][32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7184160724715883781.mp4[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7184160724715883781.mp4[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7184160724715883781.mp4 | Selected 6 frames[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=100[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-28 08:41:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall, on a golden iron frame, what is happening on the screen when a transparent light bulb appears for the first time?
A. Disassembling the table lamp
B. Turning on the table lamp
C. Repairing the table lamp
D. Assembling the table lamp
E. Cleaning the table lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 51/150 [02:02<03:18,  2.00s/it][32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eDso3zHFxL8.mp4[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eDso3zHFxL8.mp4[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eDso3zHFxL8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=102[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the context of the setting, how many human figures are subtly visible? In front of the mirror is a man wearing a green outfit and sporting short curly hair. What does the man do the first time he appears?
A. Smokes a cigarette
B. Takes out a phone
C. Waves at the mirror
D. Eats a piece of bread
E. Drinks a glass of water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F2OhCCEIOcU.mp4[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F2OhCCEIOcU.mp4[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F2OhCCEIOcU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=101[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The individual on the screen is a man wearing a black hat and a white T-shirt. To his right, there is a photo that shows the back silhouette of a person looking at a sculpture. On the left side, there is also a yellow building. What is the man in the screen doing?
A. Raising both hands and facing away from a mirror while talking
B. Raising both hands and looking up while talking
C. Raising both hands and nodding while talking
D. Raising both hands and looking down while talking
E. Raising both hands and facing a mirror while talking
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 52/150 [02:04<03:28,  2.13s/it][32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Sn7JPKbG6tY.mp4[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Sn7JPKbG6tY.mp4[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Sn7JPKbG6tY.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=104[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, many people are sitting on the grass. On the screen, there is a man with blonde hair wearing a necklace and an overcoat with a white inner layer, sitting cross-legged on the ground. In which other scene does the man wearing the white inner layer appear in the video?
A. Inside a room
B. At the seaside
C. Inside a cargo truck
D. In a milk tea shop
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iDFDxwPTjeU.mp4[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iDFDxwPTjeU.mp4[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iDFDxwPTjeU.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=103[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:41:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, sunlight passes through the window and shines in. The room is decorated with many green plants. There is also a shelf containing books and other items. A woman is holding a makeup item. What shape are the glasses the woman is wearing?
A. Triangle
B. Irregular round shape
C. Square
D. Circle
E. Stair-shaped
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 53/150 [02:07<03:46,  2.33s/it][32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SO3czkzeFjw.mp4[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SO3czkzeFjw.mp4[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SO3czkzeFjw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=106[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the beginning of the video, a calendar and a hand-drawn booklet appear. With which subtitle did they appear together?
A. the key
B. do you know
C. say you want
D. which is a very big adulting thing that
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7321010343067618592.mp4[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7321010343067618592.mp4[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7321010343067618592.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=105[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, on a sunny road, a boy in black clothes holding a skateboard opens the door of a house and walks out. Next, a man in white clothes opens a door inside a building with many doors and walks out. Finally, a boy wearing a purple shirt with yellow floral patterns is sitting in a room full of items, explaining in front of a mirror.
B. First, on a sunny road, a boy in black clothes holding a skateboard opens the door of a house and walks out. Next, a boy wearing a purple shirt with yellow floral patterns is sitting in a room full of items, explaining in front of a mirror. Finally, a man in white clothes opens a door inside a building with many doors and walks out.
C. First, a boy wearing a purple shirt with yellow floral patterns is sitting in a room full of items, explaining in front of a mirror. Next, on a sunny road, a boy in black clothes holding a skateboard opens the door of a house and walks out. Finally, a man in white clothes opens a door inside a building with many doors and walks out.
D. First, a man in white clothes opens a door inside a building with many doors and walks out. Next, on a sunny road, a boy in black clothes holding a skateboard opens the door of a house and walks out. Finally, a boy wearing a purple shirt with yellow floral patterns is sitting in a room full of items, explaining in front of a mirror.
E. First, a man in white clothes opens a door inside a building with many doors and walks out. Next, a boy wearing a purple shirt with yellow floral patterns is sitting in a room full of items, explaining in front of a mirror. Finally, on a sunny road, a boy in black clothes holding a skateboard opens the door of a house and walks out.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 54/150 [02:10<03:55,  2.46s/it][32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d-GKQeu4S6M.mp4[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d-GKQeu4S6M.mp4[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d-GKQeu4S6M.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=108[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which object appears first in the video?
A. A bag of chips
B. Transparent glass cup
C. Transparent glass bowl
D. Black and white cat
E. Toaster
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1D9TgBrW6Sw.mp4[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1D9TgBrW6Sw.mp4[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1D9TgBrW6Sw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=107[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top right corner of the video, there are two minimized screens with women. On a white background, there are four formulas. After the subtitle 'so check next thing we look at is just' appears, what does the woman in the top right corner wearing a gray short sleeve and glasses do?
A. Takes off her glasses
B. Supports her face with one hand
C. Stretches her waist
D. Holds her glasses with one hand
E. One hand grabs a handful of hair, the other hand touches her head
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 55/150 [02:13<04:03,  2.56s/it][32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7275485247351901442.mp4[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7275485247351901442.mp4[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7275485247351901442.mp4 | Selected 9 frames[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=110[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 08:41:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the screen, there is a man wearing black clothes and a black hat talking to a man wearing a gray coat. On the left side, there is a man wearing a windbreaker. In the video, which subtitle appears along with the man wearing a black hat?
A. (SINGING) Don't settle for some of the taste some of the time
B. of the most influential bands of all time
C. heart disease, and birth defects including
D. I know every inch of the 707.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UO_6TQnnOxM.mp4[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UO_6TQnnOxM.mp4[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UO_6TQnnOxM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=109[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a building, a man wearing a green coat throws a punch towards a man in black clothes. The man in black dodges, and when the man in the green coat and the subtitle 'Accidentally, the eldest brother‚Äôs punch shattered everything about the sixth sibling.' appear simultaneously, what change occurs to him?
A. He takes off his outer coat.
B. He falls to the ground.
C. He holds his arm with his hand.
D. He looks to the side as he moves past.
E. He raises both hands above his head.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 56/150 [02:14<03:17,  2.10s/it][32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _qepWb_NVj4.mp4[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_qepWb_NVj4.mp4[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _qepWb_NVj4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=112[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows two black men sitting and performing music and singing under the lights. The man towards the left-back is wearing an olive-colored suit, while the man on the right is holding a wooden guitar and wearing a blue patterned robe and singing into a microphone. In the top-right corner of the screen, there is a small video of a black man wearing a white shirt with a blue collar. What is the hairstyle of the man holding the guitar?
A. Long blonde hair
B. Short blonde hair
C. Black cornrows
D. Black afro
E. Short curly hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eJr-y6UXnRE.mp4[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eJr-y6UXnRE.mp4[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eJr-y6UXnRE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=111[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are several blocks on the screen, including a red block, a green block, and a purple block. The other blocks are light green. What change occurs to these blocks when the phrase 'Antarctica but ask a person from South' is mentioned?
A. The blocks turn orange, blue, pink, and red
B. The blocks turn red and green
C. The blocks turn yellow, pink, purple, and blue
D. All blocks turn light green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 57/150 [02:17<03:40,  2.37s/it][32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ixAU3l0sX_o.mp4[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ixAU3l0sX_o.mp4[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ixAU3l0sX_o.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=114[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:41:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On screen, a short-haired woman puts her entire right hand into her mouth. There are many people behind her, including a man wearing a striped shirt sitting in the background. What color clothing is this woman wearing?
A. Blue
B. Red
C. White
D. Black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 58/150 [02:19<03:26,  2.25s/it][32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mB7NW91REF4.mp4[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mB7NW91REF4.mp4[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mB7NW91REF4.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=116[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the first food item displayed in the video?
A. Avocado
B. Beverage with ice cubes
C. Watermelon
D. Apple
E. Potato chips
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TFbGLEZ4qt0.mp4[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TFbGLEZ4qt0.mp4[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TFbGLEZ4qt0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=113[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, the woman with the long black hair, wearing a scarf and earrings, is about to go out. Where did she go after going out?
A. On a spacious street
B. In a convenience store
C. In a barbecue restaurant
D. In a bar
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 59/150 [02:21<03:16,  2.16s/it][32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hXFfPjytMo0.mp4[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hXFfPjytMo0.mp4[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hXFfPjytMo0.mp4 | Selected 10 frames[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=118[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 08:41:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A lady with long black straight hair is in a white room. She is wearing a white coat and a pink top. To her right is the door of the room, and to her left is a white display shelf with a table lamp, vase, and some pictures on it. She is sitting in front of a table, talking. There is also a bucket with many colored pencils and a bunch of flowers to the left of the table. What action did this lady do?
A. She used a purple colored pencil
B. She moved her hand to the right
C. She got up and opened the room door
D. She picked up the bunch of flowers
E. She got up and walked out of the room
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tdm72-vYxTs.mp4[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tdm72-vYxTs.mp4[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tdm72-vYxTs.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=115[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a grey chair, two people are sitting on a sofa watching a broadcasted news program on TV. On the TV screen, a blond female reporter in a red coat is speaking into a microphone. When the subtitle says 'but after seeing that Terence is being accused of involvement in the murder as well as the media's...', what is the color of the wall behind the TV?
A. red
B. green
C. white
D. blue
E. black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 60/150 [02:22<02:48,  1.87s/it][32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hf4WUOagFAw.mp4[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hf4WUOagFAw.mp4[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hf4WUOagFAw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=120[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is a beige stool with a green bowl on top. The bowl contains yellow food, and there is a silver spoon inside the bowl. What happens after the spoon is placed in the bowl?
A. The spoon stirs around in the bowl
B. The spoon scoops up the food
C. New food is added to the green bowl
D. The green bowl is carried away
E. The spoon hits the green bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eDso3zHFxL8.mp4[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eDso3zHFxL8.mp4[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eDso3zHFxL8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=117[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the golden stage, what was the last action performed by the man wearing a light yellow jacket and white shirt, who stood in front of the mirror, bit his tongue, and gestured with his hands?
A. Made a 'yeah' gesture towards the mirror
B. Put his hand on someone's shoulder
C. Turned his back to the mirror
D. Ran towards the center of the stage
E. Sat on the ground of the stage and stretched his waist
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 61/150 [02:25<03:21,  2.27s/it][32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fsz6bkkIHzQ.mp4[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fsz6bkkIHzQ.mp4[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fsz6bkkIHzQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=122[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a man wearing a black hat and a white t-shirt. To his right, there is an equation written with white characters. The background behind the man is pure black. What is this man doing?
A. The man is holding a photo of a person and talking about it.
B. Spreading both hands open and facing the camera while speaking.
C. Pointing with both hands in the direction of the equation while speaking.
D. Raising both hands and facing the camera while speaking.
E. The man is holding a photo of a person and facing away from the camera.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d5JlCEDlHGE.mp4[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d5JlCEDlHGE.mp4[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d5JlCEDlHGE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=119[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black and white scene featuring a statue of the goddess of liberty, when the subtitle 'They arrived as immigrants, speaking no English at Ellis Island in late 1913' appears, what happens on the screen?
A. The screen gradually becomes clear
B. The camera moves from right to left
C. The camera moves from bottom to top
D. The camera moves from left to right
E. The camera moves from top to bottom
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 62/150 [02:28<03:36,  2.46s/it][32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gJuOMPiixUA.mp4[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gJuOMPiixUA.mp4[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gJuOMPiixUA.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=124[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:41:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, there is a man wearing blue clothes and earphones, and a man wearing a grey suit jacket. In the video, which person turns around and clenches their fist?
A. The man wearing a grey suit
B. The man wearing a grey suit and earphones
C. Both turned around
D. The man wearing blue clothes and earphones
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 63/150 [02:29<02:55,  2.01s/it][32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JLnsWrzV_j4.mp4[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JLnsWrzV_j4.mp4[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JLnsWrzV_j4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=126[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white, square-patterned floor, there is a person with some white hair, wearing a black short-sleeve shirt with red designs. He also has a beard. What is this man doing?
A. Reading a book
B. Fishing
C. Drinking water
D. Playing piano
E. Talking
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mHARxee4EzQ.mp4[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mHARxee4EzQ.mp4[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mHARxee4EzQ.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=121[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:41:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing glasses, puffing on a cigarette, dressed in a grey long-sleeve shirt with rolled-up sleeves, and holding a handful of red feed is feeding a fish with a big mouth. In which of the following places did he appear?
A. On a boat being blown by the wind
B. In a crowded talent show venue
C. On a flying airplane
D. In a quiet park
E. In a boxing ring
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oddHY1vwcjo.mp4[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oddHY1vwcjo.mp4[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oddHY1vwcjo.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=123[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:41:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man with black parted hair, wearing a blue shirt, a black backpack, and a wristwatch is kneeling on the ground, looking troubled at the scattered items on the ground. When the caption 'having an accident that distracts her' appears, what color is the wristwatch worn by this man?
A. Blue
B. Pink
C. Green
D. White
E. Black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 64/150 [02:32<03:10,  2.22s/it][32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1IpgyV9u5nE.mp4[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1IpgyV9u5nE.mp4[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1IpgyV9u5nE.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=128[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:41:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The sky is already late, a man under a dim yellow streetlamp with his right hand slightly clenched is looking at a mirror. What clothes is he wearing?
A. He is wearing a red top
B. He is wearing a red short-sleeved shirt
C. Wearing a light yellow windbreaker
D. Wearing a light yellow top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 65/150 [02:33<02:40,  1.88s/it][32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ro_8-CCORzk.mp4[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ro_8-CCORzk.mp4[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ro_8-CCORzk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=130[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman are standing by the roadside talking. The woman has her brown hair tied up and is wearing a shirt. The man also has brown hair. In the distance, there are buildings, traffic lights, and a road. The image is blurry, and the whole scene is shrouded in darkness. What material is the man's jacket made of?
A. A woolen jacket
B. A mohair jacket
C. A denim jacket
D. A cotton jacket
E. A silk jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -QSAotqKqX8.mp4[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-QSAotqKqX8.mp4[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -QSAotqKqX8.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=125[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the first character to appear on screen?
A. The long-haired man in a black coat
B. The man in a gray coat and blue hat
C. The long-haired woman in a black floral dress
D. The man in a gray coat and black hat
E. The short-haired man in a black coat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = o2F-N42Ufo4.mp4[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/o2F-N42Ufo4.mp4[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: o2F-N42Ufo4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=127[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a woman with black and yellow hair wearing a light blue suit. She has a necklace on and is speaking in front of a mirror, slightly angled. Behind her is a gray-white background wall. When she and a short-haired woman in black clothes are sitting at a small round table talking, with a picture of a building with a light strip on the wall, what change happens to this woman?
A. The woman is fixing her hair.
B. The woman stands up.
C. The woman is shaking hands with the woman in black clothes.
D. The woman is listening with her hands on her knees.
E. The woman sits upright holding a glass of water.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 66/150 [02:35<02:58,  2.13s/it][32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 61SYvhojGvg.mp4[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/61SYvhojGvg.mp4[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 61SYvhojGvg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=132[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scenarios is in the correct sequence?
A. First, a scene of a man in a gray suit with a black and white tie holding a gun is shown, followed by a photo of a person in a black suit with a black and red tie against a white background, and finally a scene of two people sitting and five people standing in a conference room is shown.
B. First, a scene of a man in a gray suit with a black and white tie holding a gun is shown, followed by a scene of two people sitting and five people standing in a conference room, and finally a photo of a person in a black suit with a black and red tie against a white background is shown.
C. First, a scene of two people sitting and five people standing in a conference room is shown, followed by a photo of a person in a black suit with a black and red tie against a white background, and finally a scene of a man in a gray suit with a black and white tie holding a gun is shown.
D. First, a photo of a person in a black suit with a black and red tie against a white background is shown, followed by a scene of two people sitting and five people standing in a conference room, and finally a scene of a man in a gray suit with a black and white tie holding a gun is shown.
E. First, a photo of a person in a black suit with a black and red tie against a white background is shown, followed by a scene of a man in a gray suit with a black and white tie holding a gun, and finally a scene of two people sitting and five people standing in a conference room is shown.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5tN9hyfdkaE.mp4[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5tN9hyfdkaE.mp4[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5tN9hyfdkaE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=129[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the wooden floor, there is a large cannon placed on the left side, tied with a thick rope. In front of it is a wooden wall with windows, and there is a protruding section at the bottom of the wall. Cannonballs are neatly arranged on it. What is the material of the cannonballs?
A. tin
B. copper
C. gold
D. wood
E. iron
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 67/150 [02:38<03:04,  2.23s/it][32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mbcvVYobCXI.mp4[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mbcvVYobCXI.mp4[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mbcvVYobCXI.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=134[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Walking on a street filled with red lanterns, a black-haired man wearing a black coat is speaking to the camera. What hairstyle did he have when the subtitle reads 'celebrated Chinese culture but really to'?
A. Long curly hair
B. Shoulder-length hair
C. Bald
D. Curly hair
E. Crew cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VwZeSoYugZk.mp4[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VwZeSoYugZk.mp4[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VwZeSoYugZk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=131[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a black egg-shaped stone on the left and a white egg-shaped stone on the right, then a pile of seaweed on the beach, and finally, two white egg-shaped stones on the beach.
B. First, two white egg-shaped stones on the beach, then a black egg-shaped stone on the left and a white egg-shaped stone on the right, and finally, a pile of seaweed on the beach.
C. First, a pile of seaweed on the beach, then a black egg-shaped stone on the left and a white egg-shaped stone on the right, and finally, two white egg-shaped stones on the beach.
D. First, two white egg-shaped stones on the beach, then a pile of seaweed on the beach, and finally, a black egg-shaped stone on the left and a white egg-shaped stone on the right.
E. First, a pile of seaweed on the beach, then two white egg-shaped stones on the beach, and finally, a black egg-shaped stone on the left and a white egg-shaped stone on the right.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 68/150 [02:40<03:04,  2.26s/it][32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8905KCkLDYc.mp4[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8905KCkLDYc.mp4[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8905KCkLDYc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=136[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a blue-green sea, there is a boat floating. There are yellow letters in the scene, and some clouds in the distant sky. The green sea is shimmering. When it mentions 'The crater is roughly 30 kilometers in diameter, and would have created a megatsunami,' what color is the roof of the boat in the scene?
A. purple
B. blue
C. orange
D. white
E. yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MPQn_orwpfA.mp4[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MPQn_orwpfA.mp4[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MPQn_orwpfA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=133[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue seawater, there are black rocks. A sea turtle is swimming, and beside it, there is a man wearing black shorts following closely with a light on his body. What objects are present in this scene?
A. Diving mask
B. Cell phone
C. Oxygen tank
D. Wetsuit
E. Net
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 69/150 [02:43<03:12,  2.38s/it][32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7TljSpTBS9c.mp4[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7TljSpTBS9c.mp4[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7TljSpTBS9c.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=138[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A strip of paper is placed on a white background, with three lines of English written on it. To the left of the paper strip, there is a black wheel-shaped object and a purple light. A hand is pointing at the paper strip while explaining something. After explaining the paper strip, what does the owner of the hand do?
A. Take a yellow toy chicken from the corner
B. Take a magazine from a black bag
C. Take a music box from the corner
D. Take a green toy from the corner
E. Take an apple from a black bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 70/150 [02:46<03:20,  2.50s/it][32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tCnelzIAHA0.mp4[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tCnelzIAHA0.mp4[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tCnelzIAHA0.mp4 | Selected 6 frames[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=140[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The floor of the room is brown, there are flags and pictures on the wall. To the right is a bookshelf filled with books. A zoomed out map appears in the top right corner. A man wearing a grey coat is sitting on a black stool. What subtitle appears together with the map in the top right corner?
A. Music
B. Europe Russia China, India and Australia most of these lines actually don't exist. So let's assume
C. 65 to 94
D. We're funding maybe about 75% of all these train lines
E. You know at first glance this picture
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Pm93D8CVlY8.mp4[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Pm93D8CVlY8.mp4[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Pm93D8CVlY8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=135[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A long-haired woman wearing round earrings, a blue top, and black inner wear appears on the screen holding a book. What type of clothing is this woman wearing?
A. Suit
B. Blouse
C. Feather coat
D. Denim jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 71/150 [02:47<02:50,  2.16s/it][32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LKQK0lud4fo.mp4[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LKQK0lud4fo.mp4[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LKQK0lud4fo.mp4 | Selected 10 frames[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=142[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 08:41:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a man, a woman, and a child on the screen. In the top-left corner, there is a yellow 'US' symbol. A red arrow is pointing to the little girl. What is the little girl doing?
A. Closing her eyes
B. Dancing
C. Running forward
D. Crying with her head in her hands
E. Opening her mouth to breathe
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 72/150 [02:48<02:24,  1.85s/it][32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bjymxow3TVQ.mp4[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bjymxow3TVQ.mp4[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bjymxow3TVQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=144[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:41:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:41:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background is a website page with icons of a supermarket, a shopping cart, as well as labels for price and source keywords. A man wearing sunglasses is talking to the microphone. What happened on the screen after the man lowered his right hand?
A. The mouse cursor moved to the English word 'Pranksy' and stopped.
B. The mouse cursor moved to the upper right corner and then stopped.
C. The mouse cursor slid to the number '0.9' and painted over it.
D. The mouse cursor slid to the number '78.88' and painted over it.
E. The mouse cursor moved to the upper left corner and then stopped.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:41:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Msz128EJeWE.mp4[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Msz128EJeWE.mp4[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Msz128EJeWE.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=137[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:41:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a bald man wearing a dark blue shirt and a suit, with a necklace, what did he do the first time he appeared?
A. He placed his hands behind his back
B. He made an X gesture with his hands
C. He placed his hands by his sides
D. He raised his hands above his head
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CdTijM0_es4.mp4[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CdTijM0_es4.mp4[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CdTijM0_es4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=139[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a large control panel, there is a man with short hair and glasses. Under the man's hand is a cream-colored paper. What style of clothing is the man with glasses wearing?
A. Black hooded jacket
B. Pink plaid shirt
C. Blue hooded jacket
D. Black suit
E. White T-shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 73/150 [02:51<02:39,  2.07s/it][32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fq3zbbp-lv4.mp4[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fq3zbbp-lv4.mp4[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fq3zbbp-lv4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=146[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a green meadow, in the distance there are gray mountains. In front of the mountains stands a group of soldiers wearing gray helmets and a group wearing dark blue helmets. In which of the following scenes do the soldiers wearing dark blue helmets appear?
A. In a desert with no vegetation
B. On a snow-covered grassland
C. In a forest during the rain
D. On a plain during a thunderstorm
E. In a scene where soldiers wearing yellow helmets are riding a blackish brown horse
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i327DBSS_iE.mp4[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i327DBSS_iE.mp4[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i327DBSS_iE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=141[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the grove of yellow leaves illuminated by sunlight, there is a woman with a checkered scarf, khaki-colored jacket, and jeans playing with a black Labrador beside her. Which of the following subtitles appeared simultaneously with the sight of this black dog?
A. "define who we are"
B. "slow down and recharge and communicate"
C. "in my case i wanted to be either a"
D. "my life is full of routines and"
E. ‚Äúthat puts me in a nostalgic mood it's‚Äù
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 74/150 [02:53<02:48,  2.22s/it][32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fWNJmZAWRNg.mp4[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fWNJmZAWRNg.mp4[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fWNJmZAWRNg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=148[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows some people pushing shopping carts in the vegetable section of a supermarket. What is the first product to appear on the screen after this?
A. Leek
B. Eraser
C. Cauliflower
D. Carrot
E. Mini Tomatoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7258968758130085146.mp4[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7258968758130085146.mp4[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7258968758130085146.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=143[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wooden platform with three potted plants, there is a person looking down with both legs raised on the table. Who is this person?
A. A woman with brown short hair
B. A woman with brown long hair
C. A woman with black short hair
D. A woman with black long hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 75/150 [02:56<02:52,  2.31s/it][32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7MemY9jOmuk.mp4[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7MemY9jOmuk.mp4[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7MemY9jOmuk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=150[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a woman wearing a white dress. She is standing on a rock, gazing into the distance. In front of her, there is a green lake, and in the distance, there are some orange buildings. After the woman gazes into the distance, what happens next?
A. The woman walks on a stone path surrounded by green plants, between pink and yellow buildings.
B. The woman walks on a stone path surrounded by green plants, between green and black buildings.
C. The woman walks on a stone path surrounded by green plants, between green and yellow buildings.
D. The woman walks on a stone path surrounded by green plants, between blue and yellow buildings.
E. The woman walks on a stone path surrounded by green plants, between green and white buildings.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = e6HwinLBK_Y.mp4[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/e6HwinLBK_Y.mp4[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: e6HwinLBK_Y.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=145[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the radio room scene, there are two soldiers holding a boy in a short-sleeved shirt and black pants against the wall. A man wearing a blue shirt with a pink tie and a blue suit is speaking in the radio room. A pink handkerchief is visible in the man's suit pocket. Which subtitle lines appear together with this man?
A. amplifying local Dynamics um however as
B. and your analysis
C. between cartel and
D. where we have a set of policies across
E. control well I'm joined Now by Vonda
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 76/150 [02:58<02:55,  2.37s/it][32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _kQXNFG664Y.mp4[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_kQXNFG664Y.mp4[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _kQXNFG664Y.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=152[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:42:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a corner of a bedroom, a short-haired woman wearing an olive green tank top is sitting in front of a bed. To the right is a bookshelf filled with books. What color is the bookshelf in the screen?
A. A three-layer pink bookshelf
B. A three-layer blue bookshelf
C. A four-layer red bookshelf
D. A five-layer orange bookshelf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 77/150 [02:59<02:22,  1.96s/it][32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DxxVla1CRvU.mp4[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DxxVla1CRvU.mp4[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DxxVla1CRvU.mp4 | Selected 15 frames[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=154[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the background of the scene, there's a green plant. In the middle, there is a black man who is Kamala Khan's clone. Next to him, there is a woman wearing a white hat. Who is smiling in the scene at this moment?
A. The woman wearing a black hat
B. Kamala Khan's clone
C. The woman wearing a white hat
D. The man wearing a white hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = k4jiEuZbN-4.mp4[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/k4jiEuZbN-4.mp4[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: k4jiEuZbN-4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=147[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of 2 parallel poles, there's a man wearing a police uniform. There are many pedestrians behind him. What is the man in the police uniform doing?
A. He is raising his hands above his head
B. He is bending down to pick something up
C. He is lying on the ground
D. He is putting his hands in front of his chest
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 78/150 [03:01<02:20,  1.95s/it][32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aCPNlZ7bvRc.mp4[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aCPNlZ7bvRc.mp4[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aCPNlZ7bvRc.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=156[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:42:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, in a room, the person in the black and white outfit is talking to a man wearing a hat. Then, the person in the black and white outfit is talking with a lady in black clothes, both having their hands on the table. Finally, a person wearing a black and white outfit with glasses is making a phone call.
B. First, the person in the black and white outfit is talking with a lady in black clothes, both having their hands on the table. Then, a person wearing a black and white outfit with glasses is making a phone call. Finally, in a room, the person in the black and white outfit is talking to a man wearing a hat.
C. First, in a room, the person in the black and white outfit is talking to a man wearing a hat. Then, a person wearing a black and white outfit with glasses is making a phone call. Finally, the person in the black and white outfit is talking with a lady in black clothes, both having their hands on the table.
D. First, a person wearing a black and white outfit with glasses is making a phone call. Then, the person in the black and white outfit is talking with a lady in black clothes, both having their hands on the table. Finally, in a room, the person in the black and white outfit is talking to a man wearing a hat.
E. First, a person wearing a black and white outfit with glasses is making a phone call. Then, in a room, the person in the black and white outfit is talking to a man wearing a hat. Finally, the person in the black and white outfit is talking with a lady in black clothes, both having their hands on the table.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9m4wi5gPdHg.mp4[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9m4wi5gPdHg.mp4[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9m4wi5gPdHg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=149[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a man in the screen wearing a green military uniform, raising his hands. There are guns on both sides of him. Who is being held at gunpoint in the video?
A. Commander Jeremiah Denton
B. Tom
C. Nancy
D. Lhcy
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 79/150 [03:03<02:16,  1.92s/it][32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZsnfXfuGRrg.mp4[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZsnfXfuGRrg.mp4[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZsnfXfuGRrg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=158[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, there stands a person in a black silhouette wearing a hat. After this person opens a safe containing gold and paper money, what does the man, who is in a black silhouette and wearing a hat, do?
A. Took the paper money
B. Danced
C. Drank water
D. Watched TV
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=151[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, a white tank appears in the lower left corner of a red screen with 'Production' written in white at the top. What change occurs to this white tank when it appears in the red screen with many small white figures and white guns at the top?
A. turns black
B. turns blue
C. turns red
D. gets smaller
E. gets bigger
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 80/150 [03:05<02:22,  2.03s/it][32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CdTijM0_es4.mp4[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CdTijM0_es4.mp4[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CdTijM0_es4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=160[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a man with short black hair, wearing black clothes, is holding a gun. He is pointing the gun at another man with short black hair, wearing black clothes with a belt. The question is, in which of the following scenes does this gun appear?
A. In the hand of the man with red hair
B. In the hand of the man with green hair
C. In the hand of the man with white hair
D. In the hand of the man with blue hair
E. In the hand of the man with purple hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rZq-8Bq3mkU.mp4[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rZq-8Bq3mkU.mp4[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rZq-8Bq3mkU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=153[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue sky and white clouds, there is an endless stretch of mountain ranges. In front of the mountain ranges, there are some brown tents with two soldiers standing beside them. The soldiers are wearing gray helmets and holding crescent-shaped shields. In which of the following scenes have soldiers wearing gray helmets appeared?
A. Inside a dense forest
B. In a desert with swirling sandstorms
C. On a high mountain covered with white snow
D. In a scene with an olive tree and numerous arrows flying in the sky
E. On a grassland during rain
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 81/150 [03:08<02:31,  2.19s/it][32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAHsR02dUc0.mp4[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAHsR02dUc0.mp4[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAHsR02dUc0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=162[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a yellow background, a man with short hair, wearing black-framed glasses and dressed in a deep purple hooded sweatshirt. What is he doing when he appears for the first time?
A. Frantically waving hands, speaking towards the camera
B. Raising both hands with palms open
C. Right hand holding the left hand, speaking towards the camera
D. Arms spread wide, speaking towards the camera
E. Left hand holding the right hand, speaking towards the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VL259eBJ68w.mp4[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VL259eBJ68w.mp4[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VL259eBJ68w.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=155[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a black screen, there are ten different colored particle-like objects sprayed on the screen, and at the bottom, there are circles of various colors from 0 to 9. After this, what happened to these different colored objects?
A. These differently colored objects became blurry and rectangular in shape
B. These differently colored objects became blurry and strip-like in shape
C. These differently colored objects became blurry and circular in shape
D. These differently colored objects were assembled together
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 82/150 [03:10<02:29,  2.20s/it][32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -PnG8Jp2gFw.mp4[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-PnG8Jp2gFw.mp4[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -PnG8Jp2gFw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=164[0m
[32m2025-11-28 08:42:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a mustard-yellow wall hangs a television screen, which displays a webpage with black and white images and some document icons. A man with a yellow and black name tag is speaking. He is facing towards the right side of the screen, wearing a military green and black camouflaged uniform with a black and white accessory on the sleeve. What happens when he mentions: 'a gimbal now there's gimbals that stab'?
A. The man opens one hand and clenches the other into a fist
B. The man turns to face the screen
C. The man brushes his hair
D. The man takes a sip of water
E. The man changes his jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 83/150 [03:13<02:32,  2.28s/it][32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qyaQ-wfojbM.mp4[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qyaQ-wfojbM.mp4[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qyaQ-wfojbM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=166[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman in a black dress in the kitchen. Behind her, there is a white cabinet with some items on it and a window with white curtains. The curtains are flanked by wooden shelves. In front of her, there is a large counter with a cast iron pot on it. Above the pot is a large stainless steel bowl which she is holding with both hands. Next to them, there is a large pink container with red liquid inside. What is the woman doing in the kitchen?
A. Turned the large bowl upside down
B. Put a lid on the large bowl
C. Moved the large bowl to the windowsill
D. Placed the large bowl on the counter
E. Put the large bowl on the pink container
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WpbB_swXHkc.mp4[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WpbB_swXHkc.mp4[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WpbB_swXHkc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=157[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the right side of a desk with a building in the background, there are three icons, and next to the icons is a video being recorded. In the video, on a sofa with red flowers embroidered on it, sits a woman wearing earrings and a long-sleeved wine-red garment. With which subtitles does this woman appear together?
A. before the time of the pandemic here
B. crowded men
C. myself
D. really exciting to me to have it all to
E. me to 
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 14ot4DrXdds.mp4[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/14ot4DrXdds.mp4[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 14ot4DrXdds.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=159[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First there is an introduction, then an advertisement, and finally, the woman explains while demonstrating the video
B. First, the woman explains while demonstrating the video, then there is an advertisement, and finally, there is an introduction
C. First there is an introduction, then a woman explains while demonstrating the video, and finally, there is an advertisement
D. First there is an introduction, then an advertisement, and finally, the woman explains while demonstrating the video
E. First, the woman explains while demonstrating the video, then there is the woman's introduction, and finally, there is an advertisement
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 84/150 [03:15<02:30,  2.29s/it][32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7203500499360877829.mp4[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7203500499360877829.mp4[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7203500499360877829.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=168[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:42:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the golden twilight, with industrial zones emitting exhaust fumes into the sky, what happened first after the subtitle 'the water while increased levels of' appeared?
A. Two molecular structures appeared simultaneously on the screen
B. A structure with a black center labeled CO‚ÇÇ, flanked by two red molecular structures, rotated and popped up on the right side of the screen
C. Three molecular structures appeared simultaneously on the screen
D. A structure with a black center labeled CO‚ÇÇ, flanked by two red molecular structures, rotated and popped up on the left side of the screen
E. A structure with a red center labeled CO‚ÇÇ, flanked by two black molecular structures, rotated and popped up on the left side of the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7269746510462536962.mp4[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7269746510462536962.mp4[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7269746510462536962.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=161[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A cat is putting its head on a white cushion. On the wall above the cat, there's a white shelf with some colorful vases on it. When the subtitle 'Thinking of running to get by' appears, what color is the cat's face?
A. Blue and white face
B. All black face
C. All white face
D. Black and white face
E. Blue face
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 85/150 [03:16<02:12,  2.04s/it][32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iJgh2dnudIU.mp4[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iJgh2dnudIU.mp4[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iJgh2dnudIU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=170[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing a green short-sleeved shirt, holding a phone in their right hand, is facing 3 bottles on the table. What is this person holding in their left hand?
A. A can
B. A bun
C. A dumpling
D. Beef
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 86/150 [03:19<02:20,  2.19s/it][32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = duxO1EZ650E.mp4[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/duxO1EZ650E.mp4[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: duxO1EZ650E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=172[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with white text 'I want you to start with that man over there, okay?' there are many people, and in front of a man in a black suit there is a triangular shelf with a basketball on it. What other objects are present in the scene?
A. A doll wearing purple clothes
B. A green plant
C. A yellow incense burner
D. A white chrysanthemum
E. A white dress
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7268167132591000833.mp4[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7268167132591000833.mp4[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7268167132591000833.mp4 | Selected 15 frames[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=163[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two people appear in the room. One person is lying on debris in the corner, while the other person is sitting by the feet of the lying person. There is a can placed inside the room, and behind the sitting man is a fireplace. What did the person lying on the debris do the first time they appeared?
A. Holding the head with both hands
B. Supporting the chin with one hand
C. Using hands to touch the top of the head
D. Crossing arms over the chest
E. Using hand to support the forehead
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 87/150 [03:21<02:18,  2.20s/it][32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MJYBHfYF8LI.mp4[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MJYBHfYF8LI.mp4[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MJYBHfYF8LI.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=174[0m
[32m2025-11-28 08:42:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene where a pair of hands is holding a phone with a black case, there is a text message on the phone containing a string of numbers 558441328. What color is the nail polish on the hands in the scene?
A. green
B. black
C. purple
D. blue
E. red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Jfp1Ks7Hh1E.mp4[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Jfp1Ks7Hh1E.mp4[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Jfp1Ks7Hh1E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=165[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the city streets, there is a white truck in the middle of the screen. In the distance, there is a yellow building, and nearby on the left, a woman in black clothes with short hair is talking to a man on the right who is also wearing black. When the subtitles mention 'you met with investors in Hong Kong and Kuala Lumpur in Singapore who are', what did the man do?
A. opened the car door
B. hugged the woman briefly
C. waved a few times to the woman
D. took out a phone
E. picked up a pair of scissors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 88/150 [03:24<02:27,  2.38s/it][32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bAGhXcYc0o4.mp4[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bAGhXcYc0o4.mp4[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bAGhXcYc0o4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=176[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the person that appears first after the man on the right side of the screen, wearing a black jacket, a gold necklace, and having black middle-parted hair?
A. The man sitting at a desk with a projector and computer in a bedroom with colorful lights, wearing a black hoodie and jeans.
B. The man with middle-parted hair holding a camera, wearing a white hoodie and dark shorts.
C. The woman in the room behind the door, wearing a gray hoodie and glasses, with her hair tied up.
D. The man sitting on a bed with colorful lights in the bedroom, wearing a black short-sleeve shirt and black pants.
E. The man leaning against a yellow wall in the corridor, wearing a gray long-sleeve shirt, black pants, and glasses, with his arms crossed.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AYMdAVxALP4.mp4[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AYMdAVxALP4.mp4[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AYMdAVxALP4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=167[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Beneath the clouds, there are two cliffs covered with patches of green moss. Between them, there's a strange boulder. When mentioning 'There's that weird boulder jammed between two cliffs,' what objects are present on the screen?
A. white arrowhead with black outline
B. pure white arrowhead
C. black arrowhead with white outline
D. pure black arrowhead
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 89/150 [03:26<02:29,  2.46s/it][32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _uL3a3aMdMQ.mp4[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_uL3a3aMdMQ.mp4[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _uL3a3aMdMQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=178[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
How many rectangular yellow metal blocks are on the table? There is a person with purple gloves in the background. When the subtitle mentions "eneficial way is difficult to say the," what changes occur on the table?
A. The number of rectangular yellow metal blocks increased by two
B. The number of rectangular yellow metal blocks increased by one
C. The number of rectangular yellow metal blocks decreased by two
D. The number of rectangular yellow metal blocks decreased by one
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9m4wi5gPdHg.mp4[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9m4wi5gPdHg.mp4[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9m4wi5gPdHg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=169[0m
[32m2025-11-28 08:42:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a white shirt and brown shoes, and another man wearing a black coat and black shoes, both with guns, are standing on a yellow surface near the entrance of a store. After they mutually kill each other, what did the man in the white shirt do?
A. Sing
B. Play the piano
C. Lie down
D. Dance
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lQODAJ_F5yE.mp4[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lQODAJ_F5yE.mp4[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lQODAJ_F5yE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=171[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a green meadow, next to it is a riverside road with many pedestrians walking. On the green meadow, there is a woman with dark skin wearing a white short-sleeve shirt and holding wheat. When she says 'everyone is mixed up with different', what shape is the hair accessory on her head?
A. Bear ears shape
B. Rose shape
C. Butterfly shape
D. Bunny ears shape
E. Feather shape
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 90/150 [03:30<02:43,  2.73s/it][32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bwDfdTh0VYs.mp4[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bwDfdTh0VYs.mp4[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bwDfdTh0VYs.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=180[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow paper, there are three strips of paper with characters written on them. In the top left corner, there is a stationery item with a black head and a colorful body. In the bottom right corner, a woman with long hair is speaking inside a red circular frame. The subtitle appears 'enthalpy stoichiometry and how to use them. So if'. What is on the woman's body?
A. Blue nail polish
B. Black nail polish
C. White outerwear
D. Necklace
E. Black and white striped outerwear
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NpYUxd1vUUE.mp4[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NpYUxd1vUUE.mp4[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NpYUxd1vUUE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=173[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue background PPT, what appears on the screen after mentioning 'look at it and it's like oh yeah they'?
A. A red airplane appears, with two lines of English text below it.
B. A black airplane appears, with two lines of English text below it.
C. A black airplane appears, with two lines of red English text below it.
D. A black airplane appears, with three lines of red English text below it.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 91/150 [03:32<02:33,  2.60s/it][32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Y1YCvEip_ko.mp4[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Y1YCvEip_ko.mp4[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Y1YCvEip_ko.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=182[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, the woman pulls up the curtain. Then, the short-haired blonde woman pulls up the room's curtain. Next, the short-haired blonde woman takes out a letter. Finally, the short-haired blonde woman shakes hands with an elderly man with white hair.
B. First, the short-haired blonde woman pulls up the room's curtain. Then, the short-haired blonde woman takes out a letter. Next, the short-haired blonde woman shakes hands with an elderly man with white hair. Finally, Anne pulls up the curtain.
C. First, Anne pulls up the curtain. Then, the short-haired blonde woman pulls up the room's curtain. Next, the short-haired blonde woman takes out a letter. Finally, the short-haired blonde woman shakes hands with an elderly man with white hair.
D. First, the short-haired blonde woman takes out a letter. Then, the short-haired blonde woman shakes hands with an elderly man with white hair. Next, the short-haired blonde woman pulls up the room's curtain. Finally, Anne pulls up the curtain.
E. First, a short-haired blonde woman shakes hands with an elderly man with white hair. Then, the short-haired blonde woman takes out a letter. Next, the short-haired blonde woman pulls up the room's curtain. Finally, Anne pulls up the curtain.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 51dUUxFOjDE.mp4[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/51dUUxFOjDE.mp4[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 51dUUxFOjDE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=175[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man wearing glasses with a black backpack is outside the airport. He is wearing a yellow hat, a black mask, and a grey hoodie. He is surrounded by white columns and large glass windows. Where else does the man's hat appear?
A. In the taxi
B. On the dining table
C. On the bus
D. In the elevator
E. On the beach
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 92/150 [03:35<02:37,  2.71s/it][32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1R5uPaL0V-0.mp4[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1R5uPaL0V-0.mp4[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1R5uPaL0V-0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=184[0m
[32m2025-11-28 08:42:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into three parts: left, center, and right. The left side is all text, the center is a map, and the right side is a man in black clothing. What did the man do after the map in the center moved?
A. Waved at the camera
B. Put on a coat
C. Stood up
D. Kneeled down
E. Looked up
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=177[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a woman in a pink outfit holding a bun filled with some meat and vegetables. She also has a spoon in her hand with some sauce on it, which she pours onto the bun. The background is blurry, and there is a cute white design on her outfit. In front of the camera, there are some green avocados. What color is the sauce that the woman pours?
A. pink
B. red
C. flesh color
D. yellow
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 93/150 [03:37<02:28,  2.61s/it][32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7094322812327906565.mp4[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7094322812327906565.mp4[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7094322812327906565.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=186[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:42:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a white dining room with a white dining table on which there is a dessert plate. Two hands are holding glasses for a toast. After the subtitle 'Thak you' appears, what happens?
A. Two hands take two pieces of dessert
B. Two people drink the wine in the glasses
C. Two people start drinking tea
D. Two people start eating the dessert
E. One hand takes a piece of dessert
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 94/150 [03:39<02:04,  2.23s/it][32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JLBsG65WoVU.mp4[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JLBsG65WoVU.mp4[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JLBsG65WoVU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=188[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the deep mountains, with overgrown weeds ahead, trees in the distance, a stone at the bottom right corner, and a wooden handrail with a hand wearing a bracelet directly in front, what action does the hand perform when the subtitle 'while do not put too much weight on this' appears?
A. pulls out the handrail
B. shakes the handrail
C. raises the thumb
D. lifts the stone
E. pulls grass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = E7FSg22MdKE.mp4[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/E7FSg22MdKE.mp4[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: E7FSg22MdKE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=179[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a row of neatly arranged green fields on the screen, with differently sized houses with gray roofs on top. Which object appears on the screen below?
A. green tree
B. yellow tree
C. white clouds
D. yellow sun
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 95/150 [03:41<02:06,  2.30s/it][32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7262468242692689194.mp4[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7262468242692689194.mp4[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7262468242692689194.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=190[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dimly lit room, there is a lamp hanging from the ceiling. Below the lamp, there is an olive-colored table, with olive-colored objects placed on it. Behind the table, there is a wall filled with square grids. Below the wall, there are two windows, and behind the windows, there are three seated people. After the subtitle mentions 'think it would be great if we could remember those things', what is the first fruit that appears?
A. Apple
B. Mango
C. Pear
D. Watermelon
E. Banana
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DoizYSYQRqU.mp4[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DoizYSYQRqU.mp4[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DoizYSYQRqU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=181[0m
[32m2025-11-28 08:42:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a wooden table in the video, and on the table there is a wooden board. A pair of hands is using a knife to cut a vegetable that has a yellow outer part and white inner part. What is the vegetable being cut?
A. Turnip
B. Carrot
C. Garlic
D. Leek
E. Onion
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 96/150 [03:44<02:11,  2.44s/it][32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7153617149041446150.mp4[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7153617149041446150.mp4[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7153617149041446150.mp4 | Selected 9 frames[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=192[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 08:42:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a car, a woman wearing a white coat is sitting with her eyes closed. She is holding a cup of coffee in her right hand and a mobile phone in her left hand. What objects are present in this scene?
A. transparent water cup
B. nose ring
C. earring
D. watch
E. earphone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2ekjGl8yWZk.mp4[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2ekjGl8yWZk.mp4[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2ekjGl8yWZk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=183[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a white rectangular bowl on a white table. The bowl contains white cream cheese cubes. A hand is holding a piece of cream cheese. What does the hand do when the white cream cheese first appears?
A. Spread the cream cheese evenly
B. Use a torch to melt the cream cheese
C. Break the cream cheese into pieces
D. Season the cream cheese
E. Take the cream cheese off
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 97/150 [03:45<01:48,  2.04s/it][32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DRIpznER-VQ.mp4[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DRIpznER-VQ.mp4[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DRIpznER-VQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=194[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the white-background PPT, there is text in English by Liu that appears. When the blue arrow first appears above the second line of English text, what happens on the screen?
A. The blue arrow moves from bottom to top.
B. The blue arrow moves from left to right.
C. The blue arrow moves from right to left.
D. The blue arrow moves from top to bottom.
E. The blue arrow enlarges.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z7Cox6lPW3c.mp4[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z7Cox6lPW3c.mp4[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z7Cox6lPW3c.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=185[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:42:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Four people are standing in a row in front of a window: two women are in the middle, and two men are on the outside. The man on the right is wearing a black coat, black-framed glasses, and carrying a backpack. One woman is wearing a gold-black patterned headscarf, and the other woman is in a black and white striped long skirt. The man on the left has a long beard, is resting his arm on the counter, and is dressed in gold-embroidered attire. In which other scenes does the man resting his arm appear?
A. Outside a store window in a high-end mall
B. At a speech venue, holding a mic
C. Outside a plant-filled balcony
D. Flipping through a book on a table
E. On a chair in a library
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:42:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 98/150 [03:47<01:48,  2.09s/it][32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UwJTCg5fpXg.mp4[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UwJTCg5fpXg.mp4[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UwJTCg5fpXg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=196[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:42:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the picture, a woman is sitting on a chair holding two children beside her. Another child is standing behind her. A boy in a black woolen coat and another boy in a blue jacket are visible. The girl is wearing a red woolen coat and a checkered skirt. There is a white glass door in the background and green plants on the side. Who is the child sitting on the armrest of the chair in the picture?
A. The child wearing a red woolen coat
B. The child wearing a blue jacket
C. The child wearing a grey jacket
D. The child wearing a green woolen coat
E. The child wearing a checkered shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 99/150 [03:49<01:41,  2.00s/it][32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VLInjyogciw.mp4[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VLInjyogciw.mp4[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VLInjyogciw.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=198[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing red clothes and a man wearing black clothes are in a video call, and a sentence starting with 'TSMC GETS' is gradually being revealed at the bottom. What kind of hair does the woman in the video call have?
A. She has short blonde hair.
B. She has black hair.
C. She has no hair.
D. She has long blonde hair.
E. She has black bob cut.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kFHVBCEwC3w.mp4[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kFHVBCEwC3w.mp4[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kFHVBCEwC3w.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=187[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:43:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a red wall with a black door. Beside the door, there is a round stone carving with several holes in the middle, seemingly sculpted into human facial features. In front of the stone carving, there is a black-striped pole. At what time did this stone carving and which subtitles appear simultaneously?
A. TRUTH
B. MOUTH OF TRUTH
C. truthfulness albeit with a mnuch lighter
D. EVENING
E. EARLY 
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 100/150 [03:51<01:36,  1.94s/it][32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ytv-9RM4e0o.mp4[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ytv-9RM4e0o.mp4[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ytv-9RM4e0o.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=200[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When sunlight shines on the building wall, an exterior green sign on a Roman building, and some passersby are standing by the poles, which object appears first after the video screen reaches this moment?
A. A man wearing a gray shirt, round glasses, and a baseball cap
B. A man wearing a green short-sleeved shirt and having a plump physique
C. A row of arch-shaped doors
D. A woman wearing a floral short-sleeved shirt and carrying a white single-shoulder bag
E. A golden yellow circular dome
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = h0OHi9uAcBo.mp4[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/h0OHi9uAcBo.mp4[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: h0OHi9uAcBo.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=189[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The woman in the black long-sleeve shirt is seated in front of the computer screen, intently reading a book. What did the woman in the black shirt do afterwards?
A. Put the book under the computer
B. Put the book into the copier
C. Put the book into the drawer
D. Put the book on the bookshelf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ClYmTkGTGYg.mp4[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ClYmTkGTGYg.mp4[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ClYmTkGTGYg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=191[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall, a man wearing a patterned red shirt sits on a black chair. Next to him is a black shelf. When the subtitle 'has been happening my birthday happened' appears, what transformation occurs to the man in the patterned red shirt?
A. The man's shirt changes from red to black.
B. The man's shirt changes from red to yellow.
C. The man's shirt changes from red to green.
D. The man's shirt changes from red to purple.
E. The man's shirt changes from red to white.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 101/150 [03:54<01:54,  2.34s/it][32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kk-iRzLv81o.mp4[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kk-iRzLv81o.mp4[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kk-iRzLv81o.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=202[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a plot of land surrounded by green trees. The land is brown, and there is a person wearing a yellow outfit with a cowboy hat and a mustache who is making a fire. There is also a person wearing white clothes and a gray skirt with a backpack behind him. Which one is carrying a gun?
A. The person wearing white clothes and a gray skirt
B. The person wearing white clothes and a gray skirt without a hat
C. The person wearing white clothes and a gray skirt with a hat
D. The person wearing yellow clothes and a hat making a fire
E. The person wearing white clothes, a gray skirt, and green shoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 102/150 [03:56<01:50,  2.31s/it][32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 51dUUxFOjDE.mp4[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/51dUUxFOjDE.mp4[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 51dUUxFOjDE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=204[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a small garden surrounded by white columns, where the greenery is luxuriant. Three people are in the garden. The person on the right has short hair, the person in the middle is facing a mirror, and the person on the left is wearing a blue coat. What kind of hairstyle does the person wearing a blue coat have?
A. Blond short curly hair
B. Blond bob cut
C. Blond shoulder-length straight hair
D. White long hair
E. Crew cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F8Ma1qs0Rkg.mp4[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F8Ma1qs0Rkg.mp4[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F8Ma1qs0Rkg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=193[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into three parts: left, center, and right. The left side is all text, the center is a map, and the right side is a man in black clothing. After the man waves his hands to greet the camera, what does he do?
A. Put on a hat
B. Coughed
C. Took a sip of water
D. Tidied his clothes
E. Picked up a book
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 103/150 [03:59<01:48,  2.30s/it][32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bwnkg6GbXwU.mp4[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bwnkg6GbXwU.mp4[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bwnkg6GbXwU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=206[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a man wearing a black shirt with white patterns and gloves sitting in the middle of the screen. His hands are open, and there are two lamps lit behind him. In the latter part of the video, what changes on the screen when this man's left palm faces upwards?
A. A book appears in the top right corner
B. A book appears in the top left corner
C. A book appears in the bottom left corner
D. A book appears in the bottom right corner
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1D9TgBrW6Sw.mp4[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1D9TgBrW6Sw.mp4[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1D9TgBrW6Sw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=195[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a screen with a blue border, there is a highway. On the highway, many cars are parked. Two horses of different colors appear on the highway. What did the yellow-brown horse do the first time it appeared?
A. Was hit by a white car
B. Ran against the direction of the traffic flow
C. Crossed the highway
D. Was hit by a black car
E. Ran in the direction of the traffic flow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 104/150 [04:02<01:55,  2.52s/it][32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7254238802577820929.mp4[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7254238802577820929.mp4[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7254238802577820929.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=208[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, the woman wearing white on the left side of the screen is lighting a match, while the woman in red on the right side is holding a cigarette and has a hair clip on her head. During which subtitle does the woman holding the cigarette appear?
A. His teeth were clenched so tightly
B. I'm OK.
C. In fact, Flash forward to March of 1971
D. (SINGING) Don't settle for some of the taste some of the time
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9dSkvxS2EB0.mp4[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9dSkvxS2EB0.mp4[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9dSkvxS2EB0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=197[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Outside a bright window, there is a boy wearing a white shirt and a boy holding a basketball. At the bottom of the screen, there is white text that says 'Tom is really a pair of'. What is the boy in the white shirt doing in the scene?
A. Holding his head and crying
B. Crouching on the boy holding the basketball
C. Fighting with the boy holding the basketball
D. Kneeling on the ground tying his shoelaces
E. Putting his arm around the boy holding the basketball
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 105/150 [04:05<01:56,  2.58s/it][32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RTUFPjliMCU.mp4[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RTUFPjliMCU.mp4[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RTUFPjliMCU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=210[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen with white background and text, the right side is blank, the upper left section contains a circuit diagram, and the text information is located in both the middle left and bottom left sections. When the text information in the middle left and bottom left sections almost disappears, what change occurs to the circuit diagram in the upper left section?
A. Shrinks
B. Covered by a yellow overlay
C. Enlarges
D. Covered by a blue overlay
E. Disappears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = BktEeBeA7a8.mp4[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/BktEeBeA7a8.mp4[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: BktEeBeA7a8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=199[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two women on the screen are explaining a question. In the problem, there is a number crossing a pink bar at the bottom and a slanted line. When the subtitle 'figs but I still would round up so I' appears, what color is the slanted line?
A. Olive Yellow
B. Light Yellow
C. Light Blue
D. Grass Green
E. Ink Green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 106/150 [04:07<01:57,  2.67s/it][32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=212[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a pink fur coat over a white slip dress, with her hair tied in a bun and facing a mirror, is standing in a brightly lit kitchen. When she opens the wooden cabinet in front of her with her right hand, what is the first item she takes out?
A. A coffee machine
B. A glass with a wooden stirrer and a straw inserted
C. A can of coffee
D. Some cutlery
E. A plate of fruit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=201[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a slightly dimly lit room, there is a woman with long hair, wearing a white short-sleeved shirt, sitting on a bed. She is holding a mobile phone. There is a white cabinet behind her, filled with various items. In which of the following scenes has the mobile phone appeared?
A. On a white perforated table
B. On a green perforated table
C. On a yellow perforated table
D. On a blue perforated table
E. On a red perforated table
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 107/150 [04:10<01:57,  2.73s/it][32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7200404243168415022.mp4[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7200404243168415022.mp4[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7200404243168415022.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=214[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:43:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman dressed in an off-shoulder top is sitting on a white sofa, wearing a necklace and a ring. Behind her, there's a black railing and a white wall with a plant on the railing. To her right is the cover of a book, and to her left is a book. What is the woman doing when the subtitle 'colleen hooper you did it again' appears?
A. The woman is holding a pen with one hand.
B. The woman is holding a book with one hand.
C. The woman is holding a book with one hand.
D. The woman is lifting the book above her head.
E. The woman is holding a book with both hands.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = luRqMb5qfhM.mp4[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/luRqMb5qfhM.mp4[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: luRqMb5qfhM.mp4 | Selected 10 frames[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=203[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 08:43:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a white bowl on a wooden grain table, containing white condensed milk. When the condensed milk is placed on a piece of green vegetable and then put on a wooden board, what kind of change occurs?
A. Red bread crumbs are sprinkled on top
B. Red goji berries are sprinkled on top
C. Red dates are sprinkled on top
D. Red goji berries are sprinkled on top
E. Red dried strawberries are sprinkled on top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 108/150 [04:12<01:44,  2.50s/it][32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SH7Unhifaj0.mp4[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SH7Unhifaj0.mp4[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SH7Unhifaj0.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=216[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:43:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are many cucumber slices on the cutting board in the kitchen. A woman wearing a black dress and a gold bracelet is holding a knife. What is she doing?
A. She is peeling the cucumber
B. She is slicing the cucumber
C. She is cleaning the cutting board
D. She is putting the cucumber into a bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=205[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bedroom with red curtains and two different types of green plants on the balcony, what is a woman wearing a red long-sleeve sweater doing?
A. She has her hands on her legs
B. She has her hands raised above her head
C. She has her hands clasped in front of her chest
D. She has her hands at her sides
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 109/150 [04:14<01:33,  2.28s/it][32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NMHmqgO04rU.mp4[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NMHmqgO04rU.mp4[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NMHmqgO04rU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=218[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black background, there are two screens. On the left, there is a white car passing by on a road in front of a construction building. On the right, there are two people conversing on a red carpet stage. What objects are present in this screen?
A. helicopter
B. green stone lion
C. black car
D. traffic light
E. handgun
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2ekjGl8yWZk.mp4[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2ekjGl8yWZk.mp4[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2ekjGl8yWZk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=207[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man in a dark suit is handling food on a cutting board with a knife. He is wearing sunglasses, and behind him are various kitchen utensils and white cabinets. On the right side of the table, there is a bottle with green packaging containing cooking oil. In the lower left and right corners of the screen, there are images of two men from the waist up. When the subtitle 'Sheesh...' appears, what is the lighting on the ceiling like?
A. Round wall lamp
B. Triangular wall lamp
C. Square wall lamp
D. Gold pendant lamp
E. Silver pendant lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 110/150 [04:17<01:38,  2.45s/it][32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSn78eNspwU.mp4[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSn78eNspwU.mp4[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSn78eNspwU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=220[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
During the appearance of the black arrow between the English text on the white background PPT with two lines at the top, what happens on the screen?
A. The arrow moves from top to bottom
B. The arrow moves from right to left
C. The arrow changes from large to small
D. The arrow moves from left to right
E. The arrow changes from small to large
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = duxO1EZ650E.mp4[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/duxO1EZ650E.mp4[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: duxO1EZ650E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=209[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, there is a scene where 'a small snow goose spreads its wings and opens its beak in front of a white snow goose's belly,' followed by 'a few snow geese walking back to the camera on the snowy field,' and finally 'a snowy field with many snow geese arranged in rows, with a tall white cliff in the distance.'
B. First, there is a scene where 'a snowy field with many snow geese arranged in rows, with a tall white cliff in the distance,' followed by 'a few snow geese walking back to the camera on the snowy field,' and finally 'a small snow goose spreads its wings and opens its beak in front of a white snow goose's belly.'
C. First, there is a scene where 'a few snow geese walking back to the camera on the snowy field,' followed by 'a small snow goose spreads its wings and opens its beak in front of a white snow goose's belly,' and finally 'a snowy field with many snow geese arranged in rows, with a tall white cliff in the distance.'
D. First, there is a scene where 'a snowy field with many snow geese arranged in rows, with a tall white cliff in the distance,' followed by 'a small snow goose spreads its wings and opens its beak in front of a white snow goose's belly,' and finally 'a few snow geese walking back to the camera on the snowy field.'
E. First, there is a scene where 'a small snow goose spreads its wings and opens its beak in front of a white snow goose's belly,' followed by 'a snowy field with many snow geese arranged in rows, with a tall white cliff in the distance,' and finally 'a few snow geese walking back to the camera on the snowy field.'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 111/150 [04:20<01:40,  2.59s/it][32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7206809277867052330.mp4[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7206809277867052330.mp4[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7206809277867052330.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=222[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:43:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On an olive-colored marble table, there is a black stove with a pot of boiling water. When the subtitle 'tall white house with an empty room and your name carved over the door Facing up to the tallest hill' appears, what object is present on the screen?
A. White plate
B. Blue flame
C. Scissors
D. Kitchen knife
E. Napkin
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 112/150 [04:21<01:23,  2.19s/it][32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0WEnmqVVbHo.mp4[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0WEnmqVVbHo.mp4[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0WEnmqVVbHo.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=224[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen is a woman wearing glasses and earrings, with books and miscellaneous items on the shelf behind her. On the right side of the screen is a man wearing a black top, with long hair and glasses. What did the man with glasses on the right side of the screen do when he appeared for the first time?
A. Crossed his arms in front of his chest
B. Supported his chin with one hand
C. Placed one hand on the other arm's forearm
D. Held a wristwatch
E. Held his forehead with one hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yFAuXmcGk2Y.mp4[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yFAuXmcGk2Y.mp4[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yFAuXmcGk2Y.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=211[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bright sunlight outside, there are lakes and green trees in the distance. A group of young people were having a picnic on the grass, surrounded by others. In the picture, who is the person being hugged by the girl wearing a white short-sleeved shirt and light blue jeans?
A. The girl wearing a beige long-sleeved outer jacket with a white short-sleeved shirt underneath
B. The man wearing a blue short-sleeved shirt and white shorts
C. The girl wearing a dark green suspender dress with a white short-sleeved shirt underneath
D. The man wearing a light blue long-sleeved outer jacket and beige long pants
E. The man wearing a white short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 113/150 [04:24<01:27,  2.38s/it][32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Lc7RikDaa30.mp4[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Lc7RikDaa30.mp4[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Lc7RikDaa30.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=226[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white background screen, in the middle left is the green letter A, the upper left is the green letter C, and the middle is the green letter B. After a large section of text appears on the left side of the screen, what change happens to letter A?
A. Got covered by a yellow layer
B. Turned red
C. Moved to the right
D. Got enlarged
E. Moved to the left
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = er1oRjH2iu8.mp4[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/er1oRjH2iu8.mp4[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: er1oRjH2iu8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=213[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
With green plants and decorative shelves on the left and right sides of the screen, a man wearing glasses and a yellow suit with a middle part hairstyle is introducing himself with a mirror. Which of the following scenes appears first?
A. A woman sitting in a car holding the steering wheel
B. A screenshot of news about COE
C. A display screen showing toll information on a road in Singapore
D. People walking and cars driving on a road
E. Tightly packed and neatly arranged cars in a parking lot
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 114/150 [04:26<01:24,  2.35s/it][32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = brZugTJ0odg.mp4[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/brZugTJ0odg.mp4[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: brZugTJ0odg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=228[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
During the concert, a man with tattoos and long hair was singing shirtless while holding a microphone. When the subtitles displayed 'We don't want to spend all our time discussing,' what change occurred to the man's upper body?
A. His shirtless body changed into wearing a red suit.
B. His shirtless body changed into wearing a black suit.
C. His tattooed body changed into a shirtless body without tattoos.
D. His shirtless body changed into wearing a white suit.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qbA42wQoWAs.mp4[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qbA42wQoWAs.mp4[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qbA42wQoWAs.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=215[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with all kinds of items, with a yellow floor, there is a woman wearing a blue long-sleeved top pushing a cart. After the subtitle 'The St. Mark's Tower is one of Frank Lloyd Wright's earliest designs for a' appears, what does she do?
A. Walks around the cart in a circle
B. Speaks into the mirror
C. Brushes something on the cart with a small brush
D. Lifts the bottom of the cart
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 115/150 [04:29<01:22,  2.36s/it][32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PzUxuZ-KGsU.mp4[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PzUxuZ-KGsU.mp4[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PzUxuZ-KGsU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=230[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the night-draped airport, four people are experiencing a ride in a vertical lift aircraft. Inside the aircraft, they are wearing earphones and fluorescent-patterned armor. Who among the following is participating?
A. A man with white hair
B. A woman with long hair
C. A child
D. An elderly man with white hair
E. A woman with green hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z00vWImw1KQ.mp4[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z00vWImw1KQ.mp4[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z00vWImw1KQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=217[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the red wooden table, there is an iron grid rack with a glass bowl containing four rolls of food. In the frame, there is a brush covered with yellow liquid decorating them. Which of the following objects did not appear?
A. Light blue brush
B. Red brush
C. Glass bowl with egg liquid
D. Black iron rack
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 116/150 [04:31<01:21,  2.40s/it][32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mfS6gyP0mwo.mp4[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mfS6gyP0mwo.mp4[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mfS6gyP0mwo.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=232[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the street, there is an ambulance with a white and green pattern in the middle. To the left is a soldier wearing camouflage clothing, and in the right seat of the ambulance is a person wearing red clothes. On the right side are onlookers. Which character closed the door of the ambulance?
A. doctor
B. police officer wearing sunglasses
C. person wearing red clothes
D. woman wearing white clothes
E. soldier wearing camouflage clothing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5tN9hyfdkaE.mp4[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5tN9hyfdkaE.mp4[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5tN9hyfdkaE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=219[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the upper right corner of the frame, there is a woman with long hair wearing a purple top, sitting on a black object. The wall behind her is white. At this moment, the camera is facing forward. When the camera turns and the yellow wall on the left is revealed, what change occurs to the object the woman is holding in her left hand?
A. It changes to a calculator
B. It changes to a ruler
C. It changes to a piece of white paper
D. It changes to a circle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 117/150 [04:33<01:18,  2.37s/it][32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = q3FAxTSENEw.mp4[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/q3FAxTSENEw.mp4[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: q3FAxTSENEw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=234[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What color pants is the woman, who is walking away from the camera on a street decorated with red lanterns, wearing when she says in the subtitles 'me to try the viral TikTok Foods in' while wearing a brown top and with long hair?
A. Gray
B. Black
C. Blue
D. White
E. Olive
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = M5YKW6fhlss.mp4[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/M5YKW6fhlss.mp4[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: M5YKW6fhlss.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=221[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which sequence of scenes appearing in the video is correct?
A. A person is in a white background, and the remaining screen shows the word 'Q Learning' first, then '1 step', and finally 'Training'
B. A person is in a white background, and the remaining screen shows the word '1 step' first, then 'Q Learning', and finally 'Training'
C. A person is in a white background, and the remaining screen shows the word 'Q Learning' first, then 'Training', and finally '1 step'
D. A person is in a white background, and the remaining screen shows the word 'Training' first, then 'Q Learning', and finally '1 step'
E. A person is in a white background, and the remaining screen shows the word 'Training' first, then '1 step', and finally 'Q Learning'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 118/150 [04:36<01:15,  2.37s/it][32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = x1FkhxMMIcg.mp4[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/x1FkhxMMIcg.mp4[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: x1FkhxMMIcg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=236[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are a few red photo frames hanging on a wooden wall. A man wearing black-rimmed glasses and a plaid shirt is explaining. To his right, there is a phone that is changing screens. In which scenes has this phone appeared before?
A. Next to an insect wearing a pink coat
B. Next to an insect with a tie
C. In the hands of a woman wearing a black coat in the park
D. In the hands of a man wearing blue pants in the park
E. In the hands of a character without a nose or mouth
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8_MG-E8QlBM.mp4[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8_MG-E8QlBM.mp4[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8_MG-E8QlBM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=223[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, the female host introduces a teacher. Then, the female host connects with the teacher, who talks about the early development of her project. After that, the teacher recounts her own experiences along with those of a little girl and a student. Finally, a female host speaks.
B. First, a male host speaks. Then, the female host connects with the teacher, who talks about the early development of her project. After that, the teacher recounts her own experiences along with those of a little girl and a student. Finally, a female host speaks.
C. First, the female host interacts with the teacher. Then, the female host introduces the teacher, who talks about the early development of her project. After that, the teacher recounts her own experiences along with those of a little girl and a student. Finally, a male host speaks.
D. First, the female host introduces a teacher. Then, the female host connects with the teacher, who talks about the early development of her project. After that, the teacher recounts her own experiences along with those of a little girl and a student. Finally, a male host speaks.
E. First, a male host introduces a teacher. Then, the female host connects with the teacher, who talks about the early development of her project. After that, the teacher recounts her own experiences along with those of a little girl and a student. Finally, a female host speaks.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 119/150 [04:38<01:15,  2.43s/it][32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HvSEKzpSdzw.mp4[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HvSEKzpSdzw.mp4[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HvSEKzpSdzw.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=238[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:43:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a young man wearing a blue uniform, with a white inner layer, and a black wristwatch, is holding a box. What is this young man doing in the room?
A. Reaching into the box
B. Stepping on the box
C. Throwing the box away
D. Cutting the box with a knife
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 120/150 [04:40<01:06,  2.21s/it][32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bqQTWdk1DAM.mp4[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bqQTWdk1DAM.mp4[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bqQTWdk1DAM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=240[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the scorching sun, a few people are standing on the yellow earth outside the home. On the right side of the screen, there is a parked yellow cart. In front of the camera, there are two men. The man on the left is wearing a black top with a distressed expression, while the man on the right is wearing a black and white striped top with rolled-up sleeves and has both hands placed on the man on the left. When the subtitle 'was being comforted by everyone who saw' appears, what is the man on the right doing?
A. Chatting with the man
B. Waving to the camera
C. Comforting the distressed man
D. Distributing food to the needy
E. Wiping the man's tears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jdbG9gmg_SA.mp4[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jdbG9gmg_SA.mp4[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jdbG9gmg_SA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=225[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x4222df00] mmco: unref short failure
[32m2025-11-28 08:43:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a multi-colored shirt is sitting in the outdoor dining area of a restaurant. The man is holding a yellow package in his hand. Next to him are a white basket and green plants. Behind the man, there is an open umbrella and other diners. On the left side of the screen, there are colorful flags and the entrance of a shop. What is the first food the man eats?
A. Apple
B. Pie
C. Mooncake
D. Bread
E. Yogurt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 121/150 [04:43<01:14,  2.57s/it][32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Efuyl2Anehg.mp4[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Efuyl2Anehg.mp4[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Efuyl2Anehg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=242[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x42bce300] mmco: unref short failure
[32m2025-11-28 08:43:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, there's a scene on a flat road with many cars parked on either side; then, a scene with a man dressed in blue sitting in the front passenger seat of a car; finally, a scene where a woman dressed in white is close to a man dressed in blue.
B. First, there's a scene where a woman dressed in white is close to a man dressed in blue; then, a scene on a flat road with many cars parked on either side; finally, a scene with a man dressed in blue sitting in the front passenger seat of a car.
C. First, there's a scene with a man dressed in blue sitting in the front passenger seat of a car; then, a scene on a flat road with many cars parked on either side; finally, a scene where a woman dressed in white is close to a man dressed in blue.
D. First, there's a scene on a flat road with many cars parked on either side; then, a scene where a woman dressed in white is close to a man dressed in blue; finally, a scene with a man dressed in blue sitting in the front passenger seat of a car.
E. First, there's a scene where a woman dressed in white is close to a man dressed in blue; then, a scene with a man dressed in blue sitting in the front passenger seat of a car; finally, a scene on a flat road with many cars parked on either side.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iJk-HMfO4yQ.mp4[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iJk-HMfO4yQ.mp4[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iJk-HMfO4yQ.mp4 | Selected 15 frames[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=227[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 08:43:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a gray coat and sporting short black hair is sitting upright on a cream-colored couch against a cream-colored background, eating from a green-white dessert bowl. What subtitle appeared at the same time as this man?
A. The next morning
B. And it comes with my own Arabic TV.
C. And if you can see, it's written in Arabic.
D. It's a little after 10 and I just made it to Bahrain.
E. You golta buy tulip bulbs.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 122/150 [04:46<01:11,  2.55s/it][32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wxWo44MoCTI.mp4[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wxWo44MoCTI.mp4[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wxWo44MoCTI.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=244[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a white car parked on the road, with trees and a red brick building behind it. Next to the trees, there is a utility pole. An officer in a black and white uniform, wearing glasses and an ID badge, is giving an interview. In front of the officer, there are two communication devices, one white labeled 'LBC' and one black. Who is the first person to pass by behind the officer?
A. A woman wearing a suit
B. A woman wearing black clothes with a hat
C. A man wearing black clothes with a hat
D. A woman wearing a hat and sunglasses
E. An elderly person wearing a hat and sunglasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -An3wZyoYe0.mp4[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-An3wZyoYe0.mp4[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -An3wZyoYe0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=229[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:43:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Once the white mold in the coffee-colored pot appears on a wooden table, what changes occur to the white mold?
A. The mold changes from white to sauce color
B. The mold changes from scattered to cake-like
C. The mold changes from sheet-like to cake-like
D. The mold changes from white to yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:43:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 123/150 [04:48<01:07,  2.51s/it][32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -kaF6SnSEo8.mp4[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-kaF6SnSEo8.mp4[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -kaF6SnSEo8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=246[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:43:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue seawater, there are coral reefs and seashells. On the screen, there is a person wearing a diving suit. When the subtitle 'beaches and plenty of drilling dive' appears, what is this person in the diving suit doing?
A. Diving in the seawater
B. Performing an underwater show
C. Playing with a sea turtle
D. Waving at the camera
E. Catching seafood
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7Q8d8Vvk6oo.mp4[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7Q8d8Vvk6oo.mp4[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7Q8d8Vvk6oo.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=231[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:44:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a man wearing a red shirt with white stripes and a man wearing a white short-sleeve shirt with red and blue patterns appear in the video, which item are they both wearing?
A. The man in the white shirt is wearing black-framed glasses, while the man in the red shirt is not
B. A blue bracelet
C. The man in the red shirt is wearing black-framed glasses, while the man in the white shirt is not
D. The man in the red shirt is wearing an orange scarf, while the man in the white shirt is not
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 124/150 [04:51<01:03,  2.43s/it][32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9WjElCiDpzM.mp4[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9WjElCiDpzM.mp4[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9WjElCiDpzM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=248[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A cute, gray-furred little animal is in a thick, clean white snowy field, with dry tree branches at the side. What is this animal doing in the white snow in the video?
A. Barking
B. Running
C. Rolling
D. Digging
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6HTO2SOxUc.mp4[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6HTO2SOxUc.mp4[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6HTO2SOxUc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=233[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand; then, the dark-skinned woman secures a small white wooden block with the yarn; finally, a dark-skinned woman combing a doll holds a tuft of yarn.
B. First, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand; then, a dark-skinned woman combing a doll holds a tuft of yarn; finally, the dark-skinned woman secures a small white wooden block with the yarn.
C. First, a dark-skinned woman combing a doll holds a tuft of yarn; then, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand; finally, the dark-skinned woman secures a small white wooden block with the yarn.
D. First, the dark-skinned woman secures a small white wooden block with the yarn; then, a dark-skinned woman combing a doll holds a tuft of yarn; finally, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand.
E. First, a dark-skinned woman combing a doll holds a tuft of yarn; then, the dark-skinned woman secures a small white wooden block with the yarn; finally, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 125/150 [04:54<01:08,  2.74s/it][32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = t1nhAnMQBHg.mp4[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/t1nhAnMQBHg.mp4[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: t1nhAnMQBHg.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=250[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There's a black surface on the table with a plate on it, inside the plate there's a multicolored dotted face mask, next to it there's a black and green cucumber model, and a yellow label with the word 'Blondies'. What other objects appear in the video?
A. Piano
B. Mobile phone
C. Television
D. Leaf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vJ9hYCUDHTo.mp4[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vJ9hYCUDHTo.mp4[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vJ9hYCUDHTo.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=235[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a gray suit and tie is speaking on a podium. He is in a large hall, with three blue flags behind him, and has short hair and wears glasses. In front of him are two microphones. When he mentions 'of a tactical or technical issue it is,' which non-existent objects are present?
A. yellow pillar
B. black glasses
C. blue flags
D. dark brown door
E. blue curtain
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aVHAr8rc-Ks.mp4[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aVHAr8rc-Ks.mp4[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aVHAr8rc-Ks.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=237[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dimly lit room, there is a chair. A man in front of the chair, wearing a white short-sleeved shirt, is bending over looking at something in his hands. When the subtitles mention 'I don't know what this is, it looks like a pointed object', what is the item on the man's head?
A. A black beret with red and white interlaced text
B. A black baseball cap with red and white interlaced text
C. A black top hat with red and white interlaced text
D. A yellow baseball cap with red and white interlaced text
E. A black baseball cap with no text
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 126/150 [04:57<01:08,  2.86s/it][32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qZVBFAtfp2A.mp4[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qZVBFAtfp2A.mp4[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qZVBFAtfp2A.mp4 | Selected 10 frames[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=252[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 08:44:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man in pink garb with a ponytail stands in front of a white wall with a white door, as well as a lantern. The man is wearing a pink garment. Not far away, there's a street with some small buildings and parked cars. Behind the man, there is a person in black clothing facing away from the camera. When the phrase 'I can't wait to surprise my mom' is mentioned, what type of garment is the man wearing?
A. Pink tank top
B. Pink T-shirt
C. Pink dress shirt
D. Pink jacket
E. Pink sweater
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 127/150 [04:58<00:55,  2.41s/it][32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UMFy3keSk-s.mp4[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UMFy3keSk-s.mp4[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UMFy3keSk-s.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=254[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who appears first in the video among the following characters?
A. A man wearing an orange jacket with a small name tag, sitting in front of a bookshelf filled with books.
B. A man wearing a white baseball cap inside a museum.
C. A woman with golden hair talking to a mirror, with a glowing display screen in the lower right corner.
D. A woman with golden hair wearing a checkered scarf inside a museum.
E. A man wearing a black top with a patterned neckline, a black beret, and black-rimmed glasses, sitting in front of a name tag.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = M5YKW6fhlss.mp4[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/M5YKW6fhlss.mp4[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: M5YKW6fhlss.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=239[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a green door and a water dispenser by the wall, a person with golden hair, without a nose or lips, is looking at a fly wearing a green coat. In which scenes has this fly appeared?
A. In a mine.
B. In a room with flies wearing pink coats and flies wearing white striped coats.
C. Next to a man wearing a plaid shirt.
D. Next to a man wearing a purple coat.
E. Next to a dalmatian.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6867204066108329221.mp4[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6867204066108329221.mp4[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6867204066108329221.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=241[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a lakeside view, there is a green tree by the lakeside, and a woman in a black jacket is running towards the lakeside. What objects are present in the scene?
A. White glasses
B. Blue skirt
C. Black skirt
D. Pink shorts
E. Pink skirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 128/150 [05:03<01:04,  2.92s/it][32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eE5Z7gDbgVA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=256[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A lady with gray hair tied up is sitting on a sofa watching TV, holding a white bowl in one hand and a spoon in the other. There's a mirror on the white wall behind her reflecting the TV screen. When 'Who you gonna call?' is mentioned, what object is not present in the scene?
A. white socks
B. green pillow
C. blue pillow
D. black belt
E. black pillow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = P9hDA0u6FO0.mp4[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/P9hDA0u6FO0.mp4[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: P9hDA0u6FO0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=243[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a black-and-white background, three men appear on the screen. The man on the right has his hands crossed in front of his chest, the man on the left is wearing a hat and his finger is pointing to the upper right. The other man is staring sharply at the man on the right. What is the style of the hat worn by the man on the left when the subtitle 'There's no way I'm going down' appears?
A. a beanie
B. a top hat
C. a denim cap
D. a baseball cap
E. a beret
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 129/150 [05:05<01:00,  2.89s/it][32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lN3WnXMaE0o.mp4[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lN3WnXMaE0o.mp4[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lN3WnXMaE0o.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=258[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. On the right, a man in a dark blue military uniform with a white flower in his hair and medals on his chest. On the left, a yellow paper sheet. A man wearing a military hat, a long coat, and long boots, with white and red English words in the frame. Under a blue sky, a man in a white short sleeve shirt holding a camera stands by a yellow rock.
B. A man wearing a military hat, a long coat, and long boots, with white and red English words in the frame. On the right, a man in a dark blue military uniform with a white flower in his hair and medals on his chest. On the left, a yellow paper sheet. Under a blue sky, a man in a white short sleeve shirt holding a camera stands by a yellow rock.
C. A man wearing a military hat, a long coat, and long boots, with white and red English words in the frame. Under a blue sky, a man in a white short sleeve shirt holding a camera stands by a yellow rock. On the right, a man in a dark blue military uniform with a white flower in his hair and medals on his chest. On the left, a yellow paper sheet.
D. On the right, a man in a dark blue military uniform with a white flower in his hair and medals on his chest. On the left, a yellow paper sheet. Under a blue sky, a man in a white short sleeve shirt holding a camera stands by a yellow rock. A man wearing a military hat, a long coat, and long boots, with white and red English words in the frame.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OmhVj_-cfH0.mp4[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OmhVj_-cfH0.mp4[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OmhVj_-cfH0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=245[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A soldier wearing a golden helmet is standing on a grassy field near a wooden fence. Holding a water bag, three drops fall from it. After the subtitle 'you will have to pay for it in blood' appears, what is the first object that appears on the screen?
A. A person with white hair holding a green shield
B. A person wearing a red robe with black hair
C. Three shields
D. A person with yellow hair holding a water bag
E. A soldier holding a red shield and wearing a helmet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 130/150 [05:08<00:53,  2.69s/it][32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WLl3SeraTV0.mp4[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WLl3SeraTV0.mp4[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WLl3SeraTV0.mp4 | Selected 11 frames[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=260[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 08:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a large marble countertop, there is a baking model. In the middle of the screen, a hand is holding a yellow jar and spraying it inward. What changes happen on the screen after the subtitle mentions 'so'?
A. This person is holding a gray scoop and is stirring it inside.
B. This person is holding a jar of chocolate sauce and is about to pour it in.
C. This person is holding a yellow jar of fruit sauce and is about to pour it in.
D. This person is holding a red scoop and is stirring it inside.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 131/150 [05:09<00:43,  2.28s/it][32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F7RSW-2rF4w.mp4[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F7RSW-2rF4w.mp4[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F7RSW-2rF4w.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=262[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is an elderly man wearing a dark brown hat, dressed in a brown suit, with a dark blue sweater and a blue shirt underneath, walking in the gallery. On the right side of the gallery, there is an artwork displayed, among which a painting shows a woman in a green dress sitting on a sofa. Can you tell what color the sofa is?
A. red
B. black
C. pink
D. green
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = J_ZmaKRpyoU.mp4[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/J_ZmaKRpyoU.mp4[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: J_ZmaKRpyoU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=247[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there are three images on the PPT. One of the images has the word 'Image/Video' below it, another one has the word 'Where?' below it, and in the bottom right corner, there is a woman wearing a dark blue inner outfit, a black outer coat, and glasses. What objects have appeared on the screen?
A. A photo of a globe
B. A photo of a satellite
C. A photo of a road at night
D. A photo of a man in a black short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tYqDvtknII4.mp4[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tYqDvtknII4.mp4[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tYqDvtknII4.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=249[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a street, next to the road, there is a house built with stones. The house has a black tiled roof and is covered with vines on the walls. A woman wearing a yellow top and a white floral half-skirt is walking on the street holding a book. From the subtitles listed below, which ones have appeared while this woman in the white floral half-skirt is present?
A. "Music"
B. "built here since 16th century"
C. "places"
D. "this title"
E. "and it does feel like time has stopped"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 132/150 [05:12<00:46,  2.59s/it][32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ErGYJ7kqIow.mp4[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ErGYJ7kqIow.mp4[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ErGYJ7kqIow.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=264[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bar chart appears on the screen, one bar is purple, and the other is yellow. The two bars are compared, with the years indicated below. What shows up after the bar chart appears?
A. A city map
B. A glass of water
C. A smartphone
D. Fried chicken
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSeq-nVSY_E.mp4[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSeq-nVSY_E.mp4[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSeq-nVSY_E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=251[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the red video frame, after a man with a mustache lies down facing the left side, what event happens on the screen?
A. The man has a green ribbon tied over his eyes.
B. The man has a green ribbon tied around his neck.
C. The man has a white ribbon in his mouth.
D. The man has a red ribbon in his mouth.
E. The man's eyes are covered.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 133/150 [05:14<00:38,  2.27s/it][32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7274542274997013761.mp4[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7274542274997013761.mp4[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7274542274997013761.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=266[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:44:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a man and a woman. The woman is wearing a white nightgown, and the man is wearing a blue shirt. When the man in the blue shirt appears in an office with brown walls, what change occurs to his clothing?
A. Changes from a blue shirt to a red shirt
B. Changes from a blue shirt to a white T-shirt
C. Changes from a blue shirt to a purple shirt
D. Changes from a blue shirt to a black hoodie
E. Wears an additional black suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 134/150 [05:15<00:32,  2.03s/it][32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UUaiqR1I454.mp4[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UUaiqR1I454.mp4[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UUaiqR1I454.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=268[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white-background PPT, the top left corner is the black English text '1st Pass: Contrastive Loss'. Below the dashed box in the middle of the screen, which subtitles have appeared at the same time as a horizontal arrow pointing to the right?
A. "the same part this it's not a very good"
B. "you're going to get a very low value for"
C. "image so when you uh so they do not work"
D. "well for U detection at Region level"
E. "pi and then what you're going to do is"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6976239624578419969.mp4[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6976239624578419969.mp4[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6976239624578419969.mp4 | Selected 15 frames[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=253[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 08:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a room, hanging on the wall are an orange bag and a green and white garment. A woman wearing green clothes is holding a baby dressed in white. In which captions does this baby appear together?
A. cuts and bruises and they did not surrender
B. cuts and bruises and years that followed his wife sadly died
C. cuts and bruises and many more suffered similarly
D. years that followed his wife sadly died and many more suffered similarly
E. they did not surrender and many more suffered similarly
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 135/150 [05:18<00:31,  2.13s/it][32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ydm72ftJStQ.mp4[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ydm72ftJStQ.mp4[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ydm72ftJStQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=270[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A hand with manicured nails is placed near the shoulder of a reclining woman. The woman is wearing a black short sleeve shirt and is smiling. There is a toy figure behind her. What did the hand with manicured nails do after being placed on the reclining woman's shoulder?
A. Tapped the reclining woman's forehead
B. Tapped the reclining woman's face
C. Tapped the reclining woman's shoulder
D. Tapped the reclining woman's stomach
E. Tapped the reclining woman's buttocks
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -if_Wg43vTk.mp4[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-if_Wg43vTk.mp4[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -if_Wg43vTk.mp4 | Selected 9 frames[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=255[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After the oil in the blue iron pot is heated, what was done with the glass bowl containing marinated meat that was picked up with both hands?
A. Poured the oil from the pot into the glass bowl.
B. Added a pinch of fermented bean curd.
C. Added white seasoning oil.
D. The marinated meat was poured into the pot.
E. Poured chili peppers into the pot.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7270293967017725185.mp4[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7270293967017725185.mp4[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7270293967017725185.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=257[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white background PPT, there is a yellow icon and black English text in the top left corner. In the center, there are black English letters saying 'Thank you'. When the caption 'here' appears, what object appears on the screen?
A. a man wearing glasses
B. a sphere
C. black English letters
D. a round shape
E. a cube
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 136/150 [05:20<00:30,  2.15s/it][32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = D7VYbsORD8k.mp4[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/D7VYbsORD8k.mp4[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: D7VYbsORD8k.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=272[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a flat surface illuminated by the sun, there is a woman wearing a gray hoodie and a black choker on her neck. Behind her, there is a white door and white columns. What hairstyle does the woman in the gray hoodie have?
A. high ponytail
B. braids
C. curly hair
D. bun
E. pigtails
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oI975O1BUu0.mp4[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oI975O1BUu0.mp4[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oI975O1BUu0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=259[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with green wall tiles, there is a woman with long hair wearing a white dress. In the lower part of the screen near her head, white text appears that says 'someone started playing drums in the back.' What change happens to her when she appears in the restroom?
A. A black bag appears on her shoulder.
B. Her top changes from white to red.
C. A white bag appears on her shoulder.
D. Her top changes from white to black.
E. A red bag appears on her shoulder.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 137/150 [05:23<00:30,  2.32s/it][32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = s49y2RP5C7E.mp4[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/s49y2RP5C7E.mp4[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: s49y2RP5C7E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=274[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the video, there is a man wearing a floral short-sleeved shirt and a cap. In the bottom right corner, there is a logo. When the subtitle mentions 'be 36 years before we could land on,' what does this man change into?
A. The floral short-sleeved shirt changes to a white outfit
B. The floral short-sleeved shirt changes to a yellow outfit
C. The floral short-sleeved shirt changes to a black outfit
D. The floral short-sleeved shirt changes to a red outfit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0WEnmqVVbHo.mp4[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0WEnmqVVbHo.mp4[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0WEnmqVVbHo.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=261[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, four soldiers are cooking food around a fire, then three soldiers are opening a can, and finally, one person is opening a can.
B. First, one person is opening a can, then three soldiers are opening a can, and finally, four soldiers are cooking food around a fire.
C. First, three soldiers are opening a can, then four soldiers are cooking food around a fire, and finally, one person is opening a can.
D. First, three soldiers are opening a can, then one person is opening a can, and finally, four soldiers are cooking food around a fire.
E. First, four soldiers are cooking food around a fire, then one person is opening a can, and finally, three soldiers are opening a can.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 138/150 [05:25<00:28,  2.36s/it][32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7190395053343296774.mp4[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7190395053343296774.mp4[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7190395053343296774.mp4 | Selected 8 frames[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=276[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 08:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The rectangular box is filled with brown-colored desserts, and it seems to have some white nuts inside. Chocolate sauce is drizzled over the food in the box. What happened after the chocolate sauce was drizzled on?
A. The food got burnt
B. The food formed into cubes
C. The food formed into long strips
D. Oats were sprinkled on the food
E. Yellow nuts were sprinkled on the food
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 139/150 [05:26<00:22,  2.02s/it][32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fPLjjr8w6DU.mp4[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fPLjjr8w6DU.mp4[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fPLjjr8w6DU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=278[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman dressed in a checkered suspender dress with a long-sleeved dark green inner layer is kneeling next to a white drum washing machine, preparing to do laundry. Beside her is a blue laundry bag. What item does she put into the washing machine?
A. laundry powder
B. clothes
C. laundry pods
D. plush toy
E. laundry detergent
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OMJc43wUPLM.mp4[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OMJc43wUPLM.mp4[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OMJc43wUPLM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=263[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a map with many colors, and on the white area of the map, there are squares in red and green colors. Next to the map, there is a red frame with a grey circle inside it. Inside the grey circle, there are three bombs drawn. When the grey circle with three bombs appears on a pure red background with five grey circle icons, showing the text '1200 Planes' in white, what changes occur to the grey circle icon with three bombs?
A. The icon becomes smaller
B. The icon becomes larger
C. The color of the bombs inside the icon changes from white to black
D. The color of the bombs inside the icon changes from white to green
E. The color of the bombs inside the icon changes from white to red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7297652941551439109.mp4[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7297652941551439109.mp4[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7297652941551439109.mp4 | Selected 14 frames[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=265[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which mode of transportation is mentioned first in the video?
A. A blue and black sports car
B. A white and black sports car
C. A yellow and black sports car
D. A purple and black sports car
E. A silver sports car
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 140/150 [05:29<00:22,  2.27s/it][32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YebUIUOCo94.mp4[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YebUIUOCo94.mp4[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YebUIUOCo94.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=280[0m
[32m2025-11-28 08:44:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the sandy beach, there are 4 kangaroos. Three of them are in a row, while the other one is stepping on a clump of dry grass. In the distance, the screen shows a blue ocean and a small island. What did the kangaroo do the first time it appeared?
A. Crossing
B. Jumping
C. Fighting
D. Walking
E. Drinking water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kOZnpwI2hIM.mp4[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kOZnpwI2hIM.mp4[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kOZnpwI2hIM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=267[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a man wearing a military uniform, with yellow decorations on his shoulders, and a red shoulder strap. When the subtitle mentions 'in the challenging years that lay ahead,' what is the man's hairstyle?
A. Bald
B. Mediterranean
C. Long hair
D. Crew cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 141/150 [05:32<00:21,  2.38s/it][32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bDpgz_2Piqg.mp4[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bDpgz_2Piqg.mp4[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bDpgz_2Piqg.mp4 | Selected 13 frames[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=282[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 08:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a grey shirt and a black hat is standing in front of a container holding food. There are many people around him, including one at the forefront wearing a black headscarf and another person in a grey shirt holding a plate of food. There's also a man wearing glasses in the corner. What type of hat is this?
A. Western cowboy hat
B. Fisherman hat
C. Duck tongue hat
D. Beret
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 142/150 [05:33<00:17,  2.16s/it][32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = V-RIpt7Tknc.mp4[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/V-RIpt7Tknc.mp4[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: V-RIpt7Tknc.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=284[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside the airport, there is a dense crowd. On the left side of the screen, there's an area surrounded by blue lines and silver pillars, with white stripes on the floor. On the right side of the screen, there's a person in a blue short-sleeve shirt and a girl with a backpack pushing a suitcase. After the word 'it' appears in the subtitles, what person(s) appear(s) on the screen?
A. A woman in blue with a work badge
B. A woman in red with a work badge
C. A man in red with a work badge
D. A potted plant
E. An umbrella
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GdFMKGNFXaE.mp4[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GdFMKGNFXaE.mp4[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GdFMKGNFXaE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=269[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a group of people dressed in formal attire are seated around a long table with paper documents placed on it. They are actively engaging in discussion. The room has podiums and paintings around. The story mentions the signing of the London Treaty at the end of May 1913. What else is mentioned?
A. Montenegro permanently leaving Bulgaria
B. Bulgaria signing an armistice agreement
C. Signing of the Treaty of Bucharest
D. Second Balkan War
E. Greco-Bulgarian War
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 143/150 [05:36<00:16,  2.41s/it][32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -PnG8Jp2gFw.mp4[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-PnG8Jp2gFw.mp4[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -PnG8Jp2gFw.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=286[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Sitting in front of the intercom, after a woman wearing a yellow sweater and glasses says in the subtitles 'from the announcements they're going to,' what action does she take?
A. Touched her nose
B. Touched her collar
C. Touched her lips
D. Touched her earlobe
E. Touched the intercom
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = s49y2RP5C7E.mp4[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/s49y2RP5C7E.mp4[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: s49y2RP5C7E.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=271[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a beige wall, a television screen is hanging, displaying a webpage along with some file icons. A man wearing a black lab coat and a yellow and black badge is standing in front of the screen talking. When he mentions, 'being you don't know that 30-second ad,' what happens?
A. The man waved his hand.
B. The man pointed at the audience listening to the lecture.
C. The man turned around to face the screen.
D. The man put on a hat.
E. The man pointed at the screen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 144/150 [05:39<00:15,  2.50s/it][32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CEZ9rbjK3P4.mp4[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CEZ9rbjK3P4.mp4[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CEZ9rbjK3P4.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=288[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x4225af00] mmco: unref short failure
[h264 @ 0x4225af00] mmco: unref short failure
[32m2025-11-28 08:44:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences is correct?
A. First, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him. Next, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Finally, a soldier inside a room takes an item out of his pocket and places it on the table.
B. First, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Next, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him. Finally, a soldier inside a room takes an item out of his pocket and places it on the table.
C. First, a soldier inside a room takes an item out of his pocket and places it on the table. Next, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him. Finally, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat.
D. First, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Next, a soldier inside a room takes an item out of his pocket and places it on the table. Finally, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him.
E. First, a soldier inside a room takes an item out of his pocket and places it on the table. Next, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Finally, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jvkmcX47bKU.mp4[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jvkmcX47bKU.mp4[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jvkmcX47bKU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=273[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman in a black top is sitting in front of a table. Behind and beside her are white walls and a bookshelf filled with books. There is a wooden object in front of her, and there are drawings on the table in front of her. Where else has this woman appeared?
A. A room with a window
B. Under green trees outdoors
C. In front of a table with potted plants
D. In front of a table with a desk lamp
E. A bench in the park
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 145/150 [05:41<00:11,  2.38s/it][32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eE5Z7gDbgVA.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=290[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A girl is sitting in a room with colorful lights, with green plants behind her. There's also a white curtain to the left of the screen. She has blond and black hair, is wearing glasses, and has a letter sweater on. While she is talking in front of a mirror, what happens after she mentions 'about myself'?
A. She put down the fork
B. She put a fork into a paper cup
C. She changed into a gray T-shirt
D. She picked up a cake
E. She took off her glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZoUsR8t8IxE.mp4[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZoUsR8t8IxE.mp4[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZoUsR8t8IxE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=275[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black-and-white scene, two police officers in uniform are holding a woman. The woman looks excited, wearing a short-sleeved shirt and a medal around her neck. The policeman on the right is wearing sunglasses, and the one on the left is wearing a watch. Behind them are buildings and a dense crowd. When the subtitle 'Not cool, Rosie' appears, what is the tattoo design on the chest of the woman in the middle?
A. Round tattoo
B. Three-leaf clover tattoo
C. Small dog tattoo
D. Square tattoo
E. Small cat tattoo
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 146/150 [05:44<00:09,  2.48s/it][32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SKET024GdlE.mp4[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SKET024GdlE.mp4[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SKET024GdlE.mp4 | Selected 5 frames[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=292[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-28 08:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the person standing in front of the wall with several rectangular maps, talking to the camera?
A. A man wearing a green shirt
B. A man wearing a red shirt
C. A man wearing a multicolored shirt
D. A man wearing a black shirt
E. A man wearing a purple shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 147/150 [05:45<00:05,  1.99s/it][32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7m9XIXyT5_I.mp4[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7m9XIXyT5_I.mp4[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7m9XIXyT5_I.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=294[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a red house with a black roof, there is a woman wearing a light blue suit and holding a microphone. There is also a blue and white caption bar at the bottom of the screen. After the phrase 'court so this case is still really at' is mentioned, who appears on the screen?
A. A woman wearing a turquoise coat appears
B. A man wearing a black suit appears
C. A woman wearing headphones and a red coat appears
D. An elderly person wearing headphones and a black-gray coat appears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NMHmqgO04rU.mp4[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NMHmqgO04rU.mp4[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NMHmqgO04rU.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=277[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the airplane, there are two soldiers wearing khaki hats. The soldier on the left has a hand on his hat, while the soldier on the right is holding a paper and a pen. What is the soldier on the right doing?
A. He is throwing the pen
B. He is tearing up the paper
C. He is putting on goggles
D. He is writing on the paper
E. He is taking off the hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 148/150 [05:47<00:04,  2.12s/it][32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kMryvefpcF8.mp4[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kMryvefpcF8.mp4[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kMryvefpcF8.mp4 | Selected 9 frames[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=296[0m
[32m2025-11-28 08:44:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 08:44:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 08:44:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man dressed in a white shirt, raising one hand, with a slight smile on his face, sitting on a black chair and speaking, this man appears with which subtitles?
A. I eventually ended up living
B. offered me his couch to crash on
C. Pyramid of Giza
D. I got a tap
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 149/150 [05:49<00:01,  1.91s/it][32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fsz6bkkIHzQ.mp4[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fsz6bkkIHzQ.mp4[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fsz6bkkIHzQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=298[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:44:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A white Pekingese dog is lying on a white cushion on the sofa. The dog is wearing a pearl necklace around its neck. There is a plaid pillow on the sofa. In the bottom left corner of the screen, there is an upper body image of a man wearing a white coat. When the subtitle 'It was just a small amount' appears, what does the sofa look like?
A. Olive-colored artificial leather sofa
B. Red artificial leather sofa
C. Red wooden sofa
D. Black artificial leather sofa
E. Olive-colored wooden sofa
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:44:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bXRuqcmTIuk.mp4[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bXRuqcmTIuk.mp4[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bXRuqcmTIuk.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=279[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow wooden floor in front of a red painting, there are two red stools. On the stool in the front, there is a woman with a pink backpack. When the subtitle ‚ÄúRothko was aware that people often burst into tears when confronted with his paintings.‚Äù appears, what is this woman doing?
A. Doing homework
B. Talking with a friend
C. Making a phone call
D. Wiping her tears
E. Looking at the painting
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [05:51<00:00,  2.16s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [05:51<00:00,  2.35s/it]
[32m2025-11-28 08:45:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two people are sitting on a screen, with a long-haired woman in a black long-sleeve dress on the left and a short-haired man in a black long-sleeve shirt on the right. Behind them, there are various types of trees. In front of them, there is a blue water cup. With which subtitles did this blue water cup appear together?
A. served at every single Chinese restaurant with the word 'dragon' in its name, because it's the
B. Here we learn that young Joe had a lot of enemies because he was a bully
C. a perp school called Evergreen Academy. which is a school Joe went to when he was younger.
D. by two loving parents, and seems to be thriving with the cello. this provides Joe with newfound
E. Right after, Joe manages to answer the first question about who he is
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NexB4vj8_54.mp4[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NexB4vj8_54.mp4[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NexB4vj8_54.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=281[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a dark red table, there is a round white plate holding a yellow cake decorated with white powdered sugar. When a silver serrated knife appears above the cake, what is the video creator doing?
A. Eating the cake
B. Setting the table
C. Cutting the cake
D. Cleaning the utensils
E. Decorating the cake
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0rWA-p4p5IM.mp4[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0rWA-p4p5IM.mp4[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0rWA-p4p5IM.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=283[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white surface, a hand places a transparent bowl on the table with an unpeeled egg inside. Where has the egg appeared?
A. In a cake
B. In a silver metal box
C. In a blue plastic container
D. In a black pot
E. In the refrigerator
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = otaJfBSlsG8.mp4[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/otaJfBSlsG8.mp4[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: otaJfBSlsG8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=285[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white cabinet, there is a woman with long black hair wearing a pink top, and there's also a green potted plant on the surface behind her. With which of the following subtitles has she appeared together?
A. history
B. develop
C. warfare
D. people
E. science
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = H_b5d-rLXJU.mp4[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/H_b5d-rLXJU.mp4[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: H_b5d-rLXJU.mp4 | Selected 10 frames[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=287[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 08:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a room, there is a bookshelf filled with books and a wall covered in wallpaper. A man wearing a red short sleeve shirt is sitting on a gaming chair. When mentioning 'smd, what is caught? Piper, aka resource, is a trace format multi,' what is this man doing?
A. He has both hands raised above his head
B. He has both hands crossed in front of his chest
C. He is doing the V-sign with both hands
D. He is doing the V-sign with one hand and clenching a fist with the other
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3JzhP8qfbqE.mp4[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3JzhP8qfbqE.mp4[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3JzhP8qfbqE.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=289[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a red road, with yellow and green plants on both sides and tall peaks in the distance, what color is the car parked on the red road?
A. Black
B. Pink
C. Silver Grey
D. Red
E. Silver White
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dE5iWeCVpGI.mp4[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dE5iWeCVpGI.mp4[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dE5iWeCVpGI.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=291[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a slightly blurred background, what is a woman with long curly hair, wearing a long-sleeved top and a necklace, doing when the caption 'work you breathe it you live it and' appears?
A. Holding a blue pen and writing something
B. Holding a black pen and writing something
C. Holding a purple pen and writing something
D. Holding a white pen and writing something
E. Holding a red pen and writing something
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OGaML8Gg8JQ.mp4[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OGaML8Gg8JQ.mp4[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OGaML8Gg8JQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=293[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man with short black hair, standing in front of a black background, wearing a purple short-sleeve shirt, in which of the following scenes did he appear?
A. A scene with a pure black background and a small green map on the side
B. A room filled with clutter and books
C. A scene with a pure white background with a small flower on the side
D. A courtyard with many fresh flowers
E. In a park with many people
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mqtJErix0ss.mp4[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mqtJErix0ss.mp4[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mqtJErix0ss.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=295[0m
[32m2025-11-28 08:45:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a backdrop of Earth and outer space, there are books and a YouTube trophy on the left wall, character images and space pictures on the right wall, and a satellite model on the desk in the lower left corner. A man wearing a white T-shirt is sitting in the center with his hands clasped together. When the subtitle 'around the Earth not fly off into space' appears, what change happens to his hand movements?
A. The palms face each other and change to the left hand raised above the head
B. The palms face each other and change to both hands clenched
C. Both hands are waving
D. Both hands extend forward
E. Both hands are crossed in front of the chest
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XVXczyheik0.mp4[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XVXczyheik0.mp4[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XVXczyheik0.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=297[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, there is a man wearing a dark blue jacket speaking on the screen. In front of him is a black microphone. He has dark skin and a mustache. On the wall behind him, there's a black map. To the left of the frame, there is a whiteboard, and to the right, there is also a wall with a piece of paper in a black frame. While this man is writing on a black background with white text that says 'How much data do we need?', what change occurs?
A. He puts on glasses
B. He changes to a grey microphone
C. He puts on a hat
D. He changes to black clothes
E. He changes to white clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = IN0osLg-Mn8.mp4[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/IN0osLg-Mn8.mp4[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: IN0osLg-Mn8.mp4 | Selected 16 frames[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=299[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 08:45:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 08:45:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a black coat is kissing a woman with a ponytail. When the subtitle 'the conspiracy Frank sends his wife, Jordan to safety in Venezuela, then burns down his casino' appears, which of the following items is present?
A. hat
B. watermelon
C. earring
D. ring
E. earphone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 08:45:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Postprocessing:   0%|          | 0/150 [00:00<?, ?it/s][32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bUaFXONIXzM_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pJI5ZU6wxqg_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7135100078221430058_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-6999997457392307457_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mld0TnA2jEs_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Sy2unO22PUE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mYotOV3Q51g_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bqQTWdk1DAM_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zVudr8cxHRE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7268771669123042562_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7262938043315686664_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2edlqFUTDVc_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mkqgTAe2_O4_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ysRFFN5nzqE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jJGbXCCU5yc_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: L-XGTMusZvc_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rwL_XPw46zQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7326709884102216965_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: n24n_20Kwe4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6THwql5c6w_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9WjElCiDpzM_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fZBC3nmvJb8_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z6Hx_BAZeUw_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _7sd4fjnmvc_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZfapKqwklG4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lN3WnXMaE0o_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @thatrecipe.us-7309241426028596523_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: cc0T2vtuJtc_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z-1lgAXOEc8_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bXRuqcmTIuk_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: athabNMGceo_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSeq-nVSY_E_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sWfcgeDth_w_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LlqsCCa6y58_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dE5iWeCVpGI_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-7194857776877817094_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAcbasjxljY_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5zbV24vyO44_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7275653401025826050_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eJr-y6UXnRE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: crmV4OduHYA_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hg2Q_O5b9w4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UN3ICsfqKEY_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aoxy2e7j9Bc_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tdA5atpqaAc_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TlaX2iIYZD4_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PCPQToF10IM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WaiGdRYD36k_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7359951777845775648_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SO3czkzeFjw_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yXXhrMqfMlk_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Dkm35G5kkcc_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mkqgTAe2_O4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pGEF7Tme3Tk_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kLuqCtnKr_8_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7324761016909188358_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CGngv8vTQOs_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UMFy3keSk-s_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jdbG9gmg_SA_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: V0h7rJShw0g_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dCscvoOX2as_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qjY9kmveQAk_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: FnKDgC9aNu0_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2zZSMnGLGao_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 22iOyzE8Ec0_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pJI5ZU6wxqg_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kbRtl58u_kk_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7MemY9jOmuk_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WmrwQMFZLqI_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OUeE8nCKWGA_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ysRFFN5nzqE_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XJ6REZOXsvM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: akoJDx23QWU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: j7kxn5CsHnw_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: BtaVRhoLpC0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -iCLYpeghJs_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gURB1JwPfJw_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Uy_o-WCq2Cc_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7318074908645264645_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zda-T6wrEhs_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jess.morg-7203120578537049386_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0rWA-p4p5IM_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d8H7hgQY9ew_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lnCPn8gX3FU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7254803496900267266_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAcbasjxljY_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vpKtHB8x0js_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lzAESaVqix0_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yqejTvYILlA_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JLBsG65WoVU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _hODR1cR9lo_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AHeq99pojLo_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7197144530024500485_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8Qe03WDCrB4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iJgh2dnudIU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JhlzvoqKOc8_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7267884432420277506_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HeRS3nwySI8_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: M7YSCIkUaNw_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F2OhCCEIOcU_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7184160724715883781_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iDFDxwPTjeU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eDso3zHFxL8_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7321010343067618592_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Sn7JPKbG6tY_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1D9TgBrW6Sw_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SO3czkzeFjw_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UO_6TQnnOxM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d-GKQeu4S6M_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eJr-y6UXnRE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7275485247351901442_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TFbGLEZ4qt0_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _qepWb_NVj4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tdm72-vYxTs_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ixAU3l0sX_o_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eDso3zHFxL8_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mB7NW91REF4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d5JlCEDlHGE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hXFfPjytMo0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mHARxee4EzQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hf4WUOagFAw_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oddHY1vwcjo_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fsz6bkkIHzQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -QSAotqKqX8_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gJuOMPiixUA_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: o2F-N42Ufo4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JLnsWrzV_j4_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5tN9hyfdkaE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1IpgyV9u5nE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VwZeSoYugZk_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ro_8-CCORzk_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MPQn_orwpfA_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 61SYvhojGvg_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Pm93D8CVlY8_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mbcvVYobCXI_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Msz128EJeWE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8905KCkLDYc_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CdTijM0_es4_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7TljSpTBS9c_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i327DBSS_iE_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tCnelzIAHA0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kelseyinlondon-7258968758130085146_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LKQK0lud4fo_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: e6HwinLBK_Y_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bjymxow3TVQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: k4jiEuZbN-4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fq3zbbp-lv4_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9m4wi5gPdHg_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fWNJmZAWRNg_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7MemY9jOmuk_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rZq-8Bq3mkU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _kQXNFG664Y_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VL259eBJ68w_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WpbB_swXHkc_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DxxVla1CRvU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 14ot4DrXdds_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aCPNlZ7bvRc_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZsnfXfuGRrg_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7269746510462536962_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7268167132591000833_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CdTijM0_es4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Jfp1Ks7Hh1E_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAHsR02dUc0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AYMdAVxALP4_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -PnG8Jp2gFw_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9m4wi5gPdHg_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qyaQ-wfojbM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lQODAJ_F5yE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7203500499360877829_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NpYUxd1vUUE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iJgh2dnudIU_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 51dUUxFOjDE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: duxO1EZ650E_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MJYBHfYF8LI_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: E7FSg22MdKE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bAGhXcYc0o4_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _uL3a3aMdMQ_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DoizYSYQRqU_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2ekjGl8yWZk_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bwDfdTh0VYs_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z7Cox6lPW3c_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Y1YCvEip_ko_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kFHVBCEwC3w_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1R5uPaL0V-0_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: h0OHi9uAcBo_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kelseyinlondon-7094322812327906565_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ClYmTkGTGYg_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JLBsG65WoVU_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F8Ma1qs0Rkg_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @thatrecipe.us-7262468242692689194_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1D9TgBrW6Sw_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7153617149041446150_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9dSkvxS2EB0_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DRIpznER-VQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: BktEeBeA7a8_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UwJTCg5fpXg_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VLInjyogciw_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: luRqMb5qfhM_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ytv-9RM4e0o_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kk-iRzLv81o_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2ekjGl8yWZk_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 51dUUxFOjDE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: duxO1EZ650E_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bwnkg6GbXwU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yFAuXmcGk2Y_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7254238802577820929_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: er1oRjH2iu8_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RTUFPjliMCU_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qbA42wQoWAs_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z00vWImw1KQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7200404243168415022_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5tN9hyfdkaE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SH7Unhifaj0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NMHmqgO04rU_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: M5YKW6fhlss_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8_MG-E8QlBM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSn78eNspwU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jdbG9gmg_SA_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jess.morg-7206809277867052330_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iJk-HMfO4yQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0WEnmqVVbHo_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -An3wZyoYe0_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Lc7RikDaa30_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7Q8d8Vvk6oo_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: brZugTJ0odg_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6HTO2SOxUc_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PzUxuZ-KGsU_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vJ9hYCUDHTo_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mfS6gyP0mwo_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: q3FAxTSENEw_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aVHAr8rc-Ks_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: M5YKW6fhlss_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: x1FkhxMMIcg_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HvSEKzpSdzw_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-6867204066108329221_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: P9hDA0u6FO0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bqQTWdk1DAM_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OmhVj_-cfH0_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Efuyl2Anehg_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: J_ZmaKRpyoU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wxWo44MoCTI_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tYqDvtknII4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -kaF6SnSEo8_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSeq-nVSY_E_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9WjElCiDpzM_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-6976239624578419969_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: t1nhAnMQBHg_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -if_Wg43vTk_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qZVBFAtfp2A_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7270293967017725185_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UMFy3keSk-s_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oI975O1BUu0_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eE5Z7gDbgVA_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0WEnmqVVbHo_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lN3WnXMaE0o_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OMJc43wUPLM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WLl3SeraTV0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7297652941551439109_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F7RSW-2rF4w_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kOZnpwI2hIM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ErGYJ7kqIow_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GdFMKGNFXaE_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7274542274997013761_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: s49y2RP5C7E_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UUaiqR1I454_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jvkmcX47bKU_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ydm72ftJStQ_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZoUsR8t8IxE_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: D7VYbsORD8k_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NMHmqgO04rU_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: s49y2RP5C7E_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bXRuqcmTIuk_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7190395053343296774_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NexB4vj8_54_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fPLjjr8w6DU_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0rWA-p4p5IM_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YebUIUOCo94_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: otaJfBSlsG8_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bDpgz_2Piqg_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: H_b5d-rLXJU_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: V-RIpt7Tknc_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3JzhP8qfbqE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -PnG8Jp2gFw_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dE5iWeCVpGI_1]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CEZ9rbjK3P4_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OGaML8Gg8JQ_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eE5Z7gDbgVA_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mqtJErix0ss_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SKET024GdlE_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XVXczyheik0_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7m9XIXyT5_I_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: IN0osLg-Mn8_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kMryvefpcF8_0]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fsz6bkkIHzQ_2]:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 3254.63it/s]
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m631[0m - [1m================================================================================[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m632[0m - [1mLONGVIDEOBENCH CUSTOM RESULTS (with Frame Selection)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m633[0m - [1m================================================================================[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m641[0m - [1m
Accuracy by Duration Group:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m642[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  15s                           : 67.50% (40 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  60s                           : 70.00% (40 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  600s                          : 54.00% (100 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  3600s                         : 55.83% (120 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m650[0m - [1m
Accuracy by Question Category:[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m651[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E2O                           : 55.56% (18 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E3E                           : 56.00% (25 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O2E                           : 64.71% (17 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O3O                           : 56.25% (16 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2A                           : 80.00% (20 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2E                           : 78.26% (23 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2O                           : 72.73% (22 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SAA                           : 23.08% (13 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SOS                           : 75.00% (20 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SSS                           : 25.00% (20 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2A                           : 70.00% (20 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2E                           : 63.16% (19 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2O                           : 75.00% (12 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3E                           : 50.00% (10 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3O                           : 36.36% (11 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TAA                           : 53.85% (13 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TOS                           : 38.09% (21 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m658[0m - [1m
================================================================================[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m659[0m - [1mOVERALL ACCURACY: 58.67% (300 samples)[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m660[0m - [1m================================================================================[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2025-11-28 08:45:27[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m287[0m - [1mSaving samples to /home/train01/miraj/lmms_eval/results/full_logs/300_run_LV/selected_dbfp_longvideobench_blip_k16_alpha1.0_sup2.0_temporal_20251128_083849_results/..__LLaVA-NeXT-Video-7B-Qwen2/20251128_163855_samples_longvideobench_custom.jsonl[0m
llava_vid (pretrained=../LLaVA-NeXT-Video-7B-Qwen2,conv_template=chatml_direct,video_decode_backend=decord,max_frames_num=16,overwrite=False), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|        Tasks        |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|---------------------|------:|------|-----:|--------------|---|-----:|---|------|
|longvideobench_custom|      1|none  |     0|lvb_custom_acc|‚Üë  |0.5867|¬±  |   N/A|

[rank0]:[W1128 08:45:27.017785635 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
