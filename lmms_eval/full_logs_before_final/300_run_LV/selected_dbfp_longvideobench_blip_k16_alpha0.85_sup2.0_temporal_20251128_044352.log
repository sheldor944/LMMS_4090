The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-11-28 04:43:56[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-28 04:43:56[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-28 04:43:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-28 04:43:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-28 04:43:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-28 04:43:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-28 04:43:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-28 04:43:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-28 04:43:58[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/300_run_LV/selected_dbfp_longvideobench_blip_k16_alpha0.85_sup2.0_temporal_20251128_044352_results'}[0m
[32m2025-11-28 04:43:58[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-28 04:43:58[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-28 04:43:58[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/300_run_LV/selected_dbfp_longvideobench_blip_k16_alpha0.85_sup2.0_temporal_20251128_044352_results'}[0m
[32m2025-11-28 04:43:58[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-28 04:43:58[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
OpenCLIP not installed
OpenCLIP not installed
force sample: False
Rank 0:  Loaded LLaVA model: ../LLaVA-NeXT-Video-7B-Qwen2
force sample: False
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.72s/it]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.94s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:05<00:04,  2.48s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:05<00:05,  2.72s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:07<00:02,  2.42s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:08<00:02,  2.68s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  1.87s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  2.10s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09<00:00,  2.04s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09<00:00,  2.30s/it]
Rank 0:  Model Class: LlavaQwenForCausalLM
[32m2025-11-28 04:44:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36m__init__[0m:[36m215[0m - [1mUsing 2 devices with data parallelism[0m
Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 300 examples [00:00, 31283.66 examples/s]
[32m2025-11-28 04:44:11[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 1 (local rank 1)[0m
[32m2025-11-28 04:44:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank1-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-28 04:44:11[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 1...[0m
  0%|          | 0/150 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 7028.54it/s]
[32m2025-11-28 04:44:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 150[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 0 (local rank 0)[0m
[32m2025-11-28 04:44:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank0-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 0...[0m
  0%|          | 0/150 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 7233.97it/s]
[32m2025-11-28 04:44:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 150[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/150 [00:00<?, ?it/s][32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ysRFFN5nzqE.mp4[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ysRFFN5nzqE.mp4[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rP7sQe784k8.mp4[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ysRFFN5nzqE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rP7sQe784k8.mp4[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=1[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rP7sQe784k8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=0[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the rightmost side of the white screen, from top to bottom, there are two person frames. The top one is a black-haired woman sitting in front of a desk, and the bottom one is a woman wearing glasses. When the subtitle says 'get a little bit technical which you,' what type of clothing is the woman wearing glasses at the bottom wearing?
A. T-shirt
B. Leather jacket
C. Sweater
D. Swimsuit
E. Suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = otaJfBSlsG8.mp4[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/otaJfBSlsG8.mp4[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: otaJfBSlsG8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=3[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a rectangular table with food ingredients, there are some green onions on the wooden tray on the far left side. What change occurred to the green onions when the subtitle says 'Onion'?
A. The green onions were cut into chunks
B. The green onions were put into a bottle
C. The green onions were placed on a rack
D. The green onions were put into a pot
E. The green onions were cut into pieces
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   1%|          | 1/150 [00:03<09:04,  3.65s/it][32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fxCRCMLJ0PU.mp4[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fxCRCMLJ0PU.mp4[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fxCRCMLJ0PU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=2[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a character dressed in green military attire with olive green camouflage on the face and a rifle on the back appears in front of a black screen. Then, a green aircraft flies in a sky with light orange and light purple hues. Finally, a little figure wearing an olive helmet holds onto a parachute and floats in the air.
B. First, a little figure wearing an olive helmet holds onto a parachute and floats in the air. Then, a character dressed in red military attire with yellow camouflage on the face and a rifle on the back stands in a military pose. Finally, a green aircraft flies in a sky with light orange and light purple hues.
C. First, a little figure wearing an olive helmet holds onto a parachute and floats in the air. Then, a character dressed in green military attire with olive green camouflage on the face and a rifle on the back stands in a military pose. Finally, a green aircraft flies in a sky with light orange and light purple hues.
D. First, a yellow aircraft flies in a sky with light orange and light purple hues. Then, a character dressed in red military attire with yellow camouflage on the face and a rifle on the back stands in a military pose. Finally, a little figure wearing an olive helmet holds onto a parachute and floats in the air.
E. First, a little figure wearing an olive helmet holds onto a parachute and floats in the air. Then, a character dressed in red military attire with yellow camouflage on the face and a rifle on the back stands in a military pose. Finally, a yellow aircraft flies in a sky with light orange and light purple hues.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   1%|‚ñè         | 2/150 [00:05<06:43,  2.73s/it][32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7265337261737217312.mp4[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7265337261737217312.mp4[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7265337261737217312.mp4 | Selected 11 frames[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=4[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white cabinet, there is a woman with long black hair wearing a pink top, and there's also a green potted plant on the surface behind her. With which of the following subtitles has she appeared together?
A. history
B. develop
C. warfare
D. people
E. science
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wSHPuI7wWIg.mp4[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wSHPuI7wWIg.mp4[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wSHPuI7wWIg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=5[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a rectangular plate containing various buns, when a piece of toast picked up with tongs is placed into a round plate with forks, what changes occur to the toast?
A. The toast turned black
B. A corner of the toast is missing
C. The toast turned into a triangle
D. The toast turned into a square
E. The toast turned red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   2%|‚ñè         | 3/150 [00:08<06:28,  2.64s/it][32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7289528053112343814.mp4[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7289528053112343814.mp4[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7289528053112343814.mp4 | Selected 7 frames[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=6[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a black coat is sitting on a stool. The man is holding a black straw and a pink drink. Behind the man, there is a white stool and a screen. The screen displays an image of a large group of people gathered together. When the caption 'Can't complain' appears, what object is present in the scene?
A. A ring
B. A plate
C. A potted plant
D. A fork
E. A table lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d5JlCEDlHGE.mp4[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d5JlCEDlHGE.mp4[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d5JlCEDlHGE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=7[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a shot of the sea with a mountain in the background appears, then a scene of a waterfall appears, and finally, it concludes with the appearance of a frog.
B. First, a scene of a waterfall appears, then a frog appears, and finally, it concludes with a shot of the sea with a mountain in the background.
C. First, a scene of a waterfall appears, then a shot of the sea with a mountain in the background, and finally, it concludes with the appearance of a frog.
D. First, a frog appears, then a shot of the sea with a mountain in the background appears, and finally, it concludes with a scene of a waterfall.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   3%|‚ñé         | 4/150 [00:09<05:22,  2.21s/it][32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = H2ksp6sRR-k.mp4[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/H2ksp6sRR-k.mp4[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: H2ksp6sRR-k.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=8[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, on a silver floor sits a man with short hair, wearing a black short-sleeved shirt and black shorts. He is holding a white plate. What is this man doing?
A. singing
B. running
C. drinking water
D. dancing
E. eating something
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ClYmTkGTGYg.mp4[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ClYmTkGTGYg.mp4[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ClYmTkGTGYg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=9[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background features a blue curtain. Three men are standing by a white powder-coated round table. The man on the left is wearing a black suit with a brick-red shirt underneath, and holding a green piece of paper in his hand. The man in the middle is dressed in a black suit with a tie and holding a green piece of paper in both hands. The man on the right is wearing a purple-blue checkered shirt and black-framed glasses, holding a green card and a pen up with both hands. What is the man on the right doing when the subtitle 'researchers named midi-chlorian' appears?
A. Closing his eyes and thinking
B. Talking to the man next to him
C. Waving to the camera
D. Looking up at the ceiling
E. Writing on the green piece of paper
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   3%|‚ñé         | 5/150 [00:12<06:00,  2.48s/it][32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TARe4G-SXfk.mp4[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TARe4G-SXfk.mp4[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TARe4G-SXfk.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=10[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:44:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a flower bed in the center of the screen, in which green plants and flowers are planted. There are two people beside the flower bed, one stands looking at the flower bed, and the other bends down to admire the flowers. What kind of outer garment is the person who is bending down wearing?
A. Gray long-sleeve coat
B. Black leather jacket
C. Gray wool sweater
D. Black knit shirt
E. Gray knit shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7068018011139050758.mp4[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7068018011139050758.mp4[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7068018011139050758.mp4 | Selected 10 frames[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=11[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a completely black image appears, then a messy room with a blue bed on the desk, and finally a man standing by a window looking out serves as the ending.
B. First, a man appears standing by a window looking out, then a completely black image appears, and finally a messy room with a blue bed on the desk serves as the ending.
C. First, a completely black image appears, then a man standing by a window looking out, and finally a messy room with a blue bed on the desk serves as the ending.
D. First, a man appears standing by a window looking out, then a messy room with a blue bed on the desk appears, and finally a completely black image serves as the ending.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   4%|‚ñç         | 6/150 [00:14<05:15,  2.19s/it][32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wxWo44MoCTI.mp4[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wxWo44MoCTI.mp4[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wxWo44MoCTI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=12[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows three women sitting by the river, facing the Eiffel Tower. The sky is very blue. The women are respectively wearing a white coat, black and white striped clothing, and a pink outfit. They have their backs to the camera. What kind of hats are the two women in the screen wearing?
A. sun hat
B. straw hat
C. cowboy hat
D. wool hat
E. beret
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3avWNHoEDAg.mp4[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3avWNHoEDAg.mp4[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3avWNHoEDAg.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=13[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:44:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Once the white mold in the coffee-colored pot appears on a wooden table, what changes occur to the white mold?
A. The mold changes from white to sauce color
B. The mold changes from scattered to cake-like
C. The mold changes from sheet-like to cake-like
D. The mold changes from white to yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   5%|‚ñç         | 7/150 [00:16<05:30,  2.31s/it][32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8ew0d0JmsfA.mp4[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8ew0d0JmsfA.mp4[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8ew0d0JmsfA.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=14[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, rocky surfaces in a pitch-black environment, then green vegetation and mountain ranges under a blue sky, and finally continuously flowing red lava
B. First, continuously flowing red lava, then rocky surfaces in a pitch-black environment, and finally green vegetation and mountain ranges under a blue sky
C. First, continuously flowing red lava, then green vegetation and mountain ranges under a blue sky, and finally rocky surfaces in a pitch-black environment
D. First, rocky surfaces in a pitch-black environment, then continuously flowing red lava, and finally green vegetation and mountain ranges under a blue sky
E. First, green vegetation and mountain ranges under a blue sky, then continuously flowing red lava, and finally rocky surfaces in a pitch-black environment
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9PD3ciudpIE.mp4[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9PD3ciudpIE.mp4[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9PD3ciudpIE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=15[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the desolate military base, parked next to two tents, there are four fully armed individuals holding water guns, and in front there are two soldiers dressed in olive military uniforms and carrying guns. Which of the following objects has not appeared?
A. A light olive helmet
B. A red rifle
C. A yellow oil drum
D. An army green tank
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:   5%|‚ñå         | 8/150 [00:18<05:15,  2.22s/it][32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yU9fGAEcxJY.mp4[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yU9fGAEcxJY.mp4[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yU9fGAEcxJY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=16[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a light yellow wall, there is a woman wearing a pink hat sitting with another woman with long hair wearing a dark blue outfit. When the subtitle mentions 'the old people that can't work anymore,' what is the woman with the pink hat wearing?
A. red short sleeves
B. red long sleeves
C. black long sleeves
D. pink short sleeves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8foMISZGiyw.mp4[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8foMISZGiyw.mp4[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8foMISZGiyw.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=17[0m
[32m2025-11-28 04:44:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After the female protagonist in the video adds melted butter into the blender containing chocolate cake mix, what happens next in the video?
A. Mix the two together
B. Pour them into a bowl
C. Add more chocolate cake mix
D. Add milk
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:   6%|‚ñå         | 9/150 [00:21<05:28,  2.33s/it][32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vP-fQu22bng.mp4[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vP-fQu22bng.mp4[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vP-fQu22bng.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=18[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a striped short-sleeve dress is sitting on a chair in front of a pink wall window. A white cloth bag is placed on her lap. What is she doing?
A. She is mending the cloth bag
B. She tore the cloth bag
C. She took a mask out of the cloth bag
D. She placed the cloth bag on the ground
E. She took a gun out of the cloth bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DoizYSYQRqU.mp4[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DoizYSYQRqU.mp4[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DoizYSYQRqU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=19[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, it shows a clip of a blue sea with distant, continuous mountains. What happens after this video finishes playing?
A. A boy wearing white and blue clothes appears and speaks
B. A ship appears
C. A boy wearing black clothes appears and speaks
D. A dolphin appears and swims in the water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:   7%|‚ñã         | 10/150 [00:23<04:50,  2.08s/it][32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = O471uwTNx6k.mp4[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/O471uwTNx6k.mp4[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: O471uwTNx6k.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=20[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a sunlit room, there is a woman wearing a black short-sleeve shirt. She is grabbing her hair with her left hand and combing her hair with her right hand. What objects are present in this scene?
A. Comb
B. Hair clip
C. Necklace
D. Glasses
E. Watch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gAgCnu82RHE.mp4[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gAgCnu82RHE.mp4[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gAgCnu82RHE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=21[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a blurry background, a man with thick eyebrows and short black hair is wearing earphones. When the scene changes to another man in a white shirt standing behind him outdoors, what change occurs to the first man?
A. The man's earphones have changed to wireless.
B. The man is no longer wearing earphones.
C. The man's earphones have changed from black to white.
D. The man's earphones have changed to a hands-free device.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   7%|‚ñã         | 11/150 [00:26<05:28,  2.36s/it][32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yqejTvYILlA.mp4[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yqejTvYILlA.mp4[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yqejTvYILlA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=22[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two pieces of green land appear in the blue background. In the blue background, there are sea and land. A cloud of black smoke appears on the screen. What object emitted this black smoke?
A. An airplane in the blue background
B. A cargo ship in the blue background
C. A waste dump in the blue background
D. A volcano on the green land
E. A volcano in the blue background
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rMXJOKhf_AA.mp4[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rMXJOKhf_AA.mp4[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rMXJOKhf_AA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=23[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x677f0f80] mmco: unref short failure
[h264 @ 0x677f0f80] mmco: unref short failure
[h264 @ 0x677f0f80] mmco: unref short failure
[32m2025-11-28 04:44:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Outside the window where there is a shelf, in the distance, there are many people sitting and eating. Nearby, from left to right, there are a woman with blonde hair, a man wearing a hat and drinking, and a short-haired white man looking into a mirror. After the black man finishes drinking, what action does he perform?
A. Falls to the ground
B. Puts the bottle on the table
C. Stands up
D. Takes out a piece of chewing gum
E. Eats a mouthful of bread
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:   8%|‚ñä         | 12/150 [00:29<05:55,  2.58s/it][32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ze66pbJYr18.mp4[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ze66pbJYr18.mp4[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ze66pbJYr18.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=24[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man dressed as a clown is standing in front of a brick wall. The man has a red ball on his nose and is adorned with red decorations on his face. He is wearing a flowery ring and a purple coat. What did the man do the first time he appeared?
A. The man ran to the left side.
B. The man kept waving his hands.
C. The man wiggled his waist up and down.
D. The man spread his hands and climbed the wall.
E. The man's flowery ring fell on the ground.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7269746510462536962.mp4[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7269746510462536962.mp4[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7269746510462536962.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=25[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the black background, there is a picture. The picture shows a blue sky and yellow stars. The color of the house on the left is yellow and gray. When the subtitle 'iconic works the quaint setting and use' appears, what object is on the screen?
A. Table and chair
B. Teapot
C. Bed
D. Table and stereo
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:   9%|‚ñä         | 13/150 [00:32<06:11,  2.71s/it][32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qbA42wQoWAs.mp4[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qbA42wQoWAs.mp4[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qbA42wQoWAs.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=26[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with white text 'I want you to start with that man over there, okay?' there are many people, and in front of a man in a black suit there is a triangular shelf with a basketball on it. What other objects are present in the scene?
A. A doll wearing purple clothes
B. A green plant
C. A yellow incense burner
D. A white chrysanthemum
E. A white dress
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=27[0m
[32m2025-11-28 04:44:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the night-draped airport, four people are experiencing a ride in a vertical lift aircraft. Inside the aircraft, they are wearing earphones and fluorescent-patterned armor. Who among the following is participating?
A. A man with white hair
B. A woman with long hair
C. A child
D. An elderly man with white hair
E. A woman with green hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:   9%|‚ñâ         | 14/150 [00:34<05:53,  2.60s/it][32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9WjElCiDpzM.mp4[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9WjElCiDpzM.mp4[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9WjElCiDpzM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=28[0m
[32m2025-11-28 04:44:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing an off-shoulder top is sitting on a white sofa. She has orange nail polish and is wearing a necklace. Behind her is a white wall and a black armrest. Two books are on either side of her. When the subtitle 'honeymooners is one of my favorites and' appears, what is the woman doing?
A. The woman is holding a book in each hand
B. The woman is holding a pen in both hands
C. The woman is holding a book in her right hand and a pen in her left hand
D. The woman is holding a book in her left hand and a paper in her right hand
E. The woman is holding a book in her left hand and a pen in her right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PCz04UJFaUY.mp4[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PCz04UJFaUY.mp4[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PCz04UJFaUY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=29[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a woman holding an open book appears; on the left page of the book, a person is standing under a tree, and on the right page, a man with red hair wearing a backpack appears against a black background. Then, a dark-skinned woman sitting on a white sofa places the index finger of her right hand on her lips, and finally, a dark-skinned woman with tightly braided hair holds two small wooden blocks in her hands.
B. First, a dark-skinned woman with tightly braided hair holds two small wooden blocks in her hands, then a dark-skinned woman sitting on a white sofa places the index finger of her right hand on her lips, and lastly, a woman holding an open book appears; on the left page of the book, a person is standing under a tree, and on the right page, a man with red hair wearing a backpack appears against a black background.
C. First, a dark-skinned woman sitting on a white sofa places the index finger of her right hand on her lips, then a woman holding an open book appears; on the left page of the book, a person is standing under a tree, and on the right page, a man with red hair wearing a backpack appears against a black background. Finally, a dark-skinned woman with tightly braided hair holds two small wooden blocks in her hands.
D. First, a woman holding an open book appears; on the left page of the book, a person is standing under a tree, and on the right page, a man with red hair wearing a backpack appears against a black background. Then, a dark-skinned woman with tightly braided hair holds two small wooden blocks in her hands, and finally, a dark-skinned woman sitting on a white sofa places the index finger of her right hand on her lips.
E. First, a dark-skinned woman sitting on a white sofa places the index finger of her right hand on her lips, then a dark-skinned woman with tightly braided hair holds two small wooden blocks in her hands, and lastly, a woman holding an open book appears; on the left page of the book, a person is standing under a tree, and on the right page, a man with red hair wearing a backpack appears against a black background.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  10%|‚ñà         | 15/150 [00:37<06:20,  2.82s/it][32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = md3LVlEzFBU.mp4[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/md3LVlEzFBU.mp4[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: md3LVlEzFBU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=30[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What happened after the person wearing a white helmet and orange goggles raised the hand with the yellow sleeve?
A. A group of people were dancing
B. A group of people were riding scooters
C. A group of people were mountain climbing
D. A group of people were skiing
E. A bird flew onto the hand of the person in the yellow long sleeve
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0rWA-p4p5IM.mp4[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0rWA-p4p5IM.mp4[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0rWA-p4p5IM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=31[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The sky is blue over a yellow desert, and there are two military vehicles facing each other. On these vehicles, there are two people wearing hats with their upper bodies exposed. When the subtitle 'legacy of service in british military' appears, what is the shape of the camera-like object in the middle of the left-hand vehicle?
A. square
B. rectangle
C. step-shape
D. circle
E. semicircle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  11%|‚ñà         | 16/150 [00:40<06:14,  2.80s/it][32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CFm3bc9gqYE.mp4[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CFm3bc9gqYE.mp4[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CFm3bc9gqYE.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=32[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white surface, there is a small silver bowl with a piece of cake inside it. A person, whose face is not visible, is using a tool to take the cake out of the bowl. Where does the cake appear?
A. In a teacup
B. In a red bag
C. On a silver plate
D. In a bucket with alcohol
E. On a black plate
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = FoeeEQ0VVFE.mp4[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/FoeeEQ0VVFE.mp4[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: FoeeEQ0VVFE.mp4 | Selected 11 frames[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=33[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 04:44:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video discussing events related to the Roman soldiers, who appears before the subtitles mention 'conditions however most historians agree'?
A. Wearing short sleeves
B. Wearing green clothes
C. Not wearing a helmet
D. Wearing a helmet and red clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  11%|‚ñà‚ñè        | 17/150 [00:41<05:03,  2.29s/it][32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSn78eNspwU.mp4[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSn78eNspwU.mp4[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSn78eNspwU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=34[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a soldier, crouching and using a gun mechanism, and wearing a camouflage helmet is in combat with the enemy, what object appears on the screen?
A. Bur
B. Grenade
C. Handgun
D. Sword
E. Rifle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5dJUUQufzw4.mp4[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5dJUUQufzw4.mp4[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5dJUUQufzw4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=35[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a scene appears with 'a white goose looking sideways at the gray-white sky and the blue-black sea', then a scene with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface', and finally a scene with 'a yellow box and some black objects floating on a blue-green water surface.'
B. First, a scene appears with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface', then a scene with 'a white goose looking sideways at the gray-white sky and the blue-black sea', and finally a scene with 'a yellow box and some black objects floating on a blue-green water surface.'
C. First, a scene appears with a 'yellow box and some black objects floating on a blue-green water surface', then a scene with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface', and finally a scene with 'a white goose looking sideways at the gray-white sky and the blue-black sea.'
D. First, a scene appears with a 'yellow box and some black objects floating on a blue-green water surface', then a scene with 'a white goose looking sideways at the gray-white sky and the blue-black sea', and finally a scene with 'on a white surface, a goose with a yellow crown lying on the ground next to several goose legs.'
E. First, a scene appears with 'a white goose looking sideways at the gray-white sky and the blue-black sea', then a scene with 'a yellow box and some black objects floating on a blue-green water surface', and finally a scene with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface.'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  12%|‚ñà‚ñè        | 18/150 [00:44<05:23,  2.45s/it][32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7254238802577820929.mp4[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7254238802577820929.mp4[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7254238802577820929.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=36[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:44:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a grassy area covered with yellow and green weeds, there is a man lying in the middle wearing a brown coat and sporting short curly hair. In which of the following scenes has the man on the grassy area appeared?
A. On a yellowish-brown boulder
B. Low air above the ground in front of a forest
C. Inside a car with red interior
D. On the roof of a red van
E. Inside a car with white interior
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 66dwcQ1Y048.mp4[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/66dwcQ1Y048.mp4[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 66dwcQ1Y048.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=37[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x5f916540] mmco: unref short failure
[h264 @ 0x5f916540] mmco: unref short failure
[32m2025-11-28 04:44:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Outside a bright window, there is a boy wearing a white shirt and a boy holding a basketball. At the bottom of the screen, there is white text that says 'Tom is really a pair of'. What is the boy in the white shirt doing in the scene?
A. Holding his head and crying
B. Crouching on the boy holding the basketball
C. Fighting with the boy holding the basketball
D. Kneeling on the ground tying his shoelaces
E. Putting his arm around the boy holding the basketball
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:44:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  13%|‚ñà‚ñé        | 19/150 [00:47<05:39,  2.59s/it][32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = f0IbZGfTgUM.mp4[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/f0IbZGfTgUM.mp4[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: f0IbZGfTgUM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=38[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:44:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man appears on the screen, wearing a striped short-sleeved round-neck shirt and sporting a goatee. In the background behind the man, there are circles of various colors and sizes. When this goateed man stands in front of the signboard holding hands with two friends, what changes occur to his clothing?
A. The striped short-sleeved shirt changes to a cotton jacket.
B. The striped short-sleeved shirt changes to a hooded jacket.
C. The striped short-sleeved shirt changes to a white short-sleeved shirt with letters.
D. The striped short-sleeved shirt changes to a suit.
E. The striped short-sleeved shirt changes to a black jacket.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = e_nAKiSutiA.mp4[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/e_nAKiSutiA.mp4[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: e_nAKiSutiA.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=39[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:45:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the exhibition hall, there are two paintings hanging on the wall. A woman wearing a black shirt with her glasses on top of her head appears. What is she doing the first time she appears?
A. She crosses her arms in front of her chest
B. She is clenching her fists
C. She raises both hands above her head
D. She has her palm up pointing opposite
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8foMISZGiyw.mp4[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8foMISZGiyw.mp4[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8foMISZGiyw.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=41[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the black screen in the top left corner, with white text saying 'Surface Design', a white tank appears below a white skull graphic. What change occurs on the screen after that?
A. A blue arrow points to the white tank
B. A red arrow points to the white tank
C. A red arrow points to the skull
D. A purple arrow points to the white tank
E. A blue arrow points to the white tank
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  13%|‚ñà‚ñé        | 20/150 [00:49<05:22,  2.48s/it][32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UN3ICsfqKEY.mp4[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UN3ICsfqKEY.mp4[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UN3ICsfqKEY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=40[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a half-open door in the room. Next to the door is a chair. A man wearing a black coat and white pants is beside the chair. What is this man doing?
A. He took off his coat.
B. He is preparing to sit on the chair.
C. He is standing up from the chair.
D. He moved the chair away.
E. He closed the door.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3u__SZlBLC0.mp4[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3u__SZlBLC0.mp4[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3u__SZlBLC0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=43[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the open space in front of a red building, a person is holding a skateboard with a design that reads '8.0', running towards a woman wearing glasses and dressed in wine-red pants. What objects are present in this scene?
A. A necklace
B. A white building
C. A yellow skateboard with a design that reads '8.0'
D. A green skateboard with a design that reads '8.0'
E. Black-framed glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  14%|‚ñà‚ñç        | 21/150 [00:52<05:36,  2.61s/it][32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GdZYLAI0vpc.mp4[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GdZYLAI0vpc.mp4[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GdZYLAI0vpc.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=42[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:45:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing an overcoat, spreading her hands, and a woman wearing a white jacket with earrings are standing in front of the house. Who appears after the phrase 'back to' is mentioned?
A. A short-haired man wearing glasses, a brown shirt, and blue pants with his hands in his pockets
B. A woman wearing a purple shirt
C. An old man holding a cane
D. A student carrying a schoolbag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  15%|‚ñà‚ñç        | 22/150 [00:54<04:55,  2.31s/it][32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fPLjjr8w6DU.mp4[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fPLjjr8w6DU.mp4[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fPLjjr8w6DU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=44[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a desk with papers stacked on it, there's a hand on the left side touching a black cup, and on the right side, there's a pair of glasses. What happens when the black cup is knocked over?
A. A hand takes away the glasses
B. The phone gets wet
C. The glasses fall to the ground
D. A hand takes away the soaked paper
E. The pencil gets wet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSeq-nVSY_E.mp4[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSeq-nVSY_E.mp4[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSeq-nVSY_E.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=45[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which character is the first to jump into the swimming pool in the video?
A. A woman in a red swimsuit
B. A man in black swim trunks
C. A woman in a white swimsuit
D. A woman in a yellow swimsuit
E. A woman in a black swimsuit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  15%|‚ñà‚ñå        | 23/150 [00:56<05:02,  2.38s/it][32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6HTO2SOxUc.mp4[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6HTO2SOxUc.mp4[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6HTO2SOxUc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=46[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white background PPT, the top left corner has the black English text '1st Pass: Contrastive Loss'. Which captions appear at the same time as the blue background icon with English text 'image Encoder' inside the dashed box in the middle of the screen?
A. 'you're going to get a very low value for'
B. 'you turn on the cross attention switch'
C. 'and when they're like further apart'
D. 'going to get a very high value for pi'
E. 'pi and then what you're going to do is'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = D0RyFh0hnkQ.mp4[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/D0RyFh0hnkQ.mp4[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: D0RyFh0hnkQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=47[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, the red dot moves on a screen with two curved wave diagrams on the far right. Then, it moves back and forth on two white backgrounds showing purple, red, and orange rectangular diagrams. Finally, the red dot moves across a grayish-black screen with six images and white text.
B. First, the red dot moves back and forth on two black backgrounds showing purple, red, and orange rectangular diagrams. Then, it moves across a grayish-black screen with six images and white text. Finally, the red dot moves on a screen with two curved wave diagrams on the far left.
C. First, the red dot moves across a grayish-black screen with six images and white text. Then, it moves back and forth on two white backgrounds showing purple, red, and orange rectangular diagrams. Finally, the red dot moves on a screen with two curved wave diagrams on the far right.
D. First, the red dot moves back and forth on two white backgrounds showing purple, red, and orange rectangular diagrams. Then, it moves across a grayish-black screen with six images and white text. Lastly, the red dot moves on a screen with two curved wave diagrams on the far right.
E. First, the red dot moves back and forth on two black backgrounds showing purple, red, and orange rectangular diagrams. Then, it moves across a grayish-black screen with six images and white text in red. Finally, the red dot moves on a screen with two curved wave diagrams on the far left.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=49[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, two men and a woman with straight hair wearing a black and white striped outfit appear, they are facing the camera and waving. There are also many objects on the table with the word JELL-O on them. Besides this, what else appears in the room?
A. Mobile phone
B. Television
C. Flower pot
D. Piano
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  16%|‚ñà‚ñå        | 24/150 [00:59<05:06,  2.43s/it][32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OmhVj_-cfH0.mp4[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OmhVj_-cfH0.mp4[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OmhVj_-cfH0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=48[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A middle-aged man wearing a dark brown hat, a suit with a dark blue coat and blue shirt is standing in a gallery. There are paintings displayed on both sides of the gallery, and there is a row of spotlights on the left side of the ceiling. What color is the suit the middle-aged man is wearing?
A. Brown
B. Blue
C. Gray
D. Black
E. Green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  17%|‚ñà‚ñã        | 25/150 [01:01<05:00,  2.41s/it][32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d7IqrLV6Tlg.mp4[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d7IqrLV6Tlg.mp4[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d7IqrLV6Tlg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=50[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a slightly dimly lit room, there is a woman with long hair, wearing a white short-sleeved shirt, sitting on a bed. She is holding a mobile phone. There is a white cabinet behind her, filled with various items. In which of the following scenes has the mobile phone appeared?
A. On a white perforated table
B. On a green perforated table
C. On a yellow perforated table
D. On a blue perforated table
E. On a red perforated table
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eE5Z7gDbgVA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=51[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a black-and-white background, three men appear on the screen. The man on the right has his hands crossed in front of his chest, the man on the left is wearing a hat and his finger is pointing to the upper right. The other man is staring sharply at the man on the right. What is the style of the hat worn by the man on the left when the subtitle 'There's no way I'm going down' appears?
A. a beanie
B. a top hat
C. a denim cap
D. a baseball cap
E. a beret
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Aau-XoIebno.mp4[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Aau-XoIebno.mp4[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Aau-XoIebno.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=53[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, many people are seen running across an endless desert; then, a man in a black short-sleeved shirt punches a man wearing a helmet; finally, a man wearing glasses lifts a curtain.
B. First, a man wearing glasses lifts a curtain; then, a man in a black short-sleeved shirt punches a man wearing a helmet; finally, many people are seen running across an endless desert.
C. First, a man in a black short-sleeved shirt punches a man wearing a helmet; then, a man wearing glasses lifts a curtain; finally, many people are seen running across an endless desert.
D. First, a man in a black short-sleeved shirt punches a man wearing a helmet; then, many people are seen running across an endless desert; finally, a man wearing glasses lifts a curtain.
E. First, a man wearing glasses lifts a curtain; then, many people are seen running across an endless desert; finally, a man in a black short-sleeved shirt punches a man wearing a helmet.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  17%|‚ñà‚ñã        | 26/150 [01:04<05:15,  2.55s/it][32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fw1rirubXiU.mp4[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fw1rirubXiU.mp4[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fw1rirubXiU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=52[0m
[32m2025-11-28 04:45:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a crimson jacket, black pants, black-framed glasses, and with black hair is sitting cross-legged in front of a silver screen. He is holding a microphone in one hand and his other hand is open, suspended by his leg. What is this man doing?
A. Scratching an itch
B. Talking into the microphone
C. Holding a water bottle
D. Waving to the audience
E. Making a phone call
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbgwG8fcIu0.mp4[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbgwG8fcIu0.mp4[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbgwG8fcIu0.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=55[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:45:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black background, there is a screen framed with a red line. On the screen, there's a man with short white hair and a pouting mouth. When this man appears next to the text 'THE WALL STREET JOURNAL', what change occurs to him?
A. He has an additional pair of gold-framed glasses on his face
B. He has an additional hat on his head
C. He has an additional pair of silver-framed glasses on his face
D. His hair changes to black
E. He has an additional pair of sunglasses on his face
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  18%|‚ñà‚ñä        | 27/150 [01:07<05:40,  2.77s/it][32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OMJc43wUPLM.mp4[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OMJc43wUPLM.mp4[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OMJc43wUPLM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=54[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall with a hanging picture frame, a woman wearing a blue uniform, black shorts, and holding a green notebook did what while facing the camera?
A. She stuck out her tongue at the camera
B. She adjusted her long hair facing the camera
C. She made a funny face at the camera
D. She showed her notes to the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XVXczyheik0.mp4[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XVXczyheik0.mp4[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XVXczyheik0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=57[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a red background, there is a white box containing a small red square. Next to the red square, there are white letters reading '26√ó.' Inside the red square, there are two small black X's and one large black X. What changes occur to the red square when it appears on a red background with white letters reading 'Lwow - Lviv - Lemberg'?
A. It changes from red to green, and the number of small X's inside the box changes from two to one.
B. It changes from red to green, and the number of small X's inside the box changes from two to four.
C. It changes from red to green, and the number of small X's inside the box changes from two to three.
D. It changes from red to green, and the number of small X's inside the box changes from two to six.
E. It changes from red to green, and the number of small X's inside the box changes from two to five.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  19%|‚ñà‚ñä        | 28/150 [01:09<05:17,  2.60s/it][32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SO3czkzeFjw.mp4[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SO3czkzeFjw.mp4[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SO3czkzeFjw.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=56[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a black background, a white-lettered title says 'How much data do we need?' with a picture of a golden retriever on the left. The word 'dog' appears on the far right, and a man is explaining in the bottom right corner. When the image of a shaking dog appears, what changes occur in the black scene?
A. The image of the shaking dog gradually shrinks
B. The arrow on the right side is labeled 'not dog'
C. The picture of the golden retriever disappears
D. The image of the shaking dog gradually enlarges
E. The man in the bottom right corner changes into a blue shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QJ6sjg7SXOQ.mp4[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QJ6sjg7SXOQ.mp4[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QJ6sjg7SXOQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=59[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of events is correct?
A. First, the video shows a boy in a blue shirt crossing over a tree trunk in a forest. Then, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing a book bag, walks up the stairs. Finally, in a bedroom, a book bag placed on the bed is shown being zipped up. The boy then wears the book bag and walks out of the room.
B. First, a book bag placed on the bed in a bedroom is shown being zipped up. Then, a boy puts on the book bag and walks out of the room. Next, the video shows a room with yellow and white walls with a staircase inside it. The boy, still wearing the book bag, walks up the stairs. Finally, the video shows a boy in a blue shirt crossing over a tree trunk in a forest.
C. First, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing a book bag, walks up the stairs. Then, the video shows a book bag placed on the bed in a bedroom being zipped up. The boy then wears the book bag and walks out of the room. Finally, the video shows a boy in a blue shirt crossing over a tree trunk in a forest.
D. First, the video shows a boy in a blue shirt crossing over a tree trunk in a forest. Then, the video shows a book bag placed on the bed in a bedroom being zipped up. The boy then wears the book bag and walks out of the room. Finally, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing the book bag, walks up the stairs.
E. First, the video shows a room with yellow and white walls with a staircase inside it. The boy, wearing a book bag, walks up the stairs. Then, the video shows a boy in a blue shirt crossing over a tree trunk in a forest. Finally, in a bedroom, the video shows a book bag placed on the bed being zipped up. The boy then wears the book bag and walks out of the room.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  19%|‚ñà‚ñâ        | 29/150 [01:12<05:20,  2.65s/it][32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iJgh2dnudIU.mp4[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iJgh2dnudIU.mp4[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iJgh2dnudIU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=58[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is split into two sections, and in the small section on the far right, what is the man wearing a hat doing in front of a brown horse?
A. Walking the horse
B. Punching towards the camera
C. Riding the horse
D. Kneeling down
E. Extending his palm forward while facing the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7115052132578921774.mp4[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7115052132578921774.mp4[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7115052132578921774.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=61[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:45:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, pour olive oil into the iron pot, then demonstrate the olive oil in the pot against the background of a white cabinet and wooden countertop, and finally demonstrate the olive oil with dark green packaging and glass bottle.
B. First, demonstrate the olive oil in the pot against the background of a white cabinet and wooden countertop, then pour the olive oil into the iron pot, and finally demonstrate the olive oil with dark green packaging and glass bottle.
C. First, demonstrate the olive oil with dark green packaging and glass bottle, then pour the olive oil into the iron pot, and finally demonstrate the olive oil in the pot against the background of a white cabinet and wooden countertop.
D. First, pour olive oil into the iron pot, then demonstrate the olive oil with dark green packaging and glass bottle, and finally demonstrate the olive oil in the pot against the background of a white cabinet and wooden countertop.
E. First, demonstrate the olive oil with dark green packaging and glass bottle, then demonstrate the olive oil in the pot against the background of a white cabinet and wooden countertop, and finally pour the olive oil into the iron pot.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eJr-y6UXnRE.mp4[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eJr-y6UXnRE.mp4[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eJr-y6UXnRE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=63[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing a green short-sleeved shirt, holding a phone in their right hand, is facing 3 bottles on the table. What is this person holding in their left hand?
A. A can
B. A bun
C. A dumpling
D. Beef
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  20%|‚ñà‚ñà        | 30/150 [01:15<05:09,  2.58s/it][32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = by3NxI0dA6w.mp4[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/by3NxI0dA6w.mp4[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: by3NxI0dA6w.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=60[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a grayish-purple background, there are white letters spelling 'NATIVE AMERICA'. Next to the white letters, there is a handicraft. When the white letters 'NATIVE AMERICA' appear on a white wall, what color change occurs to the letters?
A. From white to blackish-gray
B. From white to yellow
C. From white to purple
D. From white to blue
E. From white to green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  21%|‚ñà‚ñà        | 31/150 [01:17<05:03,  2.55s/it][32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Y1YCvEip_ko.mp4[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Y1YCvEip_ko.mp4[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Y1YCvEip_ko.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=62[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the color of the first piece of clothing shown in the video?
A. white
B. purple
C. red
D. olive
E. black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bwnkg6GbXwU.mp4[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bwnkg6GbXwU.mp4[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bwnkg6GbXwU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=65[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a spacious room, a woman with long black hair and wearing black clothes, a man with glasses in white clothes, and another man in blue clothes are sitting on the floor. There is a silver frame above their heads. The man on the right is wearing jeans and sitting cross-legged. The woman on the left is wearing black shoes, sitting with her legs straight, resting one hand on the floor, and holding an interview device in the other hand. Where else does this woman appear?
A. On an escalator at the airport
B. Inside a hotel
C. In a taxi
D. On the light yellow sofa inside the room
E. On a bus
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  21%|‚ñà‚ñà‚ñè       | 32/150 [01:19<04:53,  2.49s/it][32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F4bDyyEO4PU.mp4[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F4bDyyEO4PU.mp4[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F4bDyyEO4PU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=64[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a few houses, three men stand before a mirror. One man is wearing a green hat, and another man is wearing black glasses. What did the man wearing black glasses do the first time he appeared?
A. Touched his head with his right hand.
B. Looked at the man wearing the green hat.
C. Touched his glasses with his right hand.
D. Lowered his head to look at a script, occasionally raising his head to speak to the mirror.
E. Covered his face with both hands.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6S_e34j6q9U.mp4[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6S_e34j6q9U.mp4[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6S_e34j6q9U.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=67[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is a round plate with small golden yellow food cubes, a polygonal plate with brown small food cubes, and another round plate with large golden yellow food pieces on a wooden table. Which plate of food appears first?
A. Polygonal plate with large golden yellow food pieces
B. Round plate with large golden yellow food pieces
C. Polygonal plate with brown small food cubes
D. Round plate with small golden yellow food cubes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = brZugTJ0odg.mp4[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/brZugTJ0odg.mp4[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: brZugTJ0odg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=69[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences is correct?
A. First, there is a food demonstration, followed by a cooking lesson including ingredient preparation, ingredient processing, and dish preparation, and then a presentation of the final cooked dishes.
B. First, there is a cooking lesson including ingredient preparation, ingredient processing, and dish preparation, followed by a presentation of the final cooked dishes, and then a food demonstration.
C. First, there is a food demonstration, followed by a presentation of the final cooked dishes, and then a cooking lesson including ingredient preparation, ingredient processing, and dish preparation.
D. First, there is a cooking lesson including ingredient preparation, ingredient processing, and dish preparation, followed by a food demonstration, and then a presentation of the final cooked dishes.
E. First, there is a presentation of the final cooked dishes, followed by a food demonstration, and then a cooking lesson including ingredient preparation, ingredient processing, and dish preparation.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 33/150 [01:23<05:20,  2.74s/it][32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UwJTCg5fpXg.mp4[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UwJTCg5fpXg.mp4[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UwJTCg5fpXg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=66[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the picture, a woman is sitting on a chair holding two children beside her. Another child is standing behind her. A boy in a black woolen coat and another boy in a blue jacket are visible. The girl is wearing a red woolen coat and a checkered skirt. There is a white glass door in the background and green plants on the side. Who is the child sitting on the armrest of the chair in the picture?
A. The child wearing a red woolen coat
B. The child wearing a blue jacket
C. The child wearing a grey jacket
D. The child wearing a green woolen coat
E. The child wearing a checkered shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  23%|‚ñà‚ñà‚ñé       | 34/150 [01:25<04:44,  2.45s/it][32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Jfp1Ks7Hh1E.mp4[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Jfp1Ks7Hh1E.mp4[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Jfp1Ks7Hh1E.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=68[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the yellow floor, a person wearing a blue top is pushing a wooden cart filled with various items. After the subtitles 'For the restoration, a lot of it was just cutting acid-free paperboard to the' appear, what does the person in the blue top do?
A. Opened the pigment tray
B. Wrote with a paintbrush
C. Held a red hammer
D. Used a brush to apply glue to the items
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WLl3SeraTV0.mp4[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WLl3SeraTV0.mp4[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WLl3SeraTV0.mp4 | Selected 11 frames[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=71[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 04:45:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a large marble countertop, there is a baking model. In the middle of the screen, a hand is holding a yellow jar and spraying it inward. What changes happen on the screen after the subtitle mentions 'so'?
A. This person is holding a gray scoop and is stirring it inside.
B. This person is holding a jar of chocolate sauce and is about to pour it in.
C. This person is holding a yellow jar of fruit sauce and is about to pour it in.
D. This person is holding a red scoop and is stirring it inside.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = T1K4rgs-1b8.mp4[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/T1K4rgs-1b8.mp4[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: T1K4rgs-1b8.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=73[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:45:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the first person to appear in the video?
A. The man sitting in front of a desk with a projector and computer in a room with hanging lights, wearing a black hoodie and jeans
B. The man sitting on the bed in a room with hanging lights, wearing a black short-sleeve shirt and black pants
C. The woman with black hair, wearing a black and white coat with a white top, a white headset around her neck, opening a door
D. The woman walking outdoors at night in front of a wall with English writing, wearing a black short-sleeve shirt and shorts, and carrying a paper bag while wearing headphones
E. The man in a dimly lit room, sitting in front of a computer, wearing a white hoodie and facing a mirror
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  23%|‚ñà‚ñà‚ñé       | 35/150 [01:27<04:45,  2.48s/it][32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = I-yg_3yx6iA.mp4[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/I-yg_3yx6iA.mp4[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: I-yg_3yx6iA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=70[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a woman with black hair tied up. Behind her is a brick wall, she is wearing a lanyard necklace, and it seems she is also wearing a black bracelet on her hand. What object is not present in the scene?
A. Red and white scarf
B. Black and white scarf
C. Brick wall
D. Red lanyard necklace
E. Black pillar
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ll3tR0kUZHc.mp4[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ll3tR0kUZHc.mp4[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ll3tR0kUZHc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=75[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under a gray sky, a bullet-riddled airplane is flying with red and white stripes on its tail wings. There is a red pattern dot on the back of the fuselage, and the rest of the plane is silver. When the subtitle 'the aircraft falling away after being' appears, what is the shape of the red pattern on the tail of the fuselage?
A. A star
B. A square
C. A triangle
D. A pattern composed of a rectangle and a star
E. A rectangle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  24%|‚ñà‚ñà‚ñç       | 36/150 [01:30<04:47,  2.53s/it][32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5zbV24vyO44.mp4[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5zbV24vyO44.mp4[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5zbV24vyO44.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=72[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A long-haired woman wearing a white short-sleeve shirt is standing in front of a white table. On the countertop behind her are some small potted plants and kitchen utensils. There is a colorful question mark sticker on the cupboard above the countertop, and the tiles on the wall are hexagonal. A paper is placed in front of the woman. After the subtitle 'be right back cover with the small oven' appears, what does the woman do?
A. The woman picks up a plate
B. The woman picks up the paper
C. The woman eats an apple
D. Search for the baking tray
E. The woman picks up a vegetable knife
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6965059948090821890.mp4[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6965059948090821890.mp4[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6965059948090821890.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=77[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:45:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a gloomy day, there is a flat road. On the road, there is a woman wearing a white top and green pants. What is the woman in the white top doing on the flat road?
A. Jumping rope
B. Running
C. Dancing
D. Doing push-ups
E. Doing high leg raises
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ytv-9RM4e0o.mp4[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ytv-9RM4e0o.mp4[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ytv-9RM4e0o.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=79[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner of the screen, there's a frame with a blue background wall, and on the wall, there are black clothes and a bag hanging, along with a man with short black hair. After this man says 'by a thousand samples of the test set,' what does he do next?
A. Touches the brain with a hand
B. One hand extends with the index finger pointing upwards
C. Both hands extend with index fingers pointing upwards
D. Both hands spread outwards
E. One hand touches the forehead
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  25%|‚ñà‚ñà‚ñç       | 37/150 [01:32<04:50,  2.57s/it][32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tYqDvtknII4.mp4[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tYqDvtknII4.mp4[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tYqDvtknII4.mp4 | Selected 15 frames[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=74[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 04:45:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bar chart appears on the screen, one bar is purple, and the other is yellow. The two bars are compared, with the years indicated below. What shows up after the bar chart appears?
A. A city map
B. A glass of water
C. A smartphone
D. Fried chicken
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  25%|‚ñà‚ñà‚ñå       | 38/150 [01:34<04:26,  2.38s/it][32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kONR5_mHofA.mp4[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kONR5_mHofA.mp4[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kONR5_mHofA.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=76[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:45:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a spacious yellow room with many lights on, there is a man wearing a red and black checkered shirt. When the subtitle 'everyone you join me' appears, what change happens to the man wearing a red and black checkered shirt?
A. The man's shirt changes from a red and black checkered shirt to a white hoodie
B. The man's shirt changes from a red and black checkered shirt to a yellow short sleeve
C. The man's shirt changes from a red and black checkered shirt to a black short sleeve
D. The man's shirt changes from a red and black checkered shirt to a blue suit
E. The man's shirt changes from a red and black checkered shirt to a black hoodie
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = T57jVsvVVR0.mp4[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/T57jVsvVVR0.mp4[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: T57jVsvVVR0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=81[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a white background in the screen with a blue and white rectangular pattern inside. The rectangle contains eight identical character icons, seven of which are green and one is brown. What change occurs on the screen when 'nurnbers sha finished 11th but by comning' is mentioned?
A. The green character below the brown character is labeled '8th place'
B. The green character below the brown character is labeled '11th place'
C. The green character below the brown character is labeled '9th place'
D. The green character below the brown character is labeled '10th place'
E. The green character below the brown character is labeled '12th place'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  26%|‚ñà‚ñà‚ñå       | 39/150 [01:36<03:57,  2.14s/it][32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mfS6gyP0mwo.mp4[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mfS6gyP0mwo.mp4[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mfS6gyP0mwo.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=78[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Standing in front of two flagpoles tied with white ribbons, what color is the clothing of the man holding the white paper and giving a speech when he says 'minister Wong and others to continue uh'?
A. black
B. blue
C. red
D. yellow
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9m4wi5gPdHg.mp4[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9m4wi5gPdHg.mp4[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9m4wi5gPdHg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=83[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the upper right corner of the frame, there is a woman with long hair wearing a purple top, sitting on a black object. The wall behind her is white. At this moment, the camera is facing forward. When the camera turns and the yellow wall on the left is revealed, what change occurs to the object the woman is holding in her left hand?
A. It changes to a calculator
B. It changes to a ruler
C. It changes to a piece of white paper
D. It changes to a circle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 40/150 [01:38<04:04,  2.22s/it][32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Efuyl2Anehg.mp4[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Efuyl2Anehg.mp4[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Efuyl2Anehg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=80[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x5361fec0] mmco: unref short failure
[32m2025-11-28 04:45:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, there stands a person in a black silhouette wearing a hat. After this person opens a safe containing gold and paper money, what does the man, who is in a black silhouette and wearing a hat, do?
A. Took the paper money
B. Danced
C. Drank water
D. Watched TV
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bgklOaBBmB8.mp4[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bgklOaBBmB8.mp4[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bgklOaBBmB8.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=85[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a gray coat and sporting short black hair is sitting upright on a cream-colored couch against a cream-colored background, eating from a green-white dessert bowl. What subtitle appeared at the same time as this man?
A. The next morning
B. And it comes with my own Arabic TV.
C. And if you can see, it's written in Arabic.
D. It's a little after 10 and I just made it to Bahrain.
E. You golta buy tulip bulbs.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 41/150 [01:41<04:12,  2.31s/it][32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JLnsWrzV_j4.mp4[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JLnsWrzV_j4.mp4[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JLnsWrzV_j4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=82[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the brown wooden table, there is a transparent bowl filled with meat and broth. A pair of hands on either side of the bowl lifts it up. After lifting the bowl, what transition occurs in the scene?
A. From the floor to the microwave
B. From the table to the floor
C. From the table to the microwave
D. From the table to the chair
E. From the table to outside
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pGEF7Tme3Tk.mp4[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pGEF7Tme3Tk.mp4[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pGEF7Tme3Tk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=87[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man with black parted hair, wearing a blue shirt, a black backpack, and a wristwatch is kneeling on the ground, looking troubled at the scattered items on the ground. When the caption 'having an accident that distracts her' appears, what color is the wristwatch worn by this man?
A. Blue
B. Pink
C. Green
D. White
E. Black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 42/150 [01:44<04:18,  2.40s/it][32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RN2g9sRuJhA.mp4[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RN2g9sRuJhA.mp4[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RN2g9sRuJhA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=84[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a silver desktop, there is a wooden board. On the wooden board, there is an empty silver metal plate. A blond man wearing a black short-sleeved shirt is holding a spatula with his left hand and looking at the plate. When the plate and the subtitle 'uh and like I was saying at the start' appear simultaneously, what change occurs to the plate?
A. Yellow food material appears in the plate
B. Green food material appears in the plate
C. Eggs appear in the plate
D. Blue flowers appear in the plate
E. Eggs and beans appear in the plate
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8MkL3W6wU3g.mp4[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8MkL3W6wU3g.mp4[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8MkL3W6wU3g.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=89[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:45:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white tiles, there is a gray countertop. Next to the countertop stands a man wearing a blue checkered shirt, with tattoos on his arms. Beside him, there is a white bowl containing potatoes. What is he doing?
A. Washing the tomatoes
B. Peeling the potatoes
C. Cutting the potatoes
D. Washing the green peppers
E. Washing the potatoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:45:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  29%|‚ñà‚ñà‚ñä       | 43/150 [01:46<04:24,  2.47s/it][32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mkqgTAe2_O4.mp4[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mkqgTAe2_O4.mp4[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mkqgTAe2_O4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=86[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:45:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some workers are working in a yard, surrounded by wooden frames. On the left side of the screen, there is a pillar, and the subtitle 'five months of working side by side we' appears. Who is the first person to appear after this?
A. A foreign man wearing a light blue shirt, khaki pants, and a hat
B. A Chinese worker wearing dark blue sleeves
C. A foreign journalist holding a camera
D. A Chinese worker wearing a red hat
E. A foreign leader taking a group photo with the workers
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VL259eBJ68w.mp4[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VL259eBJ68w.mp4[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VL259eBJ68w.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=91[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman, dressed as ordinary people, are holding shovels and digging soil. The man is wearing a hat, and the woman is wearing a headscarf. There are two soldiers in blue uniforms with black hats holding guns nearby. In the distance, there are some green plants. What is present in this scene?
A. A photographer wearing a hat
B. Skirts
C. Advancing cannons
D. NP-News-Programers
E. Various colored horses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  29%|‚ñà‚ñà‚ñâ       | 44/150 [01:49<04:20,  2.46s/it][32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -kaF6SnSEo8.mp4[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-kaF6SnSEo8.mp4[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -kaF6SnSEo8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=88[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman in a black dress in the kitchen. Behind her, there is a white cabinet with some items on it and a window with white curtains. The curtains are flanked by wooden shelves. In front of her, there is a large counter with a cast iron pot on it. Above the pot is a large stainless steel bowl which she is holding with both hands. Next to them, there is a large pink container with red liquid inside. What is the woman doing in the kitchen?
A. Turned the large bowl upside down
B. Put a lid on the large bowl
C. Moved the large bowl to the windowsill
D. Placed the large bowl on the counter
E. Put the large bowl on the pink container
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mq6L8CnNJXc.mp4[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mq6L8CnNJXc.mp4[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mq6L8CnNJXc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=93[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a pie chart representing the Czech Ethnicity appears in the video, with blue occupying the largest portion, red being the second, and light green the least, which of the following sentences is displayed on the screen?
A. 25% "Unspecified"
B. 60% ‚Äúdeclared‚Äù Czech
C. 95% Czech
D. 38% Czech
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  30%|‚ñà‚ñà‚ñà       | 45/150 [01:51<04:18,  2.46s/it][32m2025-11-28 04:46:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SCZ_Z4NnikA.mp4[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SCZ_Z4NnikA.mp4[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SCZ_Z4NnikA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=90[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white shelf, there is a pair of mismatched shoes, and next to the shoes, there's a wooden-colored bag. What kind of fastener does the bag in the video have?
A. It is a gold square fastener
B. It is a silver square fastener
C. It is a silver round fastener
D. It is a gold round fastener
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eE5Z7gDbgVA.mp4[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eE5Z7gDbgVA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=95[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a river in a grove, with green grass on the hillside next to it. On the left side of the river are green plants, and on the right side are white rocks. Some water is flowing in the river, and there is a bridge above it. What color are the railings of the bridge?
A. Yellow
B. White
C. Brown
D. Green
E. Black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  31%|‚ñà‚ñà‚ñà       | 46/150 [01:54<04:28,  2.58s/it][32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VL259eBJ68w.mp4[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VL259eBJ68w.mp4[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VL259eBJ68w.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=92[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a yellow shirt is standing in front of a gray background. His mouth shows a full set of white teeth. The man is holding a toy in one hand and a bag of food in the other hand. There is a paper bag in front of him. When the subtitle 'a whole lot easier' appears, what is the man's hairstyle like?
A. golden long hair
B. silver short hair
C. black short hair
D. silver long hair
E. golden short hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LfUsGv-ESbc.mp4[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LfUsGv-ESbc.mp4[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LfUsGv-ESbc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=97[0m
[32m2025-11-28 04:46:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a black-haired woman wearing a black strappy dress and a man with dark skin in a black chef's uniform are in a kitchen. The cabinets behind them are white, and the windows have white curtains. On either side of the windows are wooden shelves holding some items. In front of them is a large wooden table. The woman has her arms crossed and is smiling slightly, while the man is holding a semi-circular lid. What are they doing in the kitchen?
A. The man lifts the lid in his hand
B. The man flips the lid in his hand
C. The woman opens the lid in the man's hand
D. The man drops the lid in his hand
E. The man and woman are shaking hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  31%|‚ñà‚ñà‚ñà‚ñè      | 47/150 [01:57<04:28,  2.61s/it][32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mS1QPVgBDQo.mp4[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mS1QPVgBDQo.mp4[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mS1QPVgBDQo.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=94[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen displays a Google webpage, with a white background featuring five pictures. The right section has a black background with one picture. In the bottom right corner, there's a man with short hair wearing glasses and dressed in black who is explaining something. He has a beard, and the background behind him is grey. Above these images on the white background, there are eight identical icons related to the images. What is the shape of these icons?
A. Oval
B. Circle
C. Triangle
D. Square
E. Rectangle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QHS9ZZBdK-g.mp4[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QHS9ZZBdK-g.mp4[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QHS9ZZBdK-g.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=99[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the interview with a green background, at the bottom, there is a visible audience, and at the top, there are three women sitting and talking. The woman in the middle is wearing a red and blue checkered shirt and has white hair. During the performance later, what change occurs to the woman in the middle, who is wearing a red and blue checkered shirt and has white hair?
A. She put on a white hat
B. She put on a black hat
C. Her hair turned black
D. She tied a black ribbon around her head
E. She changed into a white suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 48/150 [02:00<04:53,  2.88s/it][32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = N7RTTiHsSjI.mp4[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/N7RTTiHsSjI.mp4[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: N7RTTiHsSjI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=96[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a beige screen, there is English text in orange, red, and black. In the lower right corner, a man is talking to Mike. What color is the jacket that the man is wearing?
A. green
B. blue
C. yellow
D. red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = xiK00WS0lkE.mp4[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/xiK00WS0lkE.mp4[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: xiK00WS0lkE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=101[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a flat ground, the left side is the exterior wall of a building. There are two windows on the exterior wall, two outdoor units of air conditioners, and several plants at the bottom. In the middle, there are 7 people, 5 of whom are looking upward. There is a car in front of them, and there is a liquid on the car. Could you please tell me the color of the liquid on the car at this time?
A. Purple
B. Black
C. Blue
D. White
E. Blood Red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 49/150 [02:03<04:48,  2.85s/it][32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbcWAfHo5j0.mp4[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbcWAfHo5j0.mp4[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbcWAfHo5j0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=98[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a man wearing gray clothes with a beard facing a whiteboard. He is holding a pen in his right hand, and the whiteboard has markings in blue and black pen. What did the man do when he appeared in the video?
A. Dropped the pen
B. Marked the whiteboard with a pen
C. Did nothing
D. Erased the whiteboard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Q4GK4asczVA.mp4[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Q4GK4asczVA.mp4[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Q4GK4asczVA.mp4 | Selected 11 frames[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=103[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 04:46:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a group of girls wearing blue tops walk down the stairs from the second floor of the building with green plants on the right, what kind of skirts are they wearing?
A. Super short skirt
B. Pleated short skirt
C. Dress
D. Knee-length skirt
E. Ankle-length skirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 50/150 [02:06<04:38,  2.79s/it][32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AnLMDMzO4QY.mp4[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AnLMDMzO4QY.mp4[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AnLMDMzO4QY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=100[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bedroom with a few paintings hanging on the wall, a woman wearing a blue shirt, suspenders, and glasses, with a smile on her face, is holding items in dark blue, white, and olive green colors. On a table, there are 3 perfume cards, each with items of dark blue, white, and olive green colors. Which scene appears first?
A. First appears the woman in a bedroom with a few paintings hanging on the wall, wearing a blue shirt, suspenders, and glasses, smiling and holding items in dark blue, white, and olive green colors. Last appears the table with 3 perfume cards, each with items in dark blue, white, and olive green colors.
B. First appears the table with 3 perfume cards, each with items in dark blue, white, and olive green colors. Last appears the woman in a bedroom with a few paintings hanging on the wall, wearing a blue shirt, suspenders, and glasses, smiling and holding items in dark blue, white, and olive green colors.
C. They appear simultaneously.
D. First appears the woman in a bedroom with a few paintings hanging on the wall, wearing a blue shirt, suspenders, and glasses, smiling and holding items in dark blue, white, and olive green colors. Last appears the solo scene of the woman.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6hBbXVkgxGE.mp4[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6hBbXVkgxGE.mp4[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6hBbXVkgxGE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=105[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which subtitles appear together with the woman wearing a white top, denim overalls, and round earrings in the beginning of the video?
A. we've got the cookies and the freezer and cooling for about maybe 10 minutes so appear together
B. love the fact they're sweet and
C. the a hint of salt

D. beath bars are mike chocolate covered
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 51/150 [02:08<04:22,  2.65s/it][32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mq6L8CnNJXc.mp4[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mq6L8CnNJXc.mp4[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mq6L8CnNJXc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=102[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing a black coat is sitting, holding a document. Next to him is a table with a gun and a cell phone on it. There's a black lamp on the table. Who is holding the document?
A. Statham
B. Dougie
C. Jan
D. Mike
E. Bullet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hznvV2bBkX4.mp4[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hznvV2bBkX4.mp4[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hznvV2bBkX4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=107[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wall with blue ceramic tiles, there's a man with a mustache, carrying a backpack and wearing a short-sleeved shirt. What is the color of the straps on the backpack he's carrying in the video?
A. Olive
B. Black
C. White
D. Gray
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 52/150 [02:11<04:29,  2.75s/it][32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7259227637992705282.mp4[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7259227637992705282.mp4[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7259227637992705282.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=104[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black and white footage, there is a curly-haired woman wearing a black dress, holding a bag, standing on an empty street. What is she doing?
A. She is turning around and greeting someone
B. She is waiting for the bus by the roadside
C. She is walking on the street
D. She is looking through her bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3pTVbQilDqY.mp4[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3pTVbQilDqY.mp4[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3pTVbQilDqY.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=109[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:46:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Sitting in a studio, what is an elderly person wearing glasses and dressed in a black coat and purple shirt doing?
A. Moving materials
B. Shaking hands with someone
C. Talking to the camera
D. Testing equipment
E. Taking photos
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gyV6EqgiPNg.mp4[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gyV6EqgiPNg.mp4[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gyV6EqgiPNg.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=111[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:46:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a ponytail appears in the middle of the screen, with 'The camera only works with people' text at the bottom of the screen. Which item appears in the middle of the screen?
A. earrings
B. hat
C. crown
D. necklace
E. earphones
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 53/150 [02:14<04:24,  2.73s/it][32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7074483613273754882.mp4[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7074483613273754882.mp4[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7074483613273754882.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=106[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:46:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen, a white plate is holding several buns, with a hand picking up one of the buns. When the subtitle 'the biggest change in the recipe was adding chocolate chips i did it for sake of my children' appears, what pattern is on the cloth under the plate?
A. white striped
B. black and white striped
C. black and white checkered
D. white checkered
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VFXJnbnN5ro.mp4[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VFXJnbnN5ro.mp4[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VFXJnbnN5ro.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=113[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a floor-to-ceiling window with a view of tall buildings there is a beauty room with pink walls and a white beauty bed. When the subtitle 'Okay, let's get started' appears, what objects are present in the scene?
A. false eyelashes
B. face mask
C. powder puff
D. lighting stand
E. mirror
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 54/150 [02:16<04:10,  2.61s/it][32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KTY9bogonyw.mp4[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KTY9bogonyw.mp4[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KTY9bogonyw.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=108[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, there's an image of a green nebula in the middle. The wallpaper's cover is a computer screenshot, and the page contains many computer desktop icons. In which of the following scenes does this green nebula image appear?
A. In space, there's a green mist-like star in the middle, with some white star points in the green background.
B. In the middle of the screen, there's a selfie of a couple. The boy has his eyes closed, with a yellow backpack strap on his right shoulder, and the girl is closely leaning against the boy's face.
C. The screen shows a semi-circle with a yellow light along its edge, and the words 'Planetary Nebula' printed in the middle.
D. In a hazy, dark gray background, a rainbow-colored drop-like object is in the middle of the screen, with the label 'SN 1604' in the lower-left corner.
E. In a black starry background with many star points, there's a reddish cloud-like object in the starry sky, with the label 'NGC 1976' in the lower-left corner.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HWyDOQrYtCk.mp4[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HWyDOQrYtCk.mp4[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HWyDOQrYtCk.mp4 | Selected 11 frames[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=115[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 04:46:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the screen, there is a white-haired man dressed in a black suit with a dark blue tie, sitting in front of a white flag with a blue Star of David. What is this white-haired man doing?
A. Drinking water
B. Sleeping
C. Writing
D. Speaking into a microphone
E. Brewing tea
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 55/150 [02:19<04:16,  2.70s/it][32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OMJc43wUPLM.mp4[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OMJc43wUPLM.mp4[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OMJc43wUPLM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=110[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the yellow table, there is a white bowl with instant noodles inside and a pair of chopsticks placed in the bowl. There is also a dark green bowl with vegetables and a blue plate with a fried egg. What items appeared after the word 'Music' was mentioned?
A. Fried egg
B. Instant noodles
C. Tablet, Milk Tea
D. Vegetables
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KWv8DJMEHsE.mp4[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KWv8DJMEHsE.mp4[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KWv8DJMEHsE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=117[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a map with many place names, there are some gray-green arrows. Beside the map, there's a standing red box. Inside the red box, there are two gray circles. In one of the gray circles, there are two opposite white arrows. When the gray circle with the two opposite white arrows appears in a pure red screen with four gray circles, what changes occur to the white arrows in the gray circle?
A. The arrows change from opposing to rotating in the same direction.
B. The white arrows change to black arrows.
C. The arrows change from opposing to intersecting with each other.
D. The arrows change from opposing to being parallel to each other.
E. The white arrows change to yellow arrows.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 56/150 [02:21<04:03,  2.59s/it][32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d5JlCEDlHGE.mp4[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d5JlCEDlHGE.mp4[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d5JlCEDlHGE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=112[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two men wearing straw hats and grey clothes stand in a grass field holding long knives. Behind them are a few green trees and a house. What does the house behind them look like?
A. Wooden house
B. Building
C. Villa
D. Straw hut
E. Earthen house
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = q2bpkhjNxf0.mp4[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/q2bpkhjNxf0.mp4[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: q2bpkhjNxf0.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=119[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:46:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows an animation with blue sky and white clouds, followed by a staircase. The grey staircase has an olive green slope in the middle. A rectangular object wrapped with a string is being pulled upwards along the slope. Which subtitles have appeared together with this rectangular object?
A. welcome
B. While it is important to note that this evidence comes
C. thak you 
D. h
E. so
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UwlKYM2Sotg.mp4[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UwlKYM2Sotg.mp4[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UwlKYM2Sotg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=121[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white, square-patterned floor, there is a person with some white hair, wearing a black short-sleeve shirt with red designs. He also has a beard. What is this man doing?
A. Reading a book
B. Fishing
C. Drinking water
D. Playing piano
E. Talking
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 57/150 [02:24<04:06,  2.65s/it][32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F2OhCCEIOcU.mp4[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F2OhCCEIOcU.mp4[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F2OhCCEIOcU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=114[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Three men appear on the screen. The man on the left is wearing a red shirt, the man in the middle is wearing a black shirt and jeans, and the man on the right is leaning on a blue shelf that holds various items. What did the man in the middle, who is wearing a black shirt, do the first time he appeared?
A. Folded his arms in front of his chest
B. Picked up a key
C. Picked up a watch
D. Put his hand on a companion's shoulder
E. Picked up a cup of water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pJuq8D1NGJQ.mp4[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pJuq8D1NGJQ.mp4[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pJuq8D1NGJQ.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=123[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:46:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
According to the video, which of the following scenes appears first?
A. A green field under a blue sky with several red-walled, black-roofed buildings
B. A construction vehicle lifting timber
C. A truck driving on the road
D. A vast wilderness with a huge pit
E. A grassy area with a lakeside and a row of trees separating the grass from the lake
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = X5v4nBo5y28.mp4[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/X5v4nBo5y28.mp4[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: X5v4nBo5y28.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=125[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, the man wearing red short sleeves and sunglasses is holding a phone in his right hand, and sitting outside with a few green plants in the background. In which other scene does this man appear?
A. By the seaside
B. Inside a room with a TV in the background
C. Inside a milk tea shop
D. Inside a fried chicken shop
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñä      | 58/150 [02:27<04:04,  2.66s/it][32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XJ6REZOXsvM.mp4[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XJ6REZOXsvM.mp4[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XJ6REZOXsvM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=116[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white walls, there is a woman with curly hair wearing a black short-sleeved shirt on the left, and a man with short hair wearing a white coat on the right. Behind them, there is a bright object. When the subtitle mentions 'She then asks him why he wants to know, and he tells her because he has been arrested,' who is the first person to appear making a phone call in prison?
A. A man in a black outfit
B. A woman in an orange outfit
C. A man in a purple outfit
D. A man in an orange outfit
E. A man in a white outfit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lzAESaVqix0.mp4[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lzAESaVqix0.mp4[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lzAESaVqix0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=127[0m
[32m2025-11-28 04:46:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, there is a table beside a sofa. On the sofa, there is a man with short hair wearing a long-sleeved shirt. In front of him, there is a transparent window. In front of the window, there is another table with decorations on it. To the left of it, there is a glowing screen. To the left of the screen, there is a burning fireplace. Next to the man, there is also a lamp. What is the shape of the glowing screen?
A. Circle
B. Pentagon
C. Oval
D. Triangle
E. Square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 59/150 [02:29<03:59,  2.64s/it][32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MJYBHfYF8LI.mp4[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MJYBHfYF8LI.mp4[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MJYBHfYF8LI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=118[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After a man wearing a red short-sleeved shirt and a black hat finished speaking in front of a black background, what did this man do?
A. picked up a basketball
B. picked up a stick
C. picked up a soccer ball
D. picked up a painting
E. picked up a pot of flowers
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7276598470151032066.mp4[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7276598470151032066.mp4[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7276598470151032066.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=129[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the city streets, there is a white truck in the middle of the screen. In the distance, there is a yellow building, and nearby on the left, a woman in black clothes with short hair is talking to a man on the right who is also wearing black. When the subtitles mention 'you met with investors in Hong Kong and Kuala Lumpur in Singapore who are', what did the man do?
A. opened the car door
B. hugged the woman briefly
C. waved a few times to the woman
D. took out a phone
E. picked up a pair of scissors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 60/150 [02:32<04:07,  2.75s/it][32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oCXKARwr6PA.mp4[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oCXKARwr6PA.mp4[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oCXKARwr6PA.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=120[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:46:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an image of a young girl with a yellow background, wearing a headscarf, accompanied by feathers and some simple ornaments, which objects have never appeared?
A. Yellow headscarf
B. Pearl earrings
C. Blue gemstone earrings
D. Blue gemstones
E. Peacock feathers
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 61/150 [02:34<03:31,  2.37s/it][32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2vVQo_GMA70.mp4[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2vVQo_GMA70.mp4[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2vVQo_GMA70.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=122[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a young man stands on the left side of the screen, and an elderly man with white hair, wearing a red plaid shirt, stands on the right side of the screen. The two face each other. What did this elderly man do the first time he appeared?
A. Was washing his hair
B. Held a knife towards himself
C. Looked in the mirror
D. Held a knife towards the person in front
E. Was cutting his hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZRMbh0wSly0.mp4[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZRMbh0wSly0.mp4[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZRMbh0wSly0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=131[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a grey concrete ground, a group of girls dressed in the same white tops and beige floral skirts hold hands to form a circle. When mentioning the 'collodion anole rain making ritual,' what kind of ornaments are on the girls' skirts?
A. Waist belts adorned with colorful flowers
B. Small skirts adorned with colorful flowers
C. Green leaf-shaped small skirts
D. Small animal-shaped ornaments made of folded green leaves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RN2g9sRuJhA.mp4[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RN2g9sRuJhA.mp4[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RN2g9sRuJhA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=133[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the first person to appear in the video?
A. The woman wearing a black T-shirt with white patterns and black long hair
B. The woman wearing a white coat and glasses
C. The child wearing a hat
D. The man wearing a suit
E. The child without a shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 62/150 [02:37<03:55,  2.67s/it][32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lN3WnXMaE0o.mp4[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lN3WnXMaE0o.mp4[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lN3WnXMaE0o.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=124[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A soldier wearing a golden helmet is standing on a grassy field near a wooden fence. Holding a water bag, three drops fall from it. After the subtitle 'you will have to pay for it in blood' appears, what is the first object that appears on the screen?
A. A person with white hair holding a green shield
B. A person wearing a red robe with black hair
C. Three shields
D. A person with yellow hair holding a water bag
E. A soldier holding a red shield and wearing a helmet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 63/150 [02:39<03:39,  2.52s/it][32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6880172230588894465.mp4[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6880172230588894465.mp4[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6880172230588894465.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=126[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a natural wood-colored floor, there is a man standing who is wearing a blue shirt and has tattoos on his arms. In front of him, there are cut tofu strips, and to the left, there is a white plate. To his right, there is an orange object. What is he doing?
A. Sprinkling salt on tofu
B. Cutting green peppers
C. Washing tofu strips
D. Frying tofu strips
E. Cutting tofu strips
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = I-yg_3yx6iA.mp4[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/I-yg_3yx6iA.mp4[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: I-yg_3yx6iA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=135[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The upper left side of the screen shows a window overlooking the street below. When the yellow-green packaged snack first appears on the screen, what is happening in the scene?
A. The screen transitions from blurry to clear
B. Pouring the snacks out
C. Tearing open the snack package
D. The person in the video is eating the snacks
E. Showing the snack package to the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 64/150 [02:41<03:23,  2.36s/it][32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ysRFFN5nzqE.mp4[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ysRFFN5nzqE.mp4[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ysRFFN5nzqE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=128[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the gray background, a row of soldiers wearing green uniforms is advancing along the diagonal staircase, holding guns. There is a bold white English text in the center of the screen. When the subtitle 'koreas the war was an international' appears, what shape is the figure at the bottom of the stairs?
A. triangle
B. square
C. pentagon
D. rectangle
E. circle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TFbGLEZ4qt0.mp4[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TFbGLEZ4qt0.mp4[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TFbGLEZ4qt0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=137[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a rectangular wooden board hanging on a wall, a woman with long black hair, wearing a black leather jacket, is sitting in front of a table with a water cup and a flat panel. What is the color of the water cup on the table when the subtitle says 'to Melissa miracle calm and I'll see you'?
A. yellow
B. white
C. blue
D. black
E. red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 65/150 [02:44<03:28,  2.46s/it][32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = soNQYQXrx_A.mp4[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/soNQYQXrx_A.mp4[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: soNQYQXrx_A.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=130[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with long black straight hair is in a white room. She is wearing a white jacket and a pink shirt. On the left side is the room's door, and on the right side is a white display shelf with a desk lamp, a vase, and some pictures. She is sitting in front of a desk talking. On the right side of the desk, there is also a bucket filled with many colored pencils and a bouquet of flowers. What action did this woman take?
A. She adjusted her hair a bit
B. She picked up the colored pencils
C. She turned around and looked at the shelf
D. She stood up and walked out of the room
E. She is gesturing with her hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7284252812194729248.mp4[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7284252812194729248.mp4[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7284252812194729248.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=139[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:46:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene where a woman wearing a white top is standing on barren ground, the subtitles say 'Hatch Flood freaks out and leaves, but Justin manages to tell him one last time where he' ‚Äî during this time, what change occurs to the woman's clothing?
A. She changes into an olive-colored coat
B. She changes into a blue coat
C. She changes into a black coat
D. She changes into a yellow floral dress
E. She changes into a white sweater
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:46:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 66/150 [02:47<03:39,  2.61s/it][32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = md3LVlEzFBU.mp4[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/md3LVlEzFBU.mp4[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: md3LVlEzFBU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=132[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:46:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What change occurred on the gray marble table with food placed on a white plate when the subtitles 'ASAP baby Hurry up don't say maybe Hi, it's me again, I'm back' appeared?
A. From indoors to outdoors on a wooden table
B. From a white plate to a black plate
C. From a white plate to a yellow plate
D. From a full plate to a partially empty plate
E. From a white plate to a blue plate
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -An3wZyoYe0.mp4[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-An3wZyoYe0.mp4[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -An3wZyoYe0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=141[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The dazzling sunlight shines in the upper left corner of the sky, a yellow tank's gun barrel pointing to the upper left, with a white C-shaped logo on the tank's body, and the tank‚Äôs tracks are pressing against the grass. When the subtitle 'serious drawback its gun could only be' appears, what color is the background of the square within the C shape on the tank?
A. white
B. blue
C. olive
D. black
E. yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 67/150 [02:49<03:35,  2.60s/it][32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Scne0ls23MA.mp4[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Scne0ls23MA.mp4[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Scne0ls23MA.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=134[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:47:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a man in a white short-sleeve shirt, with a large rectangular account book (or register) behind him, and a brown object with a round spike at the top right corner of the screen, which of the following characters has appeared before?
A. A person wearing a blue and white headscarf and a black short-sleeve shirt
B. A person wearing a blue and white headscarf and a white short-sleeve shirt
C. A person wearing a red and white headscarf and a black short-sleeve shirt
D. A person wearing a red and white headscarf and a black and white striped short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 68/150 [02:51<02:58,  2.18s/it][32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WmrwQMFZLqI.mp4[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WmrwQMFZLqI.mp4[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WmrwQMFZLqI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=136[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a woman dressed in a blue suit with black hair adorned with a pink flower is squatting in a green vegetable garden. Next to her, a little girl with golden hair wearing a white outfit and a white hat is also squatting. When the subtitle 'making conservation education enjoyable' appears, what are they doing?
A. Picking vegetables
B. Planting flowers
C. Planting vegetables
D. Watering the vegetables
E. Playing a game
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = x1FkhxMMIcg.mp4[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/x1FkhxMMIcg.mp4[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: x1FkhxMMIcg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=143[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a short-haired woman wearing a long-sleeved suit with an apron in the video. Her hands are placed in front of her chest, with her right thumb pointing up. In front of her is a stove with a yellow pot on it. What color is the apron worn by the woman in the video?
A. Green
B. Black
C. Yellow
D. White
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 69/150 [02:53<02:58,  2.20s/it][32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GGwHSz9towk.mp4[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GGwHSz9towk.mp4[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GGwHSz9towk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=138[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, the male host speaks, then the female host and the teacher have an online discussion, and finally, the female host introduces the teacher.
B. First, the male host speaks, then the female host introduces the teacher, and finally, the female host and the teacher have an online discussion.
C. First, the female host introduces a teacher, then the female host and the teacher have an online discussion, and finally, a male host speaks.
D. First, the female host and the teacher have an online discussion, then the female host introduces the teacher, and finally, a male host speaks.
E. First, the female host and the teacher have an online discussion, then the male host speaks, and finally, the female host introduces the teacher.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = t48HXAjjDAU.mp4[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/t48HXAjjDAU.mp4[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: t48HXAjjDAU.mp4 | Selected 15 frames[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=145[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 04:47:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The curly-haired man in the blue shirt, standing in front of the stone carving, what is the curly-haired man in the blue shirt doing?
A. Touching
B. Painting
C. Admiring
D. Carving
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 70/150 [02:55<02:57,  2.21s/it][32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6Lb1PyJxVQM.mp4[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6Lb1PyJxVQM.mp4[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6Lb1PyJxVQM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=140[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into two different characters' headshots on the left and right. The left headshot is of a person with glasses shouting. In the red frame at the bottom, it is written in white English text 'Hundreds rally in Tel Aviv for ceasefire in Gaza'. Whose hair is being blown messily by the strong wind in the screen?
A. A female reporter wearing a white coat
B. A male reporter wearing a grey coat
C. A female reporter wearing a black coat
D. A female reporter with glasses
E. A female reporter wearing a purple coat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bUaFXONIXzM.mp4[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bUaFXONIXzM.mp4[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bUaFXONIXzM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=147[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, who is the person standing in front of the yellow dirt slope, holding food in their left hand and chopsticks in their right hand?
A. The man wearing a white short-sleeve shirt with tattoos on both arms
B. The woman wearing a black short-sleeve shirt
C. The man wearing a yellow short-sleeve shirt
D. The man wearing a black jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 71/150 [02:58<03:08,  2.39s/it][32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 88LbBgZP1vQ.mp4[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/88LbBgZP1vQ.mp4[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 88LbBgZP1vQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=142[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A long-haired woman wearing a white long-sleeved shirt is holding a cup of a brown-packaged drink with a green human face printed on it. Where has this drink appeared before?
A. In a kitchen
B. On a grass field
C. In the hands of a woman looking at a yellow stain on a white shirt
D. On a table
E. In a coffee shop
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ip9DbdOtqF4.mp4[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ip9DbdOtqF4.mp4[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ip9DbdOtqF4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=149[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a car, there is a black seat, a short-haired man wearing a gray shirt, and a long-haired woman sitting next to him. In which of the following locations has the short-haired man appeared?
A. Verdant forest
B. Beautiful seaside
C. Quiet park
D. Crowded amusement park
E. Indoor basketball court
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 72/150 [03:01<03:26,  2.65s/it][32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7257359603489443073.mp4[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7257359603489443073.mp4[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7257359603489443073.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=144[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A little girl appears in front of a wall. She is holding two whips and is dressed in a light-colored top and dark-colored trousers. There is a piece of white paper hanging on the wall in front of her. What did the little girl do the first time she appeared on the scene?
A. Grabbed the white paper
B. Raised both hands
C. Used a tool to imprint a design on the white paper
D. Bent down and bowed
E. Waved her hands left and right
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bwDfdTh0VYs.mp4[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bwDfdTh0VYs.mp4[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bwDfdTh0VYs.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=151[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a woman with white hair wearing blue clothes. Behind her, there is a man in a white coat and another woman in white clothes. They are in a futuristic-looking glass room. What is the object present in the scene?
A. Orange-red thread
B. Blue clothing with a yellow collar
C. Yellow pants
D. Blue clothing with a black collar
E. Rose-colored pants
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 73/150 [03:02<02:54,  2.26s/it][32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vix2_R79-l4.mp4[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vix2_R79-l4.mp4[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vix2_R79-l4.mp4 | Selected 7 frames[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=146[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-28 04:47:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a long-haired woman wearing black clothes, holding a mobile phone in her right hand. The time on the phone screen shows 11:43. After the subtitle "don't have time so now" appears, what changes does the woman's phone screen undergo?
A. The time on the phone screen is 12:00
B. There are two long-haired women on the phone screen
C. The phone screen is black
D. The phone screen shows 'in call'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 74/150 [03:04<02:26,  1.92s/it][32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7233851486474636570.mp4[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7233851486474636570.mp4[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7233851486474636570.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=148[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the blue background PPT, there's a text style for 'Virtual and Real Attrition.' After mentioning 'real attrition because of every air attack,' what appears on the screen?
A. Three dark blue circular icons and two lines of English text in red font appear
B. Five yellow circular icons appear
C. Four square icons appear
D. A red airplane icon appears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aVHAr8rc-Ks.mp4[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aVHAr8rc-Ks.mp4[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aVHAr8rc-Ks.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=153[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Holding two cups containing liquid, the cup on the right has some bubbles inside. In the distance, there is a sunset. What happens when the two cups touch for the first time?
A. A third cup appears
B. Bubbles appear in the left cup
C. The bubbles in the right cup disappear
D. They clink the cups again
E. The cups move out of the frame
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 75/150 [03:05<02:10,  1.75s/it][32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KIf2fGmluhY.mp4[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KIf2fGmluhY.mp4[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KIf2fGmluhY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=150[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who appears first in the video among the following characters?
A. A man wearing an orange jacket with a small name tag, sitting in front of a bookshelf filled with books.
B. A man wearing a white baseball cap inside a museum.
C. A woman with golden hair talking to a mirror, with a glowing display screen in the lower right corner.
D. A woman with golden hair wearing a checkered scarf inside a museum.
E. A man wearing a black top with a patterned neckline, a black beret, and black-rimmed glasses, sitting in front of a name tag.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YehqA9xoGTY.mp4[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YehqA9xoGTY.mp4[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YehqA9xoGTY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=155[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The title on the screen is 'Datasets', below it are inference formulas, and a dynamic graph appears in the middle. In the top right corner, there is a man with glasses explaining. What did the boy holding the ball do when he appeared for the first time?
A. Threw the ball into the distance
B. Shot the ball towards the basket
C. Dribbled the ball
D. Stepped on the ball with his foot
E. Passed the ball to someone else
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 76/150 [03:07<02:21,  1.91s/it][32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tdA5atpqaAc.mp4[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tdA5atpqaAc.mp4[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tdA5atpqaAc.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=152[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:47:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with blue lighting, there is a white table. Next to the table, there is a woman wearing a black top. What is the woman wearing the black top doing when she first appears?
A. Fixing her hair
B. Sitting facing the mirror with both hands on the white table
C. Clapping happily
D. Supporting her head with her right hand
E. Supporting her head with her left hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hg2Q_O5b9w4.mp4[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hg2Q_O5b9w4.mp4[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hg2Q_O5b9w4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=157[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top-right corner of the brown cutting board, there are several pieces of already-cut meat. On the left side of the cutting board, there is uncut meat on a metal plate. In the middle of the screen, a person is holding a pair of tongs. What is this person doing?
A. Placing the tongs on the cutting board
B. Placing the meat from the metal plate onto the cutting board
C. Using the tongs to grab vegetables
D. Placing the cut meat from the cutting board onto the metal plate
E. Putting the tongs into a bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 77/150 [03:09<02:07,  1.74s/it][32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -eRimFrm6kQ.mp4[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-eRimFrm6kQ.mp4[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -eRimFrm6kQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=154[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white-background PPT screen, there is black text at the bottom, yellow-highlighted text on the left, and in the middle, an illustration composed of a blue rectangle, a green circle, and a blue triangle. When the subtitle 'spaceship this and this and so right and' appears, what changes occur to the illustration?
A. Covered by a blue highlight
B. A star appeared in the middle
C. Got bigger
D. Got smaller
E. A red dot appeared in the middle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OmhVj_-cfH0.mp4[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OmhVj_-cfH0.mp4[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OmhVj_-cfH0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=159[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which country's flag appears first in the video?
A. Singapore
B. Kiribati
C. India
D. St. Kitts
E. Barbados
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 78/150 [03:11<02:20,  1.95s/it][32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fZBC3nmvJb8.mp4[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fZBC3nmvJb8.mp4[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fZBC3nmvJb8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=156[0m
[32m2025-11-28 04:47:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is an elderly man wearing a dark brown hat, dressed in a brown suit, with a dark blue sweater and a blue shirt underneath, walking in the gallery. On the right side of the gallery, there is an artwork displayed, among which a painting shows a woman in a green dress sitting on a sofa. Can you tell what color the sofa is?
A. red
B. black
C. pink
D. green
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qyaQ-wfojbM.mp4[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qyaQ-wfojbM.mp4[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qyaQ-wfojbM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=161[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man with a beard is holding a paintbrush and intently painting on a canvas. What object is turning white at this moment?
A. canvas
B. man's finger
C. brush
D. scissors
E. easel
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 79/150 [03:14<02:35,  2.19s/it][32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i8TJ7RgimNM.mp4[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i8TJ7RgimNM.mp4[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i8TJ7RgimNM.mp4 | Selected 10 frames[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=158[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 04:47:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bright room, there is a woman wearing earrings and a necklace, dressed in green, sitting with an elderly woman wearing a gray sleeveless top with a necklace. When the woman in green, with her hands open and the backs of her hands facing outwards, naturally hangs them down, what is the elderly woman doing?
A. Raising hand
B. Standing up
C. Swaying left and right
D. Listening attentively
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 80/150 [03:16<02:23,  2.05s/it][32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ro_8-CCORzk.mp4[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ro_8-CCORzk.mp4[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ro_8-CCORzk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=160[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, there is a cooking demonstration video, then the lady explains. Next, the lady continues explaining, then a cooking demonstration, the lady explains again, then another cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, and then the cooking video wraps up.
B. First, the lady with the yellow ribbon explains cooking, then there is a cooking demonstration. Next, the lady continues explaining, then another cooking demonstration, the lady explains again, then a cooking demonstration, the lady continues explaining, then another cooking demonstration, then another cooking demonstration, then the lady explains, and finally the lady concludes.
C. First, there is a cooking demonstration video, then the lady explains. Next, the lady continues explaining, then a cooking demonstration, the lady explains again, then another cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, then another cooking demonstration, and finally the lady explains the last part of the cooking process.
D. First, there is a cooking demonstration video, then the lady explains. Next, there is another cooking demonstration, followed by yet another cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, then another cooking demonstration, the lady explains again, and then the cooking video wraps up.
E. First, there is an introduction, followed by a cooking demonstration. Next, the lady continues explaining, then another cooking demonstration, the lady explains again, then a cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, then another cooking demonstration, and finally the lady explains the last part of the cooking process.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 97nEBjiQI1M.mp4[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/97nEBjiQI1M.mp4[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 97nEBjiQI1M.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=163[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue seawater filled with white and olive pearls, and with some small fish swimming among the pearls, what happens on the screen after the subtitle 'might not fall back as expected a sign' appears?
A. The camera switches to a scene of a forest being illuminated by sunlight
B. The camera switches to a news anchor speaking to the camera
C. The camera switches to a man sitting in front of multiple display screens, speaking to the camera
D. A turtle swims next to a reef in the blue seawater
E. The camera switches to a woman wearing an orange flowered top and an earpiece
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = o2F-N42Ufo4.mp4[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/o2F-N42Ufo4.mp4[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: o2F-N42Ufo4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=165[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are two men in suits standing together, both lightly resting their crossed hands in front of them. The man on the left is wearing a black suit with a brown tie and black-framed glasses. The man on the right has some grey in his hair and is wearing a maroon tie. Behind them is a blue wall with some blue rectangular logos and two flags in front of the wall. When the camera is focused solely on the man with greyish hair on the right, with a blue flag behind him, what kind of change does this man undergo?
A. The man sits down
B. The man's tie changes to purple
C. The man turns his head to look to the side
D. The man has an extra pin on his chest
E. The man raises his hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 81/150 [03:18<02:37,  2.28s/it][32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 60oHeCZHtvI.mp4[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/60oHeCZHtvI.mp4[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 60oHeCZHtvI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=162[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT, there is a technical data label at the top, an armored vehicle with tracks in the middle, and 'Empty Weight' with 7 000kg (15 432 lbs) written below the vehicle. What is the color of the tracked armored vehicle?
A. Pink
B. Red
C. Black
D. Tan and green
E. White
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 82/150 [03:21<02:34,  2.28s/it][32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bAGhXcYc0o4.mp4[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bAGhXcYc0o4.mp4[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bAGhXcYc0o4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=164[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, two people with long hair leaning against the wall in a grayscale photo were shown, followed by an orange-bordered screen with a blue interior, then a screen with a purple background and yellow letters, and lastly, a scene of a man in black clothes with white hair talking.
B. First, a scene of a man in black clothes with white hair talking was played, then an orange-bordered screen with a blue interior, followed by a screen with a purple background and yellow letters, and lastly, two people with long hair leaning against the wall in a grayscale photo were shown.
C. First, a scene of a man in black clothes with white hair talking was played, followed by two people with long hair leaning against the wall in a grayscale photo, then an orange-bordered screen with a blue interior, and lastly, a screen with a purple background and yellow letters was shown.
D. First, an orange-bordered screen with a blue interior was played, then a screen with a purple background and yellow letters, followed by a scene of a man in black clothes with white hair talking. Lastly, two people with long hair leaning against the wall in a black-and-white photo were shown.
E. First, two people with long hair leaning against the wall in a grayscale photo were shown, followed by a scene of a man in black clothes with white hair talking, then an orange-bordered screen with a blue interior, and lastly, a screen with a purple background and yellow letters.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7231566545263103259.mp4[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7231566545263103259.mp4[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7231566545263103259.mp4 | Selected 15 frames[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=167[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 04:47:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Beneath the clouds, there are two cliffs covered with patches of green moss. Between them, there's a strange boulder. When mentioning 'There's that weird boulder jammed between two cliffs,' what objects are present on the screen?
A. white arrowhead with black outline
B. pure white arrowhead
C. black arrowhead with white outline
D. pure black arrowhead
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 83/150 [03:23<02:33,  2.30s/it][32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vVRC-0VKPrg.mp4[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vVRC-0VKPrg.mp4[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vVRC-0VKPrg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=166[0m
[32m2025-11-28 04:47:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white marble tabletop, there is a white bowl with some brown sauce inside. There is a glass bottle pouring oil onto a metal spatula over the bowl. After the subtitle 'All I need is your love tonight.' appears, what object appears?
A. Raw meat chunk
B. White sugar
C. Used oil
D. White vinegar
E. Half a lime
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7270058010888768770.mp4[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7270058010888768770.mp4[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7270058010888768770.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=169[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:47:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a phone, and the screen of the phone shows the number 911. When the subtitle "However, the girl used a disposable phone without a chip, making it impossible to locate her" appears, what change happens to the text in the middle of the phone screen?
A. Changes from the number 911 to the number 129
B. Changes from the number 911 to the blue text 'New Voicemail RAUL'
C. Changes from the number 911 to the number 119
D. Changes from the number 911 to the blue text 'save me'
E. Changes from the number 911 to the number 110
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CEZ9rbjK3P4.mp4[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CEZ9rbjK3P4.mp4[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CEZ9rbjK3P4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=171[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x63065a00] mmco: unref short failure
[32m2025-11-28 04:47:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the top of the screen, there is a red search box. Below the search box, there are characters aligned to the left, which are composed of red and black colors. In the bottom right corner, a man wearing sunglasses and dressed in black is speaking into a microphone. What is this man doing?
A. The man is drawing a circle with his hand
B. The man is adjusting his glasses
C. The man is making a scissor hand gesture
D. The man is making a heart hand gesture
E. The man is making an OK hand gesture
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 84/150 [03:26<02:43,  2.48s/it][32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7109221563697876225.mp4[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7109221563697876225.mp4[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7109221563697876225.mp4 | Selected 15 frames[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=168[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 04:47:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[h264 @ 0x63065a00] mmco: unref short failure
[h264 @ 0x63065a00] mmco: unref short failure
[32m2025-11-28 04:47:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a wooden table, there is a wooden cutting board covered with a layer of white paper. There are six pieces of tofu on the cutting board with red sauce spread on top. On the right side of the screen, there is a pink brush. What happens in the screen at this moment?
A. The tofu pieces are being stir-fried
B. The brush is applying oil to the tofu pieces
C. The brush is applying sauce to the tofu pieces
D. The tofu pieces are being fried
E. The tofu pieces are being baked
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 85/150 [03:28<02:28,  2.28s/it][32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7267884432420277506.mp4[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7267884432420277506.mp4[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7267884432420277506.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=170[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the center of the screen is a drawing, depicting a person resting their hand on their forehead on a yellowish paper. The drawing is composed of lines and lacks colors. Where else has this artwork appeared?
A. In a room with a bookshelf
B. On a bench outside
C. In front of a table holding a vase
D. On the glass of a transparent window
E. In front of a table with a desk lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pPJq1rMDRGs.mp4[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pPJq1rMDRGs.mp4[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pPJq1rMDRGs.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=173[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with the white text 'to partner in the firm', there is a man wearing a blue shirt who is resting his hand on the shoulder of another man beside him. What kind of beard does the man in the blue shirt have?
A. Mountain goat beard
B. Connected beard
C. Eight-character beard
D. One-character beard
E. Shaving beard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 86/150 [03:30<02:32,  2.39s/it][32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UUaiqR1I454.mp4[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UUaiqR1I454.mp4[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UUaiqR1I454.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=172[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' then a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right,' and finally, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background.'
B. First, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background,' then a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' and finally, a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right.'
C. First, a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' then a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background,' and finally, a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right.'
D. First, a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right,' then a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' and finally, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background.'
E. First, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background,' then a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right,' and finally, a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood.'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wvfctNd-Aio.mp4[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wvfctNd-Aio.mp4[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wvfctNd-Aio.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=175[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a room, hanging on the wall are an orange bag and a green and white garment. A woman wearing green clothes is holding a baby dressed in white. In which captions does this baby appear together?
A. cuts and bruises and they did not surrender
B. cuts and bruises and years that followed his wife sadly died
C. cuts and bruises and many more suffered similarly
D. years that followed his wife sadly died and many more suffered similarly
E. they did not surrender and many more suffered similarly
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 87/150 [03:33<02:29,  2.38s/it][32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MPQn_orwpfA.mp4[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MPQn_orwpfA.mp4[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MPQn_orwpfA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=174[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left is black text in English with a red icon below, and on the right side of the screen is a stack of newspapers. Below the news headline, on a ticker tape, there is a black background with yellow text reading 'BREAKING NEWS'. Which subtitles have appeared at the same time as this icon?
A. ‚ÄúGPS and health workers insisting that‚Äù
B. ‚Äúand 37 and the polling station that have‚Äù
C. ‚Äúthe QR code you'll see on screen during‚Äù
D. ‚Äúopened in Russia their elections taking‚Äù
E. ‚Äústart with the times world uh Pages 36‚Äù
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = baFsMWNavQ4.mp4[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/baFsMWNavQ4.mp4[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: baFsMWNavQ4.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=177[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:47:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is a black-skinned woman wearing a white and green shirt with black floral patterns. She is standing in a white room with a large screen behind her displaying some images. The woman is speaking with her hands open, facing the camera. What subtitles appeared simultaneously with this woman?
A. Thank you
B. that we were doing
C. waht
D. SO

E. Can you
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F7RSW-2rF4w.mp4[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F7RSW-2rF4w.mp4[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F7RSW-2rF4w.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=179[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The floor of the room is brown, there are flags and pictures on the wall. To the right is a bookshelf filled with books. A zoomed out map appears in the top right corner. A man wearing a grey coat is sitting on a black stool. What subtitle appears together with the map in the top right corner?
A. Music
B. Europe Russia China, India and Australia most of these lines actually don't exist. So let's assume
C. 65 to 94
D. We're funding maybe about 75% of all these train lines
E. You know at first glance this picture
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 88/150 [03:35<02:33,  2.47s/it][32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yXXhrMqfMlk.mp4[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yXXhrMqfMlk.mp4[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yXXhrMqfMlk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=176[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a dark and gloomy day, on a street lined with stone-built houses, there's a red and white round traffic barrier at the side of the street. Which of the following subtitles appeared together with the round traffic barrier?
A. "sometimes we feel that our problems are"
B. "unbearable"
C. "with their own problems and everyday"
D. "and things are so bad that it's almost"
E. "Music"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = u-vYvqxHejY.mp4[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/u-vYvqxHejY.mp4[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: u-vYvqxHejY.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=181[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:47:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a narrow alley flanked by yellow buildings, a man wearing a black short-sleeved shirt and a hat is walking. Sunlight casts on his face, reflecting a dazzling glare. When the subtitles mention 'growing and learning and maturing as a', what object is present in the scene?
A. a round hat
B. a top hat
C. a duckbill cap
D. a black car
E. a pair of black-framed glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 89/150 [03:38<02:36,  2.56s/it][32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7m9XIXyT5_I.mp4[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7m9XIXyT5_I.mp4[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7m9XIXyT5_I.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=178[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a blonde woman is explaining something while wearing a black coat. When the person speaking mentions 'Oh, and here's a picture of her at the printing press,' there is a shadow of her pointing to an object on the wall. What is the object present in the screen?
A. Tree
B. Black and white photo
C. Book
D. Watercolor painting
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ro_8-CCORzk.mp4[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ro_8-CCORzk.mp4[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ro_8-CCORzk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=183[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen, there is a house with only its frame remaining. A man wearing a gray hat is extending half of his body out from the black middle section while holding a bucket. What is this man doing?
A. He filled the bucket with water.
B. He closed the door.
C. He took off his hat.
D. He is pouring the contents of the bucket outside.
E. He put down the bucket.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 90/150 [03:41<02:32,  2.54s/it][32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6Lb1PyJxVQM.mp4[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6Lb1PyJxVQM.mp4[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6Lb1PyJxVQM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=180[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with short blonde hair and wearing earrings is speaking in front of a mirror. She is wearing black clothes, with a gray background wall behind her. In front of her is a white subtitle bar that reads 'BLANC:PENSIONS MARKETGROWING'. The subtitle bar changes to 'BLANC: CHANGETHROUGH AITO COMEIN WAVES', and a pop-up window appears on the right side of the screen that reads 'Amanda Blanc'. What change did this woman experience?
A. The woman shook hands with a person next to her
B. The woman got a haircut
C. The woman raised both hands
D. The woman stood up
E. The woman took a sip of water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZRMbh0wSly0.mp4[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZRMbh0wSly0.mp4[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZRMbh0wSly0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=185[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Looking at the screen full of people, how many people are holding a blue and yellow interwoven banner? In the middle of the screen, a woman in a black leather jacket is holding a little girl with a blue headscarf with star and moon designs. When mentioning 'on to their culture language and claim,' what kind of glasses is this woman wearing who is dressed in leather and wearing a black hat?
A. Wearing glasses with black frames and purple lenses
B. Wearing glasses with purple frames and black lenses
C. Wearing red-framed sunglasses
D. Wearing black-framed sunglasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qksR2Zvd-FM.mp4[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qksR2Zvd-FM.mp4[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qksR2Zvd-FM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=187[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a black car parked on the beach by the sea. A man has his left hand on his waist and his right hand on the car. Who is the man making this gesture?
A. The man wearing a purple short-sleeved shirt
B. The man wearing a white short-sleeved shirt with tattoos on both arms
C. The man wearing a blue uniform
D. The man wearing a black short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 91/150 [03:44<02:44,  2.79s/it][32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HQns-h_82qU.mp4[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HQns-h_82qU.mp4[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HQns-h_82qU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=182[0m
[32m2025-11-28 04:47:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:47:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bullet hits the green tank and sparks fly. Who is the character that first appears after Bai mentions 'period in World War II'?
A. The soldier wearing a red headscarf
B. The soldier wearing a black headscarf and green camouflage uniform
C. The soldier without a helmet, with short blond hair, wearing a green camouflage uniform
D. The soldier wearing a green helmet, black scarf, and camouflage uniform
E. The soldier wearing a green helmet and gray clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:47:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = athabNMGceo.mp4[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/athabNMGceo.mp4[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: athabNMGceo.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=189[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:47:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the animated scene, the left side features a pitch-black sky, the middle shows a cliff face that is currently exploding, and the right side is a rock wall illuminated by a red light. What event occurred after the explosion?
A. A man lifted up a cane
B. A woman fell to the ground
C. A tiger fell to the ground
D. A panda took out a bamboo stick
E. A panda fell to the ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 92/150 [03:47<02:50,  2.94s/it][32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qjY9kmveQAk.mp4[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qjY9kmveQAk.mp4[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qjY9kmveQAk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=184[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, a man wearing black-framed glasses and a white short-sleeve shirt with a small bird pattern is explaining. Which of the following animals evolved hindgut fermentation?
A. Ostrich
B. Rabbit
C. Kangaroo
D. Whale
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wvfctNd-Aio.mp4[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wvfctNd-Aio.mp4[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wvfctNd-Aio.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=191[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a train, a person wearing a green military uniform and a green face mask is making a phone call. What other items appear on this train?
A. Biscuit
B. Flower
C. Gun
D. Piano
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 93/150 [03:49<02:35,  2.72s/it][32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6862748507976011013.mp4[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6862748507976011013.mp4[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6862748507976011013.mp4 | Selected 7 frames[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=186[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-28 04:48:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are two slices of bread. The one on the left has been spread with chocolate sauce, while the one on the right has been spread with orange sauce. When the subtitle says 'And then slice up your favorite fruit. I'm choosing a nectarine today', what change occurs to the bread slices?
A. The left bread slice adds a lemon
B. The left bread slice adds a peach
C. The left bread slice adds a watermelon
D. The right bread slice adds a peach
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 94/150 [03:51<02:05,  2.24s/it][32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fLn06p2HtAc.mp4[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fLn06p2HtAc.mp4[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fLn06p2HtAc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=188[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the news footage, on the left is a woman with long blue sleeves and dark red hair, and on the right is a bald man in a black suit with a white shirt underneath. Which subtitle appears simultaneously with the glass in the man's right hand?
A. ‚Äúthe the headlines about the end of‚Äù
B. "they they can desent no because there"
C. "descent from from Russians as much as"
D. "and that we are seeing this open um"
E. ‚Äúdefending it all I'm saying uh is that I‚Äù
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 86CxyhFV9MI.mp4[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/86CxyhFV9MI.mp4[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 86CxyhFV9MI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=193[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a small person figure wearing a blue duckbill cap and dressed in blue clothes. Where has this blue-clothed character appeared before?
A. A room with a map in front, including 3 guitars of different colors, a computer, an olive-colored sofa, and a bookshelf.
B. A room with a map in front, including 2 guitars of different colors and a computer.
C. A room with a map in front, including an olive-colored sofa, a computer, and a bookshelf.
D. A room with a map in front, including an olive-colored sofa and a bookshelf.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 95/150 [03:53<02:02,  2.23s/it][32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2vVQo_GMA70.mp4[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2vVQo_GMA70.mp4[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2vVQo_GMA70.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=190[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, which subtitles appear at the same time as the man with black hair, dressed in grey clothes with black sleeves, on stage?
A. promisc has come to an end, in and run away countless times, i was just scared, i still
B. run away countless times, i was just scared, i still and front of our crown, like a world of souls,
C. promisc has come to an end, in and front of our crown, like a world of souls,
D. promisc has come to an end, in and captain of the godson, three three three three three three
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UD5ifzOPzhc.mp4[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UD5ifzOPzhc.mp4[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UD5ifzOPzhc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=195[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, after the yellow-bordered rectangular strip of paper is pasted, what appears next?
A. red strip of paper
B. pencil
C. notebook
D. mobile phone
E. white strip of paper with lines on it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 96/150 [03:56<02:13,  2.48s/it][32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RQOdl64DtdI.mp4[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RQOdl64DtdI.mp4[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RQOdl64DtdI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=192[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white background at the top with black English letters 'K-nearest neighbor' written on it, there is a man wearing glasses and a suit in the bottom right corner. The screen has some red error symbols. When the subtitles say 'okay because these might be some noise,' what is the shape of the green graphic on the screen?
A. rectangle
B. circle
C. triangle
D. star
E. square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kj3Po7zUeyw.mp4[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kj3Po7zUeyw.mp4[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kj3Po7zUeyw.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=197[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a woman with red hair is wearing a white top, holding a mirror in one hand and combing her long hair with the other. After mentioning the explanation 'rules rounding are back to a time when,' which character appears afterward?
A. Naked man
B. Woman lying in the water
C. Mona Lisa
D. Angel
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 97/150 [03:59<02:19,  2.64s/it][32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7297000148201262341.mp4[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7297000148201262341.mp4[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7297000148201262341.mp4 | Selected 10 frames[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=194[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 04:48:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the ethnicity of the first person to appear in the video?
A. White
B. Black
C. Asian
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = acAWfzV__XI.mp4[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/acAWfzV__XI.mp4[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: acAWfzV__XI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=199[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the sea, a woman wearing sunglasses and long hair is sitting in a cart with the text 'WATER LINK' on the side. What is this woman doing?
A. She is driving an amphibious car
B. She jumped out of the car
C. She is swimming
D. She jumped into the sea
E. She is lying in the car
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 98/150 [04:00<01:57,  2.26s/it][32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = e6HwinLBK_Y.mp4[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/e6HwinLBK_Y.mp4[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: e6HwinLBK_Y.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=196[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white screen, there are many letters written, and at the bottom, there is also a blue arrow drawn. A hand is holding a pen. After the text 'topological sort' appears on the screen, what does the hand holding the pen do?
A. Draws a blue question mark on the white screen
B. Draws a blue arrow on the white screen
C. Draws an orange arrow on the white screen
D. Writes the black text 'Not' on the white screen
E. Draws a black line on the white screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F8Ma1qs0Rkg.mp4[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F8Ma1qs0Rkg.mp4[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F8Ma1qs0Rkg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=201[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the background of the scene, there's a green plant. In the middle, there is a black man who is Kamala Khan's clone. Next to him, there is a woman wearing a white hat. Who is smiling in the scene at this moment?
A. The woman wearing a black hat
B. Kamala Khan's clone
C. The woman wearing a white hat
D. The man wearing a white hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 99/150 [04:03<01:57,  2.30s/it][32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mFliMGufpwc.mp4[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mFliMGufpwc.mp4[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mFliMGufpwc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=198[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a woman with medium-length wavy black hair on the screen, wearing a black and grey suit jacket, sitting on a chair facing a mirror. What objects are present in this scene?
A. notebook
B. mobile phone
C. cup
D. camera
E. pen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 100/150 [04:05<01:55,  2.31s/it][32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8MkL3W6wU3g.mp4[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8MkL3W6wU3g.mp4[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8MkL3W6wU3g.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=200[0m
[32m2025-11-28 04:48:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a man in the middle of the screen wearing a black short-sleeved shirt with white floral patterns. His hands are placed below, and there is an orange subtitle below as well. What changes occur on the screen after the man raises his left hand?
A. The orange subtitle changes to black
B. An additional line of orange subtitle appears
C. No changes
D. The orange subtitle disappears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = n24n_20Kwe4.mp4[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/n24n_20Kwe4.mp4[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: n24n_20Kwe4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=203[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are two Chinese men. The Chinese man on the left, dressed in a grey work uniform, is sitting on a stone bench. The man on the right, wearing a dark blue and grey pants, is also seated. After the subtitle 'the Chinese word for landscape is Shan' appears, what is the first object that appears?
A. A fake mountain with flowing water
B. A small red wooden scroll table
C. A classic window with green bamboo and a fake mountain
D. A sign with Chinese characters inside a house
E. A lantern hanging from the beam
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 101/150 [04:08<02:05,  2.55s/it][32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6S_e34j6q9U.mp4[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6S_e34j6q9U.mp4[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6S_e34j6q9U.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=202[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a half-open brown door, some flowers painted on the white wall, and a girl standing in the doorway. She has two ponytails and is wearing a red inner clothing with a purple fur coat. When the subtitle 'appeared she must have been hiding when' appears, what happens to the girl?
A. Holds a doll and smiles at the camera
B. Holds a doll and shows a fearful expression
C. Holds a pillow and squats down
D. Holds a doll and squats down
E. Looks at a kitten nearby
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Y5833KeDmp4.mp4[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Y5833KeDmp4.mp4[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Y5833KeDmp4.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=205[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:48:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a man with black clothes and black hair and a woman with vintage hair styled in a court manner and wearing a light green dress. Behind them is a walkway with hanging lanterns and a large chandelier. What did the two do?
A. shake hands
B. embrace
C. look at each other
D. hold hands
E. run
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SFfWUrsg4gE.mp4[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SFfWUrsg4gE.mp4[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SFfWUrsg4gE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=207[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, within a kitchen with a row of white cabinets in the background, there is a man with curly hair wearing a striped shirt. On the table in front of him, there is a bottle of oil, a glass bowl containing egg liquid with a blue egg beater, a square box with colorful question marks, an empty glass bowl, and an empty small glass bowl. Which item appears first?
A. A square box with colorful question marks
B. An empty glass bowl
C. A small empty glass bowl
D. A glass bowl containing egg liquid with a blue egg beater
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 102/150 [04:10<01:58,  2.47s/it][32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7141686631676808454.mp4[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7141686631676808454.mp4[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7141686631676808454.mp4 | Selected 13 frames[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=204[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 04:48:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white marble countertop, there is a rectangular container lined with white paper. On the white paper, there is a large piece of chocolate-colored dessert sprinkled with yellow hard fruit bits. Which subtitles have appeared simultaneously with this chocolate dessert?
A. Doing it all night, all summer'in Chinese Simplified can be translated
B. live my day as if it was no past
C. Doing it all night, all summer
D. It looks good to eat
E. Got my day, my heart out till the dawn
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 103/150 [04:12<01:45,  2.24s/it][32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZfapKqwklG4.mp4[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZfapKqwklG4.mp4[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZfapKqwklG4.mp4 | Selected 13 frames[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=206[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a well-lit room, what did a man dressed in a white lab coat and green plaid outerwear do after saying 'nothing too fancy here'?
A. Turned the camera towards a bedroom with a guitar
B. Used his hand to open the door of a white wardrobe
C. Made a gesture of peace towards the camera
D. Zoomed in with the camera
E. Pointed his hand towards the balcony outside
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GGwHSz9towk.mp4[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GGwHSz9towk.mp4[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GGwHSz9towk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=209[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the phrase 'forbidden instead they were welcome to' was mentioned, what action did the man in the red and purple striped clothes do in the old, broken room?
A. Got up from the bed and ran
B. Ate
C. Covered his ears with both hands
D. Picked up a cup and drank water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 104/150 [04:14<01:33,  2.04s/it][32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NMHmqgO04rU.mp4[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NMHmqgO04rU.mp4[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NMHmqgO04rU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=208[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man with curly hair wearing a blue shirt, with floral patterns on the right sleeve, is standing next to a transparent display case on his left. What is this man in the blue shirt doing?
A. Petting
B. Taking a photo
C. Painting
D. Observing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _ZIa6SEJEyg.mp4[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_ZIa6SEJEyg.mp4[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _ZIa6SEJEyg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=211[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A white Pekingese dog is lying on a white cushion on the sofa. The dog is wearing a pearl necklace around its neck. There is a plaid pillow on the sofa. In the bottom left corner of the screen, there is an upper body image of a man wearing a white coat. When the subtitle 'It was just a small amount' appears, what does the sofa look like?
A. Olive-colored artificial leather sofa
B. Red artificial leather sofa
C. Red wooden sofa
D. Black artificial leather sofa
E. Olive-colored wooden sofa
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 105/150 [04:16<01:38,  2.20s/it][32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = D0RyFh0hnkQ.mp4[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/D0RyFh0hnkQ.mp4[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: D0RyFh0hnkQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=210[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white background with some text and mathematical formulas, there is an orange dialogue box. In the lower right corner, a woman wearing white clothing is extending two fingers on her left hand. After the subtitle mentions 'the coffee beans and the milk so that‚Äôs,' what is the green letter that appears in the video?
A. F
B. used
C. O
D. g
E. R
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GawGUhl9zuQ.mp4[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GawGUhl9zuQ.mp4[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GawGUhl9zuQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=213[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a red dot moves across a gray-black screen with two images and text; then the red dot moves across a gray-black screen without any images; finally, a blue dot moves across a gray-black screen with a red bar graph.
B. First, a red dot moves across a gray-black screen with a blue bar graph; then the red dot moves across a gray-black screen without any images; finally, the red dot moves across a gray-black screen with two images and text.
C. First, a red dot moves across a gray-black screen with two images and text; then the red dot moves across a gray-black screen without any images; finally, the red dot moves across a gray-black screen with a blue bar.
D. First, a blue dot moves across a gray-black screen with two images and text; then the blue dot moves across a gray-black screen without any images; finally, the blue dot moves across a gray-black screen with a red bar graph.
E. First, a red dot moves across a gray, dark screen without any images; then the red dot moves across a gray-black screen with two images and text; finally, the red dot moves across a gray-black screen with a blue bar graph.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 106/150 [04:18<01:34,  2.15s/it][32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wFrztzzohJ8.mp4[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wFrztzzohJ8.mp4[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wFrztzzohJ8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=212[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Between two connected videos, there is a white notebook in the middle held by a female. The notebook has an additional paper attached with a figure on it. What changes happen to the notebook when the subtitle mentions 'there good and then'?
A. The additional paper on the notebook is gone
B. The notebook only has a blue figure drawn with a pen
C. The notebook has an additional paper and a black figure drawn with a pen
D. The notebook has an additional paper and a black figure drawn with a pen
E. The notebook has an additional paper and a blue figure drawn with a pen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GdFMKGNFXaE.mp4[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GdFMKGNFXaE.mp4[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GdFMKGNFXaE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=215[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a grey wall with a huge oil painting hanging on it, there's a dense row of people standing and admiring this artwork. Which objects have not appeared in the scene?
A. Blue backpack
B. White pocket
C. Red hat
D. Red handbag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 107/150 [04:21<01:37,  2.28s/it][32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pFtKaT3GF9I.mp4[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pFtKaT3GF9I.mp4[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pFtKaT3GF9I.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=214[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the small inset at the bottom left of the screen, a male presenter dressed in a gray suit and blue shirt is explaining. In the video behind the inset, next to a pile of burning bear dolls with golden flames, there is a man with his back facing the inset, covered in white cloth. What happened after this man, who is facing away, says in the subtitles 'comfort although it's kind of unclear'?
A. Looked for something near the fire pile
B. Took off his shoes and walked away
C. Took off his clothes and threw them into the fire
D. Used a fire extinguisher to put out the fire
E. Threw an object in his hand into the fire
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = US5Oz0q0BVE.mp4[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/US5Oz0q0BVE.mp4[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: US5Oz0q0BVE.mp4 | Selected 6 frames[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=217[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, a picture with the flag of Iraq is shown, followed by a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner, and lastly a man discussing a picture with a sheep and a desert is shown.
B. First, a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner is shown, followed by a picture with the flag of Iraq, and lastly a man discussing a picture with a sheep and a desert is shown.
C. First, a man discussing a picture with a sheep and a desert is shown, followed by a picture with the flag of Iraq, and lastly a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner is shown.
D. First, a man discussing a picture with a sheep and a desert is shown, followed by a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner, and lastly a picture with the flag of Iraq is shown.
E. First, a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner is shown, followed by a man discussing a picture with a sheep and a desert, and lastly a picture with the flag of Iraq is shown.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 108/150 [04:24<01:42,  2.44s/it][32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JpjytHmGHZ4.mp4[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JpjytHmGHZ4.mp4[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JpjytHmGHZ4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=216[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with two rows of bookshelves, there is a desk in front of the bookshelves. On the desk are two paintings, one upright and one lying flat. Sitting next to the desk is a woman dressed in black. What style of glasses is this woman wearing?
A. Not wearing glasses
B. Black-frame glasses
C. Red-frame glasses
D. Monocle
E. Gold-frame glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WmrwQMFZLqI.mp4[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WmrwQMFZLqI.mp4[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WmrwQMFZLqI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=219[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man holding a guitar dressed in a red short-sleeve shirt is standing behind a microphone on stage under the lights. On the screen behind him with a black background, two large English words appear. There is a row of audience members seated in front of the stage. When the subtitles 'Thank you' appear, what are the audience members doing?
A. Giving flowers to the man on stage
B. Asking the man on stage a question
C. Standing up and leaving
D. Clapping
E. Sitting still
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 109/150 [04:26<01:38,  2.40s/it][32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dE5iWeCVpGI.mp4[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dE5iWeCVpGI.mp4[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dE5iWeCVpGI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=218[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a person wearing a black apron with the word 'TASTY' on it. They are wearing a ring on their left hand which is resting on a dough. There is a wooden board on the table. What is the shape of the dough in the video?
A. Square
B. Oval
C. Round
D. Triangular
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JuthlQ2Zo38.mp4[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JuthlQ2Zo38.mp4[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JuthlQ2Zo38.mp4 | Selected 13 frames[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=221[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 04:48:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a slightly blurred background, what is a woman with long curly hair, wearing a long-sleeved top and a necklace, doing when the caption 'work you breathe it you live it and' appears?
A. Holding a blue pen and writing something
B. Holding a black pen and writing something
C. Holding a purple pen and writing something
D. Holding a white pen and writing something
E. Holding a red pen and writing something
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 110/150 [04:28<01:35,  2.38s/it][32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Aau-XoIebno.mp4[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Aau-XoIebno.mp4[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Aau-XoIebno.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=220[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the white curtain, when a woman in a light blue denim jacket with long hair lifts her hand, what is she doing?
A. The woman is holding a white bottle and giving a detailed introduction about it.
B. The woman is taking off her earrings.
C. The woman is taking off her hair tie from her wrist and tying her hair.
D. The woman is taking off her jacket and placing it on the ground.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2F7d7aUCmUU.mp4[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2F7d7aUCmUU.mp4[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2F7d7aUCmUU.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=223[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dense forest, a boy wearing a black short-sleeve shirt is sitting on a bench. When the subtitle mentions 'to positively influence us all that said', what action does the boy take?
A. Makes a fist
B. Waves his hand
C. Stands up
D. Claps his hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = V-RIpt7Tknc.mp4[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/V-RIpt7Tknc.mp4[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: V-RIpt7Tknc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=225[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On screen, two men are sitting on a stage. The man on the right is wearing glasses, a beige coat, and brown shoes, sitting cross-legged with a microphone in his hands resting on his lap. The man on the left is wearing a black coat, black pants, and beige shoes, also sitting cross-legged with a microphone in his hand. What is he doing with his raised right hand?
A. Raising his right hand and pointing towards the man next to him
B. Raising his right hand and waving
C. Raising his right hand and drinking water
D. Raising his right hand and pointing towards the stage
E. Raising his right hand and scratching his head
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 111/150 [04:32<01:42,  2.64s/it][32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9WjElCiDpzM.mp4[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9WjElCiDpzM.mp4[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9WjElCiDpzM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=222[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A group of people are gathered in front of a large building's gate, where there is a round ball ornament on top of the gate, and plants on both sides of the gate. There is also a mention of the year 1908. After mentioning the Young Turk Revolution shaking the Ottoman Empire, what other event is mentioned?
A. Bulgaria's proclamation of independence
B. The war between the Ottoman Empire and Greece
C. The signing of the Treaty of Bucharest
D. The Greek War
E. The Second Balkan War
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vVRC-0VKPrg.mp4[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vVRC-0VKPrg.mp4[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vVRC-0VKPrg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=227[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, the braided-haired woman holding a book opens it to a page where the left side shows a long branch with some people on it, and the right side is blue. Then, the dark-skinned woman on the white sofa lifts a book with the cover marked 'EXTRA YARN'. Finally, the dark-skinned woman on the white sofa holds a colored pencil in each hand.
B. First, the dark-skinned woman on the white sofa holds a colored pencil in each hand. Then, she lifts a book with the cover marked 'EXTRA YARN'. Lastly, the braided-haired woman holds a book, opens it to a page where the left side shows a long branch with some people on it, and the right side is blue.
C. First, a dark-skinned woman sitting on a white sofa lifts a book with the cover marked 'EXTRA YARN'. Then, a woman with braided hair holding a book opens to a page with a long branch on the left side with some people on it. The right side of the page is blue. Finally, the dark-skinned woman on the white sofa holds a colored pencil in each hand.
D. First, a dark-skinned woman sitting on a white sofa lifts a book with the cover marked 'EXTRA YARN'. Then, the same woman on the white sofa holds a colored pencil in each hand. Lastly, the braided-haired woman holds a book, opens it, and the left page shows a long branch with some people on it, while the right page is blue.
E. First, the braided-haired woman holding a book opens it to a page where the left side shows a long branch with some people on it, and the right side is blue. Then, the dark-skinned woman on the white sofa holds a colored pencil in each hand. Lastly, the dark-skinned woman on the white sofa lifts a book with the cover marked 'EXTRA YARN'.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 112/150 [04:35<01:46,  2.82s/it][32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZsnfXfuGRrg.mp4[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZsnfXfuGRrg.mp4[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZsnfXfuGRrg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=224[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom left corner of the white background is a rectangular frame with curves and color variations. Inside the frame, there are blue and yellow arrows and characters. The top of the frame has handwritten colorful characters above which there are black lines and characters. In the bottom right corner of the screen are a cartoon dog and the symbol œÄ (pi). What is happening to the right of the handwritten colorful characters?
A. A hand-drawn line is getting thinner.
B. A hand-drawn line is shortening.
C. A hand-drawn line is moving parallel.
D. A hand-drawn line is getting thicker.
E. A hand-drawn line is extending and eventually forms an arrowhead.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = luRqMb5qfhM.mp4[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/luRqMb5qfhM.mp4[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: luRqMb5qfhM.mp4 | Selected 10 frames[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=229[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 04:48:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are many cucumber slices on the cutting board in the kitchen. A woman wearing a black dress and a gold bracelet is holding a knife. What is she doing?
A. She is peeling the cucumber
B. She is slicing the cucumber
C. She is cleaning the cutting board
D. She is putting the cucumber into a bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ezhafkxoRdo.mp4[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ezhafkxoRdo.mp4[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ezhafkxoRdo.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=231[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What change occurs to the book held by a bald man with a mustache, wearing a gray shirt, which has a black cover with the English word 'STUKA' written on it, when the screen shows the text 'Early testprint of the German text' in white letters at the bottom?
A. The pages of the book turn black.
B. The book is opened.
C. A cartoon image appears on the book.
D. The pages of the book turn yellow.
E. The book is torn.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 113/150 [04:37<01:41,  2.75s/it][32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7267308320413797650.mp4[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7267308320413797650.mp4[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7267308320413797650.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=226[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a blue background, a man wearing a dark grey short-sleeve shirt and black-framed glasses with short black hair said "Thank you for watching this episode of SciShow!" After he finished speaking, what was the first action he took?
A. Crossed his hands into fists
B. Placed both hands on his abdomen
C. Raised his right hand with palm open
D. Took off his glasses with both hands open
E. Raised both hands with palms open
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jdbG9gmg_SA.mp4[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jdbG9gmg_SA.mp4[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jdbG9gmg_SA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=233[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a person holding a phone taking a photo of their leg; then a pale-skinned woman and a dark-skinned man kissing; and finally, a woman wearing a green headband sliding down a hill being pulled back by someone.
B. First, a pale-skinned woman and a dark-skinned man kissing; then a person holding a phone taking a photo of their leg; and finally, a woman wearing a green headband sliding down a hill being pulled back by someone.
C. First, a pale-skinned woman and a dark-skinned man kissing; then a woman wearing a green headband sliding down a hill being pulled back by someone; and finally, a person holding a phone taking a photo of their leg.
D. First, a person holding a phone taking a photo of their leg; then a woman wearing a green headband sliding down a hill being pulled back by someone; and finally, a pale-skinned woman and a dark-skinned man kissing.
E. First, a woman wearing a green headband sliding down a hill being pulled back by someone; then a pale-skinned woman and a dark-skinned man kissing; and finally, a person holding a phone taking a photo of their leg.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 114/150 [04:40<01:33,  2.61s/it][32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = acAWfzV__XI.mp4[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/acAWfzV__XI.mp4[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: acAWfzV__XI.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=228[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x61d84040] mmco: unref short failure
[32m2025-11-28 04:48:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white screen, there are many formulas written, at the top there is blue text, below there is a black circle connected by a black arrow, and to the left there is also a blue arrow. After the subtitle "empty queue" appears, what happens to the blue arrow?
A. Moves down
B. Disappears
C. Moves up
D. Becomes wider
E. Becomes narrower
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 115/150 [04:42<01:29,  2.56s/it][32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = athabNMGceo.mp4[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/athabNMGceo.mp4[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: athabNMGceo.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=230[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, there's a scene on a flat road with many cars parked on either side; then, a scene with a man dressed in blue sitting in the front passenger seat of a car; finally, a scene where a woman dressed in white is close to a man dressed in blue.
B. First, there's a scene where a woman dressed in white is close to a man dressed in blue; then, a scene on a flat road with many cars parked on either side; finally, a scene with a man dressed in blue sitting in the front passenger seat of a car.
C. First, there's a scene with a man dressed in blue sitting in the front passenger seat of a car; then, a scene on a flat road with many cars parked on either side; finally, a scene where a woman dressed in white is close to a man dressed in blue.
D. First, there's a scene on a flat road with many cars parked on either side; then, a scene where a woman dressed in white is close to a man dressed in blue; finally, a scene with a man dressed in blue sitting in the front passenger seat of a car.
E. First, there's a scene where a woman dressed in white is close to a man dressed in blue; then, a scene with a man dressed in blue sitting in the front passenger seat of a car; finally, a scene on a flat road with many cars parked on either side.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = er1oRjH2iu8.mp4[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/er1oRjH2iu8.mp4[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: er1oRjH2iu8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=235[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, a man wearing a pair of black-rimmed glasses and a white short-sleeved shirt with a small bird pattern is explaining something. Which of the following animals can spray feces up to 40 cm?
A. Hamster
B. Whale
C. Ostrich
D. Rabbit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 116/150 [04:45<01:26,  2.54s/it][32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LAbtlJJhUlY.mp4[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LAbtlJJhUlY.mp4[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LAbtlJJhUlY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=232[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
During the concert, a man with tattoos and long hair was singing shirtless while holding a microphone. When the subtitles displayed 'We don't want to spend all our time discussing,' what change occurred to the man's upper body?
A. His shirtless body changed into wearing a red suit.
B. His shirtless body changed into wearing a black suit.
C. His tattooed body changed into a shirtless body without tattoos.
D. His shirtless body changed into wearing a white suit.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = s49y2RP5C7E.mp4[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/s49y2RP5C7E.mp4[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: s49y2RP5C7E.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=237[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:48:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:48:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman in a black coat with yellow vertical stripes and colorful badge dots is standing in the center of the screen. She has accessories on her wrist, holding scissors in one hand and a white paper in the other. Behind her, there is a table with a lamp and clutter. The wall is decorated with pictures and miscellaneous items. What does the woman do after picking up the scissors and the white paper?
A. The woman picks up a magazine
B. The woman drops the white paper
C. The woman puts down the white paper
D. The woman puts down the scissors
E. The woman cuts the white paper with the scissors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:48:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 117/150 [04:47<01:23,  2.52s/it][32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7267233980473314606.mp4[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7267233980473314606.mp4[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7267233980473314606.mp4 | Selected 7 frames[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=234[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-28 04:48:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table in the kitchen, a person is adding yellow lemon slices to a glass jar filled with yellow squash slices. When the subtitle says 'I'm a New York Medicine Ave,' what other objects are present in the room?
A. Refrigerator
B. Red flowers
C. Yellow flowers
D. Green plants
E. Oven
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 118/150 [04:48<01:06,  2.07s/it][32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8wbNEJjBa0k.mp4[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8wbNEJjBa0k.mp4[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8wbNEJjBa0k.mp4 | Selected 13 frames[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=236[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences is correct?
A. First, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him. Next, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Finally, a soldier inside a room takes an item out of his pocket and places it on the table.
B. First, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Next, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him. Finally, a soldier inside a room takes an item out of his pocket and places it on the table.
C. First, a soldier inside a room takes an item out of his pocket and places it on the table. Next, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him. Finally, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat.
D. First, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Next, a soldier inside a room takes an item out of his pocket and places it on the table. Finally, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him.
E. First, a soldier inside a room takes an item out of his pocket and places it on the table. Next, on the battlefield, two soldiers holding guns stand beside a soldier wearing a red hat. Finally, a soldier sits in front of a tent eating food from his hand, with two women in orange shorts beside him.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XuQswmEPgxU.mp4[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XuQswmEPgxU.mp4[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XuQswmEPgxU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=239[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a man with short hair, who is wearing a red tight shirt, appears next to a woman with long golden hair, who is wearing a tight outfit, in front of a solid black background, what changes in him?
A. Both hands change from being clasped in front of the abdomen to having palms up, pointing to the left
B. The left hand changes from touching the forehead to touching the nose
C. Both hands change from arms placed in front and behind to being clasped together
D. Both hands change from one hand clenched into a fist to both hands clenched into fists
E. Both hands change from being clasped in front of the abdomen to having palms up, pointing to the right
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 119/150 [04:50<00:58,  1.90s/it][32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ytv-9RM4e0o.mp4[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ytv-9RM4e0o.mp4[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ytv-9RM4e0o.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=238[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the gray background, on the far right side, there is a picture. In the picture, a woman is turning her head to look at a man behind her. Below the picture, in white English text, it says 'James Van Der Zee, Self-Portrait with Gaynella Greenlee'. Where else has this picture appeared?
A. Appears in the top right corner of a screen displaying eight pictures at the same time
B. Appears in the top left corner of a screen displaying six pictures at the same time
C. Appears in the top right corner of a screen displaying six pictures at the same time
D. Appears in the bottom left corner of a screen displaying six pictures at the same time
E. Appears in the bottom right corner of a screen displaying six pictures at the same time
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aqUisZS9Ruw.mp4[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aqUisZS9Ruw.mp4[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aqUisZS9Ruw.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=241[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall, a man wearing a patterned red shirt sits on a black chair. Next to him is a black shelf. When the subtitle 'has been happening my birthday happened' appears, what transformation occurs to the man in the patterned red shirt?
A. The man's shirt changes from red to black.
B. The man's shirt changes from red to yellow.
C. The man's shirt changes from red to green.
D. The man's shirt changes from red to purple.
E. The man's shirt changes from red to white.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 120/150 [04:53<01:09,  2.33s/it][32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7275734357799652640.mp4[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7275734357799652640.mp4[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7275734357799652640.mp4 | Selected 9 frames[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=240[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-28 04:49:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a woman with long black hair wearing a white coat is clenching her hands tightly. On the screen, there is the word 'but'. In which subtitles has this woman appeared together with these words?
A. hope you want to
B. museums I saw my first dog just
C. please take please take my car s if they
D. people here also really nice especially
E. be spending all the night Moon
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fO7nwCix8xU.mp4[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fO7nwCix8xU.mp4[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fO7nwCix8xU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=243[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a close-up of a purple flower. The entire petal of the flower is elongated. The stamen is yellow, and there are many similar purple flowers nearby. What happened when the flower first appeared?
A. Two bees landed on the flower.
B. A bee was flying over the flower.
C. Several bees were flying over the flower.
D. A bee landed on the flower.
E. Two bees were flying over the flower.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 121/150 [04:54<00:57,  1.97s/it][32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fryyNwUCPWA.mp4[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fryyNwUCPWA.mp4[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fryyNwUCPWA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=242[0m
[32m2025-11-28 04:49:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a slightly dimly lit room with a light beam, three men are sitting by a gray table. On the left is a man with short hair wearing a black shirt and a red tie. In the middle is a man wearing a yellow long-sleeve shirt and a red tie. On the right is another man in a black shirt. There are several items placed on the table. Which of the following items has appeared on the table?
A. Jump rope
B. Book
C. Drink
D. Snacks
E. Cup
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PCPQToF10IM.mp4[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PCPQToF10IM.mp4[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PCPQToF10IM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=245[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a round cylindrical space, there is a man sitting who is wearing a white coat and blue jeans. When the subtitle 'orange nice well I honestly never' appears, what objects are present on the screen?
A. white hat
B. silver ring
C. red shoes
D. blue hat
E. black-framed glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 122/150 [04:57<01:01,  2.19s/it][32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -0aM99dMu_4.mp4[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-0aM99dMu_4.mp4[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -0aM99dMu_4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=244[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the desert, there are three mannequins. In front of the mannequins, there is a man wearing an olive-colored coat. Next to him, a person wearing a black hat and black clothes is holding a handgun. After the subtitle mentions 'off target by 0.5 mm sensing', what item appears in the video?
A. ÊâãË°®
B. È¶ôÁÉü
C. Ê£ãÁõò
D. Êú®Ê°å
E. ÊâãÊû™
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sEiyR7-0FOA.mp4[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sEiyR7-0FOA.mp4[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sEiyR7-0FOA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=247[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black-bordered, white-background image, there are three equally sized video windows labeled 'timesteps'. When 'the unsupervised method will discover' is mentioned, what change occurs in the first video window?
A. It shows one segment of a black-and-white grid with two green objects.
B. It shows two segments of a black-and-white grid with two green objects.
C. It shows two segments of a pure black screen with two green objects.
D. It shows one segment of a pure black screen with two green objects.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 123/150 [04:59<00:59,  2.21s/it][32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 51dUUxFOjDE.mp4[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/51dUUxFOjDE.mp4[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 51dUUxFOjDE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=246[0m
[32m2025-11-28 04:49:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two people are standing on an orange ground. On the left is a person wearing a helmet and holding a knife and shield. On the right is a person with black hair, also holding a knife and shield. When the subtitle 'threat of death or severe injury ever' appears, what is the shape of the shield held by the person on the left?
A. Square
B. Pentagon
C. Rectangle
D. Circle
E. Parallelogram
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TlaX2iIYZD4.mp4[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TlaX2iIYZD4.mp4[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TlaX2iIYZD4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=249[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into three parts: left, center, and right. The left side is all text, the center is a map, and the right side is a man in black clothing. What did the man do after the map in the center moved?
A. Waved at the camera
B. Put on a coat
C. Stood up
D. Kneeled down
E. Looked up
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 124/150 [05:01<00:58,  2.25s/it][32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VwZeSoYugZk.mp4[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VwZeSoYugZk.mp4[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VwZeSoYugZk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=248[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Above a green lake, there is a small building by the shore. In the distance, there are some mountain peaks and a deep blue sky with clouds floating in it. The small building by the lake is light yellow with two windows. When it is mentioned that 'and only allowing a small group of people and animals, to survive and repopulate,' what is the shape of the roof of the small building?
A. Staircase
B. Square
C. Triangle
D. Rectangle
E. Semi-circle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 125/150 [05:04<01:00,  2.41s/it][32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DVsw1brd_Yc.mp4[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DVsw1brd_Yc.mp4[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DVsw1brd_Yc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=250[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the top of the PPT in the video, there are three lines of English titles, with the bottom filled with chemical formulas. On the right, there are video frames of two women. The woman in the lower right is wearing a light-colored short-sleeve, long hair, and black-rimmed glasses. The woman in the upper right is wearing a black-and-white checkered jacket with a dark red inner layer. What is the hairstyle of the woman in the upper right when the subtitle 'of these and the limiting reactant is' appears?
A. Short curly hair
B. Short black hair
C. Long straight black hair
D. Curly black hair
E. Brown hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F4bDyyEO4PU.mp4[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F4bDyyEO4PU.mp4[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F4bDyyEO4PU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=251[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white desk with an open book and a black keyboard, there is an orange-red book with the words 'LUCKY PLANET' on the cover. In which of the following scenes has this book appeared?
A. In the hands of a child wearing a black short-sleeve shirt
B. In the hands of a woman wearing black scrubs
C. In the hands of a man wearing black scrubs
D. In the hands of a man wearing a black short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 126/150 [05:07<00:58,  2.44s/it][32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JpjytHmGHZ4.mp4[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JpjytHmGHZ4.mp4[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JpjytHmGHZ4.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=252[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the cooking tutorial, which of the following sequences of steps is correct?
A. First, demonstrate how to use purple sweet potatoes and red peppers to make a side dish; then demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; finally, demonstrate how to use beef, green onions, and related seasonings to make beef patties.
B. First, demonstrate how to use beef, green onions, and related seasonings to make beef patties; then demonstrate how to use purple sweet potatoes and red peppers to make a side dish; finally, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan.
C. First, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; then demonstrate how to use beef, green onions, and related seasonings to make beef patties; finally, demonstrate how to use purple sweet potatoes and red peppers to make a side dish.
D. First, demonstrate how to use purple sweet potatoes and red peppers to make a side dish; then demonstrate how to use beef, green onions, and related seasonings to make beef patties; finally, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan.
E. First, demonstrate how to use beef, green onions, and related seasonings to make beef patties; then demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; finally, demonstrate how to use purple sweet potatoes and red peppers to make a side dish.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = a_8G0PzVFbc.mp4[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/a_8G0PzVFbc.mp4[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: a_8G0PzVFbc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=253[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of an olive background, a man wearing a red short-sleeved shirt holding a guitar is standing in front of a microphone. When the subtitle 'ask she should have an irrational fear' appears, what is this man doing?
A. Waving to the audience
B. Making a speech
C. Performing magic
D. Dancing on stage
E. Playing the guitar and singing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 127/150 [05:09<00:55,  2.43s/it][32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = X5v4nBo5y28.mp4[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/X5v4nBo5y28.mp4[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: X5v4nBo5y28.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=254[0m
[32m2025-11-28 04:49:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a grassy area where fresh sprouts are just emerging, there is a long-haired cat with black and yellow fur. To its right, there is a large tree with some blue buds, and on the grassland with a red wall, there is a small rabbit sitting. Which of these two animals appeared first?
A. Long-haired cat
B. Neither appeared
C. Small rabbit
D. Both appeared at the same time
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zVudr8cxHRE.mp4[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zVudr8cxHRE.mp4[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zVudr8cxHRE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=255[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a white house by the river, with various trees planted around it. Two people in long sleeves are walking towards the white house. When the subtitles mention 'They run into landlady and she tells them that Abigail disappeared one day and never ', which of the following items appears for the first time?
A. computer
B. snack
C. mobile phone
D. balloon
E. scissors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 128/150 [05:12<00:58,  2.68s/it][32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LHXS0QR1ThA.mp4[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LHXS0QR1ThA.mp4[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LHXS0QR1ThA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=256[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are two men in a room. The man on the left is wearing a yellow shirt, a hat backwards, and a watch on his left hand. The man on the right is wearing a shirt with red flowers and green leaves and has a bracelet on his left hand. When the subtitle mentions "interested enough to join us but first," what change happens to the man wearing the shirt with red flowers and green leaves?
A. He takes off his bracelet
B. He changes into a black short-sleeved shirt
C. He changes into a white long-sleeved shirt
D. He changes into a black jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KFqlW0APKRA.mp4[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KFqlW0APKRA.mp4[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KFqlW0APKRA.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=257[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:49:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman with long hair wearing a black coat explaining a protest activity in an empty room. What was her first action when she appeared?
A. Sitting
B. Lying down
C. Standing
D. Crouching
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7303594391850044678.mp4[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7303594391850044678.mp4[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7303594391850044678.mp4 | Selected 14 frames[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=259[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, there is a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37, then a page with the word 'results' appears, and finally 9 small animals appear.
B. First, there is a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37, then 9 small animals appear, and finally a page with the word 'results' appears.
C. First, 9 small animals appear, then a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37, and finally a page with the word 'results' appears.
D. First, a page with the word 'results' appears, then 9 small animals appear, and finally a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 129/150 [05:15<00:53,  2.55s/it][32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7258968758130085146.mp4[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7258968758130085146.mp4[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7258968758130085146.mp4 | Selected 11 frames[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=258[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-28 04:49:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a small island on the blue sea, the island is full of green plants, and there are many boats docked along the shore. Among them, the largest boat in the middle, what color is the largest boat in the middle?
A. red
B. black
C. yellow
D. white
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = O3Hwh0uv8Mg.mp4[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/O3Hwh0uv8Mg.mp4[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: O3Hwh0uv8Mg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=261[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a woman wearing a white dress. She is standing on a rock, gazing into the distance. In front of her, there is a green lake, and in the distance, there are some orange buildings. After the woman gazes into the distance, what happens next?
A. The woman walks on a stone path surrounded by green plants, between pink and yellow buildings.
B. The woman walks on a stone path surrounded by green plants, between green and black buildings.
C. The woman walks on a stone path surrounded by green plants, between green and yellow buildings.
D. The woman walks on a stone path surrounded by green plants, between blue and yellow buildings.
E. The woman walks on a stone path surrounded by green plants, between green and white buildings.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 130/150 [05:16<00:45,  2.29s/it][32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 88LbBgZP1vQ.mp4[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/88LbBgZP1vQ.mp4[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 88LbBgZP1vQ.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=260[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the movie scene, there is a man in gray-black clothes standing between a red door and wall on the left, and a silver-white window and yellow wall on the right. After this man appears, which person or object appears first?
A. ambulance
B. woman in yellow clothes
C. car
D. motorcycle
E. woman in red clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7125042270381853995.mp4[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7125042270381853995.mp4[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7125042270381853995.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=263[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an indoor basketball court with red walls and a yellow floor, there is a girl wearing a purple short-sleeve shirt with her hair tied up, holding a basketball. In which of the following places has the girl appeared?
A. In a room with a beige sofa
B. In a playground
C. In a quiet park
D. By the beach
E. In a clothing store with many beautiful clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 131/150 [05:20<00:53,  2.81s/it][32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WpbB_swXHkc.mp4[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WpbB_swXHkc.mp4[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WpbB_swXHkc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=262[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the text 'Now for the sweet part, add some sweetened condensed milk right on top.' appears at the bottom of the screen, what changes happen in the transparent glass bowl containing green avocado?
A. Red tomato sauce is added
B. Pink condensed milk is added
C. Sweetened condensed milk is added
D. Green fruit sauce is added
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = N4VtpYgZLVg.mp4[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/N4VtpYgZLVg.mp4[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: N4VtpYgZLVg.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=265[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the right side of a desk with a building in the background, there are three icons, and next to the icons is a video being recorded. In the video, on a sofa with red flowers embroidered on it, sits a woman wearing earrings and a long-sleeved wine-red garment. With which subtitles does this woman appear together?
A. before the time of the pandemic here
B. crowded men
C. myself
D. really exciting to me to have it all to
E. me to 
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 132/150 [05:23<00:48,  2.67s/it][32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7270058445577948418.mp4[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7270058445577948418.mp4[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7270058445577948418.mp4 | Selected 13 frames[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=264[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-28 04:49:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the restaurant beside the dim street, a man in a gray short-sleeved shirt is sitting by the tree for a meal. On his left, there is a man wearing glasses and a white short-sleeved shirt along with a woodpile. On his right, there is someone in a yellow outfit and his friend sitting in a dark corner. What items are present in the scene?
A. a cat
B. a watch
C. a bicycle
D. a hat
E. a dog
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2ekjGl8yWZk.mp4[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2ekjGl8yWZk.mp4[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2ekjGl8yWZk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=267[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scenario sequences is correct?
A. First, flames engulf a person, then a woman in yellow clothing and a person in a black outfit lie together, and finally, a man wearing a grey outfit lights a lighter.
B. First, a man wearing a grey outfit lights a lighter, then flames engulf a person, and finally, a woman in yellow clothing and a person in a black outfit lie together.
C. First, a man wearing a grey outfit lights a lighter, then a woman in yellow clothing and a person in a black outfit lie together, and finally, flames engulf a person.
D. First, flames engulf a person, then a man wearing a grey outfit lights a lighter, and finally, a woman in yellow clothing and a person in a black outfit lie together.
E. First, a woman in yellow clothing and a person in a black outfit lie together, then a man wearing a grey outfit lights a lighter, and finally, flames engulf a person.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 133/150 [05:24<00:39,  2.35s/it][32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bgklOaBBmB8.mp4[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bgklOaBBmB8.mp4[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bgklOaBBmB8.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=266[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:49:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table in the video, there is a transparent bowl containing orange food. What happened when the subtitle 'foreign' appears?
A. Holding a spoon and stirring the food in the bowl
B. A hand is holding a transparent bowl
C. Both hands are holding a transparent bowl
D. Holding chopsticks and stirring the food in the bowl
E. Holding a spoon and scooping the food in the bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 134/150 [05:26<00:34,  2.17s/it][32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Dkm35G5kkcc.mp4[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Dkm35G5kkcc.mp4[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Dkm35G5kkcc.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=268[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the white-background PPT, there is text in English by Liu that appears. When the blue arrow first appears above the second line of English text, what happens on the screen?
A. The blue arrow moves from bottom to top.
B. The blue arrow moves from left to right.
C. The blue arrow moves from right to left.
D. The blue arrow moves from top to bottom.
E. The blue arrow enlarges.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0ln2qdCR5lA.mp4[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0ln2qdCR5lA.mp4[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0ln2qdCR5lA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=269[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a man pins a map onto the lampshade with thumbtacks, then a man with headphones starts crying with his eyes closed, and finally someone walks into an empty classroom.
B. First, a man with headphones starts crying with his eyes closed, then a man pins a map onto the lampshade with thumbtacks, and finally someone walks into an empty classroom.
C. First, a man pins a map onto the lampshade with thumbtacks, then someone walks into an empty classroom, and finally a man with headphones starts crying with his eyes closed.
D. First, a man with headphones starts crying with his eyes closed, then someone walks into an empty classroom, and finally a man pins a map onto the lampshade with thumbtacks.
E. First, someone walks into an empty classroom, then a man pins a map onto the lampshade with thumbtacks, and finally someone walks into an empty classroom again.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 135/150 [05:28<00:33,  2.21s/it][32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = otaJfBSlsG8.mp4[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/otaJfBSlsG8.mp4[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: otaJfBSlsG8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=270[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are many instruments on the shelves of the laboratory. A man with short black hair, wearing a gray bulletproof vest, picks up a blue cup from the shelf. What did the man do after picking up the blue cup?
A. Kneeled down
B. Talked while turning around
C. Drank water
D. Ate something
E. Talked while running
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7161798161395240197.mp4[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7161798161395240197.mp4[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7161798161395240197.mp4 | Selected 12 frames[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=271[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-28 04:49:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a prepared wrap, with a piece cut off and held by a pair of hands. The background is a white marble table. In which other scene does this wrap appear?
A. Still on a marble table, there is a round green plate with the wrap covered in sesame seeds.
B. Still on a marble table, there is a round yellow plate with the wrap covered in sesame seeds.
C. Still on a marble table, there is a round black plate with the wrap covered in sesame seeds.
D. Still on a marble table, there is a round white plate with the wrap covered in sesame seeds.
E. Still on a marble table, there is a round pink plate with the wrap covered in sesame seeds.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2vVQo_GMA70.mp4[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2vVQo_GMA70.mp4[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2vVQo_GMA70.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=273[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white cabinet, there is a green potted plant on the side. In front, there is a woman with long black hair holding an illustrated book. Which of the following subtitles appeared with this illustrated book?
A. that afternoon stella and her clay
B. let's find a cozy spot and let's get
C. let's begin with our welcome song just
D. started
E. story time and activity now
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 136/150 [05:31<00:34,  2.49s/it][32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z7Cox6lPW3c.mp4[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z7Cox6lPW3c.mp4[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z7Cox6lPW3c.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=272[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, after the blue yarn ring appears for the first time, what is attached?
A. purple yarn ring
B. pencil
C. rubber eraser
D. animal head sticker
E. a piece of paper with 'Aldehyde' written on it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GuEptwLiAvs.mp4[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GuEptwLiAvs.mp4[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GuEptwLiAvs.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=275[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing red clothes and a man wearing black clothes are in a video call, and a sentence starting with 'TSMC GETS' is gradually being revealed at the bottom. What kind of hair does the woman in the video call have?
A. She has short blonde hair.
B. She has black hair.
C. She has no hair.
D. She has long blonde hair.
E. She has black bob cut.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 137/150 [05:34<00:32,  2.54s/it][32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = g_kziK-UOSU.mp4[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/g_kziK-UOSU.mp4[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: g_kziK-UOSU.mp4 | Selected 10 frames[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=274[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 04:49:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A car is stuck in a crevice between mountain rocks, severely damaged and emitting white smoke upwards. A person wearing blue clothing approaches the accident scene. What did this person in blue do afterwards?
A. Hold a fire extinguisher in their left hand
B. Hold a fire extinguisher in their right hand
C. Climb the mountain holding something in their left hand
D. Climb the mountain holding something in their right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 138/150 [05:35<00:26,  2.17s/it][32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zTeDF7mQ88A.mp4[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zTeDF7mQ88A.mp4[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zTeDF7mQ88A.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=276[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. A man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen; a man wearing gray sportswear with black earbuds is running outside.
B. A man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen; a man wearing gray sportswear with black earbuds is running outside; a man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf.
C. A man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing gray sportswear with black earbuds is running outside; a man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen.
D. A man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen; a man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing gray sportswear with black earbuds is running outside.
E. A man wearing gray sportswear with black earbuds is running outside; a man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sKvvuo9Yxqk.mp4[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sKvvuo9Yxqk.mp4[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sKvvuo9Yxqk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=277[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the palace, a man dressed in colorful underwear and a white cloak, wearing tree branch decorations on his head, is dragging a woman in a skirt whose eyes sparkle with pink hearts. What change happened the last time this woman with sparkling pink hearts in her eyes appeared?
A. Her eyes changed from pink heart shapes to black tears streaming.
B. Her glasses changed from black with tears to pink heart shapes.
C. The woman held a shield.
D. She went from standing to sitting.
E. She wore a woven grass headband.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 139/150 [05:38<00:23,  2.18s/it][32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eJr-y6UXnRE.mp4[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eJr-y6UXnRE.mp4[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eJr-y6UXnRE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=278[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with many yellow pages as the background, there is a blue-gray map. What changes occurred to the blue-gray map when the subtitle "subcontinent" appeared?
A. The entire map changed from blue-gray to red
B. The entire map changed from blue-gray to green
C. Different colors filled in the regions
D. The entire map changed from blue-gray to white
E. The entire map changed from blue-gray to purple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QPth_xqBXGY.mp4[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QPth_xqBXGY.mp4[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QPth_xqBXGY.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=279[0m
[32m2025-11-28 04:49:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the first food item displayed in the video?
A. Avocado
B. Beverage with ice cubes
C. Watermelon
D. Apple
E. Potato chips
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 140/150 [05:40<00:23,  2.34s/it][32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -QSAotqKqX8.mp4[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-QSAotqKqX8.mp4[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -QSAotqKqX8.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=280[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:49:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
How many women appear in the video in total?
A. 4 women
B. 5 women
C. 2 women
D. 1 woman
E. 3 women
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 141/150 [05:41<00:17,  1.96s/it][32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TMe7oXMJoSM.mp4[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TMe7oXMJoSM.mp4[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TMe7oXMJoSM.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=282[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen displays a black PPT background with the title 'War in Ukraine Factors' in gray letters. Below are three circles containing some drawings, followed by gray and red rectangles with some content written inside. What changes occur to the rectangles when the phrase 'actions of mot. riflemen and tanks to accomplish the task.' is mentioned?
A. Both rectangles became empty
B. Both rectangles were filled with more content
C. The gray rectangle disappeared
D. The red rectangle disappeared
E. The red rectangle was enlarged
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZGMGQsnSdLE.mp4[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZGMGQsnSdLE.mp4[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZGMGQsnSdLE.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=281[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen is a woman wearing a black low-cut top, and on the right side of the screen is a man with glasses wearing a grey suit. The man is holding a lyric book and singing. What change occurs to this man when the lyrics 'our iise up good God good God iise up' appear?
A. Wearing glasses changes to not wearing glasses
B. Standing on the stage changes to kneeling on one knee
C. Holding a lyric book changes to tightly holding the woman's hand
D. Standing on the stage changes to sitting on a bench
E. Holding a lyric book changes to holding a dumbbell
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 142/150 [05:44<00:17,  2.21s/it][32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iJgh2dnudIU.mp4[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iJgh2dnudIU.mp4[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iJgh2dnudIU.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=284[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
This is a model of the Earth. The blue ocean is surrounded by green and white land. When this image appeared together with the subtitle 'virgent plate boundaries on our planet,' what changes occurred?
A. The surface of the image has additional red lines, arrows, and black boxes with white text inside the black boxes
B. The white color on the image disappeared
C. The blue color on the image disappeared
D. The green color on the image disappeared
E. The surface of the image only has additional red lines
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7286546546932370721.mp4[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7286546546932370721.mp4[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7286546546932370721.mp4 | Selected 8 frames[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=283[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-28 04:49:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:49:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Next to a refrigerator covered in many pictures, there is a woman with purple hair wearing a green top. Her hands are open with the palms facing upwards. What items are behind her to the left?
A. Green and gray boards
B. A pot and some knives
C. Tea cup
D. Water faucet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:49:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 143/150 [05:46<00:15,  2.24s/it][32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = er1oRjH2iu8.mp4[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/er1oRjH2iu8.mp4[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: er1oRjH2iu8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=286[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:49:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, on the bustling street with many cars on the road, there is a man in a yellow short sleeve shirt also on the street. What is this man doing?
A. He is walking
B. He is running
C. He is riding a motorcycle
D. He is riding a bicycle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VkNF0rXuDXw.mp4[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VkNF0rXuDXw.mp4[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VkNF0rXuDXw.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=285[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A white-framed black screen shows no image. When the caption mentions 'Fahlman posted this note, which would solve everything,' what changes occur on the black screen?
A. Blue English text appears on the screen
B. Green English text appears on the screen
C. Green numbers appear on the screen
D. Red English text appears on the screen
E. Yellow English text appears on the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 144/150 [05:49<00:14,  2.42s/it][32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -kaF6SnSEo8.mp4[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-kaF6SnSEo8.mp4[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -kaF6SnSEo8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=288[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a piece of white paper, there is a black frame drawn on it, filled with blue water. Someone is holding a yellow pen. What is he doing?
A. Coloring the roof in the drawing
B. Coloring the flowers in the drawing
C. Coloring the radish in the drawing
D. Coloring the sun in the drawing
E. Coloring the western red cedar in the drawing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hXFfPjytMo0.mp4[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hXFfPjytMo0.mp4[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hXFfPjytMo0.mp4 | Selected 10 frames[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=287[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-28 04:50:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a grey chair, two people are sitting on a sofa watching a broadcasted news program on TV. On the TV screen, a blond female reporter in a red coat is speaking into a microphone. When the subtitle says 'but after seeing that Terence is being accused of involvement in the murder as well as the media's...', what is the color of the wall behind the TV?
A. red
B. green
C. white
D. blue
E. black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ip8khYCMb8Y.mp4[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ip8khYCMb8Y.mp4[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ip8khYCMb8Y.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=289[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a man wearing a red shirt with white stripes and a man wearing a white short-sleeve shirt with red and blue patterns appear in the video, which item are they both wearing?
A. The man in the white shirt is wearing black-framed glasses, while the man in the red shirt is not
B. A blue bracelet
C. The man in the red shirt is wearing black-framed glasses, while the man in the white shirt is not
D. The man in the red shirt is wearing an orange scarf, while the man in the white shirt is not
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 145/150 [05:52<00:11,  2.37s/it][32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = crmV4OduHYA.mp4[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/crmV4OduHYA.mp4[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: crmV4OduHYA.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=290[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the man wearing a yellow short-sleeve shirt and black shorts first appears on the surfboard in the desert, what is he doing?
A. Resting on the beach
B. Waving at the camera
C. Playing on the surfboard in the desert
D. Talking with friends
E. Making a phone call
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JhlzvoqKOc8.mp4[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JhlzvoqKOc8.mp4[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JhlzvoqKOc8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=291[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some people are sitting face-to-face at a long table outdoors, wearing name tags around their necks and smiling at each other. What happened earlier in the video?
A. A woman in a brick-red suit jacket is sitting and talking in front of a camera.
B. In the upper right corner of the screen, a man in a red short-sleeve shirt is explaining the PPT shown on the screen.
C. A man in a black shirt and a woman in a white coat with a grey inner lining are sitting in front of a camera, with the woman lifting her legs.
D. In the upper right corner of the screen, a man in a red short-sleeve shirt is pointing to a picture on the screen.
E. A man in a black shirt and a woman in a white coat with a grey inner lining are sitting in front of a mural and having a conversation.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 146/150 [05:55<00:10,  2.62s/it][32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 4ouAf1ldH60.mp4[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/4ouAf1ldH60.mp4[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 4ouAf1ldH60.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=292[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
By the riverbank, a woman in a pink backpack and black pants says in the subtitles, 'have intercourse. However, she changes her mind at the last moment and returns home.' What action did she take?
A. Picked up the white clothes
B. Threw the white clothes into the fire
C. Threw the white clothes into the river
D. Threw the white clothes on the ground
E. Put the white clothes on
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rIU_BQEuKQ8.mp4[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rIU_BQEuKQ8.mp4[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rIU_BQEuKQ8.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=293[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Underneath a shelf filled with round wooden logs, a man is stretching his arms while pulling a long, thin white noodle. What color is the shirt the man is wearing?
A. white
B. olive
C. red
D. black
E. purple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 147/150 [05:59<00:08,  2.96s/it][32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Jaw7eWzgWr0.mp4[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Jaw7eWzgWr0.mp4[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Jaw7eWzgWr0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=294[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, there is a sofa and a staircase. To the left, there are some black shelves. The background is a bit blurry. A man with black hair wearing a white T-shirt is sitting in front of a mirror. To his left, there is a pop-up image showing a group photo of 10 people. After he mentions, 'However, keep in mind the Chinese spoken here is more in reference to Cantonese and the other southern dialects rather than Mandarin,' what happens?
A. The pop-up on the left shows a picture of an old building under a blue sky
B. The photo pop-up on the left shows a picture of a man and a woman sitting on a beach holding a child, with '10%' written on it
C. The photo pop-up on the left disappears
D. The man changes into a jacket
E. The man takes out a cup
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UMFy3keSk-s.mp4[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UMFy3keSk-s.mp4[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UMFy3keSk-s.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=295[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with many musical instruments, there is a man wearing a dark green suit with a light blue shirt underneath, a blue tie, and glasses, holding a musical instrument. What is the color of the gloves worn by the man with glasses?
A. Black
B. Red
C. White
D. Yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 148/150 [06:01<00:05,  2.75s/it][32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7268213090708245761.mp4[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7268213090708245761.mp4[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7268213090708245761.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=296[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white walls, there is a brown wardrobe and a black television. A man in a pink short-sleeve shirt is sitting in the room. Which objects are present in the room with white walls?
A. A blue hat
B. A blue curtain
C. A black chair
D. A black and grey backpack
E. A white bed
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAHsR02dUc0.mp4[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAHsR02dUc0.mp4[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAHsR02dUc0.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=297[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with white text 'Tom used his eyes to signal Mike to take action', there is a table with many codes on it, and beside the table, there is a woman with short white hair wearing a red blouse. What is the woman in the red blouse doing when she first appears?
A. Covering her face with both hands
B. Putting both hands on the table with many codes
C. Drinking a glass of red wine
D. Brushing her hair with her right hand
E. Brushing her hair with her left hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 149/150 [06:04<00:02,  2.78s/it][32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wKd804fWOyQ.mp4[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wKd804fWOyQ.mp4[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wKd804fWOyQ.mp4 | Selected 15 frames[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=298[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-28 04:50:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a black screen, there are ten different colored particle-like objects sprayed on the screen, and at the bottom, there are circles of various colors from 0 to 9. After this, what happened to these different colored objects?
A. These differently colored objects became blurry and rectangular in shape
B. These differently colored objects became blurry and strip-like in shape
C. These differently colored objects became blurry and circular in shape
D. These differently colored objects were assembled together
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rzIiQ4Vxlbk.mp4[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rzIiQ4Vxlbk.mp4[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rzIiQ4Vxlbk.mp4 | Selected 16 frames[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=299[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-28 04:50:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-28 04:50:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room cluttered with various small objects, a man wearing black glasses and a green lab coat is sitting. Before the subtitle reads 'so yeah that's', what object appears first on the screen?
A. A refrigerator
B. A water dispenser
C. A bicycle
D. An oven
E. A small green plant
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [06:06<00:00,  2.71s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [06:06<00:00,  2.44s/it]
[32m2025-11-28 04:50:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What action did the curly-haired man wearing a striped black-and-white shirt, who was crouching in front of a camera, take when he said 'shoot had already started' in the subtitles?
A. Crouched on the ground
B. Looked down at the camera in his hand
C. Sat on the ground
D. Took off the striped black-and-white shirt
E. Picked up the camera and took a photo
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-28 04:50:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Postprocessing:   0%|          | 0/150 [00:00<?, ?it/s][32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rP7sQe784k8_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ysRFFN5nzqE_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: otaJfBSlsG8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fxCRCMLJ0PU_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wSHPuI7wWIg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7265337261737217312_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d5JlCEDlHGE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7289528053112343814_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: H2ksp6sRR-k_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ClYmTkGTGYg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kelseyinlondon-7068018011139050758_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TARe4G-SXfk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wxWo44MoCTI_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3avWNHoEDAg_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8ew0d0JmsfA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9PD3ciudpIE_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yU9fGAEcxJY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8foMISZGiyw_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vP-fQu22bng_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DoizYSYQRqU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: O471uwTNx6k_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gAgCnu82RHE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yqejTvYILlA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rMXJOKhf_AA_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7269746510462536962_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ze66pbJYr18_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qbA42wQoWAs_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PCz04UJFaUY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9WjElCiDpzM_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0rWA-p4p5IM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: md3LVlEzFBU_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: FoeeEQ0VVFE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CFm3bc9gqYE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5dJUUQufzw4_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSn78eNspwU_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 66dwcQ1Y048_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7254238802577820929_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: e_nAKiSutiA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: f0IbZGfTgUM_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8foMISZGiyw_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UN3ICsfqKEY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3u__SZlBLC0_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GdZYLAI0vpc_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSeq-nVSY_E_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fPLjjr8w6DU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: D0RyFh0hnkQ_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6HTO2SOxUc_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OmhVj_-cfH0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d7IqrLV6Tlg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eE5Z7gDbgVA_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fw1rirubXiU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Aau-XoIebno_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbgwG8fcIu0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OMJc43wUPLM_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SO3czkzeFjw_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XVXczyheik0_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QJ6sjg7SXOQ_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iJgh2dnudIU_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7115052132578921774_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: by3NxI0dA6w_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eJr-y6UXnRE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Y1YCvEip_ko_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F4bDyyEO4PU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bwnkg6GbXwU_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UwJTCg5fpXg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6S_e34j6q9U_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: brZugTJ0odg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Jfp1Ks7Hh1E_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WLl3SeraTV0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: I-yg_3yx6iA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5zbV24vyO44_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: T1K4rgs-1b8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tYqDvtknII4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ll3tR0kUZHc_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kONR5_mHofA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-6965059948090821890_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mfS6gyP0mwo_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ytv-9RM4e0o_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Efuyl2Anehg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: T57jVsvVVR0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JLnsWrzV_j4_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9m4wi5gPdHg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RN2g9sRuJhA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bgklOaBBmB8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mkqgTAe2_O4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pGEF7Tme3Tk_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -kaF6SnSEo8_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8MkL3W6wU3g_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SCZ_Z4NnikA_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VL259eBJ68w_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VL259eBJ68w_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mq6L8CnNJXc_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mS1QPVgBDQo_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eE5Z7gDbgVA_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: N7RTTiHsSjI_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LfUsGv-ESbc_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbcWAfHo5j0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QHS9ZZBdK-g_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AnLMDMzO4QY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: xiK00WS0lkE_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mq6L8CnNJXc_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Q4GK4asczVA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7259227637992705282_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6hBbXVkgxGE_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-7074483613273754882_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hznvV2bBkX4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KTY9bogonyw_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3pTVbQilDqY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OMJc43wUPLM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gyV6EqgiPNg_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d5JlCEDlHGE_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VFXJnbnN5ro_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F2OhCCEIOcU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HWyDOQrYtCk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XJ6REZOXsvM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KWv8DJMEHsE_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MJYBHfYF8LI_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: q2bpkhjNxf0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oCXKARwr6PA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UwlKYM2Sotg_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2vVQo_GMA70_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pJuq8D1NGJQ_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lN3WnXMaE0o_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: X5v4nBo5y28_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-6880172230588894465_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lzAESaVqix0_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ysRFFN5nzqE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7276598470151032066_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: soNQYQXrx_A_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZRMbh0wSly0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: md3LVlEzFBU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RN2g9sRuJhA_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Scne0ls23MA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: I-yg_3yx6iA_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WmrwQMFZLqI_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TFbGLEZ4qt0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GGwHSz9towk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7284252812194729248_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6Lb1PyJxVQM_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -An3wZyoYe0_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 88LbBgZP1vQ_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: x1FkhxMMIcg_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7257359603489443073_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: t48HXAjjDAU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vix2_R79-l4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bUaFXONIXzM_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @luxtravelbe-7233851486474636570_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ip9DbdOtqF4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KIf2fGmluhY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bwDfdTh0VYs_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tdA5atpqaAc_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aVHAr8rc-Ks_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -eRimFrm6kQ_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YehqA9xoGTY_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fZBC3nmvJb8_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hg2Q_O5b9w4_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i8TJ7RgimNM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OmhVj_-cfH0_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ro_8-CCORzk_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qyaQ-wfojbM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 60oHeCZHtvI_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 97nEBjiQI1M_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bAGhXcYc0o4_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: o2F-N42Ufo4_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vVRC-0VKPrg_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7231566545263103259_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @asianfoodrecipes-7109221563697876225_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7270058010888768770_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7267884432420277506_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CEZ9rbjK3P4_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UUaiqR1I454_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pPJq1rMDRGs_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MPQn_orwpfA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wvfctNd-Aio_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yXXhrMqfMlk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: baFsMWNavQ4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7m9XIXyT5_I_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F7RSW-2rF4w_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6Lb1PyJxVQM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: u-vYvqxHejY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HQns-h_82qU_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ro_8-CCORzk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qjY9kmveQAk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZRMbh0wSly0_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-6862748507976011013_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qksR2Zvd-FM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fLn06p2HtAc_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: athabNMGceo_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2vVQo_GMA70_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wvfctNd-Aio_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RQOdl64DtdI_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 86CxyhFV9MI_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7297000148201262341_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UD5ifzOPzhc_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: e6HwinLBK_Y_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kj3Po7zUeyw_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mFliMGufpwc_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: acAWfzV__XI_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8MkL3W6wU3g_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F8Ma1qs0Rkg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6S_e34j6q9U_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: n24n_20Kwe4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7141686631676808454_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Y5833KeDmp4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZfapKqwklG4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SFfWUrsg4gE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NMHmqgO04rU_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GGwHSz9towk_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: D0RyFh0hnkQ_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _ZIa6SEJEyg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wFrztzzohJ8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GawGUhl9zuQ_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pFtKaT3GF9I_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GdFMKGNFXaE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JpjytHmGHZ4_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: US5Oz0q0BVE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dE5iWeCVpGI_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WmrwQMFZLqI_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Aau-XoIebno_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JuthlQ2Zo38_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9WjElCiDpzM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2F7d7aUCmUU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZsnfXfuGRrg_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: V-RIpt7Tknc_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7267308320413797650_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vVRC-0VKPrg_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: acAWfzV__XI_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: luRqMb5qfhM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: athabNMGceo_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ezhafkxoRdo_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jdbG9gmg_SA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LAbtlJJhUlY_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7267233980473314606_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: er1oRjH2iu8_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8wbNEJjBa0k_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: s49y2RP5C7E_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ytv-9RM4e0o_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XuQswmEPgxU_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @_eat_sleep_travel_repeat-7275734357799652640_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aqUisZS9Ruw_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fryyNwUCPWA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fO7nwCix8xU_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -0aM99dMu_4_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PCPQToF10IM_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 51dUUxFOjDE_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sEiyR7-0FOA_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VwZeSoYugZk_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TlaX2iIYZD4_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DVsw1brd_Yc_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F4bDyyEO4PU_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JpjytHmGHZ4_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: a_8G0PzVFbc_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: X5v4nBo5y28_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zVudr8cxHRE_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LHXS0QR1ThA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KFqlW0APKRA_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kelseyinlondon-7258968758130085146_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7303594391850044678_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 88LbBgZP1vQ_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: O3Hwh0uv8Mg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WpbB_swXHkc_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7125042270381853995_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7270058445577948418_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: N4VtpYgZLVg_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bgklOaBBmB8_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2ekjGl8yWZk_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Dkm35G5kkcc_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0ln2qdCR5lA_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: otaJfBSlsG8_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7161798161395240197_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z7Cox6lPW3c_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2vVQo_GMA70_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: g_kziK-UOSU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GuEptwLiAvs_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zTeDF7mQ88A_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sKvvuo9Yxqk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eJr-y6UXnRE_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QPth_xqBXGY_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -QSAotqKqX8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZGMGQsnSdLE_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TMe7oXMJoSM_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @luxtravelbe-7286546546932370721_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iJgh2dnudIU_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VkNF0rXuDXw_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: er1oRjH2iu8_2]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hXFfPjytMo0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -kaF6SnSEo8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ip8khYCMb8Y_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: crmV4OduHYA_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JhlzvoqKOc8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 4ouAf1ldH60_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rIU_BQEuKQ8_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Jaw7eWzgWr0_1]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UMFy3keSk-s_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7268213090708245761_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAHsR02dUc0_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wKd804fWOyQ_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rzIiQ4Vxlbk_0]:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 3300.57it/s]
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m631[0m - [1m================================================================================[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m632[0m - [1mLONGVIDEOBENCH CUSTOM RESULTS (with Frame Selection)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m633[0m - [1m================================================================================[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m641[0m - [1m
Accuracy by Duration Group:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m642[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  15s                           : 60.00% (40 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  60s                           : 75.00% (40 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  600s                          : 59.00% (100 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  3600s                         : 64.17% (120 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m650[0m - [1m
Accuracy by Question Category:[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m651[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E2O                           : 81.82% (11 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E3E                           : 75.00% (16 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O2E                           : 63.16% (19 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O3O                           : 72.22% (18 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2A                           : 71.43% (21 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2E                           : 77.42% (31 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2O                           : 66.67% (21 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SAA                           : 70.59% (17 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SOS                           : 64.29% (14 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SSS                           : 38.46% (26 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2A                           : 66.67% (21 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2E                           : 60.00% (15 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2O                           : 62.50% (8 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3E                           : 60.00% (10 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3O                           : 46.67% (15 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TAA                           : 52.38% (21 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TOS                           : 50.00% (16 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m658[0m - [1m
================================================================================[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m659[0m - [1mOVERALL ACCURACY: 63.33% (300 samples)[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m660[0m - [1m================================================================================[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2025-11-28 04:50:20[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m287[0m - [1mSaving samples to /home/train01/miraj/lmms_eval/results/full_logs/300_run_LV/selected_dbfp_longvideobench_blip_k16_alpha0.85_sup2.0_temporal_20251128_044352_results/..__LLaVA-NeXT-Video-7B-Qwen2/20251128_124358_samples_longvideobench_custom.jsonl[0m
llava_vid (pretrained=../LLaVA-NeXT-Video-7B-Qwen2,conv_template=chatml_direct,video_decode_backend=decord,max_frames_num=16,overwrite=False), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|        Tasks        |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|---------------------|------:|------|-----:|--------------|---|-----:|---|------|
|longvideobench_custom|      1|none  |     0|lvb_custom_acc|‚Üë  |0.6333|¬±  |   N/A|

[rank0]:[W1128 04:50:21.437019689 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
