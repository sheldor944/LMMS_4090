The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-11-29 11:57:22[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-29 11:57:22[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-29 11:57:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-29 11:57:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-29 11:57:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-29 11:57:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-29 11:57:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-29 11:57:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-29 11:57:24[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_3.0_r60_5.0_r600_9.0_r3600_12.0_score_diff_iter1_20251129_115718_results'}[0m
[32m2025-11-29 11:57:24[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-29 11:57:24[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-29 11:57:24[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_3.0_r60_5.0_r600_9.0_r3600_12.0_score_diff_iter1_20251129_115718_results'}[0m
[32m2025-11-29 11:57:24[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-29 11:57:24[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
OpenCLIP not installed
OpenCLIP not installed
force sample: False
force sample: False
Rank 0:  Loaded LLaVA model: ../LLaVA-NeXT-Video-7B-Qwen2
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:07,  2.57s/it]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.88s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:04,  2.33s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:05<00:05,  2.64s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:06<00:02,  2.27s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:07<00:02,  2.57s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  1.79s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  2.00s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  1.98s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  2.23s/it]
Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 330 examples [00:00, 35051.67 examples/s]
[32m2025-11-29 11:57:37[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 1 (local rank 1)[0m
[32m2025-11-29 11:57:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank1-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-29 11:57:37[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 1...[0m
  0%|          | 0/165 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 6965.81it/s]
[32m2025-11-29 11:57:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 165[0m
Rank 0:  Model Class: LlavaQwenForCausalLM
[32m2025-11-29 11:57:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36m__init__[0m:[36m215[0m - [1mUsing 2 devices with data parallelism[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 0 (local rank 0)[0m
[32m2025-11-29 11:57:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank0-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 0...[0m
  0%|          | 0/165 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 7082.80it/s]
[32m2025-11-29 11:57:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 165[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/165 [00:00<?, ?it/s][32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tWiGnu2BNsY.mp4[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tWiGnu2BNsY.mp4[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tWiGnu2BNsY.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=0[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=1[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a yellow coat is shopping with a red shopping basket in a supermarket. To his left is a woman wearing blue clothes. What happened in front of the man while he was shopping?
A. Kissed a prison guard
B. Fought with a prison guard
C. Danced with a prison guard
D. Shook hands with a prison guard
E. Hugged a prison guard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:   1%|          | 1/165 [00:03<09:10,  3.36s/it][32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mqtJErix0ss.mp4[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mqtJErix0ss.mp4[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mqtJErix0ss.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=2[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman dressed in an off-shoulder top is sitting on a white sofa, wearing a necklace and a ring. Behind her, there's a black railing and a white wall with a plant on the railing. To her right is the cover of a book, and to her left is a book. What is the woman doing when the subtitle 'colleen hooper you did it again' appears?
A. The woman is holding a pen with one hand.
B. The woman is holding a book with one hand.
C. The woman is holding a book with one hand.
D. The woman is lifting the book above her head.
E. The woman is holding a book with both hands.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7233851486474636570.mp4[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7233851486474636570.mp4[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7233851486474636570.mp4 | Selected 9 frames[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=3[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 11:57:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Holding two cups containing liquid, the cup on the right has some bubbles inside. In the distance, there is a sunset. What happens when the two cups touch for the first time?
A. A third cup appears
B. Bubbles appear in the left cup
C. The bubbles in the right cup disappear
D. They clink the cups again
E. The cups move out of the frame
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7TljSpTBS9c.mp4[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7TljSpTBS9c.mp4[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7TljSpTBS9c.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=5[0m
[32m2025-11-29 11:57:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark environment, an old-fashioned rotary television is playing a scene where a missile emits light and rushes upwards. What change occurs to the missile when the subtitle 'it seems that whenever they were' appears?
A. The missile turns into a wooden head
B. The missile turns into plastic
C. The missile splits into two halves
D. The missile turns into an ice block
E. The missile explodes into smoke
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   1%|          | 2/165 [00:05<07:24,  2.73s/it][32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PQRyGacBRA4.mp4[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PQRyGacBRA4.mp4[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PQRyGacBRA4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=4[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A strip of paper is placed on a white background, with three lines of English written on it. To the left of the paper strip, there is a black wheel-shaped object and a purple light. A hand is pointing at the paper strip while explaining something. After explaining the paper strip, what does the owner of the hand do?
A. Take a yellow toy chicken from the corner
B. Take a magazine from a black bag
C. Take a music box from the corner
D. Take a green toy from the corner
E. Take an apple from a black bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F4bDyyEO4PU.mp4[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F4bDyyEO4PU.mp4[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F4bDyyEO4PU.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=7[0m
[32m2025-11-29 11:57:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a suit and a purple tie is walking on a concrete road surrounded by trees and parked cars. He has short hair and is holding a piece of white paper in his hand. What other scenes did this man appear in?
A. On a stage with British flags displayed
B. In a library with a brown bookshelf full of books, in front of a green desk
C. In front of a blue backdrop with the British flag
D. In front of a complex building with a bell tower and some withered branches on the left
E. In front of a green backdrop painted with various colorful buildings
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   2%|‚ñè         | 3/165 [00:07<06:45,  2.51s/it][32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CGngv8vTQOs.mp4[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CGngv8vTQOs.mp4[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CGngv8vTQOs.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=6[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a starry backdrop, there is a shrunken image of the Earth in the upper left corner with a gray rocket on it. Alongside the image, the word 'Playlist' is written in red text. What is the gray rocket doing?
A. Flying towards the Sun
B. Flying towards Jupiter
C. Rotating with its head and tail separated
D. Flying towards Uranus
E. Flying downward
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   2%|‚ñè         | 4/165 [00:10<06:22,  2.38s/it][32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YebUIUOCo94.mp4[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YebUIUOCo94.mp4[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YebUIUOCo94.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=8[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the cooking tutorial, which of the following sequences of steps is correct?
A. First, demonstrate how to use purple sweet potatoes and red peppers to make a side dish; then demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; finally, demonstrate how to use beef, green onions, and related seasonings to make beef patties.
B. First, demonstrate how to use beef, green onions, and related seasonings to make beef patties; then demonstrate how to use purple sweet potatoes and red peppers to make a side dish; finally, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan.
C. First, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; then demonstrate how to use beef, green onions, and related seasonings to make beef patties; finally, demonstrate how to use purple sweet potatoes and red peppers to make a side dish.
D. First, demonstrate how to use purple sweet potatoes and red peppers to make a side dish; then demonstrate how to use beef, green onions, and related seasonings to make beef patties; finally, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan.
E. First, demonstrate how to use beef, green onions, and related seasonings to make beef patties; then demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; finally, demonstrate how to use purple sweet potatoes and red peppers to make a side dish.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bqQTWdk1DAM.mp4[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bqQTWdk1DAM.mp4[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bqQTWdk1DAM.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=9[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a man wearing a military uniform, with yellow decorations on his shoulders, and a red shoulder strap. When the subtitle mentions 'in the challenging years that lay ahead,' what is the man's hairstyle?
A. Bald
B. Mediterranean
C. Long hair
D. Crew cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:   3%|‚ñé         | 5/165 [00:12<06:09,  2.31s/it][32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DVsw1brd_Yc.mp4[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DVsw1brd_Yc.mp4[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DVsw1brd_Yc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=10[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a multi-colored shirt is sitting in the outdoor dining area of a restaurant. The man is holding a yellow package in his hand. Next to him are a white basket and green plants. Behind the man, there is an open umbrella and other diners. On the left side of the screen, there are colorful flags and the entrance of a shop. What is the first food the man eats?
A. Apple
B. Pie
C. Mooncake
D. Bread
E. Yogurt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yFAuXmcGk2Y.mp4[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yFAuXmcGk2Y.mp4[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yFAuXmcGk2Y.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=11[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with two display screens in the background, a man in a black coat is holding a blue book with a black cap in his left hand. In which of the following scenarios does this book appear?
A. On a black keyboard
B. On a piano key
C. On a white bookshelf
D. On an olive-colored desk
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   4%|‚ñé         | 6/165 [00:14<06:20,  2.39s/it][32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = e-EtQHH4aWE.mp4[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/e-EtQHH4aWE.mp4[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: e-EtQHH4aWE.mp4 | Selected 7 frames[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=12[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white background with black text, there is a segment of bold black text in the middle containing the phrase 'Benefit Tasks.' Above this, some words are partially covered with a yellow overlay. After the phrase 'Benefit Tasks' is enlarged on the screen, what changes occur?
A. Turned red
B. Shrunk
C. Covered with yellow overlay
D. Disappeared
E. Covered with blue overlay
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dCscvoOX2as.mp4[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dCscvoOX2as.mp4[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dCscvoOX2as.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=13[0m
[32m2025-11-29 11:57:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are five women talking in a room on screen. They are sitting on a couch. The second woman from the left is wearing red high heels. What does the second woman from the left do with her hands after the subtitle mentions 'the proposal we're doing for google in'?
A. Clasp hands together
B. No change
C. Make a fist
D. Shake hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:   4%|‚ñç         | 7/165 [00:15<05:07,  1.95s/it][32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fxCRCMLJ0PU.mp4[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fxCRCMLJ0PU.mp4[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fxCRCMLJ0PU.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=14[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x2f9d9c80] mmco: unref short failure
[32m2025-11-29 11:57:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a group of soldiers making rowing motions sitting in a green boat on a river, then several gray guns and two green grenades appear against a red background, and finally, five soldiers with helmets and face paint holding guns fiercely facing the camera.
B. First, a group of soldiers making rowing motions sitting in a green boat on a river, then several gray guns and two green grenades appear against a green background, and finally, three soldiers with helmets and face paint holding guns fiercely facing the camera.
C. First, several gray guns and two green grenades appear against a green background, then a group of soldiers making rowing motions sitting in a green boat on a river, and finally, three soldiers with helmets and face paint holding guns fiercely facing the camera.
D. First, several gray guns and two green grenades appear against a green background, then three soldiers with helmets and face paint holding guns fiercely facing the camera, and finally, a group of soldiers making rowing motions sitting in a green boat on a river.
E. First, a group of soldiers making rowing motions sitting in a green boat on a river, then several gray guns and two green grenades appear against a blue background, and finally, two soldiers with helmets and face paint holding guns fiercely facing the camera.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   5%|‚ñç         | 8/165 [00:17<05:12,  1.99s/it][32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZaXpMou55lw.mp4[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZaXpMou55lw.mp4[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZaXpMou55lw.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=16[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a grey coat and blue jeans is standing in front of a building with a glass facade. To his left, there is a small tree with red leaves. Between the man and the tree, there is the text 'FAZER'. What is the first white text that appears on the screen after this?
A. EKiM 2021
B. KASIM 2021
C. Subscribe
D. SANOMATALO
E. OODI KESKUSTAKIRJASTO
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MJYBHfYF8LI.mp4[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MJYBHfYF8LI.mp4[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MJYBHfYF8LI.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=15[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the upper right corner of a white background, a middle-aged man wearing a gray short-sleeved shirt is explaining. Behind him are a piano keyboard and various objects. At the top of the screen are bold English letters, and in the center is a table with white data on a black background. What object is present in the scene?
A. A silver bracelet
B. A pair of glasses
C. There is a URL
D. There is a wristwatch
E. A yellow bracelet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   5%|‚ñå         | 9/165 [00:20<05:38,  2.17s/it][32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=18[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:57:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:57:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At a presentation with a black background, what action did a man wearing black clothing and glasses take while speaking towards the microphone when he mentioned 'stack and the higher memory. And it's the to die within the same'?
A. Put on a hat
B. Removed his glasses
C. Showed two GPU chips to the camera
D. Took a sip of water
E. Took off his outer garment
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:57:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i6C6r2g4Y7Q.mp4[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i6C6r2g4Y7Q.mp4[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i6C6r2g4Y7Q.mp4 | Selected 12 frames[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=17[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 11:57:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a space with a wall marked with an 's', there are three elevator doors. Three men and three women are standing in front of the elevator doors, tossing two basketballs to each other. What action does the person wearing a black leather jacket first take when they appear?
A. He steps back into the crowd and then turns around with his back facing the elevator doors
B. He walks forward into the crowd and then turns around with his back facing the elevator doors
C. He walks backward straight through the crowd
D. He steps back into the crowd and then turns around facing the elevator doors
E. He walks forward into the crowd and then turns around facing the elevator doors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HWyDOQrYtCk.mp4[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HWyDOQrYtCk.mp4[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HWyDOQrYtCk.mp4 | Selected 7 frames[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=19[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a canyon, the walls on both sides are covered with green plants. There is a small stream below, with several stones on the left side and a golden-haired person on the right. In front of the camera is a man wearing a red headscarf and holding a black backpack. When the subtitle 'gonna weather proof my stuff like this' appears, what action does this man take?
A. Pats the black backpack
B. Raises his thumb
C. Opens the backpack
D. Puts down the backpack
E. Take off the headscarf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:   6%|‚ñå         | 10/165 [00:23<06:22,  2.47s/it][32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AnLMDMzO4QY.mp4[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AnLMDMzO4QY.mp4[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AnLMDMzO4QY.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=20[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the yellow table, there is a white bowl with instant noodles inside and a pair of chopsticks placed in the bowl. There is also a dark green bowl with vegetables and a blue plate with a fried egg. What items appeared after the word 'Music' was mentioned?
A. Fried egg
B. Instant noodles
C. Tablet, Milk Tea
D. Vegetables
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = baFsMWNavQ4.mp4[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/baFsMWNavQ4.mp4[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: baFsMWNavQ4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=21[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which subtitles appear together with the woman wearing a white top, denim overalls, and round earrings in the beginning of the video?
A. we've got the cookies and the freezer and cooling for about maybe 10 minutes so appear together
B. love the fact they're sweet and
C. the a hint of salt

D. beath bars are mike chocolate covered
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:   7%|‚ñã         | 11/165 [00:25<06:05,  2.38s/it][32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bgklOaBBmB8.mp4[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bgklOaBBmB8.mp4[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bgklOaBBmB8.mp4 | Selected 12 frames[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=22[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is a black-skinned woman wearing a white and green shirt with black floral patterns. She is standing in a white room with a large screen behind her displaying some images. The woman is speaking with her hands open, facing the camera. What subtitles appeared simultaneously with this woman?
A. Thank you
B. that we were doing
C. waht
D. SO

E. Can you
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F2OhCCEIOcU.mp4[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F2OhCCEIOcU.mp4[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F2OhCCEIOcU.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=23[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table in the video, there is a transparent bowl containing orange food. What happened when the subtitle 'foreign' appears?
A. Holding a spoon and stirring the food in the bowl
B. A hand is holding a transparent bowl
C. Both hands are holding a transparent bowl
D. Holding chopsticks and stirring the food in the bowl
E. Holding a spoon and scooping the food in the bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   7%|‚ñã         | 12/165 [00:27<05:29,  2.15s/it][32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tygk9-aneC4.mp4[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tygk9-aneC4.mp4[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tygk9-aneC4.mp4 | Selected 8 frames[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=24[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 11:58:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a bar chart comparing the cost-effectiveness of different German tanks during World War II. Which tank, introduced first, has the lowest cost?
A. Main Battle Tank
B. Tiger
C. Heavy Tank
D. Panther
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:   8%|‚ñä         | 13/165 [00:28<04:33,  1.80s/it][32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iDFDxwPTjeU.mp4[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iDFDxwPTjeU.mp4[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iDFDxwPTjeU.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=26[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, the man wearing red short sleeves and sunglasses is holding a phone in his right hand, and sitting outside with a few green plants in the background. In which other scene does this man appear?
A. By the seaside
B. Inside a room with a TV in the background
C. Inside a milk tea shop
D. Inside a fried chicken shop
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KlZpZVphLrc.mp4[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KlZpZVphLrc.mp4[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KlZpZVphLrc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=25[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the beginning of the video, a calendar and a hand-drawn booklet appear. With which subtitle did they appear together?
A. the key
B. do you know
C. say you want
D. which is a very big adulting thing that
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   8%|‚ñä         | 14/165 [00:30<04:35,  1.82s/it][32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9S9i12n0TIw.mp4[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9S9i12n0TIw.mp4[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9S9i12n0TIw.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=28[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The BBC is broadcasting news. A woman with gray hair, wearing a red striped dress and glasses, is speaking. Behind her, there is another woman with black hair wearing a yellow dress and a man with glasses wearing a gray dress. There are several people behind them all listening attentively. When the phrase 'create the conditions for a sustainable' is mentioned, which item is not present in the scene?
A. diamond necklace
B. green clothes
C. pearl earrings
D. microphone used for talking
E. pearl necklace
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7321010343067618592.mp4[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7321010343067618592.mp4[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7321010343067618592.mp4 | Selected 8 frames[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=27[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 11:58:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which object appears first in the video?
A. A bag of chips
B. Transparent glass cup
C. Transparent glass bowl
D. Black and white cat
E. Toaster
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d8H7hgQY9ew.mp4[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d8H7hgQY9ew.mp4[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d8H7hgQY9ew.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=29[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wall displaying a blue and white map, what is the man with white hair wearing a black short-sleeved shirt doing when he first appears?
A. Smiling at the camera
B. Making a mark on the map
C. Making a 'Yay' sign towards the camera
D. Raising his hand to greet
E. Talking to the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   9%|‚ñâ         | 15/165 [00:33<05:31,  2.21s/it][32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kLuqCtnKr_8.mp4[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kLuqCtnKr_8.mp4[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kLuqCtnKr_8.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=30[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a jade-green ocean, there is a huge rock with a hole standing in the ocean. Several people are standing on the rock, and one person is running forward. What did he do next?
A. Rushed towards another person standing on the rock
B. Jumped into someone's arms
C. Jumped into the jade-green sea
D. Hugged the person in front of him
E. Fell down on the rock
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  10%|‚ñâ         | 16/165 [00:35<05:40,  2.28s/it][32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Q4GK4asczVA.mp4[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Q4GK4asczVA.mp4[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Q4GK4asczVA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=32[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an interview setting, a man in a suit and a woman are having a conversation. Behind them on the left is a model made of red lines, and on the right is a screen with red and black letters. Both the man and the woman are sitting on stools. In front of them is a round table, which also has red triangular lines with the letters cna printed on it. When the letters 'Rahm and Hovland' in the bottom scrolling black area moved to the left, what event occurred?
A. The man smoothed his clothes
B. The man stood up
C. The man picked up a piece of paper from the table
D. The man took a sip of water
E. The woman adjusted her hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 14ot4DrXdds.mp4[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/14ot4DrXdds.mp4[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 14ot4DrXdds.mp4 | Selected 6 frames[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=31[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 11:58:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the golden twilight, with industrial zones emitting exhaust fumes into the sky, what happened first after the subtitle 'the water while increased levels of' appeared?
A. Two molecular structures appeared simultaneously on the screen
B. A structure with a black center labeled CO‚ÇÇ, flanked by two red molecular structures, rotated and popped up on the right side of the screen
C. Three molecular structures appeared simultaneously on the screen
D. A structure with a black center labeled CO‚ÇÇ, flanked by two red molecular structures, rotated and popped up on the left side of the screen
E. A structure with a red center labeled CO‚ÇÇ, flanked by two black molecular structures, rotated and popped up on the left side of the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = j6beJTHUT_c.mp4[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/j6beJTHUT_c.mp4[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: j6beJTHUT_c.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=33[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bedroom with a few paintings hanging on the wall, a woman wearing a blue shirt, suspenders, and glasses, with a smile on her face, is holding items in dark blue, white, and olive green colors. On a table, there are 3 perfume cards, each with items of dark blue, white, and olive green colors. Which scene appears first?
A. First appears the woman in a bedroom with a few paintings hanging on the wall, wearing a blue shirt, suspenders, and glasses, smiling and holding items in dark blue, white, and olive green colors. Last appears the table with 3 perfume cards, each with items in dark blue, white, and olive green colors.
B. First appears the table with 3 perfume cards, each with items in dark blue, white, and olive green colors. Last appears the woman in a bedroom with a few paintings hanging on the wall, wearing a blue shirt, suspenders, and glasses, smiling and holding items in dark blue, white, and olive green colors.
C. They appear simultaneously.
D. First appears the woman in a bedroom with a few paintings hanging on the wall, wearing a blue shirt, suspenders, and glasses, smiling and holding items in dark blue, white, and olive green colors. Last appears the solo scene of the woman.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  10%|‚ñà         | 17/165 [00:37<05:26,  2.21s/it][32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6HTO2SOxUc.mp4[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6HTO2SOxUc.mp4[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6HTO2SOxUc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=34[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a woman with long black hair is sitting on the left, and a woman with yellow hair is sitting on the right. The woman with black hair is putting makeup on the woman with yellow hair. A man in yellow and white clothing is standing in the middle of the screen. After the subtitle 'Lisa is the female lead, replacing Polina. While getting ready, Lisa told her boyfriend, Alexey,', what does the woman with long black hair do?
A. Running
B. Leaving
C. Drinking water
D. Eating something
E. Fixing the yellow-haired woman's hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tCnelzIAHA0.mp4[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tCnelzIAHA0.mp4[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tCnelzIAHA0.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=35[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, two men and a woman with straight hair wearing a black and white striped outfit appear, they are facing the camera and waving. There are also many objects on the table with the word JELL-O on them. Besides this, what else appears in the room?
A. Mobile phone
B. Television
C. Flower pot
D. Piano
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  11%|‚ñà         | 18/165 [00:40<05:24,  2.21s/it][32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F2OhCCEIOcU.mp4[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F2OhCCEIOcU.mp4[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F2OhCCEIOcU.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=36[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A long-haired woman wearing round earrings, a blue top, and black inner wear appears on the screen holding a book. What type of clothing is this woman wearing?
A. Suit
B. Blouse
C. Feather coat
D. Denim jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=37[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen is a man wearing a white long-sleeved shirt, and on the right side is a man wearing a blue and white checkered shirt and a watch. They are in a room. In which other scene does the man wearing the white long-sleeved shirt appear?
A. In front of a car
B. By the sea
C. In a hamburger store
D. Inside a truck
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  12%|‚ñà‚ñè        | 19/165 [00:42<05:47,  2.38s/it][32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = I-yg_3yx6iA.mp4[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/I-yg_3yx6iA.mp4[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: I-yg_3yx6iA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=38[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a street at night, there are two people. Among them, a woman with long black hair wearing a red coat is sitting on the ground. In front of her, a short-haired man wearing an olive-colored outfit is kneeling. In which of the following scenes did this woman appear?
A. In the woods
B. Inside a room
C. In the desert
D. In the sea
E. On a plane
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fySqsm5kNl4.mp4[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fySqsm5kNl4.mp4[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fySqsm5kNl4.mp4 | Selected 5 frames[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=39[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under a gray sky, a bullet-riddled airplane is flying with red and white stripes on its tail wings. There is a red pattern dot on the back of the fuselage, and the rest of the plane is silver. When the subtitle 'the aircraft falling away after being' appears, what is the shape of the red pattern on the tail of the fuselage?
A. A star
B. A square
C. A triangle
D. A pattern composed of a rectangle and a star
E. A rectangle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  12%|‚ñà‚ñè        | 20/165 [00:45<05:56,  2.46s/it][32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2W2ZkYARds4.mp4[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2W2ZkYARds4.mp4[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2W2ZkYARds4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=40[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bright sunny outdoor setting, there is a hole in the ground. When a man wearing a black short-sleeve shirt and a hat appears in front of the hole for the first time, holding a wooden stick, what does he do?
A. He kneels down.
B. He jumps into the hole.
C. He throws the wooden stick into the hole.
D. He steps over the hole.
E. He throws the wooden stick outside the hole.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7318074908645264645.mp4[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7318074908645264645.mp4[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7318074908645264645.mp4 | Selected 8 frames[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=41[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 11:58:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A light-colored building is located on the left side of the screen, with exquisite carvings on its walls. At the entrance at the front of the building, a red UNIQLO sign is hanging. The entrance area is surrounded by a crowd of pedestrians. After the camera finishes filming the entrance of UNIQLO, what does it film next?
A. It films the scene inside the UNIQLO store.
B. It films the art museum next door.
C. It films the library next door.
D. It films the hotel next door.
E. It films the restaurant next door.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NpYUxd1vUUE.mp4[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NpYUxd1vUUE.mp4[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NpYUxd1vUUE.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=43[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a flat ground, there is a building with a brick wall behind, a car with an open trunk on the left, and a police officer with a police dog on the right. What happened when the police dog appeared?
A. The police dog bit a tire.
B. The police officer drove away.
C. The police dog smelled the brick wall.
D. The police dog jumped into the car's trunk.
E. The police officer closed the car's trunk.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  13%|‚ñà‚ñé        | 21/165 [00:48<06:18,  2.63s/it][32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = H2ksp6sRR-k.mp4[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/H2ksp6sRR-k.mp4[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: H2ksp6sRR-k.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=42[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a pair of hands flips through a photo album, then a man embraces a child, followed by a pair of hands pouring a liquid with medicine into a sink, and finally a short-haired blonde woman points a gun at three people.
B. First, a short-haired blonde woman points a gun at three people, then a pair of hands pours a liquid with medicine into a sink, followed by a pair of hands flipping through a photo album, and finally a man embraces a child.
C. First, a man embraces a child, then a pair of hands pours a liquid with medicine into a sink, followed by a pair of hands flipping through a photo album, and finally a short-haired blonde woman points a gun at three people.
D. First, a short-haired blonde woman points a gun at three people, then a pair of hands pours a liquid with medicine into a sink, followed by a man embracing a child, and finally a pair of hands flipping through a photo album.
E. First, a man embraces a child, then a pair of hands flips through a photo album, followed by a pair of hands pouring a liquid with medicine into a sink, and finally a short-haired blonde woman points a gun at three people.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sKvvuo9Yxqk.mp4[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sKvvuo9Yxqk.mp4[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sKvvuo9Yxqk.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=45[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with long curly hair wearing a white coat and black-framed glasses is standing in front of a green background. On the right side of the screen, there are green, yellow, and white English texts. What is this woman doing when the subtitle 'including a luminous Toberman right and' appears?
A. Raising both hands to waist height and talking to the camera
B. Playing with her hair with both hands
C. Looking at her phone
D. Talking with a friend
E. Waving at the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  13%|‚ñà‚ñé        | 22/165 [00:50<05:54,  2.48s/it][32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TFbGLEZ4qt0.mp4[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TFbGLEZ4qt0.mp4[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TFbGLEZ4qt0.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=44[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A lady with long black straight hair is in a white room. She is wearing a white coat and a pink top. To her right is the door of the room, and to her left is a white display shelf with a table lamp, vase, and some pictures on it. She is sitting in front of a table, talking. There is also a bucket with many colored pencils and a bunch of flowers to the left of the table. What action did this lady do?
A. She used a purple colored pencil
B. She moved her hand to the right
C. She got up and opened the room door
D. She picked up the bunch of flowers
E. She got up and walked out of the room
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  14%|‚ñà‚ñç        | 23/165 [00:52<05:39,  2.39s/it][32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = crmV4OduHYA.mp4[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/crmV4OduHYA.mp4[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: crmV4OduHYA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=46[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with many yellow pages as the background, there is a blue-gray map. What changes occurred to the blue-gray map when the subtitle "subcontinent" appeared?
A. The entire map changed from blue-gray to red
B. The entire map changed from blue-gray to green
C. Different colors filled in the regions
D. The entire map changed from blue-gray to white
E. The entire map changed from blue-gray to purple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5dJUUQufzw4.mp4[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5dJUUQufzw4.mp4[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5dJUUQufzw4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=47[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some people are sitting face-to-face at a long table outdoors, wearing name tags around their necks and smiling at each other. What happened earlier in the video?
A. A woman in a brick-red suit jacket is sitting and talking in front of a camera.
B. In the upper right corner of the screen, a man in a red short-sleeve shirt is explaining the PPT shown on the screen.
C. A man in a black shirt and a woman in a white coat with a grey inner lining are sitting in front of a camera, with the woman lifting her legs.
D. In the upper right corner of the screen, a man in a red short-sleeve shirt is pointing to a picture on the screen.
E. A man in a black shirt and a woman in a white coat with a grey inner lining are sitting in front of a mural and having a conversation.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  15%|‚ñà‚ñç        | 24/165 [00:56<06:15,  2.66s/it][32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kOZnpwI2hIM.mp4[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kOZnpwI2hIM.mp4[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kOZnpwI2hIM.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=48[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
By the blue-green waterside of the lake, a man in black clothes is sitting on the ground on the left, and a man in a hooded jacket is standing on the right. In which of the following scenes does the man standing by the lake appear?
A. On the ground in front of a red hill
B. On the ground in front of a yellow hill
C. On a jade-green grassland
D. At a crowded intersection
E. On a yacht on the blue sea
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbgwG8fcIu0.mp4[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbgwG8fcIu0.mp4[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbgwG8fcIu0.mp4 | Selected 4 frames[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=49[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 11:58:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall with a hanging picture frame, a woman wearing a blue uniform, black shorts, and holding a green notebook did what while facing the camera?
A. She stuck out her tongue at the camera
B. She adjusted her long hair facing the camera
C. She made a funny face at the camera
D. She showed her notes to the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9dSkvxS2EB0.mp4[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9dSkvxS2EB0.mp4[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9dSkvxS2EB0.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=51[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside the airport, there is a dense crowd. On the left side of the screen, there's an area surrounded by blue lines and silver pillars, with white stripes on the floor. On the right side of the screen, there's a person in a blue short-sleeve shirt and a girl with a backpack pushing a suitcase. After the word 'it' appears in the subtitles, what person(s) appear(s) on the screen?
A. A woman in blue with a work badge
B. A woman in red with a work badge
C. A man in red with a work badge
D. A potted plant
E. An umbrella
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  15%|‚ñà‚ñå        | 25/165 [00:59<06:27,  2.77s/it][32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = M5YKW6fhlss.mp4[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/M5YKW6fhlss.mp4[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: M5YKW6fhlss.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=50[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT slide with a white background, there is a black text block on the left, and some parts of the text are covered with a yellow overlay. To the right, there's a blank white area. In the center, there's a main graphic composed of red and blue circles and letters. After the text block on the left disappears, what changes occur to the central graphic?
A. Disappeared
B. Covered by the yellow overlay
C. Shrunk
D. Moved slightly to the bottom left, and new parts appear in the screen
E. Moved to the right
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0_YDrJoUe8s.mp4[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0_YDrJoUe8s.mp4[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0_YDrJoUe8s.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=53[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a green door and a water dispenser by the wall, a person with golden hair, without a nose or lips, is looking at a fly wearing a green coat. In which scenes has this fly appeared?
A. In a mine.
B. In a room with flies wearing pink coats and flies wearing white striped coats.
C. Next to a man wearing a plaid shirt.
D. Next to a man wearing a purple coat.
E. Next to a dalmatian.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  16%|‚ñà‚ñå        | 26/165 [01:01<06:14,  2.69s/it][32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MvgJAD6tZXo.mp4[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MvgJAD6tZXo.mp4[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MvgJAD6tZXo.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=52[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman is sitting inside a gallery. She is wearing a red coat and black clothes. Her hair is blond, and she has a watch on her wrist. There are two paintings hanging on the wall behind her. When she mentions 'his work is incredibly worked out and um,' what change occurs to the woman onscreen?
A. The woman walks to admire four artworks.
B. The woman starts introducing the artworks.
C. The woman changed her clothes.
D. The woman sits down to admire four artworks.
E. The woman's hair was tied up.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9WjElCiDpzM.mp4[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9WjElCiDpzM.mp4[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9WjElCiDpzM.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=55[0m
[32m2025-11-29 11:58:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue sky, on the left is the blue sea and sandy beach, while on the right, there is a cliff. On the cliff, there is a woman wearing a white shirt and a man wearing blue armor. What is the man on the cliff doing?
A. Holding the woman's hand
B. Holding the woman's waist
C. Throwing a stone towards the beach
D. Touching the woman's hair
E. Waving at the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  16%|‚ñà‚ñã        | 27/165 [01:04<06:09,  2.68s/it][32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d7IqrLV6Tlg.mp4[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d7IqrLV6Tlg.mp4[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d7IqrLV6Tlg.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=54[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand; then, the dark-skinned woman secures a small white wooden block with the yarn; finally, a dark-skinned woman combing a doll holds a tuft of yarn.
B. First, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand; then, a dark-skinned woman combing a doll holds a tuft of yarn; finally, the dark-skinned woman secures a small white wooden block with the yarn.
C. First, a dark-skinned woman combing a doll holds a tuft of yarn; then, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand; finally, the dark-skinned woman secures a small white wooden block with the yarn.
D. First, the dark-skinned woman secures a small white wooden block with the yarn; then, a dark-skinned woman combing a doll holds a tuft of yarn; finally, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand.
E. First, a dark-skinned woman combing a doll holds a tuft of yarn; then, the dark-skinned woman secures a small white wooden block with the yarn; finally, a woman sitting on a white sofa, combing a doll, holds scissors in her right hand and a coloring pencil in her left hand.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = BktEeBeA7a8.mp4[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/BktEeBeA7a8.mp4[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: BktEeBeA7a8.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=57[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, many people are seen running across an endless desert; then, a man in a black short-sleeved shirt punches a man wearing a helmet; finally, a man wearing glasses lifts a curtain.
B. First, a man wearing glasses lifts a curtain; then, a man in a black short-sleeved shirt punches a man wearing a helmet; finally, many people are seen running across an endless desert.
C. First, a man in a black short-sleeved shirt punches a man wearing a helmet; then, a man wearing glasses lifts a curtain; finally, many people are seen running across an endless desert.
D. First, a man in a black short-sleeved shirt punches a man wearing a helmet; then, many people are seen running across an endless desert; finally, a man wearing glasses lifts a curtain.
E. First, a man wearing glasses lifts a curtain; then, many people are seen running across an endless desert; finally, a man in a black short-sleeved shirt punches a man wearing a helmet.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  17%|‚ñà‚ñã        | 28/165 [01:07<06:13,  2.73s/it][32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ng2rNm6Nwsg.mp4[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ng2rNm6Nwsg.mp4[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ng2rNm6Nwsg.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=56[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman dressed in a beige long-sleeved top, black tight pants, and white sneakers with curly hair draped over, stands on a low wooden platform in a forest bathed in golden sunlight. What is the first plant to appear?
A. Wild flowers
B. Vegetables
C. Melon
D. Some colorful trees
E. A pile of green grass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = h0OHi9uAcBo.mp4[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/h0OHi9uAcBo.mp4[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: h0OHi9uAcBo.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=59[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are many abstract landscape paintings on the wall. On the right side of the screen, a man with thinning hair and wearing round glasses is sternly looking into a mirror. What happened in the video?
A. A family is standing in front of a house taking a family photo.
B. Three children are playing around the house.
C. A man and a woman are creating something with paper and pen.
D. Three women are sitting in front of a house having a conversation.
E. The background is a tiled house with a two-story white staircase. Three men are sitting in front of the house having a discussion, and the man on the far right is smoking.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  18%|‚ñà‚ñä        | 29/165 [01:09<06:05,  2.69s/it][32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7303594391850044678.mp4[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7303594391850044678.mp4[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7303594391850044678.mp4 | Selected 14 frames[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=58[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 11:58:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man wearing a green jacket and holding a green bag is talking to a long-haired woman in a white dress sitting at a desk. What did the long-haired woman in a white sleeveless top do after picking up a pen?
A. Retouched a photo
B. Drew a picture on paper
C. Drank water
D. Wrote
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MvgJAD6tZXo.mp4[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MvgJAD6tZXo.mp4[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MvgJAD6tZXo.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=61[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a small island on the blue sea, the island is full of green plants, and there are many boats docked along the shore. Among them, the largest boat in the middle, what color is the largest boat in the middle?
A. red
B. black
C. yellow
D. white
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  18%|‚ñà‚ñä        | 30/165 [01:11<05:24,  2.41s/it][32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbcWAfHo5j0.mp4[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbcWAfHo5j0.mp4[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbcWAfHo5j0.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=60[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the wall between blue and white hangs several paintings with golden frames. On the blue sofa in front of the wall sits a man wearing a blue suit and a woman wearing a pink dress. What is the woman on the sofa doing?
A. Waving to the camera
B. Handing a black dog to the man
C. Handing a white dog to the man
D. Handing a white cat to the man
E. Handing a white box to the man
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XVXczyheik0.mp4[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XVXczyheik0.mp4[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XVXczyheik0.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=63[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a group of girls wearing blue tops walk down the stairs from the second floor of the building with green plants on the right, what kind of skirts are they wearing?
A. Super short skirt
B. Pleated short skirt
C. Dress
D. Knee-length skirt
E. Ankle-length skirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  19%|‚ñà‚ñâ        | 31/165 [01:13<05:13,  2.34s/it][32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mYotOV3Q51g.mp4[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mYotOV3Q51g.mp4[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mYotOV3Q51g.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=62[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, a man wearing a dark blue jacket is speaking on screen. There is a black microphone in front of him, he has dark skin, and he is sporting a beard. A black map is hanging on the wall behind him, there is a whiteboard on the left side of the screen, and on the right side, there is another wall with a black-bordered paper on it. What changes occur to this man's position on the screen when the 'Quiz Time 3' title, featuring many horizontal grids with black letters, appears?
A. The man disappears from the screen.
B. The man starts wearing sunglasses.
C. The man's position on the screen shifts to the bottom-left corner.
D. The man's position on the screen shifts to the bottom-right corner.
E. The man changes to a white shirt.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = h4jIoMxZopU.mp4[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/h4jIoMxZopU.mp4[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: h4jIoMxZopU.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=65[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen, a man wearing a mask and short sleeves is serving coffee to two seated people. The woman on the left is wearing a denim jacket, and the man on the right is wearing a red short-sleeved shirt and a hat. What did the woman on the left do the first time she appeared?
A. Shaking hands
B. Hugging
C. Raising her phone
D. Lying down
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  19%|‚ñà‚ñâ        | 32/165 [01:16<05:13,  2.36s/it][32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6qLYX6bzsl4.mp4[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6qLYX6bzsl4.mp4[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6qLYX6bzsl4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=64[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a blue background, a gentleman wearing a shirt with pink floral patterns is speaking. What did the gentleman do after becoming friends with the unicorn?
A. Put on a watch
B. Changed into a different shirt
C. Put on a mask
D. Put on a pair of sunglasses
E. Put on a unicorn headpiece
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MvgJAD6tZXo.mp4[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MvgJAD6tZXo.mp4[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MvgJAD6tZXo.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=67[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black iron pot with some oil, there is a lump of dough. A person, only showing one hand, is holding a silver ladle and spreads the dough in the pot. Where has this ladle appeared before?
A. In a green porcelain bowl
B. In a bowl rack
C. In a red bag
D. In a cupboard
E. In a black bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  20%|‚ñà‚ñà        | 33/165 [01:18<05:27,  2.48s/it][32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7rMgpExA4kM.mp4[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7rMgpExA4kM.mp4[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7rMgpExA4kM.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=66[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a house with black wooden walls, there is a door on the left that lets in sunlight. Next to the door on the left is a man wearing black clothes, and on the right is the silhouette of a person also wearing black clothes. What is the man next to the door on the left, inside the house, doing?
A. Waving towards the door
B. Picking up a stick from the ground
C. Drinking water
D. Picking up a noodle
E. Moving a box
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAHsR02dUc0.mp4[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAHsR02dUc0.mp4[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAHsR02dUc0.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=69[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:58:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What happens first on the screen after the subtitle 'and I am getting ready to go' appears, featuring a man wearing a black cold hat with an English letter logo, dressed in black clothes, carrying a black backpack, and sporting a stubbly mustache?
A. Manufacturing airplane wheels in a factory.
B. An airplane model suspended by several steel wires is displayed.
C. The man sits in a car looking out the window at the sunlit grass and trees.
D. Manufacturing the interior of an airplane fuselage.
E. Viewing the city from above.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:58:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  21%|‚ñà‚ñà        | 34/165 [01:21<05:20,  2.45s/it][32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = td35F9LNazA.mp4[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/td35F9LNazA.mp4[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: td35F9LNazA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=68[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:58:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a white-screen background, at the top of the screen, there is a conspicuous title 'Lagrangian Mechanics.' On the right side, there's a black frame with sharp edges, inside of which are irregular blue lines. What happens to these blue lines afterward?
A. In the 0-6 region, it descends, then in the 6-8 region, it rapidly spirals up and then descends again.
B. In the 0-4 region, it ascends, then rapidly descends in the 6-8 region.
C. It becomes a straight horizontal line.
D. In the 0-6 region, it rises, then in the 6-8 region, it rapidly spirals down and then rises again.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7277548218106367234.mp4[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7277548218106367234.mp4[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7277548218106367234.mp4 | Selected 7 frames[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=71[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 11:59:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with portraits on the wall, there is a white sofa with a woman lying on it. What was the first outfit the woman on the white sofa was wearing when she appeared?
A. A pink long-sleeve top
B. A white dress
C. A black hoodie
D. A dark blue top with floral prints
E. A blue bodysuit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ip9DbdOtqF4.mp4[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ip9DbdOtqF4.mp4[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ip9DbdOtqF4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=73[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man holding a laptop stands in front of a glass window. He is wearing a black short-sleeved shirt, has short black hair, and is wearing jeans. What changes occur to him when a woman wearing a grey long-sleeved shirt appears next to him?
A. He changed into a grey short-sleeved shirt
B. He changed into a grey and white long-sleeved shirt
C. He changed into a grey and white short-sleeved shirt
D. He changed into a green long-sleeved shirt
E. He changed into a white short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  21%|‚ñà‚ñà        | 35/165 [01:23<05:27,  2.52s/it][32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Aw1_7wSaeKk.mp4[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Aw1_7wSaeKk.mp4[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Aw1_7wSaeKk.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=70[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A group of women are sitting in front of a white table, where they are engaging in handmade crafts. There are colored paper and tools scattered on the table. A woman wearing glasses is sitting on the right side of the table. She has short black hair and is wearing earrings. Outside the table, a grey-haired woman in a black top is observing. What did the woman with short hair and glasses sitting at the table do the first time she appeared?
A. Waved her hands left and right
B. Held her face with both hands
C. Supported her forehead with one hand
D. Cut materials with scissors
E. Held her face with one hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CdTijM0_es4.mp4[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CdTijM0_es4.mp4[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CdTijM0_es4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=75[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A handheld drill lies on the green grass, with a red button on the handle. The drill body is mainly gray with red letters BOSCH on it. After the subtitle 'this was no regular drill and was a ' appears, what happens in the center of the screen?
A. An image of a machete appears in the center of the screen.
B. The grass background becomes blurry, and an image of a gun appears in the center of the screen.
C. An identical drill appears.
D. An image of a hammer appears in the center of the screen.
E. An image of an eagle appears in the center of the screen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 36/165 [01:26<05:14,  2.44s/it][32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DVsw1brd_Yc.mp4[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DVsw1brd_Yc.mp4[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DVsw1brd_Yc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=72[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue sky and white clouds, there is an endless stretch of mountain ranges. In front of the mountain ranges, there are some brown tents with two soldiers standing beside them. The soldiers are wearing gray helmets and holding crescent-shaped shields. In which of the following scenes have soldiers wearing gray helmets appeared?
A. Inside a dense forest
B. In a desert with swirling sandstorms
C. On a high mountain covered with white snow
D. In a scene with an olive tree and numerous arrows flying in the sky
E. On a grassland during rain
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kMryvefpcF8.mp4[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kMryvefpcF8.mp4[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kMryvefpcF8.mp4 | Selected 9 frames[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=77[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white desk, there is an open book, and in front of it stands a book with a black side face silhouette cutout on its cover, which also has bold white text. In which of the following scenes does this book with the cutout appear?
A. In the hands of a man wearing black clothes
B. In the hands of a man sitting in a subway
C. In a quiet library
D. In the hands of a woman wearing black clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 37/165 [01:28<05:11,  2.44s/it][32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qyaQ-wfojbM.mp4[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qyaQ-wfojbM.mp4[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qyaQ-wfojbM.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=74[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man dressed in a white shirt, raising one hand, with a slight smile on his face, sitting on a black chair and speaking, this man appears with which subtitles?
A. I eventually ended up living
B. offered me his couch to crash on
C. Pyramid of Giza
D. I got a tap
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = V-RIpt7Tknc.mp4[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/V-RIpt7Tknc.mp4[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: V-RIpt7Tknc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=79[0m
[32m2025-11-29 11:59:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, there is a cooking demonstration video, then the lady explains. Next, the lady continues explaining, then a cooking demonstration, the lady explains again, then another cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, and then the cooking video wraps up.
B. First, the lady with the yellow ribbon explains cooking, then there is a cooking demonstration. Next, the lady continues explaining, then another cooking demonstration, the lady explains again, then a cooking demonstration, the lady continues explaining, then another cooking demonstration, then another cooking demonstration, then the lady explains, and finally the lady concludes.
C. First, there is a cooking demonstration video, then the lady explains. Next, the lady continues explaining, then a cooking demonstration, the lady explains again, then another cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, then another cooking demonstration, and finally the lady explains the last part of the cooking process.
D. First, there is a cooking demonstration video, then the lady explains. Next, there is another cooking demonstration, followed by yet another cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, then another cooking demonstration, the lady explains again, and then the cooking video wraps up.
E. First, there is an introduction, followed by a cooking demonstration. Next, the lady continues explaining, then another cooking demonstration, the lady explains again, then a cooking demonstration, the lady continues explaining, then another cooking demonstration, the lady explains again, then another cooking demonstration, and finally the lady explains the last part of the cooking process.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  23%|‚ñà‚ñà‚ñé       | 38/165 [01:30<05:04,  2.40s/it][32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tdm72-vYxTs.mp4[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tdm72-vYxTs.mp4[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tdm72-vYxTs.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=76[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, a group of people are gathered outside. They are surrounding a man who is wearing a hat and dressed in white. Next to the man is a white horse, and in the upper right corner, someone is raising a flag. The story mentions that Serbia achieved autonomy. What happened next?
A. Russia supported Bulgaria
B. The empire was sacked
C. Italy and Germany each achieved unification
D. Greece was marginalized
E. Democratic thought flourished
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ysRFFN5nzqE.mp4[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ysRFFN5nzqE.mp4[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ysRFFN5nzqE.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=81[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a beige mat, there is a black plate with multiple layers of thin pancakes on it. A few slices of tomato are placed on top of the pancakes. A knife appears on the screen. What is this knife doing?
A. The knife is broken
B. The knife is cutting the thin pancakes
C. The knife is inserted into the table
D. The knife is smashing the plate
E. The knife is cutting open the beige mat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  24%|‚ñà‚ñà‚ñé       | 39/165 [01:34<05:36,  2.67s/it][32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7308098412078025989.mp4[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7308098412078025989.mp4[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7308098412078025989.mp4 | Selected 3 frames[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=78[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 11:59:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a turquoise lake with a rocky pile at the side of the lake. In the middle of the screen, there are yellow letters stating 'FOR MULTIPLE.' After the subtitle 'This is the world's top-ranked beach for multiple reasons' is mentioned, what objects appear?
A. Seaweed
B. Ordinary green plants
C. Small fish
D. Coconuts on the coconut tree
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  24%|‚ñà‚ñà‚ñç       | 40/165 [01:34<04:17,  2.06s/it][32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7267233980473314606.mp4[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7267233980473314606.mp4[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7267233980473314606.mp4 | Selected 3 frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=80[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table in the kitchen, a person is adding yellow lemon slices to a glass jar filled with yellow squash slices. When the subtitle says 'I'm a New York Medicine Ave,' what other objects are present in the room?
A. Refrigerator
B. Red flowers
C. Yellow flowers
D. Green plants
E. Oven
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  25%|‚ñà‚ñà‚ñç       | 41/165 [01:35<03:16,  1.58s/it][32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pGEF7Tme3Tk.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=82[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the rightmost side of the white screen, from top to bottom, there are two person frames. The top one is a black-haired woman sitting in front of a desk, and the bottom one is a woman wearing glasses. When the subtitle says 'get a little bit technical which you,' what type of clothing is the woman wearing glasses at the bottom wearing?
A. T-shirt
B. Leather jacket
C. Sweater
D. Swimsuit
E. Suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = cceTeD4JADU.mp4[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/cceTeD4JADU.mp4[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: cceTeD4JADU.mp4 | Selected 15 frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=83[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 11:59:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman with blue hair wearing blue clothes. How many times did she look at the computer in total?
A. 2
B. 5
C. 1
D. 4
E. 3
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HPunfsyjETs.mp4[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HPunfsyjETs.mp4[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HPunfsyjETs.mp4 | Selected 4 frames[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=85[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are several small bowls used for holding items on the screen. In which scenes do these small bowls appear?
A. One scene involves pouring flour into a bowl, another scene involves adding colorful frosting to a big bowl, and another scene involves adding a liquid oil substance.
B. Adding colorful frosting to a big bowl.
C. One scene is adding colorful frosting to a big bowl, another scene is adding a liquid oil substance.
D. Adding a liquid oil substance.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = s5edwp0PEqk.mp4[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/s5edwp0PEqk.mp4[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: s5edwp0PEqk.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=87[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a silver desktop, there is a wooden board. On the wooden board, there is an empty silver metal plate. A blond man wearing a black short-sleeved shirt is holding a spatula with his left hand and looking at the plate. When the plate and the subtitle 'uh and like I was saying at the start' appear simultaneously, what change occurs to the plate?
A. Yellow food material appears in the plate
B. Green food material appears in the plate
C. Eggs appear in the plate
D. Blue flowers appear in the plate
E. Eggs and beans appear in the plate
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  25%|‚ñà‚ñà‚ñå       | 42/165 [01:37<03:44,  1.83s/it][32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5zbV24vyO44.mp4[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5zbV24vyO44.mp4[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5zbV24vyO44.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=84[0m
[32m2025-11-29 11:59:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a coding algorithm context, there is a box in the bottom right corner. Inside the box, there is a blue background wall with a black piece of clothing hanging on it. There is a man with short black hair wearing a plaid shirt. After he says 'this cell', what does he do?
A. Touches his chin with his hand
B. Touches his nose with his hand
C. Makes a 'Yay' gesture with his hand
D. Holds his fist with one hand
E. Touches his forehead with his hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  26%|‚ñà‚ñà‚ñå       | 43/165 [01:40<04:17,  2.11s/it][32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sEiyR7-0FOA.mp4[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sEiyR7-0FOA.mp4[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sEiyR7-0FOA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=86[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes in the video are correct?
A. First, a woman wearing a blue mask and glasses is leaning against the window inside a moving train, then a man wearing a white short-sleeved shirt and glasses is drawing on a round wooden table with a palette, and finally, a woman wearing an olive coat, khaki plaid pants, and a blue mask is posing on a platform in front of a house with red brick and white walls.
B. First, a man wearing a white short-sleeved shirt and glasses is drawing on a round wooden table with a palette, then a woman wearing a blue mask and glasses is leaning against the window inside a moving train, and finally, a woman wearing an olive coat, khaki plaid pants, and a blue mask is posing on a platform in front of a house with red brick and white walls.
C. First, a man wearing a white short-sleeved shirt and glasses is drawing on a round wooden table with a palette, then a woman wearing an olive coat, khaki plaid pants, and a blue mask is posing on a platform in front of a house with red brick and white walls, and finally, a woman wearing a blue mask and glasses is leaning against the window inside a moving train.
D. First, a woman wearing an olive coat, khaki plaid pants, and a blue mask is posing on a platform in front of a house with red brick and white walls, then a woman wearing a blue mask and glasses is leaning against the window inside a moving train, and finally, a man wearing a white short-sleeved shirt and glasses is drawing on a round wooden table with a palette.
E. First, a woman wearing a blue mask and glasses is leaning against the window inside a moving train, then a woman wearing an olive coat, khaki plaid pants, and a blue mask is posing on a platform in front of a house with red brick and white walls, and finally, a man wearing a white short-sleeved shirt and glasses is drawing on a round wooden table with a palette.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lQODAJ_F5yE.mp4[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lQODAJ_F5yE.mp4[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lQODAJ_F5yE.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=89[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On yellow paper lies white paper with black symbols on it and a black arrow. The white paper and the arrow form a formula. Pink paper strips are used as markers. Below, the two largest sheets of paper are orange and blue. In the upper left corner is a black-headed, multicolored pencil. A hand with red nails is holding a pen and writing. The subtitle reads 'The first answer is with a negative sign because heat is released. We could have also written'. What elements are present in this scene?
A. Red triangular paper with 'b' written on it
B. Orange triangular paper with 'b' written on it
C. Red rectangular paper with 'b' written on it
D. Red round paper with 'b' written on it
E. Orange round paper with 'b' written on it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UN3ICsfqKEY.mp4[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UN3ICsfqKEY.mp4[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UN3ICsfqKEY.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=91[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two people are standing on an orange ground. On the left is a person wearing a helmet and holding a knife and shield. On the right is a person with black hair, also holding a knife and shield. When the subtitle 'threat of death or severe injury ever' appears, what is the shape of the shield held by the person on the left?
A. Square
B. Pentagon
C. Rectangle
D. Circle
E. Parallelogram
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 44/165 [01:43<04:40,  2.32s/it][32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lnCPn8gX3FU.mp4[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lnCPn8gX3FU.mp4[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lnCPn8gX3FU.mp4 | Selected 5 frames[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=88[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 11:59:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a restaurant, what is the man wearing a white shirt and a gray patterned jacket doing, standing to the right of a black-haired girl with Liu Hai hairstyle in white clothes?
A. Hugging the girl
B. Pulling the girl next to him and looking at her
C. Pinching the girl's cheek
D. Kissing
E. Touching the girl's head
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 45/165 [01:43<03:39,  1.83s/it][32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3hyPwjkdHEA.mp4[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3hyPwjkdHEA.mp4[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3hyPwjkdHEA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=90[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the open space in front of a red building, a person is holding a skateboard with a design that reads '8.0', running towards a woman wearing glasses and dressed in wine-red pants. What objects are present in this scene?
A. A necklace
B. A white building
C. A yellow skateboard with a design that reads '8.0'
D. A green skateboard with a design that reads '8.0'
E. Black-framed glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _7sd4fjnmvc.mp4[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_7sd4fjnmvc.mp4[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _7sd4fjnmvc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=93[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a ground covered with dry grass, there is a woman standing in a yellow floral dress. Behind the woman is a black dog. The woman is holding a hat in her hand. Which of the following subtitles appeared along with the black dog following the woman?
A. "you can give yourself than a homemade"
B. "of care"
C. "meal"
D. "after a long day i find no greater gift"
E. "and faith that anything is possible and"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 46/165 [01:46<04:05,  2.06s/it][32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fWNJmZAWRNg.mp4[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fWNJmZAWRNg.mp4[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fWNJmZAWRNg.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=92[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a purple dress with an injured face is lying on a wooden floor, and a man is helping her up. In what scenes has the woman in the purple dress appeared?
A. A woman sitting on a running horse
B. A woman sitting on a chair, holding her waist with her hands, next to her is a man with a peaked cap with his hands on a table, and there is a red hat on the table
C. A woman sitting on a chair, holding her waist with her hands, next to her is a man with a peaked cap with his hands on a table, and there is a black hat on the table
D. On a road filled with wooden logs
E. On a boat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ezhafkxoRdo.mp4[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ezhafkxoRdo.mp4[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ezhafkxoRdo.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=95[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room where all the furniture is made of solid wood, there is a person sitting on a chair holding an embroidery with blue fabric. Who is this person doing the embroidery?
A. A woman in a white dress
B. A woman in a blue dress
C. A woman in a black dress
D. A woman in a crimson dress
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 47/165 [01:48<04:09,  2.11s/it][32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YcbKamVxDzI.mp4[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YcbKamVxDzI.mp4[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YcbKamVxDzI.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=94[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, with a small green icon in the bottom right corner, a man wearing a dark grey short-sleeved shirt, with short black hair, and black-framed glasses, after he says "or as an added layer of security against potential predators," what does he do first?
A. Takes off glasses and wipes the lenses
B. Both palms clasped together
C. Right hand raised with palm open
D. Both hands raised with palms open
E. Both hands placed on the abdomen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7rMgpExA4kM.mp4[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7rMgpExA4kM.mp4[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7rMgpExA4kM.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=97[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the distant view framed by black borders, on the green meadow, there are two individuals facing the camera on the left, dressed in white and gray clothes, respectively. What characters appear after the subtitle 'happily as they walk towards their rooms'?
A. A man wearing white clothes and a red hat
B. A man wearing white clothes and sunglasses
C. A woman wearing a yellow hat and sunglasses
D. A man wearing black clothes and a red hat
E. A man wearing white clothes and a yellow hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  29%|‚ñà‚ñà‚ñâ       | 48/165 [01:51<04:35,  2.36s/it][32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8MkL3W6wU3g.mp4[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8MkL3W6wU3g.mp4[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8MkL3W6wU3g.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=96[0m
[32m2025-11-29 11:59:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a white airplane is taxiing on the runway at the airport, with a backdrop of golden hills and an orange sky. What happens first on screen after the caption 'water on runway' appears?
A. Two men in work uniforms are manufacturing an airplane in a workshop.
B. At night, a man leans out from the front of a parked airplane to talk to the camera.
C. The airplane skids on a water puddle on the runway, splashing a huge spray of water.
D. A hand is drawing two buildings with a river flowing between them on white paper.
E. A person is working in a warehouse filled with boxes of paper.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XVXczyheik0.mp4[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XVXczyheik0.mp4[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XVXczyheik0.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=99[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some workers are working in a yard, surrounded by wooden frames. On the left side of the screen, there is a pillar, and the subtitle 'five months of working side by side we' appears. Who is the first person to appear after this?
A. A foreign man wearing a light blue shirt, khaki pants, and a hat
B. A Chinese worker wearing dark blue sleeves
C. A foreign journalist holding a camera
D. A Chinese worker wearing a red hat
E. A foreign leader taking a group photo with the workers
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  30%|‚ñà‚ñà‚ñâ       | 49/165 [01:54<04:51,  2.51s/it][32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QPth_xqBXGY.mp4[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QPth_xqBXGY.mp4[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QPth_xqBXGY.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=98[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a black background, a white-lettered title says 'How much data do we need?' with a picture of a golden retriever on the left. The word 'dog' appears on the far right, and a man is explaining in the bottom right corner. When the image of a shaking dog appears, what changes occur in the black scene?
A. The image of the shaking dog gradually shrinks
B. The arrow on the right side is labeled 'not dog'
C. The picture of the golden retriever disappears
D. The image of the shaking dog gradually enlarges
E. The man in the bottom right corner changes into a blue shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LAbtlJJhUlY.mp4[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LAbtlJJhUlY.mp4[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LAbtlJJhUlY.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=101[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen displays a black PPT background with the title 'War in Ukraine Factors' in gray letters. Below are three circles containing some drawings, followed by gray and red rectangles with some content written inside. What changes occur to the rectangles when the phrase 'actions of mot. riflemen and tanks to accomplish the task.' is mentioned?
A. Both rectangles became empty
B. Both rectangles were filled with more content
C. The gray rectangle disappeared
D. The red rectangle disappeared
E. The red rectangle was enlarged
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  30%|‚ñà‚ñà‚ñà       | 50/165 [01:57<04:48,  2.51s/it][32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hg2Q_O5b9w4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=100[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A hand is holding a pen and coloring a design on white paper. The wrist of this hand has a silver item attached to it. The pen's body is black, and the tip is olive yellow. On the white paper, there are three bells drawn. Next to the bells, there is a sketch. The pen tip is currently positioned on this sketch. What did this pair of hands do after coloring?
A. Picked up a pair of scissors
B. Dropped the piece of paper on the ground
C. Picked up the piece of paper
D. Picked up a book
E. Tore the piece of paper
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _7sd4fjnmvc.mp4[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_7sd4fjnmvc.mp4[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _7sd4fjnmvc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=103[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT slide with a white background, there is a group of words enclosed in a rounded rectangle at the bottom. In the middle, there is a doodle composed of letters in blue parentheses, blue, and green. What change occurs to the doodle when the subtitle 'that if I put in this representation' appears?
A. Moved to the far left
B. Entirely turned black
C. Covered by a yellow overlay
D. Moved to the far right
E. Enlarged
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  31%|‚ñà‚ñà‚ñà       | 51/165 [01:59<04:34,  2.41s/it][32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LHXS0QR1ThA.mp4[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LHXS0QR1ThA.mp4[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LHXS0QR1ThA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=102[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the dark night, there is an old man wearing a hat, one hand holding a flickering candle, one hand on the door, and watching a man and a woman. In which scenes has the old man in the hat appeared?
A. A crowded street
B. Sitting in a room with a glowing light bulb
C. Lying in a room with a flickering candle
D. Sitting in a room with a flickering candle
E. Sitting in a carriage
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = T5bTeGzgJFs.mp4[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/T5bTeGzgJFs.mp4[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: T5bTeGzgJFs.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=105[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, there is a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37, then a page with the word 'results' appears, and finally 9 small animals appear.
B. First, there is a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37, then 9 small animals appear, and finally a page with the word 'results' appears.
C. First, 9 small animals appear, then a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37, and finally a page with the word 'results' appears.
D. First, a page with the word 'results' appears, then 9 small animals appear, and finally a girl on a white background with text and the same image appearing twice, once at 47:39 and once at 50:37.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 52/165 [02:01<04:34,  2.43s/it][32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 60oHeCZHtvI.mp4[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/60oHeCZHtvI.mp4[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 60oHeCZHtvI.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=104[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a mountain cave, there is a person on the right wearing something, and on the left, there is a wolf baring its teeth at the person wearing something. Below the wolf, there is a coil of rope. Which of the following subtitles have appeared with the wolf?
A. on a further ledge, where he breaks a leg and falls unconscious. Desperate to save his san,
B. snowstorms become more common, so Keda is having difficulty making much progress each day,
C. Keda tells Alpha to go with them, so now he is left to continue traveling alone. As time passer,
D. men bring the sleds to carry the bison on, Tau stays by the edge of the diff, crying in denial.
E. finds with the wolf as well. But worms are not enough to keep themselves fed, so Keda finally
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 51dUUxFOjDE.mp4[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/51dUUxFOjDE.mp4[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 51dUUxFOjDE.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=107[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
An armored vehicle is traveling on a sandy ground. There is a person extending their upper body out of the armored vehicle. Behind the armored vehicle, there are several tanks. Among these tanks, there is a person wearing a green vest. What is the color of the traveling armored vehicle?
A. Red
B. Camouflage
C. White
D. Pink
E. Black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 53/165 [02:04<04:48,  2.58s/it][32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = V-RIpt7Tknc.mp4[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/V-RIpt7Tknc.mp4[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: V-RIpt7Tknc.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=106[0m
[32m2025-11-29 11:59:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into three sections: the left is all text, the center is a map, and the right shows a man in black clothing. After gesturing with his hand towards the camera, what did the man do next?
A. Took a sip of water
B. Lifted a stool slightly
C. Touched his own face with his hand
D. Touched his hair briefly
E. Knocked over a cup of water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = npLd4WTSQsM.mp4[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/npLd4WTSQsM.mp4[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: npLd4WTSQsM.mp4 | Selected 7 frames[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=109[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 11:59:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On this yellow cutting board, two chicken breasts are placed side by side. After this person places the chicken breasts horizontally, what does he do next?
A. He throws the chicken breasts away.
B. He puts the chicken breasts into a pot.
C. He does nothing.
D. He uses a knife to cut the two whole chicken breasts into evenly sized small pieces.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = x4dFLY_-vKs.mp4[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/x4dFLY_-vKs.mp4[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: x4dFLY_-vKs.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=111[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a group of people dressed in formal attire are seated around a long table with paper documents placed on it. They are actively engaging in discussion. The room has podiums and paintings around. The story mentions the signing of the London Treaty at the end of May 1913. What else is mentioned?
A. Montenegro permanently leaving Bulgaria
B. Bulgaria signing an armistice agreement
C. Signing of the Treaty of Bucharest
D. Second Balkan War
E. Greco-Bulgarian War
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 54/165 [02:07<04:52,  2.63s/it][32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vEy6tcU6eLU.mp4[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vEy6tcU6eLU.mp4[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vEy6tcU6eLU.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=108[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a tree outside a bright window, a man dressed in black and wearing glasses is talking. When the subtitle mentions 'But we don't understand everything,' what is the man wearing on his head at this moment?
A. black cap
B. green cap
C. red maple leaf
D. white overcoat
E. red-framed glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ng2rNm6Nwsg.mp4[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ng2rNm6Nwsg.mp4[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ng2rNm6Nwsg.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=113[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing an orange shirt appears in front of a black background. The man rolls up his sleeves, and to his left, there is a square frame with green and white inside. When the subtitle 'Vegetarian and this one means' appears, what is the shape at the center of the green area inside the square frame on the left?
A. Circle
B. Triangle
C. Rectangle
D. Square
E. Droplet shape
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 55/165 [02:09<04:33,  2.49s/it][32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7214559428471770374.mp4[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7214559428471770374.mp4[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7214559428471770374.mp4 | Selected 4 frames[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=110[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 11:59:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a gray-green top and a black mask, with black short hair clipped with four red and yellow hair curlers, holding a blue hair dryer in one hand, what is he doing when the subtitle 'Firstly, starting off with flat hair, you want to use' appears?
A. Blow-drying hair
B. Brushing teeth
C. Washing face
D. Spraying hair with styling mist
E. Burning hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 56/165 [02:11<03:58,  2.19s/it][32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _zEM6Fc-7NI.mp4[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_zEM6Fc-7NI.mp4[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _zEM6Fc-7NI.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=112[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are two abstract landscape paintings on the screen. What happens after the camera moves from left to right?
A. Three men appear on the screen, sitting around a table chatting.
B. An old man wearing a checkered suit and round glasses appears on the right side of the screen, standing in front of a wall full of paintings. On the left side, a woman is playing the guitar on a sofa, while a man is sitting on the sofa creating with a pencil.
C. An old man wearing a checkered suit and round glasses appears on the right side of the screen, standing in front of a wall full of paintings. On the left side, a woman is sitting on a sofa creating with a pencil, while a man is sitting on the sofa playing the guitar.
D. An old man wearing a checkered suit and round glasses appears on the left side of the screen, standing in front of a wall full of paintings. On the right side, a woman is sitting on a sofa creating with a pencil, while a man is sitting on the sofa playing the guitar.
E. An old man wearing a checkered suit and round glasses appears on the left side of the screen, standing in front of a wall full of paintings. On the right side, a woman is playing the guitar on a sofa, while a man is sitting on the sofa creating with a pencil.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PS0gXPNBZy8.mp4[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PS0gXPNBZy8.mp4[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PS0gXPNBZy8.mp4 | Selected 10 frames[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=115[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 11:59:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing floral prints is walking on a small path in the countryside, surrounded by trees. There is a fence made of tree trunks on one side of the path, with a black cat walking on it. What did the woman do after leaving the path?
A. Go to the market
B. Kneel down to pick flowers
C. Go to the riverside
D. Go home
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vVRC-0VKPrg.mp4[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vVRC-0VKPrg.mp4[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vVRC-0VKPrg.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=117[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wall with white lacquer on both sides and a yellow wooden board in the middle, on the left side is a tree trunk, with a white and yellow prismatic barrier next to the right side of the trunk. When the commentary mentions 'protesting or I must sleep in my bed my,' which object is on the screen?
A. portrait of a woman with short hair
B. wine glass
C. airplane
D. armored vehicle
E. police
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 57/165 [02:13<04:00,  2.23s/it][32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 49YMA0f1yhI.mp4[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/49YMA0f1yhI.mp4[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 49YMA0f1yhI.mp4 | Selected 5 frames[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=114[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 11:59:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the driver's seat of a car, a tense-looking man with a seatbelt on is driving. The car is speeding down the road. What color shirt is the man wearing?
A. Blue
B. Brown
C. Green
D. White
E. Black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 58/165 [02:14<03:06,  1.75s/it][32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = I2Fyzav8MxE.mp4[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/I2Fyzav8MxE.mp4[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: I2Fyzav8MxE.mp4 | Selected 12 frames[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=116[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 11:59:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the top of the screen, there is a red search box. Below the search box, there are characters aligned to the left, which are composed of red and black colors. In the bottom right corner, a man wearing sunglasses and dressed in black is speaking into a microphone. What is this man doing?
A. The man is drawing a circle with his hand
B. The man is adjusting his glasses
C. The man is making a scissor hand gesture
D. The man is making a heart hand gesture
E. The man is making an OK hand gesture
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qjY9kmveQAk.mp4[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qjY9kmveQAk.mp4[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qjY9kmveQAk.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=119[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the screen zooms in to show a hand holding a tool adding water from a red bowl into a white tray with blue paint, what appears first?
A. A man wearing a black short-sleeve shirt and black pants
B. A piece of fabric with yellow paint
C. A man wearing a black short-sleeve shirt and white pants
D. A piece of fabric with red paint
E. A man wearing a white short-sleeve shirt and black pants
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 59/165 [02:15<03:01,  1.71s/it][32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fp1r40w_PtA.mp4[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fp1r40w_PtA.mp4[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fp1r40w_PtA.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=118[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the sandy ground with good light, a patterned brown rattlesnake coils its body together, extending its head. What did the snake do when it appeared?
A. Coiled its body
B. Opened its mouth
C. Launched an attack
D. Shook its tail
E. Twisted its neck
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 60/165 [02:17<03:07,  1.79s/it][32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7309241426028596523.mp4[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7309241426028596523.mp4[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7309241426028596523.mp4 | Selected 9 frames[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=120[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 11:59:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a train, a person wearing a green military uniform and a green face mask is making a phone call. What other items appear on this train?
A. Biscuit
B. Flower
C. Gun
D. Piano
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LVFvRNRTEd4.mp4[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LVFvRNRTEd4.mp4[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LVFvRNRTEd4.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=121[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow table, there is a yellow cutting board with a piece of chicken breast on it. A person wearing a glove on the left hand has the left hand placed on the chicken breast, while holding a knife with the right hand on the chicken breast. When mentioning 'Only these ingredients and my family loves it,' what is this person doing?
A. This person is frying chicken breast
B. This person is frying a steak
C. This person is cutting chicken breast
D. This person is washing chicken breast
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 61/165 [02:19<03:18,  1.91s/it][32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZaXpMou55lw.mp4[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZaXpMou55lw.mp4[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZaXpMou55lw.mp4 | Selected 16 frames[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=122[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 11:59:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Among the group of people in the video, there is a woman wearing a blue jacket with a white shirt underneath. She is raising her right hand, holding a large stuffed toy in her left hand, and carrying a white plastic bag filled with items. When the subtitle mentions 'those and the word balikbayan means,' what color is the stuffed toy?
A. purple
B. red
C. blue
D. green
E. yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 11:59:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2F7d7aUCmUU.mp4[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2F7d7aUCmUU.mp4[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2F7d7aUCmUU.mp4 | Selected 12 frames[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=123[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 11:59:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dense forest, a boy wearing a black short-sleeve shirt is sitting on a bench. When the subtitle mentions 'to positively influence us all that said', what action does the boy take?
A. Makes a fist
B. Waves his hand
C. Stands up
D. Claps his hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OGaML8Gg8JQ.mp4[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OGaML8Gg8JQ.mp4[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OGaML8Gg8JQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=125[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a grey short-sleeve shirt is sitting in a chair and talking. Behind him, there's a black and white piano keyboard and a black microphone stand. The curtain next to the keyboard is white. In the corner of the room, there is a guitar and a drum set. What objects are present in the scene?
A. black wristwatch
B. jeans jacket
C. black baseball cap
D. necklace
E. silver wristwatch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 62/165 [02:22<03:37,  2.11s/it][32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6THwql5c6w.mp4[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6THwql5c6w.mp4[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6THwql5c6w.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=124[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a backdrop with a plant illustration, there is a man wearing a white hat, a gray T-shirt, and a black wristwatch. In which of the following scenes does he appear?
A. In front of a pure black backdrop, there is a scene with a man wearing a white short-sleeved shirt.
B. In front of a pure black backdrop, there is a scene with a man wearing a pink short-sleeved shirt.
C. In front of a pure black backdrop, there is a scene with a man wearing a green short-sleeved shirt.
D. In front of a pure black backdrop, there is a scene with a man wearing a red short-sleeved shirt.
E. In front of a pure black backdrop, there is a scene with a man wearing a blue short-sleeved shirt.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fPLjjr8w6DU.mp4[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fPLjjr8w6DU.mp4[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fPLjjr8w6DU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=127[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the top of the screen, there are three flags, with the American flag in the middle. A person in a black suit is speaking in front of a microphone in the center. After the captions mention 'punching domo in toner mau 9 term,' what appears on the screen?
A. Stars
B. Sun
C. Moon
D. A piece of white paper
E. Satellite map
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 63/165 [02:24<03:43,  2.19s/it][32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QPth_xqBXGY.mp4[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QPth_xqBXGY.mp4[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QPth_xqBXGY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=126[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a black PPT background with the title 'Interwar' on the slide. There are three white circles at the bottom containing drawings, and also a white line drawing of a tank. When the subtitle 'debate, as discussed in an article by Walther Nehring about anti-tank defense from 1936' appears, what happens to the tank?
A. The tank rotates
B. The tank gradually shrinks
C. The tank gradually enlarges
D. The tank disappears
E. The tank rotates in circles on the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 64/165 [02:27<03:59,  2.37s/it][32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iwXp1fT89-M.mp4[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iwXp1fT89-M.mp4[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iwXp1fT89-M.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=128[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which mode of transportation is mentioned first in the video?
A. A blue and black sports car
B. A white and black sports car
C. A yellow and black sports car
D. A purple and black sports car
E. A silver sports car
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = M-YfPangEfA.mp4[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/M-YfPangEfA.mp4[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: M-YfPangEfA.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=129[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:00:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the yellow wooden dining table in the video, some food and tableware are placed. Which of the following items do not exist?
A. Noodles
B. A glass of water
C. Silver fork
D. Black fork
E. Bun
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SYqEMs0EYoI.mp4[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SYqEMs0EYoI.mp4[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SYqEMs0EYoI.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=131[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:00:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the beginning of the video, with a blue background, a short clip is played in the middle of the screen. Who is the first person to appear in this clip?
A. A woman wearing a sleeveless military green top and a pink hat
B. A woman wearing a floral cheongsam
C. A man wearing a black short-sleeve shirt and striped shorts
D. A man wearing a pink shirt and black pants
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yz3lOAe32Tw.mp4[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yz3lOAe32Tw.mp4[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yz3lOAe32Tw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=133[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, in a small frame on a pure yellow background, a green straightener is displayed. Next, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Finally, on a pure yellow background, there is green text 'BEAUTY'.
B. First, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Next, on a pure yellow background, there is green text 'BEAUTY'. Finally, on the yellow background, a small frame displays a green straightener.
C. First, on a pure yellow background, there is green text 'BEAUTY'. Next, in a small frame on a pure yellow background, a green straightener is displayed. Finally, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern.
D. First, on a pure yellow background, there is green text 'BEAUTY'. Next, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Finally, in a small frame on a pure yellow background, a green straightener is displayed.
E. First, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Next, in a small frame on a pure yellow background, a green straightener is displayed. Finally, on the yellow background, there is green text 'BEAUTY'.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 65/165 [02:30<04:18,  2.59s/it][32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = J1IwKg2ufk8.mp4[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/J1IwKg2ufk8.mp4[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: J1IwKg2ufk8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=130[0m
[32m2025-11-29 12:00:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the room with the yellow walls, on the right side, there's a rectangular window with rounded corners. In the middle, there is a hemispherical object and a man wearing a gray coat. What action did the man take before the subtitle mentioned 'to smoke'?
A. Steve holding a packed paper box
B. A man lying in the bathtub with a towel over his eyes
C. Donna holding a baby, with Steve standing behind her
D. Jessica stroking Ted's mechanical arm
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7258968758130085146.mp4[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7258968758130085146.mp4[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7258968758130085146.mp4 | Selected 11 frames[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=135[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 12:00:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing an embroidered dress, whose face is not visible, is cutting a tomato on a wooden board with a vegetable knife. What objects are present in this scene?
A. golden fork
B. wooden spoon
C. ring
D. parsley
E. pasta
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 66/165 [02:33<04:20,  2.63s/it][32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -kaF6SnSEo8.mp4[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-kaF6SnSEo8.mp4[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -kaF6SnSEo8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=132[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a woman wearing a white dress. She is standing on a rock, gazing into the distance. In front of her, there is a green lake, and in the distance, there are some orange buildings. After the woman gazes into the distance, what happens next?
A. The woman walks on a stone path surrounded by green plants, between pink and yellow buildings.
B. The woman walks on a stone path surrounded by green plants, between green and black buildings.
C. The woman walks on a stone path surrounded by green plants, between green and yellow buildings.
D. The woman walks on a stone path surrounded by green plants, between blue and yellow buildings.
E. The woman walks on a stone path surrounded by green plants, between green and white buildings.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = X0U3fP0tZyY.mp4[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/X0U3fP0tZyY.mp4[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: X0U3fP0tZyY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=137[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a pie chart representing the Czech Ethnicity appears in the video, with blue occupying the largest portion, red being the second, and light green the least, which of the following sentences is displayed on the screen?
A. 25% "Unspecified"
B. 60% ‚Äúdeclared‚Äù Czech
C. 95% Czech
D. 38% Czech
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 67/165 [02:35<03:55,  2.41s/it][32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -PnG8Jp2gFw.mp4[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-PnG8Jp2gFw.mp4[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -PnG8Jp2gFw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=134[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a red lettered t-shirt is explaining in front of a background wall with musical instruments hanging on it. The instruments on the background wall are all string instruments made of wood. There's also a white board with some words written on it for introduction. What is the first object that appears after mentioning 'performed by a wonderful cuatrista, Fabiola Mendez.'?
A. A woman in a black dress playing the piano
B. A woman in black clothing sitting and playing a small string instrument
C. A woman in purple clothing sitting and playing a small string instrument
D. A woman in a white dress playing the piano
E. A woman in a black dress sitting and playing a cello
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7268936523481943297.mp4[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7268936523481943297.mp4[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7268936523481943297.mp4 | Selected 12 frames[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=139[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 12:00:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a mustard-yellow wall hangs a television screen, which displays a webpage with black and white images and some document icons. A man with a yellow and black name tag is speaking. He is facing towards the right side of the screen, wearing a military green and black camouflaged uniform with a black and white accessory on the sleeve. What happens when he mentions: 'a gimbal now there's gimbals that stab'?
A. The man opens one hand and clenches the other into a fist
B. The man turns to face the screen
C. The man brushes his hair
D. The man takes a sip of water
E. The man changes his jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 68/165 [02:37<03:47,  2.34s/it][32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Lk9ZihSgjdo.mp4[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Lk9ZihSgjdo.mp4[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Lk9ZihSgjdo.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=136[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a little boy and a little girl. The little boy is wearing black clothes, the little girl is wearing white clothes, and there is also an older man in the background. At the same time, what subtitles appear with the little girl?
A. He told me.
B. h
C. thanks
D. thank you
E. so
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kj3Po7zUeyw.mp4[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kj3Po7zUeyw.mp4[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kj3Po7zUeyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=141[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a short-haired man and a bald man are making pizza in the kitchen. What action does the short-haired man do when he appears for the first time?
A. Shake hands
B. Raise thumbs up
C. Hug
D. Bow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 69/165 [02:38<03:08,  1.97s/it][32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vpKtHB8x0js.mp4[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vpKtHB8x0js.mp4[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vpKtHB8x0js.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=138[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the first person to die in the video?
A. Grace
B. Philip
C. Sarah Douglas
D. Kate
E. John
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = uWBh0meTg08.mp4[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/uWBh0meTg08.mp4[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: uWBh0meTg08.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=143[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Before the subtitle says, 'she quickly hides inside a dead tree with James. The latter wants her to return to,' what does the woman in a blue top do?
A. She is swimming in the water
B. She assists a person in walking
C. She is combing her hair
D. She wakes up a man lying on the ground
E. She is applying lipstick
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 70/165 [02:41<03:21,  2.12s/it][32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AxciimuEZAc.mp4[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AxciimuEZAc.mp4[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AxciimuEZAc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=140[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a building made of glass, there are some green plants and benches around, as well as red and orange striped sculptures. A man is walking down the steps on a marble-paved ground. In front of him, there is a black sculpture covered in raised dots. When the phrase 'sculpture garden looking at' is mentioned, what is this man wearing?
A. blue long-sleeve shirt
B. blue vest
C. blue short-sleeve jacket
D. blue T-shirt
E. blue jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 71/165 [02:43<03:14,  2.07s/it][32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MPQn_orwpfA.mp4[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MPQn_orwpfA.mp4[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MPQn_orwpfA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=142[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white background, after a hand writes the words 'Neural Architecture Search' in blue ink and then writes 'YOLO-NAS' over it in black ink with a big bracket, what follows next?
A. Draws a cartoon figure with raised hands standing next to a board filled with sketches on the left of the English text
B. Draws a timeline
C. Draws a table composed of colored lines
D. Draws a square frame
E. Draws two gears, one blue and one black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GFg98TDqCpw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=145[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the lower right corner of the video, there is a bald person wearing sunglasses and dressed in black. There are also three boys on the screen: the one on the left is wearing a blue short-sleeve shirt, the one on the right is wearing a red long-sleeve shirt, and the one in the middle is wearing a gray short-sleeve shirt. Which of the following items does not appear in the video?
A. Black hat
B. White hat
C. Sunglasses
D. Blue short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Dkm35G5kkcc.mp4[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Dkm35G5kkcc.mp4[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Dkm35G5kkcc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=147[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The floor of the room is tan, there are flags and pictures posted on the walls, a bookshelf filled with books on the right side, in the upper right corner there is a picture of an airplane flying in a clear sky, a man wearing a gray coat sitting on a black chair, which subtitle does this airplane picture appear together with?
A. Europe Russia China, India and Australia most of these lines actually don't exist. So let's assume
B. We're funding maybe about 75% of all these train lines
C. You konw at first glance this picture
D. We live in a time in which air travel is the preferred method of long distance Journeys however
E. 65 to 94
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 72/165 [02:45<03:22,  2.18s/it][32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VSZ8ywgGNGM.mp4[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VSZ8ywgGNGM.mp4[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VSZ8ywgGNGM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=144[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a man pins a map onto the lampshade with thumbtacks, then a man with headphones starts crying with his eyes closed, and finally someone walks into an empty classroom.
B. First, a man with headphones starts crying with his eyes closed, then a man pins a map onto the lampshade with thumbtacks, and finally someone walks into an empty classroom.
C. First, a man pins a map onto the lampshade with thumbtacks, then someone walks into an empty classroom, and finally a man with headphones starts crying with his eyes closed.
D. First, a man with headphones starts crying with his eyes closed, then someone walks into an empty classroom, and finally a man pins a map onto the lampshade with thumbtacks.
E. First, someone walks into an empty classroom, then a man pins a map onto the lampshade with thumbtacks, and finally someone walks into an empty classroom again.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -PnG8Jp2gFw.mp4[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-PnG8Jp2gFw.mp4[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -PnG8Jp2gFw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=149[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a lioness inside an iron mesh enclosure. Outside the iron mesh, someone is extending a pair of tongs through the mesh towards the lioness's nose. What is being clamped by the tongs that are reaching towards the lioness's nose?
A. A flower
B. Catnip
C. A piece of meat
D. A leaf
E. A chicken
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 73/165 [02:47<03:28,  2.26s/it][32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mfS6gyP0mwo.mp4[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mfS6gyP0mwo.mp4[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mfS6gyP0mwo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=146[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with long hair, wearing a purple top and a necklace, is giving an introduction at the beginning of the video and later gives a lecture. What changes occur in the color of the wall behind her at these times?
A. White changes to blue
B. Olive green changes to white
C. White changes to olive green
D. Olive green changes to blue
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 74/165 [02:50<03:28,  2.29s/it][32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = athabNMGceo.mp4[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/athabNMGceo.mp4[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: athabNMGceo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=148[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a beige wall, a television screen is hanging, displaying a webpage along with some file icons. A man wearing a black lab coat and a yellow and black badge is standing in front of the screen talking. When he mentions, 'being you don't know that 30-second ad,' what happens?
A. The man waved his hand.
B. The man pointed at the audience listening to the lecture.
C. The man turned around to face the screen.
D. The man put on a hat.
E. The man pointed at the screen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7252661595875183874.mp4[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7252661595875183874.mp4[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7252661595875183874.mp4 | Selected 13 frames[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=151[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-29 12:00:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man with black hair wearing a green coat sits with a boy who also has black hair. The man is saying something to the boy. In which subtitles have this man appeared before?
A. I am a photographer
B. I know
C. He buys the things and then returns to his son who was waiting for him
D. Help me
E. Don't do this
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VFXJnbnN5ro.mp4[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VFXJnbnN5ro.mp4[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VFXJnbnN5ro.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=153[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, a man wearing black-framed glasses and a white short-sleeve shirt with a small bird pattern is explaining. Which of the following animals evolved hindgut fermentation?
A. Ostrich
B. Rabbit
C. Kangaroo
D. Whale
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 75/165 [02:52<03:27,  2.30s/it][32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7079970495499717934.mp4[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7079970495499717934.mp4[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7079970495499717934.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=150[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:00:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the correct order of the following scenes?
A. First, a red heart-shaped screen, then a dimly lit street scene, followed by a gas station screen.
B. First, a gas station screen, then a dimly lit street scene, followed by a red heart-shaped screen.
C. First, a dimly lit street scene, then a gas station screen, followed by a red heart-shaped screen.
D. First, a gas station screen, then a red heart-shaped screen, followed by a dimly lit street scene.
E. First, a dimly lit street scene, then a red heart-shaped screen, followed by a gas station screen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 76/165 [02:53<02:50,  1.92s/it][32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7m9XIXyT5_I.mp4[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7m9XIXyT5_I.mp4[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7m9XIXyT5_I.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=152[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a space setting, there is a yellow sun design in the center with the word 'Emission' below. In which of the following scenarios has this sun design appeared?
A. In the starry sky from a side view, there is a glaring white light in the center, surrounded by a halo of white light.
B. In a red cloud-like background, there is a cluster of bright light spots emitting strong light in the center.
C. In a black night sky, there is a purple circular object emitting purple light, with the words 'Protoplanetary Nebula' inscribed on it.
D. In a space background, there is a yellow design on the left side with radiating lines around it, and on the right side, there is a circular design with light blocked by something, with a yellow line attached to the sun.
E. In a blue background, the center is sparkling with densely packed light dots.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2vVQo_GMA70.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=155[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the airplane, there are two soldiers wearing khaki hats. The soldier on the left has a hand on his hat, while the soldier on the right is holding a paper and a pen. What is the soldier on the right doing?
A. He is throwing the pen
B. He is tearing up the paper
C. He is putting on goggles
D. He is writing on the paper
E. He is taking off the hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 77/165 [02:56<03:08,  2.14s/it][32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = L-XGTMusZvc.mp4[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/L-XGTMusZvc.mp4[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: L-XGTMusZvc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=154[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, after the blue yarn ring appears for the first time, what is attached?
A. purple yarn ring
B. pencil
C. rubber eraser
D. animal head sticker
E. a piece of paper with 'Aldehyde' written on it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Jfp1Ks7Hh1E.mp4[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Jfp1Ks7Hh1E.mp4[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Jfp1Ks7Hh1E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=157[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a gray background, there are two lines of English sentences in white font on a red and black base in the upper left corner, and five white circular icons in the middle. What happened after the subtitle 'proper channels for requesting close air support' appeared?
A. A fighter jet crashes from the sky
B. A fighter jet crashes into the sea
C. A pilot jumps off the fighter jet
D. A fighter jet is engaging in ground combat
E. A fighter jet is hit by artillery
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 78/165 [02:58<03:09,  2.18s/it][32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vVRC-0VKPrg.mp4[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vVRC-0VKPrg.mp4[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vVRC-0VKPrg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=156[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the person that appears first after the man on the right side of the screen, wearing a black jacket, a gold necklace, and having black middle-parted hair?
A. The man sitting at a desk with a projector and computer in a bedroom with colorful lights, wearing a black hoodie and jeans.
B. The man with middle-parted hair holding a camera, wearing a white hoodie and dark shorts.
C. The woman in the room behind the door, wearing a gray hoodie and glasses, with her hair tied up.
D. The man sitting on a bed with colorful lights in the bedroom, wearing a black short-sleeve shirt and black pants.
E. The man leaning against a yellow wall in the corridor, wearing a gray long-sleeve shirt, black pants, and glasses, with his arms crossed.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ozpGTw6DrXs.mp4[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ozpGTw6DrXs.mp4[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ozpGTw6DrXs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=159[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The top of the screen shows a red search box, below the search box is left-aligned text, with bold black characters at the bottom. Some characters in the upper right center are on a blue background. In the lower right corner, there is a man in black wearing sunglasses explaining something using a speech bubble. What is this man doing?
A. Using the mouse pointer to add a green background to part of the text
B. Using the mouse pointer to select part of the text on the screen
C. Using the mouse pointer to add a red background to part of the text
D. Using the mouse pointer to add a yellow background to part of the text
E. Using the mouse pointer to add a white background to part of the text
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 79/165 [03:01<03:22,  2.36s/it][32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mq6L8CnNJXc.mp4[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mq6L8CnNJXc.mp4[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mq6L8CnNJXc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=158[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a blue object at sea, there is a blonde woman wearing a blue swimsuit. In which other scene does this woman appear?
A. She appears in a library.
B. She appears in a kitchen.
C. She appears on a path between a white building on one side and a gray building on the other.
D. She appears in a restaurant.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kj3Po7zUeyw.mp4[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kj3Po7zUeyw.mp4[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kj3Po7zUeyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=161[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white shelf, there is a pair of mismatched shoes, and next to the shoes, there's a wooden-colored bag. What kind of fastener does the bag in the video have?
A. It is a gold square fastener
B. It is a silver square fastener
C. It is a silver round fastener
D. It is a gold round fastener
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 80/165 [03:04<03:33,  2.51s/it][32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = brZugTJ0odg.mp4[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/brZugTJ0odg.mp4[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: brZugTJ0odg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=160[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the ethnicity of the first person to appear in the video?
A. White
B. Black
C. Asian
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6933580627824495878.mp4[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6933580627824495878.mp4[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6933580627824495878.mp4 | Selected 15 frames[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=163[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with all kinds of items, with a yellow floor, there is a woman wearing a blue long-sleeved top pushing a cart. After the subtitle 'The St. Mark's Tower is one of Frank Lloyd Wright's earliest designs for a' appears, what does she do?
A. Walks around the cart in a circle
B. Speaks into the mirror
C. Brushes something on the cart with a small brush
D. Lifts the bottom of the cart
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 81/165 [03:06<03:20,  2.38s/it][32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ll3tR0kUZHc.mp4[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ll3tR0kUZHc.mp4[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ll3tR0kUZHc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=162[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a green lake with a few small boats docked at the pier, then a green lake with two people rowing a boat, and finally a green lake with no boats in sight, with mountains and trees in the distance.
B. First, a green lake with a few small boats docked at the pier, then a green lake with no boats in sight, with mountains and trees in the distance, and finally a green lake with two people rowing a boat.
C. First, a green lake with two people rowing a boat, then a green lake with a few small boats docked at the pier, and finally a green lake with no boats in sight, with mountains and trees in the distance.
D. First, a green lake with two people rowing a boat, then a green lake with no boats in sight, with mountains and trees in the distance, and finally a green lake with a few small boats docked at the pier.
E. First, a green lake with no boats in sight, with mountains and trees in the distance, then a green lake with a few small boats docked at the pier, and finally a green lake with two people rowing a boat.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i327DBSS_iE.mp4[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i327DBSS_iE.mp4[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i327DBSS_iE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=165[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A long-haired woman wearing a white short-sleeve shirt is standing in front of a white table. On the counter behind her, there are small potted plants and kitchen utensils. The cabinet above the counter has a colorful question mark sticker on it. The tiles on the wall are hexagonal. At the center of the table, there is a blue scale. To the left of the table, there is a jar containing white seasoning, and a glass bowl is placed to the right of the scale. The glass bowl contains white ingredients and green leaves. After the subtitle 'two tablespoons of powdered sugar i am' appears, what does the woman do?
A. The woman picks up a fork
B. The woman lifts the glass bowl
C. The woman is holding a knife and cutting a slender ingredient
D. The woman picks up a white paper to look at it
E. The woman is stirring the white ingredients with a whisk
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 82/165 [03:08<03:17,  2.38s/it][32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8MkL3W6wU3g.mp4[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8MkL3W6wU3g.mp4[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8MkL3W6wU3g.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=164[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are two Chinese men. The Chinese man on the left, dressed in a grey work uniform, is sitting on a stone bench. The man on the right, wearing a dark blue and grey pants, is also seated. After the subtitle 'the Chinese word for landscape is Shan' appears, what is the first object that appears?
A. A fake mountain with flowing water
B. A small red wooden scroll table
C. A classic window with green bamboo and a fake mountain
D. A sign with Chinese characters inside a house
E. A lantern hanging from the beam
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 83/165 [03:11<03:31,  2.58s/it][32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lN3WnXMaE0o.mp4[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lN3WnXMaE0o.mp4[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lN3WnXMaE0o.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=166[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After a video scene of a woman wearing a light-colored coat, carrying a red bag, walking a small dog through a forest filled with red leaves, which season appears first?
A. Autumn
B. Summer
C. Winter
D. Spring
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z-1lgAXOEc8.mp4[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z-1lgAXOEc8.mp4[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z-1lgAXOEc8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=167[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the right side of the screen, there are three soldiers holding shield banners with olive patterns, armed with spears and swords. On the left side, there is a person dressed in red clothes with black hair. What object first appeared on the screen after the subtitle 'creating a ruckus that echoed throughout' appeared?
A. A person with yellow hair holding a waterskin
B. Three soldiers with green shield banners and white-haired with long swords
C. A person dressed in a red robe with black hair
D. Three baskets
E. A soldier holding a red shield banner wearing a helmet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 84/165 [03:13<03:16,  2.42s/it][32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZGMGQsnSdLE.mp4[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZGMGQsnSdLE.mp4[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZGMGQsnSdLE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=168[0m
[32m2025-11-29 12:00:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a leather jacket is standing by the side of the road, behind him is a black iron gate and columns, surrounded by some green leaves and small yellow flowers. On the left side of the screen, there is a traffic light. In the distance, there are some buildings. In which other scenes does this man appear?
A. In a green photo green ceiling with two storefront pizza shops.
B. In a place with blue sky and white clouds, red buildings on both sides, a crosswalk on the road, and traffic lights hanging on a pole.
C. In a place with orange pillars and glass doors with PIZZA stickers, at the top of the storefront, there is a grid-style pizza shop sign.
D. In a long corridor covered with photos.
E. In an open kitchen with white cabinets and a black stove, there is also a white door nearby.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = otaJfBSlsG8.mp4[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/otaJfBSlsG8.mp4[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: otaJfBSlsG8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=169[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Amidst the thick black smoke, a burst of yellow flames is erupting. When these flames appear together with the subtitles 'forth basaltic magma from the mantle in', what change occurs to the flames?
A. It extinguishes.
B. Its color changes to blue.
C. Its color changes to orange.
D. Its color changes to red.
E. Its color changes to purple.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 85/165 [03:16<03:27,  2.60s/it][32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7184469162956246277.mp4[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7184469162956246277.mp4[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7184469162956246277.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=170[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:00:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white cabinet, there is a woman with long black hair wearing a pink top, and there's also a green potted plant on the surface behind her. With which of the following subtitles has she appeared together?
A. history
B. develop
C. warfare
D. people
E. science
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JhlzvoqKOc8.mp4[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JhlzvoqKOc8.mp4[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JhlzvoqKOc8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=171[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man wearing a black shirt appears in the center of the screen, he's wearing sunglasses, his hair is parted in the middle, and he has a white accessory at the collar. Behind him is a green field, trees, and a white sky, with people resting on the grass. In which other locations has this man wearing sunglasses appeared?
A. White sofa
B. Path by the water
C. Spacious theater
D. Hill in the grass field
E. Bench in the grass field
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 86/165 [03:18<03:00,  2.28s/it][32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PbiTIR8N4Hc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=172[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:00:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
By the riverbank, a woman in a pink backpack and black pants says in the subtitles, 'have intercourse. However, she changes her mind at the last moment and returns home.' What action did she take?
A. Picked up the white clothes
B. Threw the white clothes into the fire
C. Threw the white clothes into the river
D. Threw the white clothes on the ground
E. Put the white clothes on
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:00:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = duxO1EZ650E.mp4[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/duxO1EZ650E.mp4[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: duxO1EZ650E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=173[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:00:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow ground, there is a fossil of a trilobite. After the narrator says "the Devonian era was an incredibly," which fossil appears next?
A. Shell fossil
B. Plant fossil
C. Insect fossil
D. Coral fossil
E. Fish fossil
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 87/165 [03:21<03:28,  2.68s/it][32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7TljSpTBS9c.mp4[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7TljSpTBS9c.mp4[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7TljSpTBS9c.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=174[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman is sitting on the ground with her hair parted in the middle, exposing her forehead. She is surrounded by exquisitely woven items, and there are tree branches and leaves behind her. What did this seated woman do the first time she appeared?
A. Holding a flower
B. Hugging a cat
C. Praying with hands clasped together
D. Holding a woven item with both hands
E. Holding her chin with one hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pPJq1rMDRGs.mp4[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pPJq1rMDRGs.mp4[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pPJq1rMDRGs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=175[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The shoe rack is filled with shoes, and there is a shoe box placed on the top of the shoe rack. A person wearing a black top picks up a pair of Nike shoes with multiple colors including red, blue, and white. The shoe laces are blue. After the person in the black top puts down the Nike shoes, what does he do next?
A. Picks up a pair of shoes
B. Touches the shoe next to him
C. Picks up a can of drink
D. Picks up a black backpack
E. Picks up a shoe box
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 88/165 [03:24<03:29,  2.72s/it][32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DRIpznER-VQ.mp4[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DRIpznER-VQ.mp4[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DRIpznER-VQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=176[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' then a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right,' and finally, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background.'
B. First, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background,' then a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' and finally, a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right.'
C. First, a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' then a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background,' and finally, a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right.'
D. First, a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right,' then a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood,' and finally, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background.'
E. First, a scene appears with 'a man in grey-green clothes standing in front of a blurred hilly background,' then a scene appears with 'a white cloud-filled sky, with a power pole on the left and a woman with golden curly hair and a sideways face on the right,' and finally, a scene appears with 'various hanging lights glowing fuzzily with a woman in the middle whose face is covered in blood.'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = alEV01SMFNk.mp4[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/alEV01SMFNk.mp4[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: alEV01SMFNk.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=177[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:01:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the woman, wearing a plaid short-sleeve shirt and dark green apron, sitting in front of the kitchen table, preparing to do with a bucket of rice wine in her hand?
A. This woman is preparing to drink it
B. Preparing to pour it out and discard it
C. Preparing to pour it into a pot to cook
D. Preparing to pour it into a glass container and mix it
E. Preparing to spread it on dumplings
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _qepWb_NVj4.mp4[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_qepWb_NVj4.mp4[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _qepWb_NVj4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=179[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Four people are standing in a row in front of a window: two women are in the middle, and two men are on the outside. The man on the right is wearing a black coat, black-framed glasses, and carrying a backpack. One woman is wearing a gold-black patterned headscarf, and the other woman is in a black and white striped long skirt. The man on the left has a long beard, is resting his arm on the counter, and is dressed in gold-embroidered attire. In which other scenes does the man resting his arm appear?
A. Outside a store window in a high-end mall
B. At a speech venue, holding a mic
C. Outside a plant-filled balcony
D. Flipping through a book on a table
E. On a chair in a library
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 89/165 [03:26<03:13,  2.55s/it][32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0up5NxTiGZE.mp4[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0up5NxTiGZE.mp4[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0up5NxTiGZE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=178[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen, there is a picture of a white island within a blue background, surrounded by a yellow line. After mentioning 'be a continent then the biggest island,' what changes occur in this screen?
A. A picture of a blue island and a picture of an olive island appear to the right of the white island.
B. A picture of a pink island appears next to the white island.
C. A picture of a red island appears next to the white island.
D. A picture of a purple island appears next to the white island.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XYsCVqz3iug.mp4[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XYsCVqz3iug.mp4[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XYsCVqz3iug.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=181[0m
[32m2025-11-29 12:01:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a house built of wooden planks, there is a brown sheep eating something. A man in a black coat is petting it. Where else has this sheep appeared?
A. In front of a wooden table under a thatched roof
B. On the grass
C. In a zoo
D. In a park
E. On the roof
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 90/165 [03:29<03:16,  2.61s/it][32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zJ2uPZfkYMk.mp4[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zJ2uPZfkYMk.mp4[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zJ2uPZfkYMk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=180[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table, there's a woman in blue on the left and a woman in gray on the right. The woman in blue has her hands on the table. What is the woman in blue doing?
A. Placed a watermelon on the table
B. Placed a banana on the table
C. Placed an apple on the table
D. Placed a light blue arrow on the table
E. Placed a dragon fruit on the table
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zda-T6wrEhs.mp4[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zda-T6wrEhs.mp4[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zda-T6wrEhs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=183[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The white window frame holds a transparent glass that reflects the snowy landscape outside. In front of the window, there are porcelain items, a red candle, and a white candle. A person walks in from the right side of the screen. When the shot changes to a woman wearing a green linen dress facing the mirror, what change occurs to the red candle on the left side of the woman?
A. The red candle becomes longer
B. The red candle turns black
C. The red candle is burned out
D. The red candle is ignited
E. The red candle burns down and becomes shorter
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 91/165 [03:32<03:11,  2.58s/it][32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=182[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the woman, who is wearing half-rimmed glasses, a white coat, and light blue jeans, doing in the vegetable-filled garden in the video?
A. Crossing both hands
B. Using one hand to stroke her hair
C. Holding her hair with both hands
D. Placing one hand on her knee
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = soNQYQXrx_A.mp4[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/soNQYQXrx_A.mp4[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: soNQYQXrx_A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=185[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On stage, a large screen in the background shows a scene of a building, and in the center of the stage, two people are seated on chairs. One is a bald man wearing a blue suit, and the other is a person in a white shirt, holding a microphone in the left hand and raising the right hand. What object is not present in this scene?
A. table
B. tie
C. glass cup
D. red lamp
E. car
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 92/165 [03:34<03:14,  2.66s/it][32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8k6M0HD162k.mp4[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8k6M0HD162k.mp4[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8k6M0HD162k.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=184[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, some people are listening to a person on the podium explaining concepts related to projectiles. The concepts include sequences, red text in English, black text in English, and diagrams of red nets. What happens on the screen after the red net diagram appears?
A. Pie chart
B. Line chart
C. Bar chart
D. Circular diagram
E. Scatter plot
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 93/165 [03:36<02:57,  2.46s/it][32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qsH6q5wNso4.mp4[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qsH6q5wNso4.mp4[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qsH6q5wNso4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=186[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene where a woman wearing a white top is standing on barren ground, the subtitles say 'Hatch Flood freaks out and leaves, but Justin manages to tell him one last time where he' ‚Äî during this time, what change occurs to the woman's clothing?
A. She changes into an olive-colored coat
B. She changes into a blue coat
C. She changes into a black coat
D. She changes into a yellow floral dress
E. She changes into a white sweater
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = O3Hwh0uv8Mg.mp4[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/O3Hwh0uv8Mg.mp4[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: O3Hwh0uv8Mg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=187[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a purely black screen, which character appears first?
A. The woman with long hair
B. The man with short hair
C. The woman wearing a hat
D. The boy holding a soccer ball
E. The woman with short hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aqGQw1bXFN4.mp4[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aqGQw1bXFN4.mp4[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aqGQw1bXFN4.mp4 | Selected 5 frames[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=189[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, which of the following sequences of scenes is correct?
A. A yellow lunar rover with the Indian flag on the moon with a blue Earth in the background, a man in front of a starry background wearing a black T-shirt with white letters, a gray hat, and headphones speaking, a grayscale photo of craters on the moon's surface taken on the moon
B. A grayscale photo of craters on the moon's surface taken on the moon, a man in front of a starry background wearing a black T-shirt with white letters, a gray hat, and headphones speaking, a yellow lunar rover with the Indian flag on the moon with a blue Earth in the background
C. A grayscale photo of craters on the moon's surface taken on the moon, a yellow lunar rover with the Indian flag on the moon with a blue Earth in the background, a man in front of a starry background wearing a black T-shirt with white letters, a gray hat, and headphones speaking
D. A yellow lunar rover with the Indian flag on the moon with a blue Earth in the background, a grayscale photo of craters on the moon's surface taken on the moon, a man in front of a starry background wearing a black T-shirt with white letters, a gray hat, and headphones speaking
E. A man in front of a starry background wearing a black T-shirt with white letters, a gray hat, and headphones speaking, a grayscale photo of craters on the moon's surface taken on the moon, a yellow lunar rover with the Indian flag on the moon with a blue Earth in the background
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 94/165 [03:40<03:08,  2.65s/it][32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8_MG-E8QlBM.mp4[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8_MG-E8QlBM.mp4[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8_MG-E8QlBM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=188[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the beginning of the scene, in front of two buildings with triangular roofs and red beams, there is a small figure dressed in grey, holding a quill and writing on a scroll. Which subtitles appear alongside this scene?
A. I will not let this law go through
B. Nevertheless
C. in spite of
D. What are you doing
E. were also the source of the tribunes' power. Any Tribune could intercede on
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GawGUhl9zuQ.mp4[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GawGUhl9zuQ.mp4[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GawGUhl9zuQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=191[0m
[32m2025-11-29 12:01:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some women wearing headscarves are standing inside the hut, while the sunlight outside is dazzling. A man in a black and white striped short sleeve is holding a mobile phone. When the subtitle 'time news arrived of another body' appears, what is the woman in the middle with her hands covering her face and carrying a child on her back doing?
A. Sweeping the floor
B. Chatting with others
C. Waving to the camera
D. Taking care of the child
E. Covering her face with both hands, looking distressed
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 95/165 [03:43<03:12,  2.75s/it][32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _EUDpS9UF9o.mp4[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_EUDpS9UF9o.mp4[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _EUDpS9UF9o.mp4 | Selected 11 frames[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=190[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white background board, there is a notebook with pictures attached. The video screen of two women connecting is split into the top left and top right corners. The woman in the top left corner is wearing a red coat and a wristwatch. When the subtitle 'There's a lonely electron' appears, what change occurs to the red-clothed woman's wristwatch?
A. The watch face changes from dim to bright.
B. The watch face changes from bright to dim.
C. The watch face changes from red to black.
D. The watch face changes from black to white.
E. The watch face changes from white to yellow.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = T15Kv6dtYO0.mp4[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/T15Kv6dtYO0.mp4[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: T15Kv6dtYO0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=193[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there's a person cutting a green onion with a knife, and in the upper left corner, there's also a screen with burning wood. When the subtitle mentions 'Onion,' what other objects are present in the scene?
A. On the table, there's also a silver bowl containing a tomato and a pumpkin.
B. Oven
C. Bread
D. Watch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 96/165 [03:44<02:44,  2.39s/it][32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = l3vxOGgAM2g.mp4[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/l3vxOGgAM2g.mp4[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: l3vxOGgAM2g.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=192[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:01:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the wooden floor, there is a pair of white sandals on the left side and a pair of red slippers along with a colorful rug on the right side. Behind the slippers is a cabinet. What color is the cabinet in the video?
A. white
B. brown
C. blue
D. red
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 60-ADf8OL9A.mp4[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/60-ADf8OL9A.mp4[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 60-ADf8OL9A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=195[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When mentioning 'Music', the man wearing a white shirt, yellow jacket, and yellow pants, what type is his jacket?
A. Sweater
B. Cotton Clothing
C. Coat
D. Jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 97/165 [03:45<02:21,  2.08s/it][32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z7Cox6lPW3c.mp4[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z7Cox6lPW3c.mp4[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z7Cox6lPW3c.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=194[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a stage with three people, three men are seated in a triangular formation. When one of the men, who is wearing a complete olive-colored suit and sitting cross-legged, mentions 'whether they are traditional artists,' what change occurs to this man?
A. Both hands change from resting on his legs to resting on the sofa.
B. His right hand changes from resting on the sofa to touching his forehead.
C. His right hand changes from resting on the sofa to being raised.
D. His left hand changes from resting on the sofa to touching his forehead.
E. His left hand changes from resting on the sofa to being raised.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0up5NxTiGZE.mp4[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0up5NxTiGZE.mp4[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0up5NxTiGZE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=197[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a background board with the word 'Bloomberg' and a high-rise building, a man with gold and gray-white short hair is speaking directly into the camera. The text in front of him is gradually appearing. What kind of clothes is this man wearing?
A. He is wearing a pure black coat.
B. He is wearing a pure black shirt.
C. He is wearing a black checkered shirt.
D. He is wearing a pure black suit.
E. He is wearing a black striped shirt.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 98/165 [03:48<02:23,  2.14s/it][32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = K24dFfIM0gI.mp4[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/K24dFfIM0gI.mp4[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: K24dFfIM0gI.mp4 | Selected 15 frames[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=196[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the narrow mountain roads where the road is blocked tightly with crawling traffic, filled with all kinds of trucks, which subtitles appear simultaneously when two rows of trucks are tightly connected on the congested road?
A. disputes Pakistan sometimes shuts is 
B. Crossings with Afghanistan causing
C. Economically and it's not only on its
D. Millions is sulfur
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 99/165 [03:49<02:10,  1.98s/it][32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wKd804fWOyQ.mp4[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wKd804fWOyQ.mp4[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wKd804fWOyQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=198[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the built wooden frame, where else has the red shredded carrots inside the round iron plate on the olive-colored wooden table appeared?
A. On the roof
B. In the refrigerator
C. In the pot
D. In the oven
E. On the snowy ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0WEnmqVVbHo.mp4[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0WEnmqVVbHo.mp4[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0WEnmqVVbHo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=199[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room cluttered with various small objects, a man wearing black glasses and a green lab coat is sitting. Before the subtitle reads 'so yeah that's', what object appears first on the screen?
A. A refrigerator
B. A water dispenser
C. A bicycle
D. An oven
E. A small green plant
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 100/165 [03:51<02:10,  2.01s/it][32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gURB1JwPfJw.mp4[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gURB1JwPfJw.mp4[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gURB1JwPfJw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=200[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white background PPT, at the top, there is a blue title 'Mole to Mole Ratios', at the bottom, there is a black chemistry formula with an arrow and an English question in small black font. In the bottom right corner, within a circular frame, there is a video screen showing a long-haired woman wearing a white coat over a black outfit. When the subtitle 'compound yeah so that's what you need' appears, what is this woman doing?
A. Touching her head with both hands
B. Both hands resting flat on the table, talking towards the webcam
C. Waving towards the webcam
D. Propping up her chin with both hands
E. Elbows resting on the table with both hands raised, giving an explanation
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 101/165 [03:54<02:13,  2.09s/it][32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = t3P11ENBZyc.mp4[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/t3P11ENBZyc.mp4[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: t3P11ENBZyc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=202[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bright sunlight outside, there are lakes and green trees in the distance. A group of young people were having a picnic on the grass, surrounded by others. In the picture, who is the person being hugged by the girl wearing a white short-sleeved shirt and light blue jeans?
A. The girl wearing a beige long-sleeved outer jacket with a white short-sleeved shirt underneath
B. The man wearing a blue short-sleeved shirt and white shorts
C. The girl wearing a dark green suspender dress with a white short-sleeved shirt underneath
D. The man wearing a light blue long-sleeved outer jacket and beige long pants
E. The man wearing a white short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LcZxjqtzXJI.mp4[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LcZxjqtzXJI.mp4[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LcZxjqtzXJI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=201[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with light, a man with a bald head wearing black-rimmed glasses stands in front of a glass showcase. The man is dressed in a black suit. Inside the transparent glass, there are two small sculptures, one of which is facing the man. What is this man doing?
A. Touching the showcase
B. Adjusting his collar
C. Knocking on the showcase
D. Adjusting his sleeve
E. Staring at the sculpture
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = FnKDgC9aNu0.mp4[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/FnKDgC9aNu0.mp4[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: FnKDgC9aNu0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=203[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, an officer wearing a yellow-green uniform is climbing up a wall. He is wearing a steel helmet, has a gun on his back, and is carrying a black item. The scene then transitions to a military doctor holding a syringe and administering an injection to a soldier on the ground, surrounded by fallen soldiers. What changes have occurred to the soldier on the ground?
A. His clothes have changed to blue and green.
B. He is drinking water.
C. He is bleeding.
D. He is sleeping.
E. His helmet is gone.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 102/165 [03:56<02:18,  2.20s/it][32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = X5v4nBo5y28.mp4[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/X5v4nBo5y28.mp4[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: X5v4nBo5y28.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=204[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, there are three men sitting. One is wearing a black short-sleeve shirt, another is wearing a dark grey short-sleeve shirt, and the third is wearing a grey-and-white dress shirt. When the subtitle 'Sicily to Libya and some technical' appears, what objects can be seen in the frame?
A. red arrow
B. white chair
C. blue water tank
D. black camera
E. black phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6976239624578419969.mp4[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6976239624578419969.mp4[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6976239624578419969.mp4 | Selected 15 frames[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=205[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white walls, there is a woman with curly hair wearing a black short-sleeved shirt on the left, and a man with short hair wearing a white coat on the right. Behind them, there is a bright object. When the subtitle mentions 'She then asks him why he wants to know, and he tells her because he has been arrested,' who is the first person to appear making a phone call in prison?
A. A man in a black outfit
B. A woman in an orange outfit
C. A man in a purple outfit
D. A man in an orange outfit
E. A man in a white outfit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 103/165 [03:59<02:27,  2.38s/it][32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UwJTCg5fpXg.mp4[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UwJTCg5fpXg.mp4[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UwJTCg5fpXg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=206[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the picture, a woman is sitting on a chair holding two children beside her. Another child is standing behind her. A boy in a black woolen coat and another boy in a blue jacket are visible. The girl is wearing a red woolen coat and a checkered skirt. There is a white glass door in the background and green plants on the side. Who is the child sitting on the armrest of the chair in the picture?
A. The child wearing a red woolen coat
B. The child wearing a blue jacket
C. The child wearing a grey jacket
D. The child wearing a green woolen coat
E. The child wearing a checkered shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 104/165 [04:01<02:14,  2.20s/it][32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dxjKdnJFmLs.mp4[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dxjKdnJFmLs.mp4[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dxjKdnJFmLs.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=208[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A hand with manicured nails is placed near the shoulder of a reclining woman. The woman is wearing a black short sleeve shirt and is smiling. There is a toy figure behind her. What did the hand with manicured nails do after being placed on the reclining woman's shoulder?
A. Tapped the reclining woman's forehead
B. Tapped the reclining woman's face
C. Tapped the reclining woman's shoulder
D. Tapped the reclining woman's stomach
E. Tapped the reclining woman's buttocks
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i327DBSS_iE.mp4[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i327DBSS_iE.mp4[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i327DBSS_iE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=207[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a small road, a man wearing a dark red short-sleeved T-shirt and a green hat is chatting with a man wearing a black short-sleeved T-shirt and a red hat. When the man wearing the green hat holds a shoe in his right hand, what action does the man wearing the black short-sleeved T-shirt and red hat do with his left hand?
A. Throwing the shoe away
B. Holding a red teacup
C. Holding a red teacup and drinking tea
D. Point with his thumb and index finger at the man wearing the green hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 105/165 [04:02<01:57,  1.96s/it][32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = o2F-N42Ufo4.mp4[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/o2F-N42Ufo4.mp4[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: o2F-N42Ufo4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=210[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, which of the following characters appears first?
A. The little boy in a dark blue short-sleeved shirt with gray and white stripes, drawing with a crayon in a drawing book
B. The short-haired woman in a misty blue long-sleeve shirt and glasses, holding a little boy
C. The short-haired woman in the black coat speaking in front of a large glass window
D. The man in a black outfit and black baseball cap, sitting in front of a shelf and looking at the camera
E. The woman in a gray shirt wearing a white mask and a blue head covering
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qYnloYaeQA8.mp4[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qYnloYaeQA8.mp4[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qYnloYaeQA8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=209[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences is correct?
A. First, a cartoon with a white background featuring two strong men and a woman in a skirt doing splits was shown. Then, a photo was shown of a man with graying hair, combed middle part, wearing a suit with a red and green tie, against a gray background. Finally, an image was shown of a man with an eye mask, shirtless with brown hair, a black tattoo on his abdomen, and a crowd in the background.
B. First, an image was shown of a man with an eye mask, shirtless with brown hair, a black tattoo on his abdomen, and a crowd in the background. Then, a cartoon with a white background featuring two strong men and a woman in a skirt doing splits was shown. Finally, a photo was shown of a man with graying hair, combed middle part, wearing a suit with a red and green tie, against a gray background.
C. First, a cartoon with a white background featuring two strong men and a woman in a skirt doing splits was shown. Then, an image was shown of a man with an eye mask, shirtless with brown hair, a black tattoo on his abdomen, and a crowd in the background. Finally, a photo was shown of a man with graying hair, combed middle part, wearing a suit with a red and green tie, against a gray background.
D. First, a photo was shown of a man with graying hair, combed middle part, wearing a suit with a red and green tie, against a gray background. Then, a cartoon with a white background featuring two strong men and a woman in a skirt doing splits was shown. Finally, an image was shown of a man with an eye mask, shirtless with brown hair, a black tattoo on his abdomen, and a crowd in the background.
E. First, a photo was shown of a man with graying hair, combed middle part, wearing a suit with a red and green tie, against a gray background. Then, an image was shown of a man with an eye mask, shirtless with brown hair, a black tattoo on his abdomen, and a crowd in the background. Finally, a cartoon with a white background featuring two strong men and a woman in a skirt doing splits was shown.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 106/165 [04:05<02:09,  2.19s/it][32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = by3NxI0dA6w.mp4[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/by3NxI0dA6w.mp4[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: by3NxI0dA6w.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=212[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the glaring sunlight, three men are running on the golden sand, with many green trees and people having fun in the background. What style of top is the man in the middle wearing?
A. Gray sweater
B. Olive suit
C. Blue sleeveless top with red and blue patterned front
D. White and black striped long sleeve
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Sn7JPKbG6tY.mp4[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Sn7JPKbG6tY.mp4[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Sn7JPKbG6tY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=211[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a grayish-purple background, there are white letters spelling 'NATIVE AMERICA'. Next to the white letters, there is a handicraft. When the white letters 'NATIVE AMERICA' appear on a white wall, what color change occurs to the letters?
A. From white to blackish-gray
B. From white to yellow
C. From white to purple
D. From white to blue
E. From white to green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 107/165 [04:07<02:04,  2.15s/it][32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7197781091162279169.mp4[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7197781091162279169.mp4[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7197781091162279169.mp4 | Selected 3 frames[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=214[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 12:01:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the beginning of the video, a woman wearing a white short-sleeved top and gray shorts is standing barefoot on a wooden platform, holding black and pink clothes. When the subtitle 'Ever since I left the city, you' appears, what change happens to this woman?
A. The gray shorts change to black shorts.
B. She goes from not wearing sunglasses to wearing sunglasses.
C. The white short-sleeved top changes to a pink plaid long-sleeved top.
D. She goes from not wearing a hat to wearing a hat.
E. Her hair changes from black to yellow.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 108/165 [04:07<01:34,  1.65s/it][32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _BDzMutoy6A.mp4[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_BDzMutoy6A.mp4[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _BDzMutoy6A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=216[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with sunlight streaming through the windows, the room is decorated with many green plants. There is also a shelf with books and other items on it. A woman is admiring her eyeshadow in a mirror. What color is the woman's nail polish?
A. black
B. green
C. red
D. purple
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mS1QPVgBDQo.mp4[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mS1QPVgBDQo.mp4[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mS1QPVgBDQo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=213[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background features a white cabinet decorated with red lanterns. On the right side, there's a silver refrigerator with a red couplet sticker on it. A woman in a red short-sleeve top and apron is standing in front of a table holding a sesame ball. On the table, there are two glass containers and an iron plate. When the subtitle 'I fell like it's so refreshing' appears, what is this woman doing?
A. kneading a sesame ball
B. cutting a sesame ball
C. eating a sesame ball
D. deep-frying a sesame ball
E. making tangyuan
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 109/165 [04:10<01:42,  1.82s/it][32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gJijNOktmoI.mp4[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gJijNOktmoI.mp4[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gJijNOktmoI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=218[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a conversation with an olive-colored background, there is an audience below with heads exposed, and above are three women. The woman on the left is holding a microphone and speaking. On the left woman's lap is a vertically placed white book. What change occurs to the white book when the woman on the left puts down the microphone?
A. It turned into a circle
B. A corner was missing
C. It became thicker
D. It was opened
E. It turned into two white books
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iJgh2dnudIU.mp4[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iJgh2dnudIU.mp4[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iJgh2dnudIU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=215[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a stretch of yellow sandbrisk–µd by jade-green seawater, a man wearing a grey short-sleeve shirt, glasses, and sporting a goatee is taking a selfie. In which of the following scenes does this goateed man appear?
A. Inside a large turtle tank
B. On a beach during the rain
C. In a dense primeval forest
D. In a park during the rain
E. In a park with a slide
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 110/165 [04:12<01:57,  2.14s/it][32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PQRyGacBRA4.mp4[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PQRyGacBRA4.mp4[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PQRyGacBRA4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=220[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man wearing black clothes with curly hair is facing the camera. Behind him is a complex building with a clock tower. There are also some withered branches on the left side. In which of the following scenes does this man appear?
A. On top of a building with a lot of reporters, and the roof is red.
B. On a viewing platform without the Union Jack flag.
C. In front of a building with black rectangular tiles, a white carved door frame, black double doors, and surrounded by windows.
D. On a road surrounded by trees with cars around.
E. On a circular stage with many people below.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 111/165 [04:14<01:53,  2.09s/it][32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2vVQo_GMA70.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=222[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Next to a refrigerator covered in many pictures, there is a woman with purple hair wearing a green top. Her hands are open with the palms facing upwards. What items are behind her to the left?
A. Green and gray boards
B. A pot and some knives
C. Tea cup
D. Water faucet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UUaiqR1I454.mp4[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UUaiqR1I454.mp4[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UUaiqR1I454.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=217[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a room, hanging on the wall are an orange bag and a green and white garment. A woman wearing green clothes is holding a baby dressed in white. In which captions does this baby appear together?
A. cuts and bruises and they did not surrender
B. cuts and bruises and years that followed his wife sadly died
C. cuts and bruises and many more suffered similarly
D. years that followed his wife sadly died and many more suffered similarly
E. they did not surrender and many more suffered similarly
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GuEptwLiAvs.mp4[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GuEptwLiAvs.mp4[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GuEptwLiAvs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=219[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the first person to appear in the video?
A. The woman wearing a black T-shirt with white patterns and black long hair
B. The woman wearing a white coat and glasses
C. The child wearing a hat
D. The man wearing a suit
E. The child without a shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 112/165 [04:18<02:11,  2.47s/it][32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7Q8d8Vvk6oo.mp4[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7Q8d8Vvk6oo.mp4[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7Q8d8Vvk6oo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=224[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:01:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. A man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen; a man wearing gray sportswear with black earbuds is running outside.
B. A man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen; a man wearing gray sportswear with black earbuds is running outside; a man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf.
C. A man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing gray sportswear with black earbuds is running outside; a man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen.
D. A man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen; a man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing gray sportswear with black earbuds is running outside.
E. A man wearing gray sportswear with black earbuds is running outside; a man wearing an orange hoodie with a red and white logo on the upper right corner sits in front of the bookshelf; a man wearing a black long-sleeved shirt holding an orange pumpkin stands in the kitchen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tYqDvtknII4.mp4[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tYqDvtknII4.mp4[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tYqDvtknII4.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=221[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:01:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A cute, gray-furred little animal is in a thick, clean white snowy field, with dry tree branches at the side. What is this animal doing in the white snow in the video?
A. Barking
B. Running
C. Rolling
D. Digging
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:01:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 113/165 [04:20<02:02,  2.35s/it][32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = H_b5d-rLXJU.mp4[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/H_b5d-rLXJU.mp4[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: H_b5d-rLXJU.mp4 | Selected 12 frames[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=226[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 12:01:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a room, there is a bookshelf filled with books and a wall covered in wallpaper. A man wearing a red short sleeve shirt is sitting on a gaming chair. When mentioning 'smd, what is caught? Piper, aka resource, is a trace format multi,' what is this man doing?
A. He has both hands raised above his head
B. He has both hands crossed in front of his chest
C. He is doing the V-sign with both hands
D. He is doing the V-sign with one hand and clenching a fist with the other
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 114/165 [04:21<01:45,  2.07s/it][32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XYsCVqz3iug.mp4[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XYsCVqz3iug.mp4[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XYsCVqz3iug.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=228[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bar chart appears on the screen, one bar is purple, and the other is yellow. The two bars are compared, with the years indicated below. What shows up after the bar chart appears?
A. A city map
B. A glass of water
C. A smartphone
D. Fried chicken
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wSHPuI7wWIg.mp4[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wSHPuI7wWIg.mp4[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wSHPuI7wWIg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=223[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing black clothes and a black mask appears at the center of the screen, with a woman in a black hooded outfit next to him. Behind the man, there is a parked red car, a person in dark long clothes, and some trees. When the subtitle 'photo spot of the Tokyo Tower' appears, what objects are present in the scene?
A. A black handbag
B. A white mask
C. A blue mask
D. A black car
E. A white handbag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fO7nwCix8xU.mp4[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fO7nwCix8xU.mp4[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fO7nwCix8xU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=225[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table, a woman wearing a blue dress is on the left side, with her hands on a white paper that says "DIFFICULTY LEVEL 1". A woman wearing a gray dress is on the right side. What is the woman in the gray dress doing?
A. Combing her hair
B. Tidying up the items on the table
C. Playing the piano
D. Doing her nails
E. Cooking
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 115/165 [04:24<01:56,  2.34s/it][32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8Gl6iy7OEM4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=230[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a map, a man with short blonde hair wearing a black short-sleeved shirt is working out in the video. Behind him is a rice-white door. What equipment is the man with short blonde hair holding?
A. black resistance band
B. red hand gripper
C. white kettlebell
D. black jump rope
E. black kettlebell
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 116/165 [04:26<01:52,  2.29s/it][32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _ZIa6SEJEyg.mp4[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_ZIa6SEJEyg.mp4[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _ZIa6SEJEyg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=232[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room that is slightly dimly lit, there is a white desk with various items on it. Next to the desk stands a man with short hair, wearing a long-sleeve black shirt and a red and white striped tie. He is surrounded by white bookshelves filled with books. Which object appears in the scene?
A. Water cup
B. Rock
C. Red desk
D. Snacks
E. Table lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6948509102305791238.mp4[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6948509102305791238.mp4[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6948509102305791238.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=227[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:02:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the subtitle: 'First, you're going to want to heat your tortillas on a pan for a little bit so that they're more flexible.' appears at the bottom of the screen, what color sauce is spread on the tortilla placed in the white speckled round plate on the gray marble countertop?
A. Green
B. Red
C. Yellow
D. White
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6THwql5c6w.mp4[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6THwql5c6w.mp4[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6THwql5c6w.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=229[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner of the screen, there is a woman with long hair wearing white. Her left hand is open with the palm facing up. In the remaining white background, there are words and a red light spot, which stops below the letter 'e'. After the subtitles mention 'out the leftover amount you‚Äôre gonna,' what object appears in the hand of the woman wearing white?
A. cup without a straw
B. milk carton
C. green cup
D. coffee beans
E. a pen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 117/165 [04:29<01:51,  2.31s/it][32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = P0BSTjziVys.mp4[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/P0BSTjziVys.mp4[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: P0BSTjziVys.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=234[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black and white scene, a group of people are charging up a hill with guns. One person is holding a flag with a five-starred red emblem. After the subtitle 'spot where t e Ah,this qv who konws it', what appears on the screen?
A. French Flag
B. American Flag
C. British Flag
D. German Flag
E. Chinese Flag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JDtVwz1R-kI.mp4[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JDtVwz1R-kI.mp4[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JDtVwz1R-kI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=231[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a green planter in the upper right corner and a curved needle against an orange background on the left. There is a green piece of paper labeled Tip1 on the screen. In which of the following scenes does the green piece of paper also appear?
A. It appears simultaneously with the last SUBSCRIBE in the video.
B. In the video, there is a green planter in the upper left corner and a curved needle against an orange background on the right. There is a piece of paper labeled Tip2 on the screen.
C. In the video, there is a green planter in the upper right corner and a curved needle against an orange background on the left. There is a piece of paper labeled TIP2 on the screen.
D. In the video, there is a green planter in the upper right corner and a curved needle against an orange background on the left. There is a piece of paper labeled NOTE on the screen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 118/165 [04:31<01:47,  2.28s/it][32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lcEaHk8f4Co.mp4[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lcEaHk8f4Co.mp4[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lcEaHk8f4Co.mp4 | Selected 6 frames[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=236[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 12:02:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Someone is holding a floral tray and pushing a tray filled with yellow block-like food material into a metal rack. What is the food material that's being pushed forward in the tray?
A. Bread
B. Tofu
C. Banana
D. Papaya
E. Butter
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 119/165 [04:32<01:32,  2.01s/it][32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3ZRVpYPFOl0.mp4[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3ZRVpYPFOl0.mp4[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3ZRVpYPFOl0.mp4 | Selected 6 frames[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=238[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The video explains what Mad Jack did after leaving the military and going to England. In England, he also learned archery. In the footage, he is wearing a blue long-sleeve shirt, holding a bow and arrow on a grassland. What object appeared when he shot the arrow?
A. boat
B. bird
C. arrow
D. target
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 120/165 [04:33<01:13,  1.63s/it][32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7161798161395240197.mp4[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7161798161395240197.mp4[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7161798161395240197.mp4 | Selected 12 frames[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=240[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 12:02:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, the ceiling light emits a blend of colors, a red typewriter is placed on the black table, and beside the table, a woman with dark skin wearing gray clothing is holding a bottle of mineral water. Where has this bottle of mineral water been placed?
A. On the brown table
B. In the trash can
C. In the car
D. On the airplane
E. On the white bed
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d5JlCEDlHGE.mp4[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d5JlCEDlHGE.mp4[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d5JlCEDlHGE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=233[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a prepared wrap, with a piece cut off and held by a pair of hands. The background is a white marble table. In which other scene does this wrap appear?
A. Still on a marble table, there is a round green plate with the wrap covered in sesame seeds.
B. Still on a marble table, there is a round yellow plate with the wrap covered in sesame seeds.
C. Still on a marble table, there is a round black plate with the wrap covered in sesame seeds.
D. Still on a marble table, there is a round white plate with the wrap covered in sesame seeds.
E. Still on a marble table, there is a round pink plate with the wrap covered in sesame seeds.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 121/165 [04:35<01:10,  1.61s/it][32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aVHAr8rc-Ks.mp4[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aVHAr8rc-Ks.mp4[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aVHAr8rc-Ks.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=242[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, on a silver floor sits a man with short hair, wearing a black short-sleeved shirt and black shorts. He is holding a white plate. What is this man doing?
A. singing
B. running
C. drinking water
D. dancing
E. eating something
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7324761016909188358.mp4[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7324761016909188358.mp4[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7324761016909188358.mp4 | Selected 2 frames[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=235[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 2 specific frames[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 2 custom frames[0m
[32m2025-11-29 12:02:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 2 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman wearing a yellow coat with a ponytail. She is holding a mobile phone in her right hand and raises it to her ear. Which object does not appear in the video?
A. Yellow coat
B. Ring
C. Swimming pool
D. Mobile phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ezhafkxoRdo.mp4[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ezhafkxoRdo.mp4[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ezhafkxoRdo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=237[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who appears first in the video among the following characters?
A. A man wearing an orange jacket with a small name tag, sitting in front of a bookshelf filled with books.
B. A man wearing a white baseball cap inside a museum.
C. A woman with golden hair talking to a mirror, with a glowing display screen in the lower right corner.
D. A woman with golden hair wearing a checkered scarf inside a museum.
E. A man wearing a black top with a patterned neckline, a black beret, and black-rimmed glasses, sitting in front of a name tag.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 122/165 [04:37<01:22,  1.91s/it][32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7253792552996867330.mp4[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7253792552996867330.mp4[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7253792552996867330.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=244[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dim room, there is a black sofa. Two women are moving forward, one in a green dress and one in a pink dress. One of them is being pushed while moving forward. Who is being pushed while moving forward?
A. The woman in the green dress
B. The woman with a ponytail
C. The woman with a bun hairstyle
D. The woman with braided pigtails
E. The woman in the pink dress
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 123/165 [04:38<01:07,  1.61s/it][32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OmhVj_-cfH0.mp4[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OmhVj_-cfH0.mp4[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OmhVj_-cfH0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=246[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a blue background, a man wearing a dark grey short-sleeve shirt and black-framed glasses with short black hair said "Thank you for watching this episode of SciShow!" After he finished speaking, what was the first action he took?
A. Crossed his hands into fists
B. Placed both hands on his abdomen
C. Raised his right hand with palm open
D. Took off his glasses with both hands open
E. Raised both hands with palms open
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iJk-HMfO4yQ.mp4[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iJk-HMfO4yQ.mp4[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iJk-HMfO4yQ.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=239[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:02:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a white car parked on the road, with trees and a red brick building behind it. Next to the trees, there is a utility pole. An officer in a black and white uniform, wearing glasses and an ID badge, is giving an interview. In front of the officer, there are two communication devices, one white labeled 'LBC' and one black. Who is the first person to pass by behind the officer?
A. A woman wearing a suit
B. A woman wearing black clothes with a hat
C. A man wearing black clothes with a hat
D. A woman wearing a hat and sunglasses
E. An elderly person wearing a hat and sunglasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7194857776877817094.mp4[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7194857776877817094.mp4[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7194857776877817094.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=241[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:02:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A middle-aged man wearing a dark brown hat, a suit with a dark blue coat and blue shirt is standing in a gallery. There are paintings displayed on both sides of the gallery, and there is a row of spotlights on the left side of the ceiling. What color is the suit the middle-aged man is wearing?
A. Brown
B. Blue
C. Gray
D. Black
E. Green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 124/165 [04:40<01:11,  1.74s/it][32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yz3lOAe32Tw.mp4[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yz3lOAe32Tw.mp4[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yz3lOAe32Tw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=248[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the person, in a room with green plants, holding chopsticks and picking up food from the round plate on the table in front, and then putting it into their mouth?
A. A black-haired woman wearing a black top
B. A black-haired man wearing a white top
C. A black-haired woman wearing a white top
D. A white-haired woman wearing a black top
E. A black-haired woman wearing a purple top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSeq-nVSY_E.mp4[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSeq-nVSY_E.mp4[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSeq-nVSY_E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=243[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall with prints and paintings, there is a woman in red clothes on the left and a young girl in white clothes on the right. They are having a conversation. What happened after the conversation mentioned 'mommy gerbil ate her offspring's head'?
A. Jessica stroked Ted's mechanical arm
B. A robot with glowing yellow eyes came through the door
C. Two adult men were playing a board game
D. A man lay in the bathtub with a towel over his eyes
E. A woman in purple grabbed the wrist of a young girl with glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 125/165 [04:42<01:13,  1.84s/it][32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = O6UedmnRJc0.mp4[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/O6UedmnRJc0.mp4[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: O6UedmnRJc0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=250[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT with a white background, the upper left corner shows the black English text 'Proposed Solution', and on the right side of the screen there's a yellow background icon with the English text 'language Decoder'. Which subtitles appear simultaneously with it?
A. "functions but mmud already has learned"
B. ‚Äúusually take some frame by frame‚Äù
C. ‚Äúpositional EMB adding sign s or cosine‚Äù
D. "some embeddings from the encoder so what"
E. "you're going to get a very low value for"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Scne0ls23MA.mp4[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Scne0ls23MA.mp4[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Scne0ls23MA.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=245[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:02:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a man in a white short-sleeve shirt, with a large rectangular account book (or register) behind him, and a brown object with a round spike at the top right corner of the screen, which of the following characters has appeared before?
A. A person wearing a blue and white headscarf and a black short-sleeve shirt
B. A person wearing a blue and white headscarf and a white short-sleeve shirt
C. A person wearing a red and white headscarf and a black short-sleeve shirt
D. A person wearing a red and white headscarf and a black and white striped short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bjymxow3TVQ.mp4[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bjymxow3TVQ.mp4[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bjymxow3TVQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=247[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background is a white wall, with a black cabinet on the right side. A man wearing a white long-sleeved shirt and black pants stands next to a round wooden table with fruit and food on it, speaking to the camera. In which other scenes does this man appear?
A. On a sandy beach by the sea
B. On a mountain covered with plants
C. Next to a man in a gym wearing a black tank top holding two dumbbells
D. By a swimming pool
E. In a dining hall
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 126/165 [04:45<01:19,  2.04s/it][32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Q47I8AdRgzc.mp4[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Q47I8AdRgzc.mp4[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Q47I8AdRgzc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=252[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white table, there is a man wearing black pants and glasses standing. In front of the man, there is a gray wooden board. What hairstyle does the man with glasses have?
A. Brown short hair
B. Brown shoulder-length curls
C. Blue short hair
D. Black shoulder-length curls
E. Black buzz cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = marOr6mJefE.mp4[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/marOr6mJefE.mp4[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: marOr6mJefE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=249[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the dark space dotted with some stars, an Earth-like sphere appears and continuously shrinks. With which subtitles has this sphere appeared together?
A. original plate structure
B. ancient history of a planet
C. creating a suitable environment
D. stagnant lid period align
E. understanding of planetary bodies like
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 127/165 [04:47<01:21,  2.15s/it][32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F2OhCCEIOcU.mp4[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F2OhCCEIOcU.mp4[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F2OhCCEIOcU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=254[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man wearing a blue and white striped shirt in the van is talking to another man wearing a black shirt and a cap. What is the man in the black shirt and cap doing at this time?
A. playing with a phone
B. playing games
C. driving
D. drinking water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7275653401025826050.mp4[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7275653401025826050.mp4[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7275653401025826050.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=251[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:02:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, many people are sitting on the grass. On the screen, there is a man with blonde hair wearing a necklace and an overcoat with a white inner layer, sitting cross-legged on the ground. In which other scene does the man wearing the white inner layer appear in the video?
A. Inside a room
B. At the seaside
C. Inside a cargo truck
D. In a milk tea shop
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 128/165 [04:50<01:26,  2.33s/it][32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=256[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a sunny outdoor setting, a fire truck stands nearby along with a firefighter whose skin is dark. In which of the following scenes has this dark-skinned firefighter appeared before?
A. In front of a burning house
B. Inside a garbage truck loaded with trash
C. Outside a forest on fire
D. In a rainy park
E. On a golden sandy beach
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d-GKQeu4S6M.mp4[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d-GKQeu4S6M.mp4[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d-GKQeu4S6M.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=253[0m
[32m2025-11-29 12:02:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top right corner of the video, there are two small screens of women. On a white background, there are some English formulas. After the subtitle 'there's p that's 1 DS next which is 2' appears, what does the woman in glasses and a grey T-shirt in the top right corner do?
A. Yawns
B. Brushes her hair with both hands
C. Stands up
D. Adjusts her glasses
E. Takes off her glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = byaqQClCO-Y.mp4[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/byaqQClCO-Y.mp4[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: byaqQClCO-Y.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=255[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing an off-shoulder top is sitting on a white sofa. She has orange nail polish and is wearing a necklace. Behind her is a white wall and a black armrest. Two books are on either side of her. When the subtitle 'honeymooners is one of my favorites and' appears, what is the woman doing?
A. The woman is holding a book in each hand
B. The woman is holding a pen in both hands
C. The woman is holding a book in her right hand and a pen in her left hand
D. The woman is holding a book in her left hand and a paper in her right hand
E. The woman is holding a book in her left hand and a pen in her right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 129/165 [04:53<01:28,  2.45s/it][32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RN2g9sRuJhA.mp4[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RN2g9sRuJhA.mp4[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RN2g9sRuJhA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=258[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, what did the woman holding the child do before the subtitle mentions 'since he first child was born seven'?
A. Touched her hair with her hand
B. Put down the child and squat
C. Held her head with both hands
D. Put her hair up
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = m7sL8LuMD8Q.mp4[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/m7sL8LuMD8Q.mp4[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: m7sL8LuMD8Q.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=257[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:02:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a kitchen, there is a man standing wearing a blue shirt with tattoos on his arms. Behind him are some white cabinets and a black countertop. On the black countertop, there is a black pot. In front of the man, there is a plate of prepared food. What is he doing?
A. Taking photos of the food
B. Eating the prepared food
C. Cutting the food with a knife
D. Picking up the food with chopsticks
E. Putting on a disposable glove
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 130/165 [04:55<01:28,  2.53s/it][32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Lc7RikDaa30.mp4[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Lc7RikDaa30.mp4[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Lc7RikDaa30.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=260[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a person resting their head against the wall, someone sitting on the windowsill, a long-haired woman leaning against the curtain, and a short-haired woman with her elbow on her knee. What action does the woman leaning against the curtain do afterward?
A. Turn her head
B. Nod
C. Stand up
D. Wave her hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mB7NW91REF4.mp4[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mB7NW91REF4.mp4[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mB7NW91REF4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=259[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
With green plants and decorative shelves on the left and right sides of the screen, a man wearing glasses and a yellow suit with a middle part hairstyle is introducing himself with a mirror. Which of the following scenes appears first?
A. A woman sitting in a car holding the steering wheel
B. A screenshot of news about COE
C. A display screen showing toll information on a road in Singapore
D. People walking and cars driving on a road
E. Tightly packed and neatly arranged cars in a parking lot
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 131/165 [04:57<01:20,  2.38s/it][32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7277140989259599105.mp4[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7277140989259599105.mp4[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7277140989259599105.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=262[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:02:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, the woman with the long black hair, wearing a scarf and earrings, is about to go out. Where did she go after going out?
A. On a spacious street
B. In a convenience store
C. In a barbecue restaurant
D. In a bar
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7324498849857326341.mp4[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7324498849857326341.mp4[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7324498849857326341.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=261[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What did the Yoda baby with big black eyes in the screen do when the subtitle said, "to obtain any information about the Yoda baby's owner"?
A. Raised one ear
B. Raised both ears
C. Blinked its eyes
D. Ran on the ground
E. Walked on the ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 132/165 [04:59<01:11,  2.16s/it][32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=264[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, in the green valley filled with green plants, there are green letters spelling 'GREENERY IN THE'. What is the color of the path in the scene?
A. green
B. blue
C. gray
D. orange
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = v0QLje6xYgA.mp4[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/v0QLje6xYgA.mp4[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: v0QLje6xYgA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=263[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark car, there is a screen above, and a clock in front displaying 0:17. A man wearing glasses sitting in the front right seat is looking at the mirror. When the subtitle 'you guys to charity what's your name' appears, what action is this man with glasses doing?
A. Pointing at the mirror with his middle finger
B. Giving a thumbs-up
C. Stretching both hands towards the mirror
D. Pointing at the mirror with his index finger
E. Closing his eyes tightly
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 133/165 [05:03<01:24,  2.63s/it][32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aCPNlZ7bvRc.mp4[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aCPNlZ7bvRc.mp4[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aCPNlZ7bvRc.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=266[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:02:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a pink stage, there's a girl with long black hair wearing a white top, white short skirt, and white knee-high stockings. When she appears for the first time, what is she doing?
A. Touching her face with her palm
B. One leg kneeling on the ground
C. Kneeling with her right hand supporting her chin
D. Kneeling with both hands resting on her left leg
E. Both legs kneeling on the ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Y1YCvEip_ko.mp4[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Y1YCvEip_ko.mp4[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Y1YCvEip_ko.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=265[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a man in the screen wearing a green military uniform, raising his hands. There are guns on both sides of him. Who is being held at gunpoint in the video?
A. Commander Jeremiah Denton
B. Tom
C. Nancy
D. Lhcy
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 134/165 [05:04<01:10,  2.28s/it][32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OmhVj_-cfH0.mp4[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OmhVj_-cfH0.mp4[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OmhVj_-cfH0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=268[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man in the black coat and the man with glasses sitting opposite him are having a meal together. The man with glasses is holding a phone in one hand and wearing a watch on the other. There is a red pillow on his left side. Reflected in the window behind the man with glasses is a service staff wearing a mask. There is a colorful cartoon character design behind the man in the black coat. He is holding a cup with both hands and has a black bag to his left. The tablecloth is a combination of olive and white colors. Where else does the man with glasses appear?
A. On the bicycle
B. In front of the hotel bed
C. On the beach
D. In the back seat of a taxi
E. On the bus
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vEy6tcU6eLU.mp4[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vEy6tcU6eLU.mp4[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vEy6tcU6eLU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=267[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is an elderly man wearing a dark brown hat, dressed in a brown suit, with a dark blue sweater and a blue shirt underneath, walking in the gallery. On the right side of the gallery, there is an artwork displayed, among which a painting shows a woman in a green dress sitting on a sofa. Can you tell what color the sofa is?
A. red
B. black
C. pink
D. green
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 135/165 [05:06<01:06,  2.23s/it][32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KTY9bogonyw.mp4[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KTY9bogonyw.mp4[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KTY9bogonyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=270[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing an orange shirt appears in front of a black background. The man rolls up his sleeves. The man is holding a plate of Indian specialty food in his hand. There is a food picture to the man's left, and when the subtitle 'These usually come to the Northern regions of India' appears, what is the shape of the plate in the picture to the right?
A. Rectangle
B. Circle
C. Square
D. Pentagon
E. Irregular Shape
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TynnVVRNZGs.mp4[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TynnVVRNZGs.mp4[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TynnVVRNZGs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=269[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the screen, there is a white-haired man dressed in a black suit with a dark blue tie, sitting in front of a white flag with a blue Star of David. What is this white-haired man doing?
A. Drinking water
B. Sleeping
C. Writing
D. Speaking into a microphone
E. Brewing tea
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 136/165 [05:09<01:07,  2.33s/it][32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PbiTIR8N4Hc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=272[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, two women are sitting in the car. The woman sitting in the driver's seat, who is on the right side of the screen, what is she doing when she appears for the first time?
A. Holding four cups of coffee
B. Exchanging coffee
C. Putting down coffee
D. Drinking a cup of coffee
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yFAuXmcGk2Y.mp4[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yFAuXmcGk2Y.mp4[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yFAuXmcGk2Y.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=271[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a blurry screen, there are two hands holding two grayish-white clods of dirt. Inside these clods there are some grayish-white objects. After the phrase 'that contain hollow cavities lined with' is spoken, what is the first object to appear?
A. Black crystals
B. Trilobite fossil
C. Pearl fossil
D. Plant fossil
E. Fish fossil
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 137/165 [05:12<01:10,  2.52s/it][32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rZq-8Bq3mkU.mp4[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rZq-8Bq3mkU.mp4[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rZq-8Bq3mkU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=274[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene with a white background, there are two 'Âè™' characters sketched incorrectly on the bottom left of the screen. When the scene changes to an image with multiple 'Âè™' characters sketched, there are many red, dark blue, and green arrows. What changes occur to the 'Âè™' character in the bottom left corner at this time?
A. Green characters and sketches appeared above the 'Âè™' character
B. The 'Âè™' character turned black
C. The 'Âè™' character turned green
D. The bottom part of the 'Âè™' character disappeared
E. Blue characters and sketches appeared above the 'Âè™' character
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7MemY9jOmuk.mp4[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7MemY9jOmuk.mp4[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7MemY9jOmuk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=273[0m
[32m2025-11-29 12:02:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a yellow background, a man with short hair, wearing black-framed glasses and dressed in a deep purple hooded sweatshirt. What is he doing when he appears for the first time?
A. Frantically waving hands, speaking towards the camera
B. Raising both hands with palms open
C. Right hand holding the left hand, speaking towards the camera
D. Arms spread wide, speaking towards the camera
E. Left hand holding the right hand, speaking towards the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 138/165 [05:14<01:04,  2.39s/it][32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -iCLYpeghJs.mp4[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-iCLYpeghJs.mp4[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -iCLYpeghJs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=276[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left, there is a topless man covering his head, while behind him stands a uniformed armed personnel wearing a mask. On the right, there is a woman sitting on a black sofa, dressed in black and white striped clothing. In which subtitles does the topless man appear?
A. in
B. the two Mexican uh criminal groups at
C. moment
D. between cartel and
E. where we have a set of policies across
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NexB4vj8_54.mp4[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NexB4vj8_54.mp4[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NexB4vj8_54.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=275[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white tiled wallpaper with icy and sweet candy circles, there are two men standing side by side, one wearing short sleeves and the other holding a remote control wearing long sleeves. When the phrase 'tlicking topping motion is that how you' is mentioned, how are their clothes described?
A. The man on the left is wearing light red short sleeves, and the man on the right is wearing a white long sleeve.
B. The man on the right is wearing light yellow short sleeves, and the man on the left is wearing a black long sleeve.
C. The man on the right is wearing light red short sleeves, and the man on the left is wearing a black long sleeve.
D. The man on the left is wearing light red short sleeves, and the man on the right is wearing a black long sleeve.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 139/165 [05:16<00:58,  2.26s/it][32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 22iOyzE8Ec0.mp4[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/22iOyzE8Ec0.mp4[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 22iOyzE8Ec0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=278[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the person in the video doing when a bowl of white yogurt appears above a transparent glass container filled with beaten yellow egg liquid on a dark red wooden table?
A. Pouring the yogurt into the container with egg liquid
B. Stirring the yogurt and egg liquid
C. Drinking the yogurt
D. Stirring the yogurt
E. Stirring the egg liquid
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pGEF7Tme3Tk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=277[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a purple background, there is a man with long black hair standing. He is clasping his hands together in front of him. In the upper right corner of the screen, there are bold subtitles in white and blue. What action does he take afterwards?
A. He tilts his head and supports his cheek with one hand.
B. He squats down to tie his shoelaces.
C. He bends down to pick something up.
D. He spreads his hands open, palms facing outward.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 140/165 [05:19<00:58,  2.33s/it][32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7337436458078260485.mp4[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7337436458078260485.mp4[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7337436458078260485.mp4 | Selected 3 frames[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=280[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue sky, there are majestic snow-capped mountains, with many houses at their base. When 'and have some of the cutest cows' is mentioned, what changes occur in the clouds over the mountains?
A. The white clouds are replaced by dark clouds
B. The white clouds move smoothly to the left side of the screen
C. The clouds are tinted by the evening glow
D. The white clouds move smoothly to the right side of the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 141/165 [05:19<00:42,  1.78s/it][32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = IN0osLg-Mn8.mp4[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/IN0osLg-Mn8.mp4[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: IN0osLg-Mn8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=282[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:02:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the white cabinet, there is a man with short hair and wearing a black short-sleeved shirt. He is holding a chickpea in his left hand with both hands raised. When he appears alongside the subtitle 'pork ragu or i‚Äôm gonna do some romesco,' what changes occur to him?
A. The chickpea in his hand turns into pork.
B. The chickpea in his hand turns into an egg.
C. The chickpea in his hand turns into a glass of milk.
D. The chickpea in his hand turns into a bluebonnet.
E. The chickpea in his hand turns into a kitchen knife.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:02:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2vVQo_GMA70.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=279[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:02:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a black coat is kissing a woman with a ponytail. When the subtitle 'the conspiracy Frank sends his wife, Jordan to safety in Venezuela, then burns down his casino' appears, which of the following items is present?
A. hat
B. watermelon
C. earring
D. ring
E. earphone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 142/165 [05:21<00:45,  1.98s/it][32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _uL3a3aMdMQ.mp4[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_uL3a3aMdMQ.mp4[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _uL3a3aMdMQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=284[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, after the yellow-bordered rectangular strip of paper is pasted, what appears next?
A. red strip of paper
B. pencil
C. notebook
D. mobile phone
E. white strip of paper with lines on it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dE5iWeCVpGI.mp4[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dE5iWeCVpGI.mp4[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dE5iWeCVpGI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=281[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a black background, there is a woman wearing a gray and white suspender dress. She is wearing a ring on her hand, and there is also a picture of a British flag beside her. When the subtitle "was there too okay this is gonna be a" appears, what kind of hairstyle does the woman in the gray and white suspender dress have?
A. Long black hair
B. Long silver hair
C. Short blonde hair
D. Long black curls
E. Long blonde curls
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 143/165 [05:24<00:46,  2.11s/it][32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pFpZvRsEGZs.mp4[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pFpZvRsEGZs.mp4[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pFpZvRsEGZs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=286[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a slightly blurred background, what is a woman with long curly hair, wearing a long-sleeved top and a necklace, doing when the caption 'work you breathe it you live it and' appears?
A. Holding a blue pen and writing something
B. Holding a black pen and writing something
C. Holding a purple pen and writing something
D. Holding a white pen and writing something
E. Holding a red pen and writing something
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = x4UBaEojM6U.mp4[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/x4UBaEojM6U.mp4[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: x4UBaEojM6U.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=283[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a white coat and a long-haired woman are standing face to face next to a shelf. The man is holding a bottle with liquid in one hand and resting the other hand on the shelf. What is the color of the liquid in the bottle?
A. Black
B. Yellow
C. White
D. Red
E. Blue
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 144/165 [05:26<00:46,  2.22s/it][32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7274542274997013761.mp4[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7274542274997013761.mp4[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7274542274997013761.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=288[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:03:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room with a greyish-white canopy, there is a woman with a headband, wearing a black short-sleeved shirt. What action does she perform when she mentions 'fast forward to castings for hot Couture'?
A. She uses her right hand to apply mascara to her right eye.
B. She uses her left hand to apply mascara to her right eye.
C. She uses her left hand to apply mascara to her left eye.
D. She uses her right hand to apply mascara to her left eye.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UMFy3keSk-s.mp4[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UMFy3keSk-s.mp4[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UMFy3keSk-s.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=285[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a man and a woman. The woman is wearing a white nightgown, and the man is wearing a blue shirt. When the man in the blue shirt appears in an office with brown walls, what change occurs to his clothing?
A. Changes from a blue shirt to a red shirt
B. Changes from a blue shirt to a white T-shirt
C. Changes from a blue shirt to a purple shirt
D. Changes from a blue shirt to a black hoodie
E. Wears an additional black suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 145/165 [05:28<00:39,  2.00s/it][32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8Gl6iy7OEM4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=290[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with pictures, two men are discussing some topics. There's a picture with a river at the bottom left corner of the screen. One of the men is saying 'a pew river the whole'. Which man is saying 'a pew river the whole'?
A. The man with fair skin
B. The man wearing a black short-sleeve shirt
C. The man wearing an olive hat
D. The man wearing a white short-sleeve shirt
E. The man wearing a yellow short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 146/165 [05:30<00:39,  2.09s/it][32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aVHAr8rc-Ks.mp4[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aVHAr8rc-Ks.mp4[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aVHAr8rc-Ks.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=292[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a lakeside view, there is a green tree by the lakeside, and a woman in a black jacket is running towards the lakeside. What objects are present in the scene?
A. White glasses
B. Blue skirt
C. Black skirt
D. Pink shorts
E. Pink skirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mfS6gyP0mwo.mp4[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mfS6gyP0mwo.mp4[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mfS6gyP0mwo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=287[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the first concept mentioned after the man, sitting in front of the microphone wearing a black shirt with a pattern on the neck and a black cap and black-rimmed glasses, talks about evolution?
A. Human evolution differences
B. Animal fossilization
C. Vertebrate
D. Plant fossilization
E. Mythical creature
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 147/165 [05:33<00:39,  2.18s/it][32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fw1rirubXiU.mp4[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fw1rirubXiU.mp4[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fw1rirubXiU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=294[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top right corner of the video, there is a woman wearing a purple outfit, holding a white pen in her left hand, sitting on a black object. The wall is white. When she explains 11.5110*21.20/(44.11+1.223) and during the summary at the end of the video, how does the color of the wall change?
A. White turns to blue
B. White turns to purple
C. White turns to green
D. White turns to black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XYsCVqz3iug.mp4[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XYsCVqz3iug.mp4[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XYsCVqz3iug.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=289[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the broadcast room, there is a man wearing a black suit and a white shirt. His right hand is on the table, and his left hand is slightly raised. On the screen next to his right hand, the text 'DYING FOR AID' appears. What change occurs to his right hand when the text on the screen changes to 'GLOBAL WATCH'?
A. He places his right hand on a mouse
B. He places his right hand on his forehead
C. He places his right hand on his chin
D. He is holding a piece of paper with his right hand
E. He is holding a phone with his right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 148/165 [05:35<00:38,  2.29s/it][32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fsz6bkkIHzQ.mp4[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fsz6bkkIHzQ.mp4[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fsz6bkkIHzQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=296[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table, there is a woman dressed in blue on the left, and a woman dressed in grey on the right. She reaches out her ring-bearing hand next to a white paper with 'Br' written on it. What is the woman in grey doing?
A. Moved a computer
B. Moved the paper with 'Br' written on it
C. Moved a teapot
D. Moved a book
E. Moved an apple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mTn_C-SyW84.mp4[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mTn_C-SyW84.mp4[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mTn_C-SyW84.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=291[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow wooden floor in front of a red painting, there are two red stools. On the stool in the front, there is a woman with a pink backpack. When the subtitle ‚ÄúRothko was aware that people often burst into tears when confronted with his paintings.‚Äù appears, what is this woman doing?
A. Doing homework
B. Talking with a friend
C. Making a phone call
D. Wiping her tears
E. Looking at the painting
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 149/165 [05:38<00:37,  2.35s/it][32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=298[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a woman wearing a white coat is facing the mirror and picking up a bouquet of flowers. One of her braids is draped between her eyes. What objects are present in this scene?
A. a necklace
B. a watch
C. a ring
D. a hair clip
E. a door
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GGwHSz9towk.mp4[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GGwHSz9towk.mp4[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GGwHSz9towk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=293[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black background, there are two screens. On the left, there is a white car passing by on a road in front of a construction building. On the right, there are two people conversing on a red carpet stage. What objects are present in this screen?
A. helicopter
B. green stone lion
C. black car
D. traffic light
E. handgun
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 150/165 [05:40<00:35,  2.37s/it][32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LYvStKy8iAc.mp4[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LYvStKy8iAc.mp4[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LYvStKy8iAc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=300[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The curly-haired man in the blue shirt, standing in front of the stone carving, what is the curly-haired man in the blue shirt doing?
A. Touching
B. Painting
C. Admiring
D. Carving
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0ln2qdCR5lA.mp4[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0ln2qdCR5lA.mp4[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0ln2qdCR5lA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=295[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white background wall, a woman with earrings and hair tied up, wearing a short-sleeved T-shirt, is pressing foundation liquid onto a sponge in her hand. Behind her, there are green leaf decorations on the wall. Her nails are pink, and she is wearing a ring on her finger. What happened after she pressed the foundation liquid onto the sponge?
A. Pressed the sponge onto her neck
B. Pressed the sponge onto her face
C. Washed dishes with the sponge
D. Pressed the sponge onto her hand
E. Threw the sponge away
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 151/165 [05:43<00:34,  2.44s/it][32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yl-6-Yzt--A.mp4[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yl-6-Yzt--A.mp4[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yl-6-Yzt--A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=302[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Many green lights were emitted on the wall, a black-haired man wearing a gray suit picked up a box and was about to leave the house. What happened after the man picked up the box?
A. Someone climbed a ladder
B. Drinking water
C. Someone sang
D. Someone ran
E. An explosion
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JLnsWrzV_j4.mp4[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JLnsWrzV_j4.mp4[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JLnsWrzV_j4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=297[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top left corner of the screen, there is a rectangular land-sea distribution map with a white question mark in the middle. On the right side of the map, there is a man wearing a gray shirt sitting. What is this man doing?
A. Lying on the desk sleeping
B. Crossing his arms in front of his chest
C. Speaking with animated hand gestures
D. Standing up and turning around
E. Sitting silently with a closed mouth
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 152/165 [05:45<00:31,  2.39s/it][32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = f2-6Mh6lyQQ.mp4[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/f2-6Mh6lyQQ.mp4[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: f2-6Mh6lyQQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=304[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the distance, there are some green plants within grey buildings. A woman dressed in a Tibetan blue long-sleeve top, a blue checkered short-sleeve shirt, black leggings, and carrying a black crossbody bag is taking a photo of a man in front of her who is wearing a Tibetan blue top and grey pants with a backpack. What is the hairstyle of this woman when the subtitle 'ignores her and walks away Yuan secretly' appears?
A. Loose hair
B. Long straight black hair
C. Tied in a ponytail
D. Short brown hair
E. Brown curly hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fWNJmZAWRNg.mp4[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fWNJmZAWRNg.mp4[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fWNJmZAWRNg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=299[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are three people on the screen. The man on the left is wearing a khaki suit with a white shirt and a tie. The man in the middle is wearing a white hoodie, purple gloves, and glasses, holding a document in his hand. The woman on the right is wearing a grey long-sleeved jacket with a black and white floral underlay, with her hands in purple gloves resting on the table. What are these three people doing around the document on the table?
A. Organizing the document
B. Making a craft
C. Disassembling the document
D. Assembling the document
E. Exploring the contents of the document
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 153/165 [05:47<00:28,  2.37s/it][32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GRPLynULvJY.mp4[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GRPLynULvJY.mp4[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GRPLynULvJY.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=306[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:03:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, a woman is standing in front of a cash register, and there are two other people behind the counter. The four people in the scene are clearly visible. The woman at the register is wearing black clothes, and the woman buying coffee is wearing an olive-green trench coat. Who is the person in the scene with their head slightly bowed and smiling?
A. The black-haired woman in the white jacket
B. The black-haired woman in the olive-green jacket
C. The man in the black shirt
D. The woman in the olive-green trench coat
E. The woman in the black dress
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 154/165 [05:48<00:21,  1.92s/it][32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=308[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wooden platform with three potted plants, there is a person looking down with both legs raised on the table. Who is this person?
A. A woman with brown short hair
B. A woman with brown long hair
C. A woman with black short hair
D. A woman with black long hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = otaJfBSlsG8.mp4[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/otaJfBSlsG8.mp4[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: otaJfBSlsG8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=301[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the deep mountains, with overgrown weeds ahead, trees in the distance, a stone at the bottom right corner, and a wooden handrail with a hand wearing a bracelet directly in front, what action does the hand perform when the subtitle 'while do not put too much weight on this' appears?
A. pulls out the handrail
B. shakes the handrail
C. raises the thumb
D. lifts the stone
E. pulls grass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 155/165 [05:51<00:23,  2.37s/it][32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZRMbh0wSly0.mp4[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZRMbh0wSly0.mp4[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZRMbh0wSly0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=310[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white cabinet, there is a green potted plant on the side. In front, there is a woman with long black hair holding an illustrated book. Which of the following subtitles appeared with this illustrated book?
A. that afternoon stella and her clay
B. let's find a cozy spot and let's get
C. let's begin with our welcome song just
D. started
E. story time and activity now
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _ZIa6SEJEyg.mp4[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_ZIa6SEJEyg.mp4[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _ZIa6SEJEyg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=303[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a grey concrete ground, a group of girls dressed in the same white tops and beige floral skirts hold hands to form a circle. When mentioning the 'collodion anole rain making ritual,' what kind of ornaments are on the girls' skirts?
A. Waist belts adorned with colorful flowers
B. Small skirts adorned with colorful flowers
C. Green leaf-shaped small skirts
D. Small animal-shaped ornaments made of folded green leaves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 156/165 [05:54<00:22,  2.45s/it][32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7261188695892462856.mp4[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7261188695892462856.mp4[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7261188695892462856.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=312[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:03:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against the white background, there are texts in both pink and black colors. In the bottom right corner of the screen, there is a woman with long black hair, wearing a pink outer garment and a black inner garment. She is raising both hands with palms facing inwards. Before the subtitle mentions 'see this topic on final exams so if you,' what number appears in the screen's bottom right corner?
A. 3
B. 4
C. 7
D. 6
E. 5
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OUeE8nCKWGA.mp4[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OUeE8nCKWGA.mp4[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OUeE8nCKWGA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=305[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a man wearing blue clothes and a blue hat is making a phone call. Then, a woman with her hair wrapped is sitting in the room tidying up clothes. Lastly, a woman wearing a hat and a skirt is playing by the seaside.
B. First, a man wearing blue clothes and a blue hat is making a phone call. Then, a woman wearing a hat and a skirt is playing by the seaside. Lastly, a woman with her hair wrapped is sitting in the room tidying up clothes.
C. First, a woman wearing a hat and a skirt is playing by the seaside. Then, a man wearing blue clothes and a blue hat is making a phone call. Lastly, a woman with her hair wrapped is sitting in the room tidying up clothes.
D. First, a woman with her hair wrapped is sitting in the room tidying up clothes. Then, a woman wearing a hat and a skirt is playing by the seaside. Lastly, a man wearing blue clothes and a blue hat is making a phone call.
E. First, a woman wearing a hat and a skirt is playing by the seaside. Then, a woman with her hair wrapped is sitting in the room tidying up clothes. Lastly, a man wearing blue clothes and a blue hat is making a phone call.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 157/165 [05:56<00:18,  2.31s/it][32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0_YDrJoUe8s.mp4[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0_YDrJoUe8s.mp4[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0_YDrJoUe8s.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=314[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a store, there are shelves with bottles and other items at the back, a bookshelf full of books in the distance, a stack of books in the bottom right corner, books on a glass counter in the middle, a white Christmas tree, glass bottles containing things, a person wearing a black coat on the left, and a man wearing glasses in the middle. What is the man wearing glasses in the middle doing?
A. Writing
B. Tearing a book
C. Holding a glass cup
D. Holding a book
E. Picking up the Christmas tree
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 4ouAf1ldH60.mp4[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/4ouAf1ldH60.mp4[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 4ouAf1ldH60.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=307[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman is sitting inside a gallery. She is wearing a red coat and black clothes. Her hair is blonde and she is wearing a watch on her wrist. There are two paintings hanging on the wall behind her. When the phrase 'want to experience the painting as the' is mentioned, what change occurs to this woman?
A. The woman shakes hands in front of the painting
B. The woman takes a picture in front of the painting
C. The woman dances in front of the painting
D. The woman flips her hair in front of the painting
E. The woman stands in front of the painting admiring it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 158/165 [05:58<00:15,  2.19s/it][32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UKU-W5bBCwY.mp4[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UKU-W5bBCwY.mp4[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UKU-W5bBCwY.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=316[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:03:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene of a movie on the screen, a group of people are dressed in very shabby clothes, with burlap bags over their heads showing only their eyes. They are in a well-decorated room. The walls of the room have orange-colored light strips, the ceiling is blue, and there are orange-colored sofas and chairs in the room. There is a red laser on the ceiling. What is the shape of the patterns on the ceiling?
A. Triangle
B. Circle
C. Spiral
D. Heart
E. Square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 159/165 [05:59<00:11,  1.91s/it][32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UwlKYM2Sotg.mp4[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UwlKYM2Sotg.mp4[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UwlKYM2Sotg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=318[0m
[32m2025-11-29 12:03:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a brown cutting board, a person is holding a knife and cutting an orange carrot. What shape are the carrot pieces that have already been cut?
A. Round
B. Triangular
C. Long strips
D. Minced
E. Square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z-1lgAXOEc8.mp4[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z-1lgAXOEc8.mp4[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z-1lgAXOEc8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=309[0m
[32m2025-11-29 12:03:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man is sitting on a couch. The man is wearing a pink top and blue jeans. He is holding a black cup in his hand. The couch is dark-colored, and there is a green handkerchief placed on the armrest of the couch. What did the man in the pink top do the first time he appeared?
A. Picked up a key
B. Held his forehead with his hand
C. Wiped his pants
D. Picked up a watch
E. Wiped his shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 160/165 [06:02<00:10,  2.04s/it][32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7094322812327906565.mp4[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7094322812327906565.mp4[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7094322812327906565.mp4 | Selected 11 frames[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=320[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 12:03:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a white dining room with a white dining table on which there is a dessert plate. Two hands are holding glasses for a toast. After the subtitle 'Thak you' appears, what happens?
A. Two hands take two pieces of dessert
B. Two people drink the wine in the glasses
C. Two people start drinking tea
D. Two people start eating the dessert
E. One hand takes a piece of dessert
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 161/165 [06:03<00:07,  1.83s/it][32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = v-7zF3Y0yJs.mp4[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/v-7zF3Y0yJs.mp4[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: v-7zF3Y0yJs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=322[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a blonde woman wearing a black tank top and a man with curly hair wearing a black T-shirt. They are talking in front of a mirror, with a black column and a thick tree behind them. There are also two white cars parked by the roadside. In which scene does the woman in the gold tank top appear?
A. On the stairs in front of a red building with black handrails.
B. On the stairs in front of a red building with white handrails.
C. On the stairs in front of a red building with gray handrails.
D. On the stairs in front of a red building with yellow handrails.
E. On the stairs in front of a red building with orange handrails.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = N7RTTiHsSjI.mp4[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/N7RTTiHsSjI.mp4[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: N7RTTiHsSjI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=311[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a screen with a blue background and a turret-shaped building on the far right, what color suit is the man sitting in front of the phone booth wearing?
A. blue
B. pink
C. white
D. black
E. yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 162/165 [06:05<00:06,  2.00s/it][32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oddHY1vwcjo.mp4[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oddHY1vwcjo.mp4[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oddHY1vwcjo.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=324[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a flat ground, the left side is the exterior wall of a building. There are two windows on the exterior wall, two outdoor units of air conditioners, and several plants at the bottom. In the middle, there are 7 people, 5 of whom are looking upward. There is a car in front of them, and there is a liquid on the car. Could you please tell me the color of the liquid on the car at this time?
A. Purple
B. Black
C. Blue
D. White
E. Blood Red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DoizYSYQRqU.mp4[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DoizYSYQRqU.mp4[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DoizYSYQRqU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=313[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman are standing by the roadside talking. The woman has her brown hair tied up and is wearing a shirt. The man also has brown hair. In the distance, there are buildings, traffic lights, and a road. The image is blurry, and the whole scene is shrouded in darkness. What material is the man's jacket made of?
A. A woolen jacket
B. A mohair jacket
C. A denim jacket
D. A cotton jacket
E. A silk jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 163/165 [06:06<00:03,  1.66s/it][32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = t3P11ENBZyc.mp4[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/t3P11ENBZyc.mp4[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: t3P11ENBZyc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=326[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a sunlit room, there is a woman wearing a black short-sleeve shirt. She is grabbing her hair with her left hand and combing her hair with her right hand. What objects are present in this scene?
A. Comb
B. Hair clip
C. Necklace
D. Glasses
E. Watch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vJ9hYCUDHTo.mp4[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vJ9hYCUDHTo.mp4[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vJ9hYCUDHTo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=315[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, three officers are dressed in dark green military uniforms with caps. The officer on the left is smoking with his right hand, and there is an eagle insignia on his cap. A rifle is placed in front of the window on the left. The officer in the middle stands with a rifle on his back, while the officer on the right is seated. When the scene changes to show four officers in a frontline bunker exchanging fire, the officer on the left is disguised with grass on his helmet and is aiming a rifle. The seated officer on the right has facial injuries. To his right, there is an officer with a steel helmet firing a rifle, and they are positioned behind a barricade. The standing officer with the eagle insignia is present. What change has this officer undergone?
A. He is standing
B. He is holding water
C. There are some wounds on his face
D. He is standing straight
E. He is holding a wooden stick
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 164/165 [06:09<00:01,  1.94s/it][32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SAkgZJllNzw.mp4[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SAkgZJllNzw.mp4[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SAkgZJllNzw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=328[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a gray suit and tie is speaking on a podium. He is in a large hall, with three blue flags behind him, and has short hair and wears glasses. In front of him are two microphones. When he mentions 'of a tactical or technical issue it is,' which non-existent objects are present?
A. yellow pillar
B. black glasses
C. blue flags
D. dark brown door
E. blue curtain
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sHUEJw1BsGQ.mp4[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sHUEJw1BsGQ.mp4[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sHUEJw1BsGQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=317[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a yellow title of State Parks at the top of the screen. In a picture on the left, there is a yellow tree and a river. Below, there is a plane, and next to the plane, there is the number 1. On the right, there is a green mountain scene, and below it, there is a plane with the number 5 next to it. When mentioning 'lot of great state parks I've hiked and,' which object does not appear on the screen?
A. A plane made of white and black
B. A plane made of white and green
C. A plane made of white, blue, and red
D. A green valley
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [06:10<00:00,  1.87s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [06:10<00:00,  2.25s/it]
[32m2025-11-29 12:03:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a car, in the front left seat sits a man wearing a green hat, with a face covered, dressed in khaki clothes. Behind him is a woman with blonde hair in white clothes. In the front right seat is a man wearing sunglasses, with a face covered, dressed in gray clothes, with a black steering wheel in front of him. Behind him is a man with short hair, dressed in a white long-sleeve shirt, wearing a black bow tie. When the subtitle mentions 'The pirates intend to take them to their boss, but Darey tricks them by asking for a cigarette,' what object is present in the picture?
A. fan
B. cup
C. cigarette
D. computer
E. mobile phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = SCZ_Z4NnikA.mp4[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/SCZ_Z4NnikA.mp4[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: SCZ_Z4NnikA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=319[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a seaside hill covered with green grass, there is a shining sea in the distance. A white building is constructed on the hill, with a red building at the bottom right corner and a white object as well. What shape is the white building?
A. cylindrical
B. rectangular
C. square
D. irregular
E. stepped
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XR3Ov2nQ39s.mp4[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XR3Ov2nQ39s.mp4[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XR3Ov2nQ39s.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=321[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:03:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an abandoned lot, there is a green tank. Next to the tank, a man wearing a black short-sleeve shirt and black pants is standing. With what subtitle did this man appear together?
A. a male beforehand and about taking
B. to full rights use them in my videos
C. masoom military and of course my
D. bovis and aircraft gun but more on this
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:03:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZsnfXfuGRrg.mp4[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZsnfXfuGRrg.mp4[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZsnfXfuGRrg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=323[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:03:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:04:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What change occurs to the book held by a bald man with a mustache, wearing a gray shirt, which has a black cover with the English word 'STUKA' written on it, when the screen shows the text 'Early testprint of the German text' in white letters at the bottom?
A. The pages of the book turn black.
B. The book is opened.
C. A cartoon image appears on the book.
D. The pages of the book turn yellow.
E. The book is torn.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:04:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fo97qfO-9_g.mp4[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fo97qfO-9_g.mp4[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fo97qfO-9_g.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=325[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:04:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:04:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the live news broadcast set, there are three paintings made into window shapes, with black grids and some tall buildings inside the frames. Two men in suits and a woman in a black skirt are conversing. The woman is looking at a piece of paper in her hand, the man in the middle has his arms crossed, and another man is speaking. There is a round table with a coffee cup in front of them. What did the man in the middle do?
A. The man speaking picked up the coffee cup
B. The man sitting on the left stood up
C. The woman and the man in the middle shook hands
D. The man sitting in the middle placed his hands on his own legs
E. The woman stood up from her seat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:04:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KTY9bogonyw.mp4[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KTY9bogonyw.mp4[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KTY9bogonyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=327[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:04:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:04:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the video switches to a screen showing a broadcast room with the number 151.86 at the bottom, there is a woman with braided hair wearing black pants sitting on the left side of the broadcast room. What is this woman doing?
A. Reading a book
B. Touching her ear
C. Stretching her waist
D. Crossing her legs
E. Standing up to move around
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:04:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = J1IwKg2ufk8.mp4[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/J1IwKg2ufk8.mp4[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: J1IwKg2ufk8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=329[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:04:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:04:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black pot, there are red ingredients being cooked. A person without a visible face is holding a spatula, stirring the contents in the pot. What objects are present in this scene?
A. chopsticks
B. noodles
C. wooden spatula
D. iron spatula
E. fork
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:04:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Postprocessing:   0%|          | 0/165 [00:00<?, ?it/s][32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tWiGnu2BNsY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mqtJErix0ss_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @luxtravelbe-7233851486474636570_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PQRyGacBRA4_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7TljSpTBS9c_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CGngv8vTQOs_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F4bDyyEO4PU_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YebUIUOCo94_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bqQTWdk1DAM_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DVsw1brd_Yc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yFAuXmcGk2Y_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: e-EtQHH4aWE_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dCscvoOX2as_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fxCRCMLJ0PU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MJYBHfYF8LI_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZaXpMou55lw_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i6C6r2g4Y7Q_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HWyDOQrYtCk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AnLMDMzO4QY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: baFsMWNavQ4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bgklOaBBmB8_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F2OhCCEIOcU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tygk9-aneC4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KlZpZVphLrc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iDFDxwPTjeU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7321010343067618592_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9S9i12n0TIw_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d8H7hgQY9ew_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kLuqCtnKr_8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 14ot4DrXdds_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Q4GK4asczVA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: j6beJTHUT_c_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6HTO2SOxUc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tCnelzIAHA0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F2OhCCEIOcU_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: I-yg_3yx6iA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fySqsm5kNl4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7318074908645264645_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2W2ZkYARds4_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NpYUxd1vUUE_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: H2ksp6sRR-k_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TFbGLEZ4qt0_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sKvvuo9Yxqk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: crmV4OduHYA_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5dJUUQufzw4_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kOZnpwI2hIM_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbgwG8fcIu0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: M5YKW6fhlss_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9dSkvxS2EB0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MvgJAD6tZXo_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0_YDrJoUe8s_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9WjElCiDpzM_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d7IqrLV6Tlg_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: BktEeBeA7a8_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ng2rNm6Nwsg_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: h0OHi9uAcBo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7303594391850044678_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MvgJAD6tZXo_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbcWAfHo5j0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XVXczyheik0_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mYotOV3Q51g_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: h4jIoMxZopU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6qLYX6bzsl4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MvgJAD6tZXo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7rMgpExA4kM_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAHsR02dUc0_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: td35F9LNazA_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7277548218106367234_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Aw1_7wSaeKk_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ip9DbdOtqF4_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DVsw1brd_Yc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CdTijM0_es4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qyaQ-wfojbM_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tdm72-vYxTs_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kMryvefpcF8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7308098412078025989_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: V-RIpt7Tknc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7267233980473314606_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ysRFFN5nzqE_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pGEF7Tme3Tk_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: cceTeD4JADU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5zbV24vyO44_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HPunfsyjETs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sEiyR7-0FOA_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: s5edwp0PEqk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lnCPn8gX3FU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lQODAJ_F5yE_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3hyPwjkdHEA_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UN3ICsfqKEY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fWNJmZAWRNg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _7sd4fjnmvc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YcbKamVxDzI_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ezhafkxoRdo_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8MkL3W6wU3g_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7rMgpExA4kM_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QPth_xqBXGY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XVXczyheik0_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hg2Q_O5b9w4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LAbtlJJhUlY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LHXS0QR1ThA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _7sd4fjnmvc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 60oHeCZHtvI_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: T5bTeGzgJFs_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: V-RIpt7Tknc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 51dUUxFOjDE_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vEy6tcU6eLU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: npLd4WTSQsM_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7214559428471770374_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: x4dFLY_-vKs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _zEM6Fc-7NI_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ng2rNm6Nwsg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 49YMA0f1yhI_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PS0gXPNBZy8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: I2Fyzav8MxE_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vVRC-0VKPrg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fp1r40w_PtA_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qjY9kmveQAk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @thatrecipe.us-7309241426028596523_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LVFvRNRTEd4_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZaXpMou55lw_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2F7d7aUCmUU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6THwql5c6w_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OGaML8Gg8JQ_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QPth_xqBXGY_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fPLjjr8w6DU_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iwXp1fT89-M_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: M-YfPangEfA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: J1IwKg2ufk8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SYqEMs0EYoI_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -kaF6SnSEo8_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yz3lOAe32Tw_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -PnG8Jp2gFw_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kelseyinlondon-7258968758130085146_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Lk9ZihSgjdo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: X0U3fP0tZyY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vpKtHB8x0js_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7268936523481943297_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AxciimuEZAc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kj3Po7zUeyw_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MPQn_orwpfA_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: uWBh0meTg08_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VSZ8ywgGNGM_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GFg98TDqCpw_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mfS6gyP0mwo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Dkm35G5kkcc_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: athabNMGceo_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -PnG8Jp2gFw_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jess.morg-7079970495499717934_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7252661595875183874_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7m9XIXyT5_I_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VFXJnbnN5ro_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: L-XGTMusZvc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2vVQo_GMA70_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vVRC-0VKPrg_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Jfp1Ks7Hh1E_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mq6L8CnNJXc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ozpGTw6DrXs_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: brZugTJ0odg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kj3Po7zUeyw_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ll3tR0kUZHc_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jetset_anna-6933580627824495878_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8MkL3W6wU3g_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i327DBSS_iE_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lN3WnXMaE0o_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z-1lgAXOEc8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZGMGQsnSdLE_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: otaJfBSlsG8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7184469162956246277_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JhlzvoqKOc8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PbiTIR8N4Hc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: duxO1EZ650E_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7TljSpTBS9c_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pPJq1rMDRGs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DRIpznER-VQ_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: alEV01SMFNk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0up5NxTiGZE_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _qepWb_NVj4_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zJ2uPZfkYMk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XYsCVqz3iug_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zda-T6wrEhs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8k6M0HD162k_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: soNQYQXrx_A_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qsH6q5wNso4_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: O3Hwh0uv8Mg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8_MG-E8QlBM_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aqGQw1bXFN4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _EUDpS9UF9o_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GawGUhl9zuQ_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: l3vxOGgAM2g_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: T15Kv6dtYO0_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z7Cox6lPW3c_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 60-ADf8OL9A_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: K24dFfIM0gI_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0up5NxTiGZE_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wKd804fWOyQ_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0WEnmqVVbHo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gURB1JwPfJw_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LcZxjqtzXJI_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: t3P11ENBZyc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: FnKDgC9aNu0_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: X5v4nBo5y28_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-6976239624578419969_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UwJTCg5fpXg_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i327DBSS_iE_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dxjKdnJFmLs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qYnloYaeQA8_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: o2F-N42Ufo4_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Sn7JPKbG6tY_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: by3NxI0dA6w_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mS1QPVgBDQo_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-7197781091162279169_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iJgh2dnudIU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _BDzMutoy6A_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UUaiqR1I454_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gJijNOktmoI_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GuEptwLiAvs_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PQRyGacBRA4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tYqDvtknII4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2vVQo_GMA70_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wSHPuI7wWIg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7Q8d8Vvk6oo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fO7nwCix8xU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: H_b5d-rLXJU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XYsCVqz3iug_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-6948509102305791238_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6THwql5c6w_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8Gl6iy7OEM4_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JDtVwz1R-kI_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _ZIa6SEJEyg_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d5JlCEDlHGE_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: P0BSTjziVys_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lcEaHk8f4Co_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7324761016909188358_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3ZRVpYPFOl0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ezhafkxoRdo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iJk-HMfO4yQ_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7161798161395240197_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aVHAr8rc-Ks_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-7194857776877817094_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7253792552996867330_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSeq-nVSY_E_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OmhVj_-cfH0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Scne0ls23MA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yz3lOAe32Tw_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bjymxow3TVQ_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: O6UedmnRJc0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: marOr6mJefE_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Q47I8AdRgzc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7275653401025826050_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F2OhCCEIOcU_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d-GKQeu4S6M_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: byaqQClCO-Y_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RN2g9sRuJhA_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: m7sL8LuMD8Q_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Lc7RikDaa30_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mB7NW91REF4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7277140989259599105_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7324498849857326341_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: v0QLje6xYgA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aCPNlZ7bvRc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Y1YCvEip_ko_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OmhVj_-cfH0_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vEy6tcU6eLU_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TynnVVRNZGs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KTY9bogonyw_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yFAuXmcGk2Y_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PbiTIR8N4Hc_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7MemY9jOmuk_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rZq-8Bq3mkU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NexB4vj8_54_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -iCLYpeghJs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pGEF7Tme3Tk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 22iOyzE8Ec0_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2vVQo_GMA70_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7337436458078260485_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dE5iWeCVpGI_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: IN0osLg-Mn8_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: x4UBaEojM6U_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _uL3a3aMdMQ_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UMFy3keSk-s_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pFpZvRsEGZs_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mfS6gyP0mwo_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7274542274997013761_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XYsCVqz3iug_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8Gl6iy7OEM4_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mTn_C-SyW84_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aVHAr8rc-Ks_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GGwHSz9towk_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fw1rirubXiU_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0ln2qdCR5lA_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fsz6bkkIHzQ_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JLnsWrzV_j4_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fWNJmZAWRNg_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LYvStKy8iAc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: otaJfBSlsG8_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yl-6-Yzt--A_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _ZIa6SEJEyg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: f2-6Mh6lyQQ_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OUeE8nCKWGA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GRPLynULvJY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 4ouAf1ldH60_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z-1lgAXOEc8_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZRMbh0wSly0_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: N7RTTiHsSjI_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7261188695892462856_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DoizYSYQRqU_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0_YDrJoUe8s_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vJ9hYCUDHTo_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UKU-W5bBCwY_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sHUEJw1BsGQ_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UwlKYM2Sotg_1]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SCZ_Z4NnikA_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kelseyinlondon-7094322812327906565_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XR3Ov2nQ39s_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: v-7zF3Y0yJs_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZsnfXfuGRrg_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oddHY1vwcjo_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fo97qfO-9_g_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: t3P11ENBZyc_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KTY9bogonyw_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: SAkgZJllNzw_0]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 3374.57it/s]
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: J1IwKg2ufk8_2]:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m631[0m - [1m================================================================================[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m632[0m - [1mLONGVIDEOBENCH CUSTOM RESULTS (with Frame Selection)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m633[0m - [1m================================================================================[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m641[0m - [1m
Accuracy by Duration Group:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m642[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  15s                           : 62.50% (40 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  60s                           : 75.00% (40 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  600s                          : 60.00% (100 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  3600s                         : 60.00% (150 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m650[0m - [1m
Accuracy by Question Category:[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m651[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E2O                           : 78.57% (14 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E3E                           : 57.14% (28 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O2E                           : 63.16% (19 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O3O                           : 50.00% (24 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2A                           : 85.00% (20 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2E                           : 87.50% (24 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2O                           : 70.59% (17 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SAA                           : 75.00% (16 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SOS                           : 67.74% (31 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SSS                           : 29.41% (17 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2A                           : 73.33% (15 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2E                           : 54.55% (22 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2O                           : 66.67% (15 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3E                           : 44.44% (18 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3O                           : 62.50% (16 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TAA                           : 52.94% (17 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TOS                           : 35.29% (17 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m658[0m - [1m
================================================================================[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m659[0m - [1mOVERALL ACCURACY: 62.12% (330 samples)[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m660[0m - [1m================================================================================[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2025-11-29 12:04:10[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m287[0m - [1mSaving samples to /home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_3.0_r60_5.0_r600_9.0_r3600_12.0_score_diff_iter1_20251129_115718_results/..__LLaVA-NeXT-Video-7B-Qwen2/20251129_195724_samples_longvideobench_custom.jsonl[0m
llava_vid (pretrained=../LLaVA-NeXT-Video-7B-Qwen2,conv_template=chatml_direct,video_decode_backend=decord,max_frames_num=16,overwrite=False), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|        Tasks        |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|---------------------|------:|------|-----:|--------------|---|-----:|---|------|
|longvideobench_custom|      1|none  |     0|lvb_custom_acc|‚Üë  |0.6212|¬±  |   N/A|

[rank0]:[W1129 12:04:10.107702687 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
