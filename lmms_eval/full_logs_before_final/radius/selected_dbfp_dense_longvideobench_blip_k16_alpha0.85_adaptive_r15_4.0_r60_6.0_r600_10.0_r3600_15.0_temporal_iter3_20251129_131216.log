The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-11-29 13:12:21[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-29 13:12:21[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-29 13:12:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-29 13:12:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-29 13:12:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-29 13:12:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-29 13:12:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-29 13:12:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-29 13:12:22[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_4.0_r60_6.0_r600_10.0_r3600_15.0_temporal_iter3_20251129_131216_results'}[0m
[32m2025-11-29 13:12:22[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-29 13:12:22[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-29 13:12:22[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_4.0_r60_6.0_r600_10.0_r3600_15.0_temporal_iter3_20251129_131216_results'}[0m
[32m2025-11-29 13:12:22[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-29 13:12:22[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
OpenCLIP not installed
OpenCLIP not installed
force sample: False
force sample: False
Rank 0:  Loaded LLaVA model: ../LLaVA-NeXT-Video-7B-Qwen2
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:07,  2.51s/it]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.92s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:04,  2.31s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:05<00:05,  2.66s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:06<00:02,  2.26s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  1.81s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  2.00s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:07<00:02,  2.55s/it]Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 330 examples [00:00, 33690.01 examples/s]
[32m2025-11-29 13:12:35[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 1 (local rank 1)[0m
[32m2025-11-29 13:12:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank1-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-29 13:12:35[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 1...[0m
  0%|          | 0/165 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 6602.75it/s]
[32m2025-11-29 13:12:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 165[0m
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  1.95s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  2.21s/it]
Rank 0:  Model Class: LlavaQwenForCausalLM
[32m2025-11-29 13:12:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36m__init__[0m:[36m215[0m - [1mUsing 2 devices with data parallelism[0m
[32m2025-11-29 13:12:36[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 0 (local rank 0)[0m
[32m2025-11-29 13:12:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank0-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-29 13:12:36[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 0...[0m
  0%|          | 0/165 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 7357.49it/s]
[32m2025-11-29 13:12:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 165[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/165 [00:00<?, ?it/s][32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _EUDpS9UF9o.mp4[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_EUDpS9UF9o.mp4[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _EUDpS9UF9o.mp4 | Selected 11 frames[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=1[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GdFMKGNFXaE.mp4[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GdFMKGNFXaE.mp4[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GdFMKGNFXaE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=0[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there's a person cutting a green onion with a knife, and in the upper left corner, there's also a screen with burning wood. When the subtitle mentions 'Onion,' what other objects are present in the scene?
A. On the table, there's also a silver bowl containing a tomato and a pumpkin.
B. Oven
C. Bread
D. Watch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7324498849857326341.mp4[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7324498849857326341.mp4[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7324498849857326341.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=3[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the conference room at the displayed time of 11:13, a bald man wearing glasses is standing in front of a blue display board, looking down at a book with a blue cover on the table. Before the subtitle says 'limited stocks in each EU country so,' what did this man do?
A. Placed the book on his shoulder
B. Picked up the book with a blue cover from the table
C. Took the book away from the scene
D. Put the book on the bookshelf
E. Sat down to read the book in his hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   1%|          | 1/165 [00:03<09:35,  3.51s/it][32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=2[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, in the green valley filled with green plants, there are green letters spelling 'GREENERY IN THE'. What is the color of the path in the scene?
A. green
B. blue
C. gray
D. orange
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -eRimFrm6kQ.mp4[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-eRimFrm6kQ.mp4[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -eRimFrm6kQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=5[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a slightly dimly lit room, there is a woman with long hair, wearing a white short-sleeved shirt, sitting on a bed. She is holding a mobile phone. There is a white cabinet behind her, filled with various items. In which of the following scenes has the mobile phone appeared?
A. On a white perforated table
B. On a green perforated table
C. On a yellow perforated table
D. On a blue perforated table
E. On a red perforated table
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   1%|          | 2/165 [00:06<08:38,  3.18s/it][32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=4[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room full of photos, a man wearing a white T-shirt, with short hair, holding a black microphone, which country does he mention first?
A. Serbia
B. Barbados
C. Pakistan
D. Balkan
E. India
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DRIpznER-VQ.mp4[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DRIpznER-VQ.mp4[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DRIpznER-VQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=7[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Four people are standing in a row in front of a window: two women are in the middle, and two men are on the outside. The man on the right is wearing a black coat, black-framed glasses, and carrying a backpack. One woman is wearing a gold-black patterned headscarf, and the other woman is in a black and white striped long skirt. The man on the left has a long beard, is resting his arm on the counter, and is dressed in gold-embroidered attire. In which other scenes does the man resting his arm appear?
A. Outside a store window in a high-end mall
B. At a speech venue, holding a mic
C. Outside a plant-filled balcony
D. Flipping through a book on a table
E. On a chair in a library
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vVRC-0VKPrg.mp4[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vVRC-0VKPrg.mp4[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vVRC-0VKPrg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=9[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On stage, a large screen in the background shows a scene of a building, and in the center of the stage, two people are seated on chairs. One is a bald man wearing a blue suit, and the other is a person in a white shirt, holding a microphone in the left hand and raising the right hand. What object is not present in this scene?
A. table
B. tie
C. glass cup
D. red lamp
E. car
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   2%|‚ñè         | 3/165 [00:09<08:02,  2.98s/it][32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LlqsCCa6y58.mp4[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LlqsCCa6y58.mp4[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LlqsCCa6y58.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=6[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black and white scene, a person is bending over, with a white skull next to them. In the distance, there are many mounds of earth. When the subtitle mentions "American modernism her art reflects the diverse Landscapes of her homes from Wisconsin to New York", what does this person do?
A. Grabs a handful of sand
B. Picks up the skull from the ground
C. Dusts off the ash from their body
D. Picks up clothes from the ground
E. Raises their hand to block the wind and sand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   2%|‚ñè         | 4/165 [00:11<07:04,  2.64s/it][32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KIf2fGmluhY.mp4[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KIf2fGmluhY.mp4[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KIf2fGmluhY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=8[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom left corner of the white background is a rectangular frame with curves and color variations. Inside the frame, there are blue and yellow arrows and characters. The top of the frame has handwritten colorful characters above which there are black lines and characters. In the bottom right corner of the screen are a cartoon dog and the symbol œÄ (pi). What is happening to the right of the handwritten colorful characters?
A. A hand-drawn line is getting thinner.
B. A hand-drawn line is shortening.
C. A hand-drawn line is moving parallel.
D. A hand-drawn line is getting thicker.
E. A hand-drawn line is extending and eventually forms an arrowhead.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mqtJErix0ss.mp4[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mqtJErix0ss.mp4[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mqtJErix0ss.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=11[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The title on the screen is 'Datasets', below it are inference formulas, and a dynamic graph appears in the middle. In the top right corner, there is a man with glasses explaining. What did the boy holding the ball do when he appeared for the first time?
A. Threw the ball into the distance
B. Shot the ball towards the basket
C. Dribbled the ball
D. Stepped on the ball with his foot
E. Passed the ball to someone else
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   3%|‚ñé         | 5/165 [00:14<07:09,  2.68s/it][32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=10[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the sky, a rocket is blazing and flying swiftly away from the Earth, with the blue and white surface of the Earth as the background. What change occurs to the rocket when the subtitle 'camera if you watch a NASA launch or a' appears?
A. The flames at the bottom of the rocket extinguish
B. Water sprays from the bottom of the rocket
C. The rocket splits into two halves
D. The surface of the rocket turns black
E. The rocket begins to split
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 66dwcQ1Y048.mp4[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/66dwcQ1Y048.mp4[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 66dwcQ1Y048.mp4 | Selected 15 frames[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=13[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 13:12:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[h264 @ 0x4d8c5f40] mmco: unref short failure
[h264 @ 0x4d8c5f40] mmco: unref short failure
[32m2025-11-29 13:12:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue sky, a yellow car is driving on the road, with a truck behind it. There are tall trees planted in the greenbelt on both sides of the road. When a basketball hoop and a man in a black t-shirt appear around the yellow car, what change occurs with the yellow car?
A. The door of the yellow car changes from closed to open.
B. The door of the yellow car shows some cartoon drawings.
C. The body of the yellow car gets sprayed with paint.
D. Some cartoon drawings appear on the body of the yellow car.
E. The headlights of the yellow car show some cartoon drawings.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HeRS3nwySI8.mp4[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HeRS3nwySI8.mp4[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HeRS3nwySI8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=15[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the deep mountains, with overgrown weeds ahead, trees in the distance, a stone at the bottom right corner, and a wooden handrail with a hand wearing a bracelet directly in front, what action does the hand perform when the subtitle 'while do not put too much weight on this' appears?
A. pulls out the handrail
B. shakes the handrail
C. raises the thumb
D. lifts the stone
E. pulls grass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   4%|‚ñé         | 6/165 [00:17<07:24,  2.79s/it][32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = f0IbZGfTgUM.mp4[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/f0IbZGfTgUM.mp4[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: f0IbZGfTgUM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=12[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top-left corner of a black background with white English text 'Explosive Reactive Armor', what happens on the screen after a gray circle with a white Star of David appears on the left side of the screen?
A. A line of white English text appears at the bottom of the black screen
B. A line of green English text appears in the middle of the black screen
C. A line of white English text appears in the middle of the black screen
D. A line of red English text appears in the top right corner of the black screen
E. A line of white Chinese text appears in the middle of the black screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   4%|‚ñç         | 7/165 [00:19<06:47,  2.58s/it][32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fWNJmZAWRNg.mp4[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fWNJmZAWRNg.mp4[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fWNJmZAWRNg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=14[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the context of the setting, how many human figures are subtly visible? In front of the mirror is a man wearing a green outfit and sporting short curly hair. What does the man do the first time he appears?
A. Smokes a cigarette
B. Takes out a phone
C. Waves at the mirror
D. Eats a piece of bread
E. Drinks a glass of water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rwL_XPw46zQ.mp4[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rwL_XPw46zQ.mp4[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rwL_XPw46zQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=17[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wooden platform with three potted plants, there is a person looking down with both legs raised on the table. Who is this person?
A. A woman with brown short hair
B. A woman with brown long hair
C. A woman with black short hair
D. A woman with black long hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   5%|‚ñç         | 8/165 [00:21<06:31,  2.49s/it][32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _BDzMutoy6A.mp4[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_BDzMutoy6A.mp4[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _BDzMutoy6A.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=16[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:12:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:12:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan. Then, a section of a gun appears with a hand holding a handgun and shooting at the section. Finally, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun.
B. First, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan. Then, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Finally, a section of a gun appears with a hand holding a handgun and shooting at the section.
C. First, a section of a gun appears with a hand holding a handgun and shooting at the section. Then, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Finally, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan.
D. First, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Then, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan. Finally, a section of a gun appears with a hand holding a handgun and shooting at the section.
E. First, a soldier wearing a steel helmet appears and is shooting towards the right side of the screen with his right hand holding the gun. Then, a section of a gun appears with a hand holding a handgun and shooting at the section. Finally, a soldier wearing a green-yellow hat appears and is giving ammo to the caravan.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:12:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7327779917989416197.mp4[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7327779917989416197.mp4[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7327779917989416197.mp4 | Selected 15 frames[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=19[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 13:12:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background features a white cabinet decorated with red lanterns. On the right side, there's a silver refrigerator with a red couplet sticker on it. A woman in a red short-sleeve top and apron is standing in front of a table holding a sesame ball. On the table, there are two glass containers and an iron plate. When the subtitle 'I fell like it's so refreshing' appears, what is this woman doing?
A. kneading a sesame ball
B. cutting a sesame ball
C. eating a sesame ball
D. deep-frying a sesame ball
E. making tangyuan
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   5%|‚ñå         | 9/165 [00:23<06:24,  2.47s/it][32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zTeDF7mQ88A.mp4[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zTeDF7mQ88A.mp4[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zTeDF7mQ88A.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=18[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, there's a red sphere in the darkness, then in outer space, a glowing object shines light on the Earth, and finally the green glow flows through the treetops at night.
B. First, the green glow flows through the treetops at night, then in outer space, a glowing object shines light on the Earth, and finally there's a red sphere in the darkness.
C. First, the green glow flows through the treetops at night, then there's a red sphere in the darkness, and finally in outer space, a glowing object shines light on the Earth.
D. First, there's a red sphere in the darkness, then the green glow flows through the treetops at night, and finally in outer space, a glowing object shines light on the Earth.
E. First, in outer space, a glowing object shines light on the Earth, then the green glow flows through the treetops at night, and finally there's a red sphere in the darkness.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fryyNwUCPWA.mp4[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fryyNwUCPWA.mp4[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fryyNwUCPWA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=21[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the palace, a man dressed in colorful underwear and a white cloak, wearing tree branch decorations on his head, is dragging a woman in a skirt whose eyes sparkle with pink hearts. What change happened the last time this woman with sparkling pink hearts in her eyes appeared?
A. Her eyes changed from pink heart shapes to black tears streaming.
B. Her glasses changed from black with tears to pink heart shapes.
C. The woman held a shield.
D. She went from standing to sitting.
E. She wore a woven grass headband.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:   6%|‚ñå         | 10/165 [00:26<06:14,  2.42s/it][32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1pxrIj9Xyps.mp4[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1pxrIj9Xyps.mp4[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1pxrIj9Xyps.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=20[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with various instruments and control panels, there is a man with short hair wearing a white lab coat. When the subtitle 'think you'll see this technology be used' appears, what objects are present in the scene?
A. a gold chain
B. a red button
C. a white button
D. a black remote
E. a black steering wheel
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DVsw1brd_Yc.mp4[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DVsw1brd_Yc.mp4[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DVsw1brd_Yc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=23[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under a blue sky, a woman with long purple hair and a black short-sleeve shirt is in the middle of the scene. There is a white house behind her on the left and trees on the right. After the subtitle 'our blood for example' appears, what action does the woman take?
A. Raised one hand
B. Covered her face
C. Stood up
D. Raised both hands
E. Took out a book
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:   7%|‚ñã         | 11/165 [00:28<06:11,  2.41s/it][32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSeq-nVSY_E.mp4[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSeq-nVSY_E.mp4[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSeq-nVSY_E.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=22[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white desk, there is an open book, and in front of it stands a book with a black side face silhouette cutout on its cover, which also has bold white text. In which of the following scenes does this book with the cutout appear?
A. In the hands of a man wearing black clothes
B. In the hands of a man sitting in a subway
C. In a quiet library
D. In the hands of a woman wearing black clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -0aM99dMu_4.mp4[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-0aM99dMu_4.mp4[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -0aM99dMu_4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=25[0m
[32m2025-11-29 13:13:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT with a white background, the upper left corner shows the black English text 'Proposed Solution', and on the right side of the screen there's a yellow background icon with the English text 'language Decoder'. Which subtitles appear simultaneously with it?
A. "functions but mmud already has learned"
B. ‚Äúusually take some frame by frame‚Äù
C. ‚Äúpositional EMB adding sign s or cosine‚Äù
D. "some embeddings from the encoder so what"
E. "you're going to get a very low value for"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   7%|‚ñã         | 12/165 [00:30<05:50,  2.29s/it][32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eJr-y6UXnRE.mp4[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eJr-y6UXnRE.mp4[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eJr-y6UXnRE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=24[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an image with a white background and black English text, where the heading is styled as 'published as a conference paper at ICLR 2020,' the top row contains photos of six machines. When 'gradient so that's the outset let's' is mentioned, what changes occur to these six images?
A. There is a yellow circle annotation at the bottom of the images.
B. There is a red circle annotation at the top of the images.
C. There is a red circle annotation at the bottom of the images.
D. There is a yellow circle annotation at the top of the images.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fw1rirubXiU.mp4[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fw1rirubXiU.mp4[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fw1rirubXiU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=27[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the first food item displayed in the video?
A. Avocado
B. Beverage with ice cubes
C. Watermelon
D. Apple
E. Potato chips
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   8%|‚ñä         | 13/165 [00:33<06:21,  2.51s/it][32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -PnG8Jp2gFw.mp4[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-PnG8Jp2gFw.mp4[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -PnG8Jp2gFw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=26[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the broadcast room, there is a man wearing a black suit and a white shirt. His right hand is on the table, and his left hand is slightly raised. On the screen next to his right hand, the text 'DYING FOR AID' appears. What change occurs to his right hand when the text on the screen changes to 'GLOBAL WATCH'?
A. He places his right hand on a mouse
B. He places his right hand on his forehead
C. He places his right hand on his chin
D. He is holding a piece of paper with his right hand
E. He is holding a phone with his right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _Y1pW77M3Pg.mp4[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_Y1pW77M3Pg.mp4[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _Y1pW77M3Pg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=29[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man wearing a black hoodie is sitting in front of a white window. The screen also displays the text 'But I think that they can feel that.' After mentioning 'no one can see that but I think they can,' what does he do?
A. He clasps his hands together and crosses them in front of his chest.
B. He clenches his fists and places them on his chest.
C. He places his left hand on his forehead.
D. He makes a 'yeah' gesture with both hands.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oddHY1vwcjo.mp4[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oddHY1vwcjo.mp4[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oddHY1vwcjo.mp4 | Selected 6 frames[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=31[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a beige wall, a television screen is hanging, displaying a webpage along with some file icons. A man wearing a black lab coat and a yellow and black badge is standing in front of the screen talking. When he mentions, 'being you don't know that 30-second ad,' what happens?
A. The man waved his hand.
B. The man pointed at the audience listening to the lecture.
C. The man turned around to face the screen.
D. The man put on a hat.
E. The man pointed at the screen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   8%|‚ñä         | 14/165 [00:36<06:32,  2.60s/it][32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8foMISZGiyw.mp4[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8foMISZGiyw.mp4[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8foMISZGiyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=28[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman are standing by the roadside talking. The woman has her brown hair tied up and is wearing a shirt. The man also has brown hair. In the distance, there are buildings, traffic lights, and a road. The image is blurry, and the whole scene is shrouded in darkness. What material is the man's jacket made of?
A. A woolen jacket
B. A mohair jacket
C. A denim jacket
D. A cotton jacket
E. A silk jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KIf2fGmluhY.mp4[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KIf2fGmluhY.mp4[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KIf2fGmluhY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=33[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a striped short-sleeve dress is sitting on a chair in front of a pink wall window. A white cloth bag is placed on her lap. What is she doing?
A. She is mending the cloth bag
B. She tore the cloth bag
C. She took a mask out of the cloth bag
D. She placed the cloth bag on the ground
E. She took a gun out of the cloth bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   9%|‚ñâ         | 15/165 [00:39<06:37,  2.65s/it][32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bjymxow3TVQ.mp4[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bjymxow3TVQ.mp4[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bjymxow3TVQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=30[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side, there are some English words and sentences. In the top right corner, there is a man in a suit explaining something. Below the man, there is a fishbowl. What did the fish do when it first appeared in the fishbowl?
A. Swam back and forth in the fishbowl
B. Fought in the bathtub
C. Slowly sank in the fishbowl
D. Swallowed each other in the bathtub
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _qepWb_NVj4.mp4[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_qepWb_NVj4.mp4[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _qepWb_NVj4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=35[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white table, there is a man wearing black pants and glasses standing. In front of the man, there is a gray wooden board. What hairstyle does the man with glasses have?
A. Brown short hair
B. Brown shoulder-length curls
C. Blue short hair
D. Black shoulder-length curls
E. Black buzz cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
Model Responding:  10%|‚ñâ         | 16/165 [00:41<06:09,  2.48s/it][32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZGMGQsnSdLE.mp4[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZGMGQsnSdLE.mp4[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZGMGQsnSdLE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=32[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are several blocks on the screen, including a red block, a green block, and a purple block. The other blocks are light green. What change occurs to these blocks when the phrase 'Antarctica but ask a person from South' is mentioned?
A. The blocks turn orange, blue, pink, and red
B. The blocks turn red and green
C. The blocks turn yellow, pink, purple, and blue
D. All blocks turn light green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JwoBdRC2fzE.mp4[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JwoBdRC2fzE.mp4[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JwoBdRC2fzE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=37[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Amidst the thick black smoke, a burst of yellow flames is erupting. When these flames appear together with the subtitles 'forth basaltic magma from the mantle in', what change occurs to the flames?
A. It extinguishes.
B. Its color changes to blue.
C. Its color changes to orange.
D. Its color changes to red.
E. Its color changes to purple.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  10%|‚ñà         | 17/165 [00:44<06:31,  2.64s/it][32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7324761016909188358.mp4[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7324761016909188358.mp4[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7324761016909188358.mp4 | Selected 2 frames[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=34[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 2 specific frames[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 2 custom frames[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 2 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman wearing a yellow coat with a ponytail. She is holding a mobile phone in her right hand and raises it to her ear. Which object does not appear in the video?
A. Yellow coat
B. Ring
C. Swimming pool
D. Mobile phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  11%|‚ñà         | 18/165 [00:44<04:51,  1.98s/it][32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UwlKYM2Sotg.mp4[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UwlKYM2Sotg.mp4[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UwlKYM2Sotg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=36[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are two statues in the background, and a group of people raising their fists watching two shirtless men wearing white shorts. What are these two shirtless men in white shorts doing?
A. Running race
B. Long jump competition
C. Swimming competition
D. Wrestling match
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zkmoxOKhpvk.mp4[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zkmoxOKhpvk.mp4[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zkmoxOKhpvk.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=39[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Three men appear on the screen. The man on the left is wearing a red shirt, the man in the middle is wearing a black shirt and jeans, and the man on the right is leaning on a blue shelf that holds various items. What did the man in the middle, who is wearing a black shirt, do the first time he appeared?
A. Folded his arms in front of his chest
B. Picked up a key
C. Picked up a watch
D. Put his hand on a companion's shoulder
E. Picked up a cup of water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  12%|‚ñà‚ñè        | 19/165 [00:47<05:08,  2.11s/it][32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mFcEWmtn3ag.mp4[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mFcEWmtn3ag.mp4[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mFcEWmtn3ag.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=38[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A pink boy stands on the green springboard, a short-sleeved boy in the left holding a blue bungee cord, a red short-sleeved man with a hat is watching. Who is assisting the pink boy to jump down from behind?
A. A woman in a yellow short-sleeved shirt
B. A man with sunglasses and a blue baseball cap
C. A man in orange pants
D. A woman in a black tank top
E. A woman with tied hair in a short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7235995901477604635.mp4[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7235995901477604635.mp4[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7235995901477604635.mp4 | Selected 4 frames[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=41[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
This video utilizes pictures, illustrations, and text explanations to narrate many historical stories and depict numerous scenes from those times. Which of the following sequences of scenes is correct?
A. First, there is a giant mail steamship on the vast ocean, followed by a splendidly dressed squire holding a cane standing in front of a fireplace in a luxurious room, and lastly, a man in a suit and tie answering a phone call.
B. First, there is a giant mail steamship on the vast ocean, followed by a man in a suit and tie answering a phone call, and lastly, a splendidly dressed squire holding a cane standing in front of a fireplace in a luxurious room.
C. First, a splendidly dressed squire holding a cane stands in front of a fireplace in a luxurious room, followed by a man in a suit and tie answering a phone call, and lastly, there is a giant mail steamship on the vast ocean.
D. First, a man in a suit and tie is answering a phone call, followed by a splendidly dressed squire holding a cane standing in front of a fireplace in a luxurious room, and lastly, there is a giant mail steamship on the vast ocean.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  12%|‚ñà‚ñè        | 20/165 [00:49<05:32,  2.29s/it][32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aqUisZS9Ruw.mp4[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aqUisZS9Ruw.mp4[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aqUisZS9Ruw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=40[0m
[32m2025-11-29 13:13:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes from the video is correct?
A. First, the chef uses a ladle to transfer the prepared food onto a white plate. Next, a chef is cooking a meal in a kitchen filled with various ingredients. Then, chopsticks are used to pick up noodles from the plate. Finally, a hand takes a bottle of purple drink from a drink cabinet.
B. First, a chef is cooking a meal in a kitchen filled with various ingredients. Next, a hand takes a bottle of purple drink from a drink cabinet. Then, the chef uses a ladle to transfer the prepared food onto a white plate. Finally, chopsticks are used to pick up noodles from the plate.
C. First, a chef is cooking a meal in a kitchen filled with various ingredients. Next, chopsticks are used to pick up noodles from the plate. Then, a hand takes a bottle of purple drink from a drink cabinet. Finally, the chef uses a ladle to transfer the prepared food onto a white plate.
D. First, a hand takes a bottle of purple drink from a drink cabinet. Next, a chef is cooking a meal in a kitchen filled with various ingredients. Then, chopsticks are used to pick up noodles from the plate. Finally, the chef uses a ladle to transfer the prepared food onto a white plate.
E. First, a chef is cooking a meal in a kitchen filled with various ingredients. Next, the chef uses a ladle to transfer the prepared food onto a white plate. Then, a hand takes a bottle of purple drink from a drink cabinet. Finally, chopsticks are used to pick up noodles from the plate.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = W94Rth-aIkc.mp4[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/W94Rth-aIkc.mp4[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: W94Rth-aIkc.mp4 | Selected 14 frames[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=43[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 13:13:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
White clouds are floating in the sky, with a mountain peak towering underneath them. The jade blue sea quietly presses against the mountain peak. What is the state of the mountain peak?
A. Jade-green mountain peak
B. Fiery-red mountain peak
C. Bare mountain peak
D. Glowing mountain peak
E. Yellow mountain peak
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Sn7JPKbG6tY.mp4[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Sn7JPKbG6tY.mp4[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Sn7JPKbG6tY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=45[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a woman with long black hair wearing a white coat is clenching her hands tightly. On the screen, there is the word 'but'. In which subtitles has this woman appeared together with these words?
A. hope you want to
B. museums I saw my first dog just
C. please take please take my car s if they
D. people here also really nice especially
E. be spending all the night Moon
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  13%|‚ñà‚ñé        | 21/165 [00:52<05:44,  2.39s/it][32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7269647281668852993.mp4[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7269647281668852993.mp4[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7269647281668852993.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=42[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:13:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a vast open area, there is a centipede formed by criminals dressed in orange uniforms. After the narration saying "In American prisons, the mouths and buttocks of 800 inmates are sewn together to form a long human centipede", what event happened in the video?
A. Criminals in orange clothes gather to gamble
B. Criminals in orange clothes gather to fight
C. A man in orange clothes is pushing his head against the person in front of him
D. Criminals in orange clothes go around killing people
E. A man in gray-green clothes is touching the brain of a dark-skinned man
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  13%|‚ñà‚ñé        | 22/165 [00:53<04:53,  2.05s/it][32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lCvQtGVhUrc.mp4[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lCvQtGVhUrc.mp4[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lCvQtGVhUrc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=44[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with sunlight streaming through the windows, the room is decorated with many green plants. There is also a shelf with books and other items on it. A woman is admiring her eyeshadow in a mirror. What color is the woman's nail polish?
A. black
B. green
C. red
D. purple
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = s49y2RP5C7E.mp4[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/s49y2RP5C7E.mp4[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: s49y2RP5C7E.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=47[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background shows a wall covered with numerous postcards and posters, with a bookshelf full of books on the right side. A bespectacled woman named Qiliu Hai is holding a book titled 'Beautiful Boy'. The cover of the book features a black-and-white photo of two men. When the camera zooms in on the woman who is hiding half of her face with the book, what changes occur to the book?
A. The book changes from being in the woman's hand to being on the table
B. The book changes from a black-and-white cover to a colored cover
C. The book changes from a full shot to a close-up
D. The book changes from brand new to damaged
E. The book changes from closed to open
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  14%|‚ñà‚ñç        | 23/165 [00:56<05:09,  2.18s/it][32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KWv8DJMEHsE.mp4[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KWv8DJMEHsE.mp4[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KWv8DJMEHsE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=46[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, four soldiers are cooking food around a fire, then three soldiers are opening a can, and finally, one person is opening a can.
B. First, one person is opening a can, then three soldiers are opening a can, and finally, four soldiers are cooking food around a fire.
C. First, three soldiers are opening a can, then four soldiers are cooking food around a fire, and finally, one person is opening a can.
D. First, three soldiers are opening a can, then one person is opening a can, and finally, four soldiers are cooking food around a fire.
E. First, four soldiers are cooking food around a fire, then one person is opening a can, and finally, three soldiers are opening a can.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6Lb1PyJxVQM.mp4[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6Lb1PyJxVQM.mp4[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6Lb1PyJxVQM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=49[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two men wearing straw hats and grey clothes stand in a grass field holding long knives. Behind them are a few green trees and a house. What does the house behind them look like?
A. Wooden house
B. Building
C. Villa
D. Straw hut
E. Earthen house
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  15%|‚ñà‚ñç        | 24/165 [00:58<05:11,  2.21s/it][32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iwXp1fT89-M.mp4[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iwXp1fT89-M.mp4[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iwXp1fT89-M.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=48[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a black car parked on the beach by the sea. A man has his left hand on his waist and his right hand on the car. Who is the man making this gesture?
A. The man wearing a purple short-sleeved shirt
B. The man wearing a white short-sleeved shirt with tattoos on both arms
C. The man wearing a blue uniform
D. The man wearing a black short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qbA42wQoWAs.mp4[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qbA42wQoWAs.mp4[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qbA42wQoWAs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=51[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, in a small frame on a pure yellow background, a green straightener is displayed. Next, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Finally, on a pure yellow background, there is green text 'BEAUTY'.
B. First, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Next, on a pure yellow background, there is green text 'BEAUTY'. Finally, on the yellow background, a small frame displays a green straightener.
C. First, on a pure yellow background, there is green text 'BEAUTY'. Next, in a small frame on a pure yellow background, a green straightener is displayed. Finally, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern.
D. First, on a pure yellow background, there is green text 'BEAUTY'. Next, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Finally, in a small frame on a pure yellow background, a green straightener is displayed.
E. First, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Next, in a small frame on a pure yellow background, a green straightener is displayed. Finally, on the yellow background, there is green text 'BEAUTY'.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  15%|‚ñà‚ñå        | 25/165 [01:01<05:47,  2.49s/it][32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6THwql5c6w.mp4[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6THwql5c6w.mp4[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6THwql5c6w.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=50[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bedroom, three men are changing clothes in front of an open wardrobe and a clothing rack filled with items. What clothing are they changing into?
A. white shirts
B. black shirts
C. white T-shirts
D. short sleeve shirts
E. black T-shirts
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8foMISZGiyw.mp4[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8foMISZGiyw.mp4[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8foMISZGiyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=53[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the top of the screen, there are three flags, with the American flag in the middle. A person in a black suit is speaking in front of a microphone in the center. After the captions mention 'punching domo in toner mau 9 term,' what appears on the screen?
A. Stars
B. Sun
C. Moon
D. A piece of white paper
E. Satellite map
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  16%|‚ñà‚ñå        | 26/165 [01:04<05:38,  2.44s/it][32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kMryvefpcF8.mp4[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kMryvefpcF8.mp4[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kMryvefpcF8.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=52[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:13:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man dressed in a white shirt, raising one hand, with a slight smile on his face, sitting on a black chair and speaking, this man appears with which subtitles?
A. I eventually ended up living
B. offered me his couch to crash on
C. Pyramid of Giza
D. I got a tap
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  16%|‚ñà‚ñã        | 27/165 [01:05<04:45,  2.07s/it][32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oCXKARwr6PA.mp4[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oCXKARwr6PA.mp4[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oCXKARwr6PA.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=54[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:13:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an image of a young girl with a yellow background, wearing a headscarf, accompanied by feathers and some simple ornaments, which objects have never appeared?
A. Yellow headscarf
B. Pearl earrings
C. Blue gemstone earrings
D. Blue gemstones
E. Peacock feathers
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  17%|‚ñà‚ñã        | 28/165 [01:06<03:52,  1.70s/it][32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ErGYJ7kqIow.mp4[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ErGYJ7kqIow.mp4[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ErGYJ7kqIow.mp4 | Selected 13 frames[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=56[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are three people in the room. One person is sitting on a red sofa, one person is standing, and another person is sitting on a chair in the corner of the room. The person sitting on the chair has white hair, is wearing white inner clothes, and a coat over them. What is the man sitting on the chair doing?
A. He is rubbing his eyes with his right hand
B. He picked up a wine glass
C. He is standing up from the chair
D. He is rubbing his eyes with his left hand
E. He is rubbing his eyes with both hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = acAWfzV__XI.mp4[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/acAWfzV__XI.mp4[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: acAWfzV__XI.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=55[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the red video frame, after a man with a mustache lies down facing the left side, what event happens on the screen?
A. The man has a green ribbon tied over his eyes.
B. The man has a green ribbon tied around his neck.
C. The man has a white ribbon in his mouth.
D. The man has a red ribbon in his mouth.
E. The man's eyes are covered.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  18%|‚ñà‚ñä        | 29/165 [01:07<03:40,  1.62s/it][32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0WEnmqVVbHo.mp4[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0WEnmqVVbHo.mp4[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0WEnmqVVbHo.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=58[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white screen, there are many letters written, and at the bottom, there is also a blue arrow drawn. A hand is holding a pen. After the text 'topological sort' appears on the screen, what does the hand holding the pen do?
A. Draws a blue question mark on the white screen
B. Draws a blue arrow on the white screen
C. Draws an orange arrow on the white screen
D. Writes the black text 'Not' on the white screen
E. Draws a black line on the white screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 66dwcQ1Y048.mp4[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/66dwcQ1Y048.mp4[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 66dwcQ1Y048.mp4 | Selected 14 frames[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=57[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 13:13:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[h264 @ 0x5661b640] mmco: unref short failure
[h264 @ 0x5661b640] mmco: unref short failure
[32m2025-11-29 13:13:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman dressed in a checkered suspender dress with a long-sleeved dark green inner layer is kneeling next to a white drum washing machine, preparing to do laundry. Beside her is a blue laundry bag. What item does she put into the washing machine?
A. laundry powder
B. clothes
C. laundry pods
D. plush toy
E. laundry detergent
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  18%|‚ñà‚ñä        | 30/165 [01:10<04:24,  1.96s/it][32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hg2Q_O5b9w4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=60[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man appears on the screen, wearing a striped short-sleeved round-neck shirt and sporting a goatee. In the background behind the man, there are circles of various colors and sizes. When this goateed man stands in front of the signboard holding hands with two friends, what changes occur to his clothing?
A. The striped short-sleeved shirt changes to a cotton jacket.
B. The striped short-sleeved shirt changes to a hooded jacket.
C. The striped short-sleeved shirt changes to a white short-sleeved shirt with letters.
D. The striped short-sleeved shirt changes to a suit.
E. The striped short-sleeved shirt changes to a black jacket.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = akoJDx23QWU.mp4[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/akoJDx23QWU.mp4[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: akoJDx23QWU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=59[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT slide with white background and black text, on the left side, there are three shapes made up of three overlapping blue squares each, and the rest of the screen is text. When the caption 'here somewhere the anchor is cropped' appears, what changes occur to the shapes?
A. Turned green
B. Covered by a yellow overlay
C. Got bigger
D. Turned yellow
E. Got smaller
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  19%|‚ñà‚ñâ        | 31/165 [01:12<04:35,  2.05s/it][32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UN3ICsfqKEY.mp4[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UN3ICsfqKEY.mp4[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UN3ICsfqKEY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=62[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman are sitting in front of a red background. The man has black hair and is wearing black clothes, while the woman has brown hair and is wearing off-white clothes. In front of them is a long black table with some items on it. When the camera zooms in and the man raises one of his arms, what change happens to the woman next to him?
A. An 'omg' icon appears on the woman's face
B. A bowtie icon appears on the woman's face
C. A sad face icon appears on the woman's face
D. A small cat icon appears on the woman's face
E. A smiley face icon appears on the woman's face
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7289528053112343814.mp4[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7289528053112343814.mp4[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7289528053112343814.mp4 | Selected 3 frames[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=61[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 13:13:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a shot of the sea with a mountain in the background appears, then a scene of a waterfall appears, and finally, it concludes with the appearance of a frog.
B. First, a scene of a waterfall appears, then a frog appears, and finally, it concludes with a shot of the sea with a mountain in the background.
C. First, a scene of a waterfall appears, then a shot of the sea with a mountain in the background, and finally, it concludes with the appearance of a frog.
D. First, a frog appears, then a shot of the sea with a mountain in the background appears, and finally, it concludes with a scene of a waterfall.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HAED3riiZkw.mp4[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HAED3riiZkw.mp4[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HAED3riiZkw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=63[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bald man is sitting in a courtyard surrounded by bamboo walls. Behind him is a rectangular object. He is wearing a gray T-shirt with a white butterfly printed on it. When the man reappears among the trees, holding a board covered with a beehive, how does he change?
A. He puts on a white brimmed hat and a gray face mask, and wears a yellow beekeeping suit.
B. He puts on a black brimmed hat and a gray face mask, and wears a white beekeeping suit.
C. He puts on a yellow brimmed hat and a gray face mask, and wears a white beekeeping suit.
D. He puts on a white brimmed hat and a gray face mask, and wears a white beekeeping suit.
E. He puts on a white brimmed hat and a gray face mask, and wears a black beekeeping suit.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TMe7oXMJoSM.mp4[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TMe7oXMJoSM.mp4[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TMe7oXMJoSM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=65[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the open space in front of a red building, a person is holding a skateboard with a design that reads '8.0', running towards a woman wearing glasses and dressed in wine-red pants. What objects are present in this scene?
A. A necklace
B. A white building
C. A yellow skateboard with a design that reads '8.0'
D. A green skateboard with a design that reads '8.0'
E. Black-framed glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  19%|‚ñà‚ñâ        | 32/165 [01:15<05:17,  2.39s/it][32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ezhafkxoRdo.mp4[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ezhafkxoRdo.mp4[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ezhafkxoRdo.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=64[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a blue background, a man wearing a dark grey short-sleeve shirt and black-framed glasses with short black hair said "Thank you for watching this episode of SciShow!" After he finished speaking, what was the first action he took?
A. Crossed his hands into fists
B. Placed both hands on his abdomen
C. Raised his right hand with palm open
D. Took off his glasses with both hands open
E. Raised both hands with palms open
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  20%|‚ñà‚ñà        | 33/165 [01:17<05:00,  2.28s/it][32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7TljSpTBS9c.mp4[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7TljSpTBS9c.mp4[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7TljSpTBS9c.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=66[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The woman wearing a black dress with braids is facing the camera. She is singing 'Don't Pull' while the word 'run' appears in the subtitles. What change happens to the woman?
A. She changes from standing on stage to sitting on one knee on the ground
B. She changes from standing on stage to sitting on a bench
C. She changes from singing on stage to kneeling on stage
D. She changes from standing on stage to sitting on both knees on the ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7280742496882134274.mp4[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7280742496882134274.mp4[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7280742496882134274.mp4 | Selected 8 frames[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=67[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 13:13:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following animals appears first in the video?
A. Snake
B. Spider
C. Chicken
D. Cicada
E. Mouse
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TMe7oXMJoSM.mp4[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TMe7oXMJoSM.mp4[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TMe7oXMJoSM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=69[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:13:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A strip of paper is placed on a white background, with three lines of English written on it. To the left of the paper strip, there is a black wheel-shaped object and a purple light. A hand is pointing at the paper strip while explaining something. After explaining the paper strip, what does the owner of the hand do?
A. Take a yellow toy chicken from the corner
B. Take a magazine from a black bag
C. Take a music box from the corner
D. Take a green toy from the corner
E. Take an apple from a black bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:13:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  21%|‚ñà‚ñà        | 34/165 [01:20<05:33,  2.54s/it][32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7XWqI121-Q4.mp4[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7XWqI121-Q4.mp4[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7XWqI121-Q4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=68[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:13:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen is a woman wearing a black low-necked dress, and on the right side of the screen is a black man with dreadlocks wearing a shirt. When the subtitle 'convict TC Whitehurst Gordon Georgia May' appears, what change happens to this man?
A. This man goes from standing to sitting
B. This man has a lyrics book in his hand
C. This man puts on glasses
D. This man becomes holding his head with both hands
E. This man has a Doberman on him
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z9JSvDVMSm0.mp4[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z9JSvDVMSm0.mp4[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z9JSvDVMSm0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=71[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bedroom with two warm-colored table lamps and two paintings hanging on the wall, a short-haired woman wearing an orange outfit is sitting on the bed turning on a computer. What did she do before turning on the computer on the bed?
A. Changed into a black coat
B. Visited a museum
C. Took a shower
D. Wrote something in front of the computer
E. Put on shoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  21%|‚ñà‚ñà        | 35/165 [01:23<05:45,  2.66s/it][32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HvSEKzpSdzw.mp4[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HvSEKzpSdzw.mp4[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HvSEKzpSdzw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=70[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the image marked with 'Ecuador' is mentioned with 'Yesterday masked gunmen raided a TV' in the video, what change occurs to the image?
A. A man in black clothes appears in the video
B. The video adds a tag of Guayaquil
C. The video adds tags of Quito and Guayaquil
D. The video adds a tag of Quito
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VGQ_djSR7zE.mp4[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VGQ_djSR7zE.mp4[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VGQ_djSR7zE.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=73[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:14:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a young man wearing a blue uniform, with a white inner layer, and a black wristwatch, is holding a box. What is this young man doing in the room?
A. Reaching into the box
B. Stepping on the box
C. Throwing the box away
D. Cutting the box with a knife
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 36/165 [01:26<05:26,  2.53s/it][32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = brZugTJ0odg.mp4[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/brZugTJ0odg.mp4[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: brZugTJ0odg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=72[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, a hand wearing a pair of white gloves is touching someone's neck, which shows signs of bruises. When the mention of 'The ME shows thetn an incision on the throat of one of the dead passengers. It is a deep,', what happens next?
A. A woman wearing glasses and dark clothes appears along with a man dressed in a white-gray coat.
B. A woman wearing glasses and dark clothes appears along with a man dressed in a black coat.
C. A woman wearing glasses and dark clothes appears along with a man dressed in a yellow coat.
D. A woman wearing glasses and dark clothes appears along with a man dressed in an olive coat.
E. A woman wearing glasses and dark clothes appears along with a man dressed in a gray coat.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = j6beJTHUT_c.mp4[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/j6beJTHUT_c.mp4[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: j6beJTHUT_c.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=75[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the yellow floor, a person wearing a blue top is pushing a wooden cart filled with various items. After the subtitles 'For the restoration, a lot of it was just cutting acid-free paperboard to the' appear, what does the person in the blue top do?
A. Opened the pigment tray
B. Wrote with a paintbrush
C. Held a red hammer
D. Used a brush to apply glue to the items
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 37/165 [01:28<05:05,  2.38s/it][32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6940704678569053446.mp4[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6940704678569053446.mp4[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6940704678569053446.mp4 | Selected 3 frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=74[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a woman in a white top is holding a large dumpling in her left hand and a white bowl in her right hand. What other items appeared together with the dumpling?
A. Glutinous rice flour, sugar, hot water, knead until it forms into a ball.
B. Coat the rice balls with water. Coat with sesame seeds. And don't want to add any filling. All you have to do is just roll them into little balls.
C. Like this, roll it out. Cut into 10 pieces.
D. 15 Shree food for 15 days.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  23%|‚ñà‚ñà‚ñé       | 38/165 [01:28<03:55,  1.86s/it][32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = X29dPzJIMbA.mp4[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/X29dPzJIMbA.mp4[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: X29dPzJIMbA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=76[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under a white sky, a man wearing an olive hat and a long-sleeved white robe, along with another person wearing a white hat, are restraining a short-haired man. There is a house behind them surrounded by trees, and to the left of the house, there is a woman dressed in a long-sleeved white garment. When the subtitle mentions 'was trying to escape, Grisha is considered a rebel and will be executed along with other rebels,' what did the two people restraining the short-haired man do to him?
A. Ran
B. Drank water
C. Tied a rope around the restrained man's neck
D. Crouched down
E. Let the restrained person go
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Pm93D8CVlY8.mp4[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Pm93D8CVlY8.mp4[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Pm93D8CVlY8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=77[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background is a web interface. In the background, the only moving object is a monkey wearing a red hat. Above the monkey, there is a sign with '9,999 items'. What is the man wearing black sunglasses and standing to the right of the screen doing?
A. Pointing at the screen behind him with his left hand and talking
B. Holding a microphone with his right hand and talking
C. Turning around and pointing at the screen behind him
D. Pointing at the screen behind him with his right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7200404243168415022.mp4[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7200404243168415022.mp4[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7200404243168415022.mp4 | Selected 14 frames[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=79[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman with long black hair wearing sunglasses, dressed in a white long-sleeve shirt, holding a blue phone in her right hand, wearing three rings, and making a 'peace' sign with her left hand. Who is taking a photo with the phone in the video?
A. Cara
B. Nancy
C. Davy
D. Jo-Anne
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  24%|‚ñà‚ñà‚ñé       | 39/165 [01:31<04:35,  2.18s/it][32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bDpgz_2Piqg.mp4[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bDpgz_2Piqg.mp4[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bDpgz_2Piqg.mp4 | Selected 3 frames[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=78[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 13:14:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a grey shirt and a black hat is standing in front of a container holding food. There are many people around him, including one at the forefront wearing a black headscarf and another person in a grey shirt holding a plate of food. There's also a man wearing glasses in the corner. What type of hat is this?
A. Western cowboy hat
B. Fisherman hat
C. Duck tongue hat
D. Beret
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  24%|‚ñà‚ñà‚ñç       | 40/165 [01:32<03:35,  1.72s/it][32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TFbGLEZ4qt0.mp4[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TFbGLEZ4qt0.mp4[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TFbGLEZ4qt0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=80[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a white bowl on a wooden grain table, containing white condensed milk. When the condensed milk is placed on a piece of green vegetable and then put on a wooden board, what kind of change occurs?
A. Red bread crumbs are sprinkled on top
B. Red goji berries are sprinkled on top
C. Red dates are sprinkled on top
D. Red goji berries are sprinkled on top
E. Red dried strawberries are sprinkled on top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z7Cox6lPW3c.mp4[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z7Cox6lPW3c.mp4[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z7Cox6lPW3c.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=81[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with long black straight hair is in a white room. She is wearing a white jacket and a pink shirt. On the left side is the room's door, and on the right side is a white display shelf with a desk lamp, a vase, and some pictures. She is sitting in front of a desk talking. On the right side of the desk, there is also a bucket filled with many colored pencils and a bouquet of flowers. What action did this woman take?
A. She adjusted her hair a bit
B. She picked up the colored pencils
C. She turned around and looked at the shelf
D. She stood up and walked out of the room
E. She is gesturing with her hands
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  25%|‚ñà‚ñà‚ñç       | 41/165 [01:34<03:52,  1.88s/it][32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = g7zuBUMBr2E.mp4[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/g7zuBUMBr2E.mp4[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: g7zuBUMBr2E.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=82[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a background board with the word 'Bloomberg' and a high-rise building, a man with gold and gray-white short hair is speaking directly into the camera. The text in front of him is gradually appearing. What kind of clothes is this man wearing?
A. He is wearing a pure black coat.
B. He is wearing a pure black shirt.
C. He is wearing a black checkered shirt.
D. He is wearing a pure black suit.
E. He is wearing a black striped shirt.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qksR2Zvd-FM.mp4[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qksR2Zvd-FM.mp4[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qksR2Zvd-FM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=83[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a space constructed with lines, featuring various colors, what objects are present when the subtitle 'they hear a mix of different sounds' appears?
A. A man with hands down, looking up
B. A woman with dark skin
C. A woman with tied hair, wearing a patterned shawl
D. A woman wearing a colorful headscarf
E. A man raising both hands with palms facing outward
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  25%|‚ñà‚ñà‚ñå       | 42/165 [01:36<03:53,  1.90s/it][32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oI975O1BUu0.mp4[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oI975O1BUu0.mp4[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oI975O1BUu0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=84[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bullet hits the green tank and sparks fly. Who is the character that first appears after Bai mentions 'period in World War II'?
A. The soldier wearing a red headscarf
B. The soldier wearing a black headscarf and green camouflage uniform
C. The soldier without a helmet, with short blond hair, wearing a green camouflage uniform
D. The soldier wearing a green helmet, black scarf, and camouflage uniform
E. The soldier wearing a green helmet and gray clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ip8khYCMb8Y.mp4[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ip8khYCMb8Y.mp4[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ip8khYCMb8Y.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=85[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the video, there is a man wearing a floral short-sleeved shirt and a cap. In the bottom right corner, there is a logo. When the subtitle mentions 'be 36 years before we could land on,' what does this man change into?
A. The floral short-sleeved shirt changes to a white outfit
B. The floral short-sleeved shirt changes to a yellow outfit
C. The floral short-sleeved shirt changes to a black outfit
D. The floral short-sleeved shirt changes to a red outfit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  26%|‚ñà‚ñà‚ñå       | 43/165 [01:39<04:16,  2.10s/it][32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mqtJErix0ss.mp4[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mqtJErix0ss.mp4[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mqtJErix0ss.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=86[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A group of young people are riding bicycles and skateboards on a bridge with red railings, surrounded by a wire mesh fence. When a boy wearing a green short-sleeve shirt and khaki pants first appears in the middle of the bridge, what is he doing?
A. Walking
B. Talking with friends
C. Riding a bicycle
D. Answering a phone call
E. Skateboarding
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VkNF0rXuDXw.mp4[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VkNF0rXuDXw.mp4[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VkNF0rXuDXw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=87[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a backdrop of Earth and outer space, there are books and a YouTube trophy on the left wall, character images and space pictures on the right wall, and a satellite model on the desk in the lower left corner. A man wearing a white T-shirt is sitting in the center with his hands clasped together. When the subtitle 'around the Earth not fly off into space' appears, what change happens to his hand movements?
A. The palms face each other and change to the left hand raised above the head
B. The palms face each other and change to both hands clenched
C. Both hands are waving
D. Both hands extend forward
E. Both hands are crossed in front of the chest
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 44/165 [01:41<04:30,  2.24s/it][32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7079970495499717934.mp4[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7079970495499717934.mp4[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7079970495499717934.mp4 | Selected 9 frames[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=88[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 13:14:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the correct order of the following scenes?
A. First, a red heart-shaped screen, then a dimly lit street scene, followed by a gas station screen.
B. First, a gas station screen, then a dimly lit street scene, followed by a red heart-shaped screen.
C. First, a dimly lit street scene, then a gas station screen, followed by a red heart-shaped screen.
D. First, a gas station screen, then a red heart-shaped screen, followed by a dimly lit street scene.
E. First, a dimly lit street scene, then a red heart-shaped screen, followed by a gas station screen.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 45/165 [01:42<03:45,  1.88s/it][32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zda-T6wrEhs.mp4[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zda-T6wrEhs.mp4[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zda-T6wrEhs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=90[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a piece of white paper, the words 'not useful' are written, and there is a downward-curving arrow. Someone is holding a white and blue pen. What are they doing?
A. Coloring the roof in the drawing
B. Drawing sweat on the little person in the drawing
C. Coloring the sky in the drawing
D. Coloring the flowers in the drawing
E. Putting clothes on the little person in the drawing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kk-iRzLv81o.mp4[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kk-iRzLv81o.mp4[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kk-iRzLv81o.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=89[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the video shows a room with black and orange colors, there is a bald man wearing a floral shirt sitting on a sofa. What is this man doing?
A. Both hands are raised
B. One hand is holding a pen and the other hand is holding a book
C. One hand is placed on his knee
D. Both hands are placed on his knees and he is clenching his fists
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 46/165 [01:44<03:55,  1.98s/it][32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3pTVbQilDqY.mp4[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3pTVbQilDqY.mp4[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3pTVbQilDqY.mp4 | Selected 11 frames[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=92[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 13:14:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a plot of land surrounded by green trees. The land is brown, and there is a person wearing a yellow outfit with a cowboy hat and a mustache who is making a fire. There is also a person wearing white clothes and a gray skirt with a backpack behind him. Which one is carrying a gun?
A. The person wearing white clothes and a gray skirt
B. The person wearing white clothes and a gray skirt without a hat
C. The person wearing white clothes and a gray skirt with a hat
D. The person wearing yellow clothes and a hat making a fire
E. The person wearing white clothes, a gray skirt, and green shoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = O6UedmnRJc0.mp4[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/O6UedmnRJc0.mp4[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: O6UedmnRJc0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=91[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Sitting in a studio, what is an elderly person wearing glasses and dressed in a black coat and purple shirt doing?
A. Moving materials
B. Shaking hands with someone
C. Talking to the camera
D. Testing equipment
E. Taking photos
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 47/165 [01:46<03:38,  1.85s/it][32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LAQRjgx_OY8.mp4[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LAQRjgx_OY8.mp4[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LAQRjgx_OY8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=94[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background is a white wall, with a black cabinet on the right side. A man wearing a white long-sleeved shirt and black pants stands next to a round wooden table with fruit and food on it, speaking to the camera. In which other scenes does this man appear?
A. On a sandy beach by the sea
B. On a mountain covered with plants
C. Next to a man in a gym wearing a black tank top holding two dumbbells
D. By a swimming pool
E. In a dining hall
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9aWPbYosJUw.mp4[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9aWPbYosJUw.mp4[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9aWPbYosJUw.mp4 | Selected 10 frames[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=93[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 13:14:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a forest surrounded by trees, there is a plant with long leaves. To the right, there is a black man wearing glasses and grinning. When he appears in the center of a grassy area with his hands in front of him, what kind of transformation does this man undergo?
A. The black tight-fitting suit transforms into a black suit
B. The olive green trench coat transforms into a black skirt
C. The black jacket transforms into a white suit
D. The purple T-shirt transforms into a blue jacket
E. The black backpack transforms into a blue jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  29%|‚ñà‚ñà‚ñâ       | 48/165 [01:49<04:12,  2.15s/it][32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VSZ8ywgGNGM.mp4[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VSZ8ywgGNGM.mp4[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VSZ8ywgGNGM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=96[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a red table, there is a white plate containing a delicious dish with a golden crust on the outside and cheese underneath, with the right side cut off. A person wearing gloves is picking up half of the dish. When they mention 'Its crispy exterior, with a soft cheesy heart, makes it irresistible delicious,' what kind of gloves is this person wearing?
A. Wearing heat-resistant cotton gloves
B. Wearing transparent plastic gloves
C. Not wearing gloves
D. Wearing black plastic gloves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PbiTIR8N4Hc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=95[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a grass field, a woman dressed in a sleeveless white shirt is crouching on the grass. In front of her lies a small tabby kitten. What is the woman holding in her hand to play with the kitten?
A. a flower
B. a string
C. a piece of cloth
D. a blade of grass
E. a cat tease stick
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  30%|‚ñà‚ñà‚ñâ       | 49/165 [01:51<04:20,  2.25s/it][32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RQOdl64DtdI.mp4[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RQOdl64DtdI.mp4[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RQOdl64DtdI.mp4 | Selected 8 frames[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=98[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 13:14:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a blurry screen, there are two hands holding two grayish-white clods of dirt. Inside these clods there are some grayish-white objects. After the phrase 'that contain hollow cavities lined with' is spoken, what is the first object to appear?
A. Black crystals
B. Trilobite fossil
C. Pearl fossil
D. Plant fossil
E. Fish fossil
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 4ouAf1ldH60.mp4[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/4ouAf1ldH60.mp4[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 4ouAf1ldH60.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=97[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a woman with red hair is wearing a white top, holding a mirror in one hand and combing her long hair with the other. After mentioning the explanation 'rules rounding are back to a time when,' which character appears afterward?
A. Naked man
B. Woman lying in the water
C. Mona Lisa
D. Angel
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  30%|‚ñà‚ñà‚ñà       | 50/165 [01:53<03:55,  2.04s/it][32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aX_HgA5SNLQ.mp4[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aX_HgA5SNLQ.mp4[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aX_HgA5SNLQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=100[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a bookshelf filled with many books, a man wearing black glasses, with short hair and dressed in a black top, is talking. After he says "that really took away the waste scene so", what is the first item that appears?
A. gold necklace
B. green coat
C. white necklace
D. white earphones
E. black and gray long tail skirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  31%|‚ñà‚ñà‚ñà       | 51/165 [01:55<04:08,  2.18s/it][32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tGiRbGGwRj8.mp4[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tGiRbGGwRj8.mp4[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tGiRbGGwRj8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=102[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a brown cutting board, a person is holding a knife and cutting an orange carrot. What shape are the carrot pieces that have already been cut?
A. Round
B. Triangular
C. Long strips
D. Minced
E. Square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7022693587703926022.mp4[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7022693587703926022.mp4[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7022693587703926022.mp4 | Selected 12 frames[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=99[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 13:14:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After a woman with green nail polish sitting in a red seat in the car holds up an eyebrow pencil to the mirror, what does she do first?
A. Apply eyebrow brush
B. Drive
C. Pound squash in the kitchen
D. Draw eyebrows
E. Toss squash in an iron pan
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = xiK00WS0lkE.mp4[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/xiK00WS0lkE.mp4[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: xiK00WS0lkE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=101[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the half blue, half pink tablecloth, this person places three pieces of paper with 'The partial pressure' and formulas written on them. At this moment, what is the color of the nail polish on their fingers?
A. pink
B. blue
C. white
D. red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 52/165 [01:57<03:59,  2.12s/it][32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = BtaVRhoLpC0.mp4[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/BtaVRhoLpC0.mp4[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: BtaVRhoLpC0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=104[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a building, there is a person wearing a white shirt and a black suit jacket. There are many microphones in front of this person. What is this person doing?
A. This person is taking a walk
B. This person is answering reporters' questions
C. This person is eating
D. This person is chatting with friends
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 53/165 [02:00<04:11,  2.25s/it][32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PCPQToF10IM.mp4[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PCPQToF10IM.mp4[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PCPQToF10IM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=106[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a man wearing gray clothes with a beard facing a whiteboard. He is holding a pen in his right hand, and the whiteboard has markings in blue and black pen. What did the man do when he appeared in the video?
A. Dropped the pen
B. Marked the whiteboard with a pen
C. Did nothing
D. Erased the whiteboard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7XWqI121-Q4.mp4[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7XWqI121-Q4.mp4[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7XWqI121-Q4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=103[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the desert, there are three mannequins. In front of the mannequins, there is a man wearing an olive-colored coat. Next to him, a person wearing a black hat and black clothes is holding a handgun. After the subtitle mentions 'off target by 0.5 mm sensing', what item appears in the video?
A. ÊâãË°®
B. È¶ôÁÉü
C. Ê£ãÁõò
D. Êú®Ê°å
E. ÊâãÊû™
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 54/165 [02:02<04:20,  2.35s/it][32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vEy6tcU6eLU.mp4[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vEy6tcU6eLU.mp4[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vEy6tcU6eLU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=108[0m
[32m2025-11-29 13:14:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After entering the museum, where did the short-haired woman in a black coat, black long skirt, and black mask visit first?
A. Sculptures
B. Bronze statues
C. Library
D. Wall paintings
E. Paintings
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LcZxjqtzXJI.mp4[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LcZxjqtzXJI.mp4[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LcZxjqtzXJI.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=105[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with light, a man with a bald head wearing black-rimmed glasses stands in front of a glass showcase. The man is dressed in a black suit. Inside the transparent glass, there are two small sculptures, one of which is facing the man. What is this man doing?
A. Touching the showcase
B. Adjusting his collar
C. Knocking on the showcase
D. Adjusting his sleeve
E. Staring at the sculpture
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GuEptwLiAvs.mp4[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GuEptwLiAvs.mp4[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GuEptwLiAvs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=107[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing an orange shirt appears in front of a black background. The man rolls up his sleeves. The man is holding a plate of Indian specialty food in his hand. There is a food picture to the man's left, and when the subtitle 'These usually come to the Northern regions of India' appears, what is the shape of the plate in the picture to the right?
A. Rectangle
B. Circle
C. Square
D. Pentagon
E. Irregular Shape
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 55/165 [02:05<04:19,  2.36s/it][32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = nWDNzv1Gk8Q.mp4[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/nWDNzv1Gk8Q.mp4[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: nWDNzv1Gk8Q.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=110[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. A man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt, a man wearing gray sportswear and black earphones running outdoors.
B. A man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf, a man wearing gray sportswear and black earphones running outdoors, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt.
C. A man wearing gray sportswear and black earphones running outdoors, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt, a man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf.
D. A man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt, a man wearing gray sportswear and black earphones running outdoors, a man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf.
E. A man wearing gray sportswear and black earphones running outdoors, a man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i327DBSS_iE.mp4[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i327DBSS_iE.mp4[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i327DBSS_iE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=109[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Sitting in the driver's seat of a car, there is a blonde woman wearing a red top and a necklace. Her left hand is placed on her chest. What is she doing?
A. She is placing her left hand on her forehead
B. She is making a 'yeah' gesture with her left hand
C. Her left hand is clenched in a fist on her chest
D. She is holding a phone in her right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 56/165 [02:08<04:30,  2.48s/it][32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7125042270381853995.mp4[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7125042270381853995.mp4[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7125042270381853995.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=112[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the text 'Now for the sweet part, add some sweetened condensed milk right on top.' appears at the bottom of the screen, what changes happen in the transparent glass bowl containing green avocado?
A. Red tomato sauce is added
B. Pink condensed milk is added
C. Sweetened condensed milk is added
D. Green fruit sauce is added
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 57/165 [02:10<04:16,  2.38s/it][32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ip9DbdOtqF4.mp4[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ip9DbdOtqF4.mp4[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ip9DbdOtqF4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=114[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows some people pushing shopping carts in the vegetable section of a supermarket. What is the first product to appear on the screen after this?
A. Leek
B. Eraser
C. Cauliflower
D. Carrot
E. Mini Tomatoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XuQswmEPgxU.mp4[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XuQswmEPgxU.mp4[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XuQswmEPgxU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=111[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A group of women are sitting in front of a white table, where they are engaging in handmade crafts. There are colored paper and tools scattered on the table. A woman wearing glasses is sitting on the right side of the table. She has short black hair and is wearing earrings. Outside the table, a grey-haired woman in a black top is observing. What did the woman with short hair and glasses sitting at the table do the first time she appeared?
A. Waved her hands left and right
B. Held her face with both hands
C. Supported her forehead with one hand
D. Cut materials with scissors
E. Held her face with one hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 58/165 [02:12<04:08,  2.33s/it][32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAHsR02dUc0.mp4[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAHsR02dUc0.mp4[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAHsR02dUc0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=116[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the gray background, on the far right side, there is a picture. In the picture, a woman is turning her head to look at a man behind her. Below the picture, in white English text, it says 'James Van Der Zee, Self-Portrait with Gaynella Greenlee'. Where else has this picture appeared?
A. Appears in the top right corner of a screen displaying eight pictures at the same time
B. Appears in the top left corner of a screen displaying six pictures at the same time
C. Appears in the top right corner of a screen displaying six pictures at the same time
D. Appears in the bottom left corner of a screen displaying six pictures at the same time
E. Appears in the bottom right corner of a screen displaying six pictures at the same time
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7303594391850044678.mp4[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7303594391850044678.mp4[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7303594391850044678.mp4 | Selected 14 frames[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=113[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 13:14:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a screen with a white background, the title is 'General Loss', below which there is a line of black mathematical symbols. After that, what happens to these mathematical symbols?
A. They are sequentially framed by four boxes in green, red, yellow, and blue, and then appear.
B. They are sequentially circled by four circles in green, red, yellow, and blue, and then appear.
C. They are sequentially circled by four circles in green, red, blue, and yellow, and then appear.
D. They are sequentially framed by four boxes in green, red, blue, and yellow, and then appear.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 59/165 [02:14<04:00,  2.27s/it][32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=118[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a small island on the blue sea, the island is full of green plants, and there are many boats docked along the shore. Among them, the largest boat in the middle, what color is the largest boat in the middle?
A. red
B. black
C. yellow
D. white
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gtX_oRpLClY.mp4[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gtX_oRpLClY.mp4[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gtX_oRpLClY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=115[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a street at night, there are two people. Among them, a woman with long black hair wearing a red coat is sitting on the ground. In front of her, a short-haired man wearing an olive-colored outfit is kneeling. In which of the following scenes did this woman appear?
A. In the woods
B. Inside a room
C. In the desert
D. In the sea
E. On a plane
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 60/165 [02:17<04:16,  2.45s/it][32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kOZnpwI2hIM.mp4[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kOZnpwI2hIM.mp4[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kOZnpwI2hIM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=120[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, the scene of removing the transparent phone case, then the scene of taking out the green phone case, and finally the scene of putting on the green phone case
B. First, the scene of taking out the green phone case, then the scene of putting on the green phone case, and finally the scene of removing the transparent phone case
C. First, the scene of taking out the green phone case, then the scene of removing the transparent phone case, and finally the scene of putting on the green phone case
D. First, the scene of removing the transparent phone case, then the scene of putting on the green phone case, and finally the scene of taking out the green phone case
E. First, the scene of putting on the green phone case, then the scene of removing the transparent phone case, and finally the scene of taking out the green phone case
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tWiGnu2BNsY.mp4[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tWiGnu2BNsY.mp4[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tWiGnu2BNsY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=117[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Blue skies with floating white clouds, the distant and nearby continuous mountain ranges, the blue sea and the deserted sandy beach, after the subtitle 'Luke decided to tell us a bit about his' appeared, which character appeared on the screen?
A. A small cat
B. A small dog
C. A man in a black short-sleeved shirt
D. A man in a blue short-sleeved shirt
E. A man in a white short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 61/165 [02:20<04:21,  2.52s/it][32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -An3wZyoYe0.mp4[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-An3wZyoYe0.mp4[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -An3wZyoYe0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=122[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:14:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing white clothes is lying on the grass in a graveyard. Next to him are yellow clothes and a black bag. On the grass, there are many standing tombstones. Before the man lies down on the grass, what was he doing?
A. Piloting a plane
B. Peeling an apple
C. Cutting a watermelon
D. Coughing
E. Opening a wheelbarrow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lzAESaVqix0.mp4[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lzAESaVqix0.mp4[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lzAESaVqix0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=119[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x4e0b50c0] mmco: unref short failure
[h264 @ 0x4e0b50c0] mmco: unref short failure
[h264 @ 0x4e0b50c0] mmco: unref short failure
[32m2025-11-29 13:14:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a woman dressed in a blue suit with black hair adorned with a pink flower is squatting in a green vegetable garden. Next to her, a little girl with golden hair wearing a white outfit and a white hat is also squatting. When the subtitle 'making conservation education enjoyable' appears, what are they doing?
A. Picking vegetables
B. Planting flowers
C. Planting vegetables
D. Watering the vegetables
E. Playing a game
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:14:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 62/165 [02:22<04:17,  2.50s/it][32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 61SYvhojGvg.mp4[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/61SYvhojGvg.mp4[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 61SYvhojGvg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=124[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:14:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside the gymnasium, standing in front of a ping pong table, a little boy wearing a blue short-sleeve shirt is holding a red ping pong paddle. After picking up a white ping pong ball from the red tray, what action did the boy take?
A. Sit on the ping pong table
B. Place the ball on the table
C. Hit the ball with the paddle
D. Throw the ball on the ground
E. Put the paddle on the table
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _kQXNFG664Y.mp4[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_kQXNFG664Y.mp4[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _kQXNFG664Y.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=121[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:15:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a corner of a bedroom, a short-haired woman wearing an olive green tank top is sitting in front of a bed. To the right is a bookshelf filled with books. What color is the bookshelf in the screen?
A. A three-layer pink bookshelf
B. A three-layer blue bookshelf
C. A four-layer red bookshelf
D. A five-layer orange bookshelf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GFg98TDqCpw.mp4[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GFg98TDqCpw.mp4[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GFg98TDqCpw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=123[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against the backdrop of a large wooden ship floating on the sea, the word 'FORECASTLE' is written at the top of the video. In the middle, there is a painting depicting a deep blue sky with three wooden ships floating on the water. One of the ships is crowded with soldiers wearing armor. What is the shape of the border area marked with 'FORECASTLE'?
A. Cuboid
B. Parallelogram
C. Rectangle
D. Circle
E. Square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 63/165 [02:24<04:10,  2.46s/it][32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TMe7oXMJoSM.mp4[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TMe7oXMJoSM.mp4[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TMe7oXMJoSM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=126[0m
[32m2025-11-29 13:15:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner of the video, there is a bald man wearing sunglasses and dressed in black. In the frame, there are two bloodshot eyeballs. Which object does not appear in the video?
A. sunglasses
B. microphone
C. a man wearing glasses and a suit
D. eyeballs
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pJI5ZU6wxqg.mp4[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pJI5ZU6wxqg.mp4[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pJI5ZU6wxqg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=125[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen is a woman wearing a black low-cut top, and on the right side of the screen is a man with glasses wearing a grey suit. The man is holding a lyric book and singing. What change occurs to this man when the lyrics 'our iise up good God good God iise up' appear?
A. Wearing glasses changes to not wearing glasses
B. Standing on the stage changes to kneeling on one knee
C. Holding a lyric book changes to tightly holding the woman's hand
D. Standing on the stage changes to sitting on a bench
E. Holding a lyric book changes to holding a dumbbell
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 64/165 [02:27<04:13,  2.51s/it][32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7PqVVjEW0LM.mp4[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7PqVVjEW0LM.mp4[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7PqVVjEW0LM.mp4 | Selected 3 frames[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=128[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 13:15:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a platter with exquisite arrangement in the video, featuring items like noodles and wrapped eggs. When the subtitle mentions 'enjoy it try to base that your,' what change occurs to this platter?
A. Completely eaten
B. Disappears
C. Sprinkled with powdery substance
D. Thrown into the trash can
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 65/165 [02:28<03:11,  1.92s/it][32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7203120578537049386.mp4[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7203120578537049386.mp4[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7203120578537049386.mp4 | Selected 3 frames[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=130[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences in the video is correct?
A. First, flipping the menu on a wooden table in a dining room, then showing a phone to a mirror in a car, and finally showing a black shopping bag to a mirror in a shopping mall.
B. First, showing a black shopping bag to a mirror in a shopping mall, then showing a phone to a mirror in a car, and finally flipping the menu on a wooden table in a dining room.
C. First, showing a phone to a mirror in a car, then showing a black shopping bag to a mirror in a shopping mall, and finally flipping the menu on a wooden table in a dining room.
D. First, flipping the menu on a wooden table in a dining room, then showing a black shopping bag to a mirror in a shopping mall, and finally showing a phone to a mirror in a car.
E. First, showing a phone to a mirror in a car, then flipping the menu on a wooden table in a dining room, and finally showing a black shopping bag to a mirror in a shopping mall.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 66/165 [02:28<02:28,  1.50s/it][32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 61SYvhojGvg.mp4[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/61SYvhojGvg.mp4[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 61SYvhojGvg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=132[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Many private cars, motorcycles, and buses are driving on a road marked with white dashed lines. On both sides of the road are orderly rows of big trees and green grass. After the white car at the bottom center of the screen disappears from view, what happens?
A. A man is washing a car
B. A man is helping a woman wash a car
C. A blue car and a person appear
D. A red car and a person appear
E. A blue car and two people appear
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jvkmcX47bKU.mp4[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jvkmcX47bKU.mp4[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jvkmcX47bKU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=127[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a storage room, many wine casks are stacked. At the top of the video, 'WATER CASKS 300 tons' is written. Two wooden pillars stand in the middle. A lamp is hanging from the back pillar. A pile of hemp ropes, an iron hook, and a white string lie to the left of the lamp. What is the shape of the bottom of the wine casks?
A. rectangular
B. round
C. square
D. stepped
E. parallelogram
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 67/165 [02:30<02:50,  1.74s/it][32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7184160724715883781.mp4[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7184160724715883781.mp4[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7184160724715883781.mp4 | Selected 3 frames[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=134[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 13:15:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall, on a golden iron frame, what is happening on the screen when a transparent light bulb appears for the first time?
A. Disassembling the table lamp
B. Turning on the table lamp
C. Repairing the table lamp
D. Assembling the table lamp
E. Cleaning the table lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 68/165 [02:31<02:29,  1.54s/it][32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NS2V_OHYkvA.mp4[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NS2V_OHYkvA.mp4[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NS2V_OHYkvA.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=136[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are many well-arranged categories of foods in the supermarket. When the subtitle mentions 'so', what object is present in the bottom row of the screen?
A. eggs
B. milk tea
C. ice cream bars
D. fried chicken
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 69/165 [02:32<02:04,  1.30s/it][32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lN3WnXMaE0o.mp4[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lN3WnXMaE0o.mp4[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lN3WnXMaE0o.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=138[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A girl is sitting in a room with colorful lights, with green plants behind her. There's also a white curtain to the left of the screen. She has blond and black hair, is wearing glasses, and has a letter sweater on. While she is talking in front of a mirror, what happens after she mentions 'about myself'?
A. She put down the fork
B. She put a fork into a paper cup
C. She changed into a gray T-shirt
D. She picked up a cake
E. She took off her glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OmhVj_-cfH0.mp4[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OmhVj_-cfH0.mp4[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OmhVj_-cfH0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=129[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A soldier wearing a golden helmet is standing on a grassy field near a wooden fence. Holding a water bag, three drops fall from it. After the subtitle 'you will have to pay for it in blood' appears, what is the first object that appears on the screen?
A. A person with white hair holding a green shield
B. A person wearing a red robe with black hair
C. Three shields
D. A person with yellow hair holding a water bag
E. A soldier holding a red shield and wearing a helmet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 70/165 [02:34<02:19,  1.47s/it][32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dCscvoOX2as.mp4[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dCscvoOX2as.mp4[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dCscvoOX2as.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=140[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is an elderly man wearing a dark brown hat, dressed in a brown suit, with a dark blue sweater and a blue shirt underneath, walking in the gallery. On the right side of the gallery, there is an artwork displayed, among which a painting shows a woman in a green dress sitting on a sofa. Can you tell what color the sofa is?
A. red
B. black
C. pink
D. green
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mHccnoh9f5w.mp4[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mHccnoh9f5w.mp4[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mHccnoh9f5w.mp4 | Selected 8 frames[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=131[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 13:15:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a gray and hazy image, there is a terrain map with vertical and horizontal grooves in the middle, with a whitish-grayish background. When 'cover Australia or Antarctica' is mentioned, what kind of arrow appears on the screen?
A. A blue arrow with a scissor tail
B. A standard red arrow
C. A red arrow with a scissor tail
D. A standard blue arrow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7282789187676294432.mp4[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7282789187676294432.mp4[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7282789187676294432.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=133[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:15:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the evening, when the lights of distant buildings are bright, a man with short hair, wearing a black shirt, stands outside. On his chest, there's a white inscription 'ALLAS SEA POOL'. Who is the first person that appears behind this man after this scene?
A. A man wearing a black long-sleeved shirt and black shorts
B. A man wearing black long pants with no shirt
C. A man wearing black shorts with no shirt
D. A man wearing white shorts with no shirt
E. A man wearing a khaki short-sleeved shirt and black shorts
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 71/165 [02:37<02:49,  1.81s/it][32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = I-yg_3yx6iA.mp4[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/I-yg_3yx6iA.mp4[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: I-yg_3yx6iA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=142[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the kitchen, after a chef pours a yellow liquid into a wok with stir-fried vegetables, what happens on the screen?
A. The chef adds eggplant to the wok.
B. The chef transfers the vegetables from the wok into a rectangular white plate containing bread.
C. The chef adds scallions to the wok.
D. The chef transfers the vegetables from the wok into a rectangular white plate containing rice.
E. The chef transfers the vegetables from the wok into a round white plate containing rice.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oI975O1BUu0.mp4[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oI975O1BUu0.mp4[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oI975O1BUu0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=135[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under a gray sky, a bullet-riddled airplane is flying with red and white stripes on its tail wings. There is a red pattern dot on the back of the fuselage, and the rest of the plane is silver. When the subtitle 'the aircraft falling away after being' appears, what is the shape of the red pattern on the tail of the fuselage?
A. A star
B. A square
C. A triangle
D. A pattern composed of a rectangle and a star
E. A rectangle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 72/165 [02:39<03:08,  2.02s/it][32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rzIiQ4Vxlbk.mp4[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rzIiQ4Vxlbk.mp4[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rzIiQ4Vxlbk.mp4 | Selected 11 frames[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=144[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a man wearing a red shirt with a beard in the middle of the screen, and there is a logo in the bottom right corner. What clothing does this man change into when the subtitle mentions 'as Caitlyn will tell you that might not'?
A. Black shirt changes to patterned short sleeves
B. White shirt changes to patterned short sleeves
C. Red shirt changes to patterned short sleeves
D. Yellow shirt changes to patterned short sleeves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _hODR1cR9lo.mp4[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_hODR1cR9lo.mp4[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _hODR1cR9lo.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=137[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What action did the curly-haired man wearing a striped black-and-white shirt, who was crouching in front of a camera, take when he said 'shoot had already started' in the subtitles?
A. Crouched on the ground
B. Looked down at the camera in his hand
C. Sat on the ground
D. Took off the striped black-and-white shirt
E. Picked up the camera and took a photo
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 73/165 [02:41<03:04,  2.00s/it][32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fO7nwCix8xU.mp4[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fO7nwCix8xU.mp4[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fO7nwCix8xU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=146[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, there is a woman with yellow hair, wearing a brown coat, a pair of necklaces, and glasses. With which of the following subtitles did she appear together?
A. "I like to wear it when I sleep"
B. "which i am wearing right now and i have"
C. "This style is particularly comfortable to wear"
D. "There are a lot of people who like to wear this"
E. "I really like this style"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fWNJmZAWRNg.mp4[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fWNJmZAWRNg.mp4[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fWNJmZAWRNg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=139[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room that is slightly dimly lit, there is a white desk with various items on it. Next to the desk stands a man with short hair, wearing a long-sleeve black shirt and a red and white striped tie. He is surrounded by white bookshelves filled with books. Which object appears in the scene?
A. Water cup
B. Rock
C. Red desk
D. Snacks
E. Table lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 74/165 [02:44<03:24,  2.25s/it][32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kN88RP3XWUU.mp4[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kN88RP3XWUU.mp4[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kN88RP3XWUU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=148[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, in front of a wooden table, there is a person wearing a light gray knitted sweater holding embroidery and a needle, doing embroidery. Who is this person doing the embroidery?
A. The woman with loose brown hair
B. The woman with loose black hair
C. The woman with black braided hair
D. The woman with brown braided hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mld0TnA2jEs.mp4[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mld0TnA2jEs.mp4[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mld0TnA2jEs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=141[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a red short-sleeve shirt and dark pants is sitting on the sofa with his hands spread out to the sides. There is a laptop on the left side of the sofa. Behind the sofa is an open kitchen with cabinets that are oak-colored. When the subtitle 'be used in machine learning algorithms' appears, what objects are present in the scene?
A. watch
B. potted plant
C. pillow
D. umbrella
E. necklace
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 14ot4DrXdds.mp4[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/14ot4DrXdds.mp4[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 14ot4DrXdds.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=143[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man who is not wearing clothes but has a piece of cloth hanging around his waist is carrying a large blue and white ball. The man has bronze-colored skin and black curly hair. Which of the following subtitles has this man appeared with?
A. punishments one of the Titans Atlas was
B. it'll come back up in just a second over
C. world looked like this kind of like an O
D. with the T inside here was Europe here
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 75/165 [02:47<03:39,  2.44s/it][32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pGEF7Tme3Tk.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=150[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the golden twilight, with industrial zones emitting exhaust fumes into the sky, what happened first after the subtitle 'the water while increased levels of' appeared?
A. Two molecular structures appeared simultaneously on the screen
B. A structure with a black center labeled CO‚ÇÇ, flanked by two red molecular structures, rotated and popped up on the right side of the screen
C. Three molecular structures appeared simultaneously on the screen
D. A structure with a black center labeled CO‚ÇÇ, flanked by two red molecular structures, rotated and popped up on the left side of the screen
E. A structure with a red center labeled CO‚ÇÇ, flanked by two black molecular structures, rotated and popped up on the left side of the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gJijNOktmoI.mp4[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gJijNOktmoI.mp4[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gJijNOktmoI.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=145[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the white cabinet, there is a man with short hair and wearing a black short-sleeved shirt. He is holding a chickpea in his left hand with both hands raised. When he appears alongside the subtitle 'pork ragu or i‚Äôm gonna do some romesco,' what changes occur to him?
A. The chickpea in his hand turns into pork.
B. The chickpea in his hand turns into an egg.
C. The chickpea in his hand turns into a glass of milk.
D. The chickpea in his hand turns into a bluebonnet.
E. The chickpea in his hand turns into a kitchen knife.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 76/165 [02:49<03:36,  2.43s/it][32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dE5iWeCVpGI.mp4[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dE5iWeCVpGI.mp4[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dE5iWeCVpGI.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=152[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under a cloudless blue sky, there is a turquoise sea. A dark-skinned woman wearing glasses and a white bikini is in the turquoise sea. In which of the following scenes has this dark-skinned woman appeared?
A. On the beach during rain
B. In a room with a red sofa
C. In a park with slides
D. In a dense primal forest
E. By the sea with a yellow boat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZaXpMou55lw.mp4[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZaXpMou55lw.mp4[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZaXpMou55lw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=147[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a black stage, there are many black frames; behind the frames, people are standing, while in front of the frames, someone is performing. There is a woman dressed in a red suspenders with black leggings. What is she doing when the subtitle 'I know that there is a leader for us the' appears?
A. Kneeling on one knee with both hands on the ground
B. Standing and singing, with her right hand raised
C. On both knees with both hands on the ground
D. On both knees with one hand on the ground
E. Kneeling on one knee with both arms open
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 77/165 [02:52<03:30,  2.39s/it][32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tWiGnu2BNsY.mp4[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tWiGnu2BNsY.mp4[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tWiGnu2BNsY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=154[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top-right corner of a white background, a man with short grey hair is explaining something. Behind the man, there is a piano keyboard and miscellaneous items. At the top of the screen, there are bold English characters, and below the characters, there are two web addresses. To the left of the web addresses, there are yellow and blue circular icons and simple cartoon graphics. Below the web addresses, there is a black rectangular text box filled with white and green characters. What objects or elements are present in the scene?
A. Red circular icon
B. Black wristwatch
C. Green circular icon
D. Black circular icon
E. White wristwatch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8ew0d0JmsfA.mp4[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8ew0d0JmsfA.mp4[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8ew0d0JmsfA.mp4 | Selected 8 frames[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=149[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 13:15:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a yellow coat is shopping with a red shopping basket in a supermarket. To his left is a woman wearing blue clothes. What happened in front of the man while he was shopping?
A. Kissed a prison guard
B. Fought with a prison guard
C. Danced with a prison guard
D. Shook hands with a prison guard
E. Hugged a prison guard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 78/165 [02:54<03:36,  2.49s/it][32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = c6fuIEzOZ2E.mp4[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/c6fuIEzOZ2E.mp4[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: c6fuIEzOZ2E.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=156[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the desolate military base, parked next to two tents, there are four fully armed individuals holding water guns, and in front there are two soldiers dressed in olive military uniforms and carrying guns. Which of the following objects has not appeared?
A. A light olive helmet
B. A red rifle
C. A yellow oil drum
D. An army green tank
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -An3wZyoYe0.mp4[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-An3wZyoYe0.mp4[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -An3wZyoYe0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=151[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a small room, a man and a woman are sitting on a white sofa. The man is wearing a dark gray jacket, and the woman is wearing a black dress. When the phrase 'people more a lot of things maybe how we' is mentioned, which objects are not present in the scene?
A. A painting with a black frame
B. A red poster
C. A black microphone with a white pattern
D. A beige pillow with blue design
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 79/165 [02:57<03:42,  2.58s/it][32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QJ6sjg7SXOQ.mp4[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QJ6sjg7SXOQ.mp4[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QJ6sjg7SXOQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=158[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue seawater, there are coral reefs and seashells. On the screen, there is a person wearing a diving suit. When the subtitle 'beaches and plenty of drilling dive' appears, what is this person in the diving suit doing?
A. Diving in the seawater
B. Performing an underwater show
C. Playing with a sea turtle
D. Waving at the camera
E. Catching seafood
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XR3Ov2nQ39s.mp4[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XR3Ov2nQ39s.mp4[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XR3Ov2nQ39s.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=153[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is split into two sections, and in the small section on the far right, what is the man wearing a hat doing in front of a brown horse?
A. Walking the horse
B. Punching towards the camera
C. Riding the horse
D. Kneeling down
E. Extending his palm forward while facing the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 80/165 [03:00<03:41,  2.61s/it][32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = xSzXFQPldJg.mp4[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/xSzXFQPldJg.mp4[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: xSzXFQPldJg.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=160[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:15:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, two soldiers and a wheeled machine appeared, followed by another wheeled machine, then several soldiers appeared. After that, another wheeled machine appeared. Next, a tank appeared, and finally, the tank extended two cannons.
B. First, several soldiers appeared, then a wheeled machine appeared, followed by two soldiers and a wheeled machine. After that, another wheeled machine appeared. Next, a tank appeared, and finally, the tank extended two cannons.
C. First, a single wheeled machine appeared, then two soldiers and a wheeled machine appeared, followed by several soldiers. After that, another wheeled machine appeared. Next, a tank appeared, and finally, the tank extended two cannons.
D. First, a tank appeared, then a wheeled machine appeared, followed by several soldiers. After that, another wheeled machine appeared. Next, two soldiers and a wheeled machine appeared, and finally, the tank extended two cannons.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 81/165 [03:01<03:01,  2.16s/it][32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = BkCbbFn21LY.mp4[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/BkCbbFn21LY.mp4[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: BkCbbFn21LY.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=162[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:15:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, when the eggs and white granules in the bowl are mixed together with chopsticks, the bowl is placed on a red and white striped cloth and placed on the ground. When the subtitle mentions '2 tbsp spelled flour', what is the substance that the person takes out?
A. powder
B. paste
C. frost-like
D. liquid
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 82/165 [03:02<02:29,  1.80s/it][32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = M7YSCIkUaNw.mp4[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/M7YSCIkUaNw.mp4[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: M7YSCIkUaNw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=164[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an abandoned lot, there is a green tank. Next to the tank, a man wearing a black short-sleeve shirt and black pants is standing. With what subtitle did this man appear together?
A. a male beforehand and about taking
B. to full rights use them in my videos
C. masoom military and of course my
D. bovis and aircraft gun but more on this
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7359951777845775648.mp4[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7359951777845775648.mp4[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7359951777845775648.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=155[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Walking through rows of shelves in a dazzling shop, ahead are humanoid figures with long white beards and plant decorations. The shelves on the right are filled with red and white Christmas toys. After the subtitle 'really happy' appears, what item appears on the screen?
A. A burning white candle
B. A little girl
C. A courier paper box
D. Santa Claus mug
E. Two books
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 83/165 [03:04<02:41,  1.97s/it][32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gAgCnu82RHE.mp4[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gAgCnu82RHE.mp4[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gAgCnu82RHE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=166[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the first item placed in the shopping cart in the video?
A. A box of blueberries
B. A net of tangerines
C. A bag of carrots
D. A bag of nuts
E. A box of cherry tomatoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XR3Ov2nQ39s.mp4[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XR3Ov2nQ39s.mp4[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XR3Ov2nQ39s.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=157[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two pieces of green land appear in the blue background. In the blue background, there are sea and land. A cloud of black smoke appears on the screen. What object emitted this black smoke?
A. An airplane in the blue background
B. A cargo ship in the blue background
C. A waste dump in the blue background
D. A volcano on the green land
E. A volcano in the blue background
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 84/165 [03:08<03:11,  2.37s/it][32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dCscvoOX2as.mp4[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dCscvoOX2as.mp4[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dCscvoOX2as.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=168[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a small road in the forest, there is a green tank riding on it, a man wearing green clothes and a hat is standing in the tank. With which subtitles does this man appear together?
A. dead areas certain anti aircraft machine
B. ride is 10 euros and 5 euros if you're
C. prices in October 2016 the regular price
D. for an adult is 7.5 euros if you have a
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WaiGdRYD36k.mp4[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WaiGdRYD36k.mp4[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WaiGdRYD36k.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=159[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen is a long-haired woman wearing a checkered coat over a black shirt, and there is a bright lamp on the wall behind her. When the subtitle mentions 'strategically on how to get the job done,' what object appears on the wall?
A. A pendant lamp
B. A potted plant
C. A painting
D. A mobile phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GFg98TDqCpw.mp4[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GFg98TDqCpw.mp4[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GFg98TDqCpw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=161[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a grey coat and blue jeans is standing in front of a building with a glass facade. To his left, there is a small tree with red leaves. Between the man and the tree, there is the text 'FAZER'. What is the first white text that appears on the screen after this?
A. EKiM 2021
B. KASIM 2021
C. Subscribe
D. SANOMATALO
E. OODI KESKUSTAKIRJASTO
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 85/165 [03:11<03:36,  2.71s/it][32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = duxO1EZ650E.mp4[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/duxO1EZ650E.mp4[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: duxO1EZ650E.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=170[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the lower right corner of the video, there is a bald person wearing sunglasses and dressed in black. There are also three boys on the screen: the one on the left is wearing a blue short-sleeve shirt, the one on the right is wearing a red long-sleeve shirt, and the one in the middle is wearing a gray short-sleeve shirt. Which of the following items does not appear in the video?
A. Black hat
B. White hat
C. Sunglasses
D. Blue short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = a_8G0PzVFbc.mp4[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/a_8G0PzVFbc.mp4[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: a_8G0PzVFbc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=163[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two people appear in the room. One person is lying on debris in the corner, while the other person is sitting by the feet of the lying person. There is a can placed inside the room, and behind the sitting man is a fireplace. What did the person lying on the debris do the first time they appeared?
A. Holding the head with both hands
B. Supporting the chin with one hand
C. Using hands to touch the top of the head
D. Crossing arms over the chest
E. Using hand to support the forehead
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 86/165 [03:13<03:24,  2.59s/it][32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 571nruSayeo.mp4[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/571nruSayeo.mp4[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 571nruSayeo.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=172[0m
[32m2025-11-29 13:15:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a big tree as the background, a black and yellow long-haired cat is walking on a horizontal wooden beam, and in a scene with a big tree as the background, a black dog is holding its front legs on a horizontal wooden beam. Which of these two animals appeared first?
A. Neither appeared
B. Black dog
C. Both appeared at the same time
D. Black and yellow long-haired cat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=165[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the news footage, in front of the virtual cityscape background, there is a man in a gray suit and red tie speaking to the camera, with the subtitle 'long has it been like that in the'. In which sentences does this man wearing a red tie appear together with those subtitles?
A. You make a duck become a beautiful swan
B. Since then great changes have taken place there
C. Capital well I I think uh what we just
D. Of all the subject
E. Time passed quickly
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 87/165 [03:16<03:22,  2.59s/it][32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = X29dPzJIMbA.mp4[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/X29dPzJIMbA.mp4[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: X29dPzJIMbA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=174[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are three women sitting on a bench. The woman on the left is wearing a black long-sleeve shirt, with her right hand extended forward. The woman in the middle is wearing a light gray long-sleeve shirt. The woman on the right is wearing a white long-sleeve shirt. Who is sitting in the middle?
A. Nancy
B. Davy
C. Jo-Anne
D. Cara
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 88/165 [03:18<03:15,  2.54s/it][32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mq6L8CnNJXc.mp4[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mq6L8CnNJXc.mp4[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mq6L8CnNJXc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=176[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a shoulder-baring top is sitting on a white sofa. She is wearing a wristwatch and a ring. Behind her are a black railing and a white wall. When the subtitle 'blackford' appears, what is the woman doing?
A. The woman is holding a book
B. The woman is holding a cat
C. The woman is holding two pieces of paper
D. The woman is holding two books
E. The woman is holding a pen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yz3lOAe32Tw.mp4[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yz3lOAe32Tw.mp4[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yz3lOAe32Tw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=167[0m
[32m2025-11-29 13:15:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall with prints and paintings, there is a woman in red clothes on the left and a young girl in white clothes on the right. They are having a conversation. What happened after the conversation mentioned 'mommy gerbil ate her offspring's head'?
A. Jessica stroked Ted's mechanical arm
B. A robot with glowing yellow eyes came through the door
C. Two adult men were playing a board game
D. A man lay in the bathtub with a towel over his eyes
E. A woman in purple grabbed the wrist of a young girl with glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _BDzMutoy6A.mp4[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_BDzMutoy6A.mp4[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _BDzMutoy6A.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=169[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:15:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wall with blue ceramic tiles, there's a man with a mustache, carrying a backpack and wearing a short-sleeved shirt. What is the color of the straps on the backpack he's carrying in the video?
A. Olive
B. Black
C. White
D. Gray
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:15:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 89/165 [03:21<03:23,  2.68s/it][32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rP7sQe784k8.mp4[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rP7sQe784k8.mp4[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rP7sQe784k8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=178[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:15:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the upper left side of the wooden table, there's a plate of white and pink tangyuan. In the lower left, there's ice water with ice cubes in a glass container. On the right, there are six tangyuan in a blue pot on a black gas stove. When the subtitle 'It'll stick to the bottom of your pan' appears, what is the hand holding a green slotted spoon doing?
A. Boiling tangyuan
B. Stir-frying tangyuan
C. Kneading tangyuan
D. Deep-frying tangyuan
E. Pan-frying tangyuan
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7097604725134118146.mp4[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7097604725134118146.mp4[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7097604725134118146.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=171[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a rectangular table with food ingredients, there are some green onions on the wooden tray on the far left side. What change occurred to the green onions when the subtitle says 'Onion'?
A. The green onions were cut into chunks
B. The green onions were put into a bottle
C. The green onions were placed on a rack
D. The green onions were put into a pot
E. The green onions were cut into pieces
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 90/165 [03:24<03:27,  2.76s/it][32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5tN9hyfdkaE.mp4[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5tN9hyfdkaE.mp4[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5tN9hyfdkaE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=180[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background is a vibrant sky with sunlight above, featuring trees and a green meadow. A woman wearing an orange dress, a green shoulder bag, and green shoes is walking on stone steps with a handrail on the right side. In which other scenes does this woman appear?
A. On a green meadow with long shadows cast by the sun
B. In a coffee shop
C. Inside a clothing store in a shopping mall
D. Next to the dining table in a dining hall
E. By the swimming pool
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = BktEeBeA7a8.mp4[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/BktEeBeA7a8.mp4[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: BktEeBeA7a8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=173[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Walking on a street filled with red lanterns, a black-haired man wearing a black coat is speaking to the camera. What hairstyle did he have when the subtitle reads 'celebrated Chinese culture but really to'?
A. Long curly hair
B. Shoulder-length hair
C. Bald
D. Curly hair
E. Crew cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 91/165 [03:27<03:22,  2.74s/it][32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ze66pbJYr18.mp4[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ze66pbJYr18.mp4[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ze66pbJYr18.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=182[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman dressed in a beige long-sleeved top, black tight pants, and white sneakers with curly hair draped over, stands on a low wooden platform in a forest bathed in golden sunlight. What is the first plant to appear?
A. Wild flowers
B. Vegetables
C. Melon
D. Some colorful trees
E. A pile of green grass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -kaF6SnSEo8.mp4[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-kaF6SnSEo8.mp4[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -kaF6SnSEo8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=175[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Sitting at a table are 5 people, one of whom is a woman wearing a hat and pouring tea from a teapot. When the subtitle 'lived in a small hut and slept on straw' appears, what objects are present on the screen?
A. Bed
B. Lamp, table, washing machine
C. Lamp, table, chair
D. TV, lamp, table
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 92/165 [03:29<03:13,  2.66s/it][32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bwnkg6GbXwU.mp4[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bwnkg6GbXwU.mp4[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bwnkg6GbXwU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=184[0m
[32m2025-11-29 13:16:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When a pie chart representing the Czech Ethnicity appears in the video, with blue occupying the largest portion, red being the second, and light green the least, which of the following sentences is displayed on the screen?
A. 25% "Unspecified"
B. 60% ‚Äúdeclared‚Äù Czech
C. 95% Czech
D. 38% Czech
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = H2ksp6sRR-k.mp4[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/H2ksp6sRR-k.mp4[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: H2ksp6sRR-k.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=177[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a few houses, three men stand before a mirror. One man is wearing a green hat, and another man is wearing black glasses. What did the man wearing black glasses do the first time he appeared?
A. Touched his head with his right hand.
B. Looked at the man wearing the green hat.
C. Touched his glasses with his right hand.
D. Lowered his head to look at a script, occasionally raising his head to speak to the mirror.
E. Covered his face with both hands.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 93/165 [03:33<03:21,  2.80s/it][32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAHsR02dUc0.mp4[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAHsR02dUc0.mp4[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAHsR02dUc0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=186[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background features a blue curtain. Three men are standing by a white powder-coated round table. The man on the left is wearing a black suit with a brick-red shirt underneath, and holding a green piece of paper in his hand. The man in the middle is dressed in a black suit with a tie and holding a green piece of paper in both hands. The man on the right is wearing a purple-blue checkered shirt and black-framed glasses, holding a green card and a pen up with both hands. What is the man on the right doing when the subtitle 'researchers named midi-chlorian' appears?
A. Closing his eyes and thinking
B. Talking to the man next to him
C. Waving to the camera
D. Looking up at the ceiling
E. Writing on the green piece of paper
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -0aM99dMu_4.mp4[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-0aM99dMu_4.mp4[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -0aM99dMu_4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=179[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a white-screen background, at the top of the screen, there is a conspicuous title 'Lagrangian Mechanics.' On the right side, there's a black frame with sharp edges, inside of which are irregular blue lines. What happens to these blue lines afterward?
A. In the 0-6 region, it descends, then in the 6-8 region, it rapidly spirals up and then descends again.
B. In the 0-4 region, it ascends, then rapidly descends in the 6-8 region.
C. It becomes a straight horizontal line.
D. In the 0-6 region, it rises, then in the 6-8 region, it rapidly spirals down and then rises again.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 94/165 [03:35<03:03,  2.59s/it][32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ozpGTw6DrXs.mp4[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ozpGTw6DrXs.mp4[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ozpGTw6DrXs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=188[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black-bordered, white-background image, there are three equally sized video windows labeled 'timesteps'. When 'the unsupervised method will discover' is mentioned, what change occurs in the first video window?
A. It shows one segment of a black-and-white grid with two green objects.
B. It shows two segments of a black-and-white grid with two green objects.
C. It shows two segments of a pure black screen with two green objects.
D. It shows one segment of a pure black screen with two green objects.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fWNJmZAWRNg.mp4[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fWNJmZAWRNg.mp4[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fWNJmZAWRNg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=181[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A blonde man wearing a gray short sleeve shirt is in front of a mountain and an ocean in the scene. In which other scene does this man appear?
A. Appears on the road between the sea and the buildings
B. Appears on the beach
C. Appears on a boat
D. Appears in a restaurant
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 95/165 [03:37<03:01,  2.60s/it][32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = E7FSg22MdKE.mp4[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/E7FSg22MdKE.mp4[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: E7FSg22MdKE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=190[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room where all the furniture is made of solid wood, there is a person sitting on a chair holding an embroidery with blue fabric. Who is this person doing the embroidery?
A. A woman in a white dress
B. A woman in a blue dress
C. A woman in a black dress
D. A woman in a crimson dress
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = u5NAcHhI_Uc.mp4[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/u5NAcHhI_Uc.mp4[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: u5NAcHhI_Uc.mp4 | Selected 15 frames[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=183[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 13:16:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a completely black background with a drawing of a soldier. He is wearing a uniform, has bullets hanging on his body, and is holding a gun. What is this soldier doing?
A. The soldier is looking upwards
B. The soldier is saluting
C. The soldier is looking to the left
D. The soldier is looking to the right
E. The soldier is standing straight
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bXRuqcmTIuk.mp4[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bXRuqcmTIuk.mp4[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bXRuqcmTIuk.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=185[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dimly lit room, there is a lamp hanging from the ceiling. Below the lamp, there is an olive-colored table, with olive-colored objects placed on it. Behind the table, there is a wall filled with square grids. Below the wall, there are two windows, and behind the windows, there are three seated people. After the subtitle mentions 'think it would be great if we could remember those things', what is the first fruit that appears?
A. Apple
B. Mango
C. Pear
D. Watermelon
E. Banana
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 96/165 [03:40<02:53,  2.52s/it][32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yn7oTvw8QRY.mp4[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yn7oTvw8QRY.mp4[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yn7oTvw8QRY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=192[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x3b9cb080] mmco: unref short failure
[h264 @ 0x3b9cb080] mmco: unref short failure
[32m2025-11-29 13:16:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with slightly dim lighting and white walls, a long-haired woman in a red dress is sitting on a chair. She is holding a red musical instrument in her hand. Behind her are a few gray chairs. On the wall behind the chairs hangs a white square board. There is a window behind her on the right side. With which subtitles does the girl's musical instrument appear together?
A. Here we learn that young Joe had a lot of enemies because he was a bully
B. Right after, Joe manages to answer the first question about who he is
C. served at every single Chinese restaurant with the word 'dragon' on its name, because it's the
D. a prep school called Evergreen Academy, which is a school Joe went to when he was younger.
E. hope. therefore he begins to write letters to his daughter, hoping that once he gets out, his
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 88LbBgZP1vQ.mp4[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/88LbBgZP1vQ.mp4[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 88LbBgZP1vQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=187[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are two images here. One shows a girl in green clothing with braided hair, holding a clay container in front of a solid color background wall. The other shows a girl in black and white floral clothing with loose hair. According to the video, which character appears first?
A. Boy with short hair and green stripes
B. Boy with golden hair
C. Girl in green clothing with loose hair
D. Girl in green clothing with braided hair
E. Girl in black and white floral clothing with loose hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 97/165 [03:42<02:51,  2.52s/it][32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7277140989259599105.mp4[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7277140989259599105.mp4[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7277140989259599105.mp4 | Selected 8 frames[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=194[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 13:16:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What did the Yoda baby with big black eyes in the screen do when the subtitle said, "to obtain any information about the Yoda baby's owner"?
A. Raised one ear
B. Raised both ears
C. Blinked its eyes
D. Ran on the ground
E. Walked on the ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 98/165 [03:44<02:28,  2.21s/it][32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = e11Q4ThFu5A.mp4[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/e11Q4ThFu5A.mp4[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: e11Q4ThFu5A.mp4 | Selected 9 frames[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=196[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 13:16:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man and a woman are leaning on each other. The woman is wearing a black backless dress and has golden hair, while the man is wearing a grey suit and a yellow tie. There are many other people in the background, and they are in a banquet hall. The woman is wearing a necklace and holding a cup in her hand. What material is the cup made of?
A. Crystal glass cup
B. Transparent glass cup
C. Metal cup
D. Ceramic cup
E. Transparent plastic cup
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 99/165 [03:45<02:03,  1.87s/it][32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7257359603489443073.mp4[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7257359603489443073.mp4[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7257359603489443073.mp4 | Selected 12 frames[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=198[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 13:16:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a car, there is a black seat, a short-haired man wearing a gray shirt, and a long-haired woman sitting next to him. In which of the following locations has the short-haired man appeared?
A. Verdant forest
B. Beautiful seaside
C. Quiet park
D. Crowded amusement park
E. Indoor basketball court
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = J1IwKg2ufk8.mp4[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/J1IwKg2ufk8.mp4[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: J1IwKg2ufk8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=189[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a woman with white hair wearing blue clothes. Behind her, there is a man in a white coat and another woman in white clothes. They are in a futuristic-looking glass room. What is the object present in the scene?
A. Orange-red thread
B. Blue clothing with a yellow collar
C. Yellow pants
D. Blue clothing with a black collar
E. Rose-colored pants
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 100/165 [03:46<01:51,  1.72s/it][32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i6C6r2g4Y7Q.mp4[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i6C6r2g4Y7Q.mp4[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i6C6r2g4Y7Q.mp4 | Selected 11 frames[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=200[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 13:16:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a space with a wall marked with an 's', there are three elevator doors. Three men and three women are standing in front of the elevator doors, tossing two basketballs to each other. What action does the person wearing a black leather jacket first take when they appear?
A. He steps back into the crowd and then turns around with his back facing the elevator doors
B. He walks forward into the crowd and then turns around with his back facing the elevator doors
C. He walks backward straight through the crowd
D. He steps back into the crowd and then turns around facing the elevator doors
E. He walks forward into the crowd and then turns around facing the elevator doors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 101/165 [03:48<01:49,  1.71s/it][32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = t48HXAjjDAU.mp4[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/t48HXAjjDAU.mp4[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: t48HXAjjDAU.mp4 | Selected 6 frames[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=202[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 13:16:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing an embroidered dress, whose face is not visible, is cutting a tomato on a wooden board with a vegetable knife. What objects are present in this scene?
A. golden fork
B. wooden spoon
C. ring
D. parsley
E. pasta
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qYnloYaeQA8.mp4[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qYnloYaeQA8.mp4[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qYnloYaeQA8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=191[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into two different characters' headshots on the left and right. The left headshot is of a person with glasses shouting. In the red frame at the bottom, it is written in white English text 'Hundreds rally in Tel Aviv for ceasefire in Gaza'. Whose hair is being blown messily by the strong wind in the screen?
A. A female reporter wearing a white coat
B. A male reporter wearing a grey coat
C. A female reporter wearing a black coat
D. A female reporter with glasses
E. A female reporter wearing a purple coat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 102/165 [03:49<01:32,  1.47s/it][32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6S_e34j6q9U.mp4[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6S_e34j6q9U.mp4[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6S_e34j6q9U.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=204[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a gray wall and a yellowish-brown door, there is a transparent glass table with dark brown edges. A man in a dark blue short-sleeved shirt is standing beside the table. What kind of hat is this man wearing?
A. A blue beret
B. A white ceremonial hat adorned with red flowers
C. An off-white baseball cap
D. A black baseball cap with a white design in the middle and on the upper side of the ear flaps
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -iCLYpeghJs.mp4[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-iCLYpeghJs.mp4[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -iCLYpeghJs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=193[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Among the characters on the screen‚Äî a man with curly brown hair wearing a striped shirt and holding a blue egg beater while whisking eggs, and a woman with long brown hair wearing a white short-sleeve T-shirt and holding a dark blue egg beater while whisking eggs‚Äî which character appears first?
A. They appear at the same time.
B. The woman with long brown hair wearing a white short-sleeve T-shirt.
C. The man with curly brown hair wearing a striped shirt.
D. The man with short brown hair wearing a white short-sleeve T-shirt.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 103/165 [03:51<01:51,  1.80s/it][32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fxCRCMLJ0PU.mp4[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fxCRCMLJ0PU.mp4[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fxCRCMLJ0PU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=206[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white tiled wallpaper with icy and sweet candy circles, there are two men standing side by side, one wearing short sleeves and the other holding a remote control wearing long sleeves. When the phrase 'tlicking topping motion is that how you' is mentioned, how are their clothes described?
A. The man on the left is wearing light red short sleeves, and the man on the right is wearing a white long sleeve.
B. The man on the right is wearing light yellow short sleeves, and the man on the left is wearing a black long sleeve.
C. The man on the right is wearing light red short sleeves, and the man on the left is wearing a black long sleeve.
D. The man on the left is wearing light red short sleeves, and the man on the right is wearing a black long sleeve.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7334544531490196741.mp4[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7334544531490196741.mp4[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7334544531490196741.mp4 | Selected 10 frames[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=195[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a character dressed in green military attire with olive green camouflage on the face and a rifle on the back appears in front of a black screen. Then, a green aircraft flies in a sky with light orange and light purple hues. Finally, a little figure wearing an olive helmet holds onto a parachute and floats in the air.
B. First, a little figure wearing an olive helmet holds onto a parachute and floats in the air. Then, a character dressed in red military attire with yellow camouflage on the face and a rifle on the back stands in a military pose. Finally, a green aircraft flies in a sky with light orange and light purple hues.
C. First, a little figure wearing an olive helmet holds onto a parachute and floats in the air. Then, a character dressed in green military attire with olive green camouflage on the face and a rifle on the back stands in a military pose. Finally, a green aircraft flies in a sky with light orange and light purple hues.
D. First, a yellow aircraft flies in a sky with light orange and light purple hues. Then, a character dressed in red military attire with yellow camouflage on the face and a rifle on the back stands in a military pose. Finally, a little figure wearing an olive helmet holds onto a parachute and floats in the air.
E. First, a little figure wearing an olive helmet holds onto a parachute and floats in the air. Then, a character dressed in red military attire with yellow camouflage on the face and a rifle on the back stands in a military pose. Finally, a yellow aircraft flies in a sky with light orange and light purple hues.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 104/165 [03:53<01:56,  1.91s/it][32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qksR2Zvd-FM.mp4[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qksR2Zvd-FM.mp4[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qksR2Zvd-FM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=208[0m
[32m2025-11-29 13:16:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Sunlight is shining on a stone wall, beneath which is a blue sea. Two white boats are anchored on the sea, and in the distance, the sea stretches out infinitely. When the camera moves to the right, what changes on the screen?
A. A cruise ship appears on the screen
B. The sun appears on the screen
C. Stars appear on the screen
D. An airplane appears on the screen
E. The moon appears on the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qZVBFAtfp2A.mp4[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qZVBFAtfp2A.mp4[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qZVBFAtfp2A.mp4 | Selected 4 frames[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=197[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 13:16:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man in pink garb with a ponytail stands in front of a white wall with a white door, as well as a lantern. The man is wearing a pink garment. Not far away, there's a street with some small buildings and parked cars. Behind the man, there is a person in black clothing facing away from the camera. When the phrase 'I can't wait to surprise my mom' is mentioned, what type of garment is the man wearing?
A. Pink tank top
B. Pink T-shirt
C. Pink dress shirt
D. Pink jacket
E. Pink sweater
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CGngv8vTQOs.mp4[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CGngv8vTQOs.mp4[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CGngv8vTQOs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=199[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the distance, there are high-rise buildings and green vegetation. A black car is underneath the vegetation. On the left side of the screen, there is a soldier wearing a black hood. In the middle, there is a soldier wearing a green hood. On the right side, there is a soldier wearing a green helmet. After the caption mentions 'this weapon can be nowadays,' who is the first person to appear?
A. A soldier wearing a gray knit cap, a backpack, and a dark yellow uniform.
B. A soldier with a white helmet that has glasses on it.
C. A soldier in an army green camo outfit wearing a black hood.
D. A man wearing a camo outfit with short sandy hair.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 105/165 [03:56<02:06,  2.11s/it][32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8_MG-E8QlBM.mp4[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8_MG-E8QlBM.mp4[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8_MG-E8QlBM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=210[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a starry backdrop, there is a shrunken image of the Earth in the upper left corner with a gray rocket on it. Alongside the image, the word 'Playlist' is written in red text. What is the gray rocket doing?
A. Flying towards the Sun
B. Flying towards Jupiter
C. Rotating with its head and tail separated
D. Flying towards Uranus
E. Flying downward
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = IGmuaY1jB1w.mp4[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/IGmuaY1jB1w.mp4[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: IGmuaY1jB1w.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=201[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some women wearing headscarves are standing inside the hut, while the sunlight outside is dazzling. A man in a black and white striped short sleeve is holding a mobile phone. When the subtitle 'time news arrived of another body' appears, what is the woman in the middle with her hands covering her face and carrying a child on her back doing?
A. Sweeping the floor
B. Chatting with others
C. Waving to the camera
D. Taking care of the child
E. Covering her face with both hands, looking distressed
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 106/165 [03:59<02:19,  2.37s/it][32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8Gl6iy7OEM4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=212[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner of the screen, the number is 31. A colorful picture appears on the screen, along with three purple rectangles containing black text. When the subtitle says 'have the image and you have the text so', what else is on the screen?
A. Sunflower
B. Airplane
C. Car
D. Radio
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dxjKdnJFmLs.mp4[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dxjKdnJFmLs.mp4[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dxjKdnJFmLs.mp4 | Selected 9 frames[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=203[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 13:16:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a small road, a man wearing a dark red short-sleeved T-shirt and a green hat is chatting with a man wearing a black short-sleeved T-shirt and a red hat. When the man wearing the green hat holds a shoe in his right hand, what action does the man wearing the black short-sleeved T-shirt and red hat do with his left hand?
A. Throwing the shoe away
B. Holding a red teacup
C. Holding a red teacup and drinking tea
D. Point with his thumb and index finger at the man wearing the green hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = H2ksp6sRR-k.mp4[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/H2ksp6sRR-k.mp4[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: H2ksp6sRR-k.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=205[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with pictures, two men are discussing some topics. There's a picture with a river at the bottom left corner of the screen. One of the men is saying 'a pew river the whole'. Which man is saying 'a pew river the whole'?
A. The man with fair skin
B. The man wearing a black short-sleeve shirt
C. The man wearing an olive hat
D. The man wearing a white short-sleeve shirt
E. The man wearing a yellow short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 107/165 [04:01<02:16,  2.36s/it][32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = q3FAxTSENEw.mp4[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/q3FAxTSENEw.mp4[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: q3FAxTSENEw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=214[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a dark red checkered shirt and black-framed glasses is standing in front of a green background. There is a blue circular pattern on the left side of the screen and a pink circular pattern on the right side of the screen. What is this man doing when the subtitle 'person will receive the I lost scishow' appears?
A. Chatting with a friend
B. Speaking to the camera
C. Talking on the phone
D. Looking at his phone
E. Nodding
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZL07dkaoHOg.mp4[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZL07dkaoHOg.mp4[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZL07dkaoHOg.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=207[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:16:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A girl wearing a knitted shirt, with her right hand, took a white piece of clothing from a grey bag. When 'music' is mentioned, what other changes does this bag undergo?
A. The color of the bag changes.
B. The bag becomes empty.
C. The bag becomes smaller.
D. The bag becomes bigger.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KFqlW0APKRA.mp4[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KFqlW0APKRA.mp4[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KFqlW0APKRA.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=209[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which sequence of scenes appearing in the video is correct?
A. A person is in a white background, and the remaining screen shows the word 'Q Learning' first, then '1 step', and finally 'Training'
B. A person is in a white background, and the remaining screen shows the word '1 step' first, then 'Q Learning', and finally 'Training'
C. A person is in a white background, and the remaining screen shows the word 'Q Learning' first, then 'Training', and finally '1 step'
D. A person is in a white background, and the remaining screen shows the word 'Training' first, then 'Q Learning', and finally '1 step'
E. A person is in a white background, and the remaining screen shows the word 'Training' first, then '1 step', and finally 'Q Learning'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 108/165 [04:04<02:18,  2.43s/it][32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vEy6tcU6eLU.mp4[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vEy6tcU6eLU.mp4[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vEy6tcU6eLU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=216[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman with long hair wearing a black coat explaining a protest activity in an empty room. What was her first action when she appeared?
A. Sitting
B. Lying down
C. Standing
D. Crouching
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZfapKqwklG4.mp4[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZfapKqwklG4.mp4[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZfapKqwklG4.mp4 | Selected 4 frames[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=211[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 13:16:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the phrase 'forbidden instead they were welcome to' was mentioned, what action did the man in the red and purple striped clothes do in the old, broken room?
A. Got up from the bed and ran
B. Ate
C. Covered his ears with both hands
D. Picked up a cup and drank water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7262938043315686664.mp4[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7262938043315686664.mp4[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7262938043315686664.mp4 | Selected 6 frames[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=213[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man appears in front of a black background. The man has thick and long hair. He is wearing a short-sleeve shirt, and the buttons of the short-sleeve shirt are not fastened. When the subtitle 'So how do they communicate with each other?' appears, what is the color of the shirt under the short-sleeve shirt of the man with thick hair?
A. yellow
B. black
C. blue
D. white
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 109/165 [04:06<02:15,  2.42s/it][32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DRIpznER-VQ.mp4[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DRIpznER-VQ.mp4[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DRIpznER-VQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=218[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a classroom with many wooden desks and chairs, there is a woman wearing a black dress and has black hair standing. The woman is surrounded by many children. With which of the following subtitles did the woman in the black dress appear together?
A. "the truth of the matter. Call on your friend and sneak into the teacher's house. The three have"
B. "against the wall."
C. "living room"
D. "The three of them had to hide behind the sofa."
E. "Unexpectedly, a few people even entered the room, discovering the previous teacher leaning"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bwnkg6GbXwU.mp4[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bwnkg6GbXwU.mp4[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bwnkg6GbXwU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=215[0m
[32m2025-11-29 13:16:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man with a blue shirt and curled hair and a woman with a checkered shirt are in a room, both looking down. In front of them is a pile of yellow cardboard-like objects. The man's black-framed glasses are in the pocket of his shirt. In which other scenes does this man appear?
A. A high-floor room in a hotel
B. In front of a shop's glass window
C. An outdoor area full of green plants
D. A room with blurred block patterns in the background and a silver support frame
E. Inside a luxurious living room
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 110/165 [04:09<02:09,  2.36s/it][32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KlZpZVphLrc.mp4[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KlZpZVphLrc.mp4[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KlZpZVphLrc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=220[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a screen with a blue border, there is a highway. On the highway, many cars are parked. Two horses of different colors appear on the highway. What did the yellow-brown horse do the first time it appeared?
A. Was hit by a white car
B. Ran against the direction of the traffic flow
C. Crossed the highway
D. Was hit by a black car
E. Ran in the direction of the traffic flow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XYsCVqz3iug.mp4[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XYsCVqz3iug.mp4[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XYsCVqz3iug.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=217[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
BBC Television is currently broadcasting the news. On the left side of the split screen, a woman with long auburn hair, wearing blue clothes, is explaining something. On the right side of the screen, a video shows a man with white hair speaking, holding a white piece of paper, with a man and a woman seated behind him. When the phrase 'must be a condemnation of all parties if' is mentioned, which of the following objects does not appear in the scene?
A. Badge with a blue strap
B. White wristwatch
C. Earring
D. Microphone
E. Blue clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 111/165 [04:11<02:02,  2.27s/it][32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gAgCnu82RHE.mp4[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gAgCnu82RHE.mp4[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gAgCnu82RHE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=222[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the table, there's a woman in blue on the left and a woman in gray on the right. The woman in blue has her hands on the table. What is the woman in blue doing?
A. Placed a watermelon on the table
B. Placed a banana on the table
C. Placed an apple on the table
D. Placed a light blue arrow on the table
E. Placed a dragon fruit on the table
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XuQswmEPgxU.mp4[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XuQswmEPgxU.mp4[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XuQswmEPgxU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=219[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue sky, white clouds are floating, a road appears near the blue sea, on the left side of the road is a green forest, and trees are planted on both sides of the road. What is moving on the road?
A. Hunting Dog
B. Helicopter
C. Pedestrian
D. Car
E. Seabird
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 112/165 [04:13<02:08,  2.43s/it][32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HeRS3nwySI8.mp4[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HeRS3nwySI8.mp4[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HeRS3nwySI8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=224[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the very beginning of the video, a woman wearing a hat and a fur coat is standing in front of a car. In the car, in the driver's seat, there is a man also wearing a fur coat. In the upper left corner of the screen, the white text 'HARLEM IS EVERY WHERE' appears. Where else does this white text appear?
A. In the purple background on the left side, there is a group of English words, and on the right side, there is a picture of a nude woman sitting with her hands hugging her knees, staring at the stove
B. In a black background on the left side, there is a picture of a person wearing a purple skirt sitting on the grass
C. In a green background on the right side, there is a picture of a person wearing a red skirt sitting in front of a stove
D. In a red background on the right side, there is a picture of a nude person sitting in front of a stove
E. In a purple background on the right side, there is a picture of a person wearing a white short-sleeve shirt sitting in front of a stove
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mkqgTAe2_O4.mp4[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mkqgTAe2_O4.mp4[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mkqgTAe2_O4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=221[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a street lined with gray and black houses, there is a woman with long hair crying on the left, and a man wearing a beige fur coat on the right. What did the man do when he appeared for the first time?
A. Put on a pair of glasses
B. Put on a coat himself
C. Took off his fur coat
D. Put on a black hat
E. Put a coat on the woman
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 113/165 [04:16<02:10,  2.51s/it][32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mTn_C-SyW84.mp4[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mTn_C-SyW84.mp4[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mTn_C-SyW84.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=226[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man and a woman, dressed as ordinary people, are holding shovels and digging soil. The man is wearing a hat, and the woman is wearing a headscarf. There are two soldiers in blue uniforms with black hats holding guns nearby. In the distance, there are some green plants. What is present in this scene?
A. A photographer wearing a hat
B. Skirts
C. Advancing cannons
D. NP-News-Programers
E. Various colored horses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fLn06p2HtAc.mp4[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fLn06p2HtAc.mp4[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fLn06p2HtAc.mp4 | Selected 14 frames[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=223[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 13:16:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with wooden walls, a woman in a grey strapless long dress stands in front of a white door, looking down and arranging her clothes. What is the object present in this scene?
A. Bracelet
B. Earrings
C. Book
D. Necklace
E. A broom
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 114/165 [04:18<02:01,  2.38s/it][32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7XWqI121-Q4.mp4[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7XWqI121-Q4.mp4[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7XWqI121-Q4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=228[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a small person figure wearing a blue duckbill cap and dressed in blue clothes. Where has this blue-clothed character appeared before?
A. A room with a map in front, including 3 guitars of different colors, a computer, an olive-colored sofa, and a bookshelf.
B. A room with a map in front, including 2 guitars of different colors and a computer.
C. A room with a map in front, including an olive-colored sofa, a computer, and a bookshelf.
D. A room with a map in front, including an olive-colored sofa and a bookshelf.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Sy2unO22PUE.mp4[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Sy2unO22PUE.mp4[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Sy2unO22PUE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=225[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing khaki-colored pants with a leather jacket and carrying a black handbag is walking on the sidewalk along the road. After this person walks past, a string of yellow English words appears. What is the first thing that happens after this?
A. The woman opens a laptop on the bed
B. The woman visits a museum
C. The woman sits on a bed in the bedroom and talks
D. The woman stands on the bridge and takes a selfie with one hand making a V sign
E. The woman goes to eat in the dining hall
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 115/165 [04:21<02:07,  2.55s/it][32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NpYUxd1vUUE.mp4[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NpYUxd1vUUE.mp4[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NpYUxd1vUUE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=230[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:16:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Four armed characters appear on the screen: two characters in green uniforms with helmets on the first floor, and two characters in yellow shirts with hats on the second floor. The characters on the second floor are shooting from kneeling positions, while the characters on the first floor are shooting from standing positions. What change occurs to the positions of the two characters in yellow shirts when the subtitle 'made their way down to the third floor' appears?
A. They go from kneeling to prostrate shooting positions
B. They go from kneeling to shooting while leaning against a railing
C. They go from kneeling to shooting while leaning against a wall
D. They go from kneeling to prone positions
E. They go from kneeling to standing positions
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:16:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GawGUhl9zuQ.mp4[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GawGUhl9zuQ.mp4[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GawGUhl9zuQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=227[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:16:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, the woman pulls up the curtain. Then, the short-haired blonde woman pulls up the room's curtain. Next, the short-haired blonde woman takes out a letter. Finally, the short-haired blonde woman shakes hands with an elderly man with white hair.
B. First, the short-haired blonde woman pulls up the room's curtain. Then, the short-haired blonde woman takes out a letter. Next, the short-haired blonde woman shakes hands with an elderly man with white hair. Finally, Anne pulls up the curtain.
C. First, Anne pulls up the curtain. Then, the short-haired blonde woman pulls up the room's curtain. Next, the short-haired blonde woman takes out a letter. Finally, the short-haired blonde woman shakes hands with an elderly man with white hair.
D. First, the short-haired blonde woman takes out a letter. Then, the short-haired blonde woman shakes hands with an elderly man with white hair. Next, the short-haired blonde woman pulls up the room's curtain. Finally, Anne pulls up the curtain.
E. First, a short-haired blonde woman shakes hands with an elderly man with white hair. Then, the short-haired blonde woman takes out a letter. Next, the short-haired blonde woman pulls up the room's curtain. Finally, Anne pulls up the curtain.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 116/165 [04:24<02:09,  2.65s/it][32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CdTijM0_es4.mp4[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CdTijM0_es4.mp4[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CdTijM0_es4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=232[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Between two connected videos, there is a white notebook in the middle held by a female. The notebook has an additional paper attached with a figure on it. What changes happen to the notebook when the subtitle mentions 'there good and then'?
A. The additional paper on the notebook is gone
B. The notebook only has a blue figure drawn with a pen
C. The notebook has an additional paper and a black figure drawn with a pen
D. The notebook has an additional paper and a black figure drawn with a pen
E. The notebook has an additional paper and a blue figure drawn with a pen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hg2Q_O5b9w4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=229[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white-background PPT screen, there is black text at the bottom, yellow-highlighted text on the left, and in the middle, an illustration composed of a blue rectangle, a green circle, and a blue triangle. When the subtitle 'spaceship this and this and so right and' appears, what changes occur to the illustration?
A. Covered by a blue highlight
B. A star appeared in the middle
C. Got bigger
D. Got smaller
E. A red dot appeared in the middle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qbA42wQoWAs.mp4[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qbA42wQoWAs.mp4[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qbA42wQoWAs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=231[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a green meadow, in the distance there are gray mountains. In front of the mountains stands a group of soldiers wearing gray helmets and a group wearing dark blue helmets. In which of the following scenes do the soldiers wearing dark blue helmets appear?
A. In a desert with no vegetation
B. On a snow-covered grassland
C. In a forest during the rain
D. On a plain during a thunderstorm
E. In a scene where soldiers wearing yellow helmets are riding a blackish brown horse
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 117/165 [04:27<02:11,  2.73s/it][32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zJ2uPZfkYMk.mp4[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zJ2uPZfkYMk.mp4[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zJ2uPZfkYMk.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=234[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the night-draped airport, four people are experiencing a ride in a vertical lift aircraft. Inside the aircraft, they are wearing earphones and fluorescent-patterned armor. Who among the following is participating?
A. A man with white hair
B. A woman with long hair
C. A child
D. An elderly man with white hair
E. A woman with green hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bwnkg6GbXwU.mp4[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bwnkg6GbXwU.mp4[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bwnkg6GbXwU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=233[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The white window frame holds a transparent glass that reflects the snowy landscape outside. In front of the window, there are porcelain items, a red candle, and a white candle. A person walks in from the right side of the screen. When the shot changes to a woman wearing a green linen dress facing the mirror, what change occurs to the red candle on the left side of the woman?
A. The red candle becomes longer
B. The red candle turns black
C. The red candle is burned out
D. The red candle is ignited
E. The red candle burns down and becomes shorter
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 118/165 [04:29<02:05,  2.67s/it][32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LAbtlJJhUlY.mp4[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LAbtlJJhUlY.mp4[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LAbtlJJhUlY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=236[0m
[32m2025-11-29 13:17:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A hand is holding a pen and coloring a design on white paper. The wrist of this hand has a silver item attached to it. The pen's body is black, and the tip is olive yellow. On the white paper, there are three bells drawn. Next to the bells, there is a sketch. The pen tip is currently positioned on this sketch. What did this pair of hands do after coloring?
A. Picked up a pair of scissors
B. Dropped the piece of paper on the ground
C. Picked up the piece of paper
D. Picked up a book
E. Tore the piece of paper
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 119/165 [04:32<01:58,  2.57s/it][32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = J1IwKg2ufk8.mp4[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/J1IwKg2ufk8.mp4[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: J1IwKg2ufk8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=238[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall, a woman wearing black clothes and a white headscarf appears. What did she do the first time she appeared?
A. Lowering her head
B. Adjusting the white headscarf
C. Covering her mouth with both hands
D. Speaking to the camera
E. Wiping tears with her hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9PD3ciudpIE.mp4[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9PD3ciudpIE.mp4[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9PD3ciudpIE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=235[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a light yellow wall, there is a woman wearing a pink hat sitting with another woman with long hair wearing a dark blue outfit. When the subtitle mentions 'the old people that can't work anymore,' what is the woman with the pink hat wearing?
A. red short sleeves
B. red long sleeves
C. black long sleeves
D. pink short sleeves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mfS6gyP0mwo.mp4[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mfS6gyP0mwo.mp4[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mfS6gyP0mwo.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=237[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing gray clothes without showing their face is holding the handle of the vegetable knife with their right hand and pressing the back of the knife with their left hand, cutting garlic on a wooden board. What objects are present in this scene?
A. Silver bracelet
B. Watch
C. Vegetable knife without letters on the blade
D. Golden ring
E. Vegetable knife with letters on the blade
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 120/165 [04:35<02:05,  2.78s/it][32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9dSkvxS2EB0.mp4[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9dSkvxS2EB0.mp4[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9dSkvxS2EB0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=240[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with long hair, wearing a purple top and a necklace, is giving an introduction at the beginning of the video and later gives a lecture. What changes occur in the color of the wall behind her at these times?
A. White changes to blue
B. Olive green changes to white
C. White changes to olive green
D. Olive green changes to blue
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VFXJnbnN5ro.mp4[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VFXJnbnN5ro.mp4[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VFXJnbnN5ro.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=239[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen with white background and text, the right side is blank, the upper left section contains a circuit diagram, and the text information is located in both the middle left and bottom left sections. When the text information in the middle left and bottom left sections almost disappears, what change occurs to the circuit diagram in the upper left section?
A. Shrinks
B. Covered by a yellow overlay
C. Enlarges
D. Covered by a blue overlay
E. Disappears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 121/165 [04:38<02:02,  2.79s/it][32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = E7FSg22MdKE.mp4[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/E7FSg22MdKE.mp4[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: E7FSg22MdKE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=242[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a space setting, there is a yellow sun design in the center with the word 'Emission' below. In which of the following scenarios has this sun design appeared?
A. In the starry sky from a side view, there is a glaring white light in the center, surrounded by a halo of white light.
B. In a red cloud-like background, there is a cluster of bright light spots emitting strong light in the center.
C. In a black night sky, there is a purple circular object emitting purple light, with the words 'Protoplanetary Nebula' inscribed on it.
D. In a space background, there is a yellow design on the left side with radiating lines around it, and on the right side, there is a circular design with light blocked by something, with a yellow line attached to the sun.
E. In a blue background, the center is sparkling with densely packed light dots.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aVHAr8rc-Ks.mp4[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aVHAr8rc-Ks.mp4[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aVHAr8rc-Ks.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=241[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, blue curtains are hanging in the middle, and below the curtains is a parquet floor. After the subtitle mentions 'timeschedhereattheinem,' what is the first glowing object that appears?
A. lamp
B. flashlight
C. fire
D. firefly
E. torch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 122/165 [04:41<01:58,  2.76s/it][32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7rMgpExA4kM.mp4[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7rMgpExA4kM.mp4[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7rMgpExA4kM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=244[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the first concept mentioned after the man, sitting in front of the microphone wearing a black shirt with a pattern on the neck and a black cap and black-rimmed glasses, talks about evolution?
A. Human evolution differences
B. Animal fossilization
C. Vertebrate
D. Plant fossilization
E. Mythical creature
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAcbasjxljY.mp4[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAcbasjxljY.mp4[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAcbasjxljY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=243[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What happens first on the screen after the subtitle 'and I am getting ready to go' appears, featuring a man wearing a black cold hat with an English letter logo, dressed in black clothes, carrying a black backpack, and sporting a stubbly mustache?
A. Manufacturing airplane wheels in a factory.
B. An airplane model suspended by several steel wires is displayed.
C. The man sits in a car looking out the window at the sunlit grass and trees.
D. Manufacturing the interior of an airplane fuselage.
E. Viewing the city from above.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 123/165 [04:43<01:51,  2.66s/it][32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1R5uPaL0V-0.mp4[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1R5uPaL0V-0.mp4[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1R5uPaL0V-0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=246[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a green grass field, a man wearing a short-sleeved shirt is crouching on the ground, and in front of him is a standing prairie dog. What is this man doing?
A. Holding the prairie dog in his hand
B. Shaking hands with the prairie dog
C. Putting the prairie dog into a basket
D. Feeding the prairie dog
E. Putting clothes on the prairie dog
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RN2g9sRuJhA.mp4[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RN2g9sRuJhA.mp4[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RN2g9sRuJhA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=245[0m
[32m2025-11-29 13:17:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, a man is conversing with a woman. They are seated in a colorful room with plants and colorful curtains. The man is sitting on a white chair, and the woman is sitting on a sofa, holding a pillow. The man is wearing a round-neck T-shirt, and the woman is dressed in pink. Both have black hair. What type of outfit is the woman wearing?
A. coat
B. suit
C. dress
D. sweater
E. shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 124/165 [04:45<01:43,  2.52s/it][32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iHNjWhx3EaI.mp4[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iHNjWhx3EaI.mp4[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iHNjWhx3EaI.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=248[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a natural wood-colored floor, there is a man standing who is wearing a blue shirt and has tattoos on his arms. In front of him, there are cut tofu strips, and to the left, there is a white plate. To his right, there is an orange object. What is he doing?
A. Sprinkling salt on tofu
B. Cutting green peppers
C. Washing tofu strips
D. Frying tofu strips
E. Cutting tofu strips
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fvCrE5NCsts.mp4[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fvCrE5NCsts.mp4[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fvCrE5NCsts.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=247[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the curly-haired man wearing a gray hoodie picks up a box of pink-packaged tea leaves and the subtitle ‚Äòediting my video drinking some yamamoto‚Äô appears, which item is not present in the room behind him?
A. Black Overcoat
B. Coat Rack
C. Television
D. Tableware
E. Refrigerator
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 125/165 [04:47<01:38,  2.46s/it][32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tdA5atpqaAc.mp4[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tdA5atpqaAc.mp4[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tdA5atpqaAc.mp4 | Selected 6 frames[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=250[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 13:17:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top-right corner of the brown cutting board, there are several pieces of already-cut meat. On the left side of the cutting board, there is uncut meat on a metal plate. In the middle of the screen, a person is holding a pair of tongs. What is this person doing?
A. Placing the tongs on the cutting board
B. Placing the meat from the metal plate onto the cutting board
C. Using the tongs to grab vegetables
D. Placing the cut meat from the cutting board onto the metal plate
E. Putting the tongs into a bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 126/165 [04:48<01:18,  2.02s/it][32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7268936523481943297.mp4[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7268936523481943297.mp4[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7268936523481943297.mp4 | Selected 12 frames[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=252[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 13:17:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a little boy and a little girl. The little boy is wearing black clothes, the little girl is wearing white clothes, and there is also an older man in the background. At the same time, what subtitles appear with the little girl?
A. He told me.
B. h
C. thanks
D. thank you
E. so
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 127/165 [04:50<01:10,  1.85s/it][32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ysRFFN5nzqE.mp4[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ysRFFN5nzqE.mp4[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ysRFFN5nzqE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=254[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black-and-white scene, there is a grass hut. Inside the grass hut, there is a person holding a long gun without revealing their body. When the subtitle mentions 'to six enemy soldiers every day,' what happens in the scene?
A. The gun fired
B. A bird landed on the ground
C. The gun was placed on the ground
D. The person stood up from the grass hut
E. The gun was thrown out
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8905KCkLDYc.mp4[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8905KCkLDYc.mp4[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8905KCkLDYc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=249[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the rightmost side of the white screen, from top to bottom, there are two person frames. The top one is a black-haired woman sitting in front of a desk, and the bottom one is a woman wearing glasses. When the subtitle says 'get a little bit technical which you,' what type of clothing is the woman wearing glasses at the bottom wearing?
A. T-shirt
B. Leather jacket
C. Sweater
D. Swimsuit
E. Suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 128/165 [04:53<01:16,  2.07s/it][32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wvfctNd-Aio.mp4[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wvfctNd-Aio.mp4[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wvfctNd-Aio.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=256[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue seawater, there are black rocks. A sea turtle is swimming, and beside it, there is a man wearing black shorts following closely with a light on his body. What objects are present in this scene?
A. Diving mask
B. Cell phone
C. Oxygen tank
D. Wetsuit
E. Net
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QPth_xqBXGY.mp4[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QPth_xqBXGY.mp4[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QPth_xqBXGY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=251[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left is black text in English with a red icon below, and on the right side of the screen is a stack of newspapers. Below the news headline, on a ticker tape, there is a black background with yellow text reading 'BREAKING NEWS'. Which subtitles have appeared at the same time as this icon?
A. ‚ÄúGPS and health workers insisting that‚Äù
B. ‚Äúand 37 and the polling station that have‚Äù
C. ‚Äúthe QR code you'll see on screen during‚Äù
D. ‚Äúopened in Russia their elections taking‚Äù
E. ‚Äústart with the times world uh Pages 36‚Äù
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 129/165 [04:55<01:21,  2.27s/it][32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tdm72-vYxTs.mp4[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tdm72-vYxTs.mp4[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tdm72-vYxTs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=258[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a black PPT background with the title 'Interwar' on the slide. There are three white circles at the bottom containing drawings, and also a white line drawing of a tank. When the subtitle 'debate, as discussed in an article by Walther Nehring about anti-tank defense from 1936' appears, what happens to the tank?
A. The tank rotates
B. The tank gradually shrinks
C. The tank gradually enlarges
D. The tank disappears
E. The tank rotates in circles on the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eE5Z7gDbgVA.mp4[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eE5Z7gDbgVA.mp4[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eE5Z7gDbgVA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=253[0m
[32m2025-11-29 13:17:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a black-and-white background, three men appear on the screen. The man on the right has his hands crossed in front of his chest, the man on the left is wearing a hat and his finger is pointing to the upper right. The other man is staring sharply at the man on the right. What is the style of the hat worn by the man on the left when the subtitle 'There's no way I'm going down' appears?
A. a beanie
B. a top hat
C. a denim cap
D. a baseball cap
E. a beret
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ydm72ftJStQ.mp4[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ydm72ftJStQ.mp4[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ydm72ftJStQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=255[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there is a beige stool with a green bowl on top. The bowl contains yellow food, and there is a silver spoon inside the bowl. What happens after the spoon is placed in the bowl?
A. The spoon stirs around in the bowl
B. The spoon scoops up the food
C. New food is added to the green bowl
D. The green bowl is carried away
E. The spoon hits the green bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 130/165 [04:58<01:29,  2.55s/it][32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yz3lOAe32Tw.mp4[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yz3lOAe32Tw.mp4[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yz3lOAe32Tw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=260[0m
[32m2025-11-29 13:17:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white background PPT, there is a yellow icon and black English text in the top left corner. In the center, there are black English letters saying 'Thank you'. When the caption 'here' appears, what object appears on the screen?
A. a man wearing glasses
B. a sphere
C. black English letters
D. a round shape
E. a cube
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = npLd4WTSQsM.mp4[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/npLd4WTSQsM.mp4[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: npLd4WTSQsM.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=257[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:17:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the room with the yellow walls, on the right side, there's a rectangular window with rounded corners. In the middle, there is a hemispherical object and a man wearing a gray coat. What action did the man take before the subtitle mentioned 'to smoke'?
A. Steve holding a packed paper box
B. A man lying in the bathtub with a towel over his eyes
C. Donna holding a baby, with Steve standing behind her
D. Jessica stroking Ted's mechanical arm
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 131/165 [05:01<01:23,  2.47s/it][32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yFAuXmcGk2Y.mp4[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yFAuXmcGk2Y.mp4[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yFAuXmcGk2Y.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=262[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On this yellow cutting board, two chicken breasts are placed side by side. After this person places the chicken breasts horizontally, what does he do next?
A. He throws the chicken breasts away.
B. He puts the chicken breasts into a pot.
C. He does nothing.
D. He uses a knife to cut the two whole chicken breasts into evenly sized small pieces.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WmrwQMFZLqI.mp4[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WmrwQMFZLqI.mp4[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WmrwQMFZLqI.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=259[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene with a white background, there are two 'Âè™' characters sketched incorrectly on the bottom left of the screen. When the scene changes to an image with multiple 'Âè™' characters sketched, there are many red, dark blue, and green arrows. What changes occur to the 'Âè™' character in the bottom left corner at this time?
A. Green characters and sketches appeared above the 'Âè™' character
B. The 'Âè™' character turned black
C. The 'Âè™' character turned green
D. The bottom part of the 'Âè™' character disappeared
E. Blue characters and sketches appeared above the 'Âè™' character
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 132/165 [05:03<01:19,  2.42s/it][32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NexB4vj8_54.mp4[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NexB4vj8_54.mp4[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NexB4vj8_54.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=264[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a person wearing a black apron with the word 'TASTY' on it. They are wearing a ring on their left hand which is resting on a dough. There is a wooden board on the table. What is the shape of the dough in the video?
A. Square
B. Oval
C. Round
D. Triangular
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WM78_KqcrSY.mp4[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WM78_KqcrSY.mp4[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WM78_KqcrSY.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=261[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the person in the video doing when a bowl of white yogurt appears above a transparent glass container filled with beaten yellow egg liquid on a dark red wooden table?
A. Pouring the yogurt into the container with egg liquid
B. Stirring the yogurt and egg liquid
C. Drinking the yogurt
D. Stirring the yogurt
E. Stirring the egg liquid
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 133/165 [05:05<01:15,  2.35s/it][32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7288701821369978144.mp4[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7288701821369978144.mp4[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7288701821369978144.mp4 | Selected 8 frames[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=266[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 13:17:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scenarios is in the correct order?
A. First, a map block appears on the left with details, then the left side shows an icon, the right side shows a screen with two icons, and finally, the left shows many small drones and the right side top shows a screen with a few small drones to conclude.
B. First, the left side shows many small drones, the right side top shows a screen with a few small drones, then a detailed map block appears on the left, and finally, as the conclusion, the left shows an icon and the right shows two icons.
C. First, a map block appears on the left with details, then the left side shows many small drones, the right side top shows a screen with a few small drones, and finally, the left side shows an icon and the right side shows two icons to conclude.
D. First, the left shows an icon, the right side shows a screen with two icons, then the left side shows many small drones, the right side top shows a screen with a few small drones, and finally, the left side shows a detailed map block.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _ZIa6SEJEyg.mp4[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_ZIa6SEJEyg.mp4[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _ZIa6SEJEyg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=263[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes in the video is correct?
A. First, take a bottle of juice from the drinks cabinet, then use chopsticks to pick up a reddish food item from the white plate, and finally pick up an orange from the dining table.
B. First, pick up an orange from the dining table, then take a bottle of juice from the drinks cabinet, and finally use chopsticks to pick up a reddish food item from the white plate.
C. First, pick up an orange from the dining table, then use chopsticks to pick up a reddish food item from the white plate, and finally take a bottle of juice from the drinks cabinet.
D. First, take a bottle of juice from the drinks cabinet, then pick up an orange from the dining table, and finally use chopsticks to pick up a reddish food item from the white plate.
E. First, use chopsticks to pick up a reddish food item from the white plate, then take a bottle of juice from the drinks cabinet, and finally pick up an orange from the dining table.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 134/165 [05:07<01:07,  2.17s/it][32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6d-EVupvWzU.mp4[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6d-EVupvWzU.mp4[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6d-EVupvWzU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=268[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against the white background, there are texts in both pink and black colors. In the bottom right corner of the screen, there is a woman with long black hair, wearing a pink outer garment and a black inner garment. She is raising both hands with palms facing inwards. Before the subtitle mentions 'see this topic on final exams so if you,' what number appears in the screen's bottom right corner?
A. 3
B. 4
C. 7
D. 6
E. 5
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fySqsm5kNl4.mp4[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fySqsm5kNl4.mp4[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fySqsm5kNl4.mp4 | Selected 4 frames[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=265[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 13:17:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a grey hat and black clothes is sitting on an off-white chair. The chair to his right is empty, and beside the empty chair, there is a potted plant. The wall behind him is blue. Among the photos that the man is showing, which photo appears first?
A. A solo photo
B. A group photo of four people
C. A group photo of five people
D. A group photo of two people
E. A group photo of three people
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 135/165 [05:09<01:05,  2.19s/it][32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F4bDyyEO4PU.mp4[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F4bDyyEO4PU.mp4[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F4bDyyEO4PU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=270[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bright sunny outdoor setting, there is a hole in the ground. When a man wearing a black short-sleeve shirt and a hat appears in front of the hole for the first time, holding a wooden stick, what does he do?
A. He kneels down.
B. He jumps into the hole.
C. He throws the wooden stick into the hole.
D. He steps over the hole.
E. He throws the wooden stick outside the hole.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _BDzMutoy6A.mp4[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_BDzMutoy6A.mp4[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _BDzMutoy6A.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=267[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a wooden table, there is a pan with light blue handles on both sides. Inside the pan, there is yellow oil and four sesame balls. There is a silver strainer on top of the pan. When the subtitles 'Also, you'll see as we fry these, they'll puff up' appear, what is happening on the screen?
A. Boiling sesame balls
B. Pan-frying sesame balls
C. Eating sesame balls
D. Frying sesame balls
E. Stir-frying sesame balls
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=269[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the cooking tutorial, which of the following sequences of steps is correct?
A. First, demonstrate how to use purple sweet potatoes and red peppers to make a side dish; then demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; finally, demonstrate how to use beef, green onions, and related seasonings to make beef patties.
B. First, demonstrate how to use beef, green onions, and related seasonings to make beef patties; then demonstrate how to use purple sweet potatoes and red peppers to make a side dish; finally, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan.
C. First, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; then demonstrate how to use beef, green onions, and related seasonings to make beef patties; finally, demonstrate how to use purple sweet potatoes and red peppers to make a side dish.
D. First, demonstrate how to use purple sweet potatoes and red peppers to make a side dish; then demonstrate how to use beef, green onions, and related seasonings to make beef patties; finally, demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan.
E. First, demonstrate how to use beef, green onions, and related seasonings to make beef patties; then demonstrate how to press the beef patties into cake shapes, coat them with flour, and fry them in a pan; finally, demonstrate how to use purple sweet potatoes and red peppers to make a side dish.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 136/165 [05:12<01:12,  2.49s/it][32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JASFwBtUK40.mp4[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JASFwBtUK40.mp4[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JASFwBtUK40.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=272[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the curtain, there is a transparent lectern with red text on it. Next to the lectern, a person wearing a blue coat is raising their right hand and speaking with their head lowered. What item is present in this scene?
A. Tie
B. Belt
C. Microphone
D. Display Screen
E. Mobile Phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AxciimuEZAc.mp4[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AxciimuEZAc.mp4[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AxciimuEZAc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=271[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a laboratory shown in the video, there are many experimental instruments and devices on an olive-colored desk. The window behind is white. When the subtitle mentions 'At this moment that we are defining and redefining', which person appears on the screen at this moment?
A. Jack
B. Patrick Craine
C. John
D. Andr√©s Jacque
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 137/165 [05:15<01:11,  2.55s/it][32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0oALTLKRWBA.mp4[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0oALTLKRWBA.mp4[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0oALTLKRWBA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=274[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a building made of glass, there are some green plants and benches around, as well as red and orange striped sculptures. A man is walking down the steps on a marble-paved ground. In front of him, there is a black sculpture covered in raised dots. When the phrase 'sculpture garden looking at' is mentioned, what is this man wearing?
A. blue long-sleeve shirt
B. blue vest
C. blue short-sleeve jacket
D. blue T-shirt
E. blue jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5zbV24vyO44.mp4[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5zbV24vyO44.mp4[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5zbV24vyO44.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=273[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a blonde girl appears, standing high up with a rose in her hand, overlooking the city. Then, a shirtless man wearing black shorts stands in front of a woman dressed in a bikini. There also appears a segment with three people on a boat traveling on the sea. What is the order of these scenes?
A. First, a blonde girl appears, standing high up with a rose in her hand, overlooking the city. Then, a shirtless man wearing black shorts stands in front of a woman dressed in a bikini, and a segment with three people on a boat traveling on the sea appears.
B. First, a shirtless man wearing black shorts stands in front of a woman dressed in a bikini. Then, a blonde girl appears, standing high up with a rose in her hand, overlooking the city. Finally, a segment with three people on a boat traveling on the sea appears.
C. First, a segment with three people on a boat traveling on the sea appears. Then, a shirtless man wearing black shorts stands in front of a woman dressed in a bikini. Finally, a blonde girl appears, standing high up with a rose in her hand, overlooking the city.
D. First, a blonde girl appears, standing high up with a rose in her hand, overlooking the city. Then, a shirtless man wearing black shorts stands in front of a woman dressed in a bikini. Finally, a segment with three people on a boat traveling on the sea appears.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 138/165 [05:19<01:17,  2.87s/it][32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2W2ZkYARds4.mp4[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2W2ZkYARds4.mp4[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2W2ZkYARds4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=276[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner of the screen, there's a frame with a blue background wall, and on the wall, there are black clothes and a bag hanging, along with a man with short black hair. After this man says 'by a thousand samples of the test set,' what does he do next?
A. Touches the brain with a hand
B. One hand extends with the index finger pointing upwards
C. Both hands extend with index fingers pointing upwards
D. Both hands spread outwards
E. One hand touches the forehead
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Aau-XoIebno.mp4[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Aau-XoIebno.mp4[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Aau-XoIebno.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=275[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:17:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a flat ground, there is a building with a brick wall behind, a car with an open trunk on the left, and a police officer with a police dog on the right. What happened when the police dog appeared?
A. The police dog bit a tire.
B. The police officer drove away.
C. The police dog smelled the brick wall.
D. The police dog jumped into the car's trunk.
E. The police officer closed the car's trunk.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:17:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 139/165 [05:22<01:16,  2.94s/it][32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = O6UedmnRJc0.mp4[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/O6UedmnRJc0.mp4[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: O6UedmnRJc0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=278[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:17:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are two men sitting on a stage. The man on the left is wearing a black jacket, black pants, and khaki shoes. He is crossing his legs and holding a microphone resting on his leg. The man on the right is wearing glasses, a khaki jacket, black pants, and olive shoes. He is also crossing his legs. What is he doing with his right hand?
A. Pointing to the ground
B. Holding a bottle of mineral water and drinking it
C. Scratching his head
D. Waving to the audience
E. Adjusting his glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = j6beJTHUT_c.mp4[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/j6beJTHUT_c.mp4[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: j6beJTHUT_c.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=277[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background features sunlit green trees and a doorway. A man wearing a white short-sleeved shirt, black pants, and sporting a goatee is sitting on a white sofa outside. In what other scenes does this man appear?
A. On a rooftop terrace
B. In the driver's seat of a car illuminated by sunlight
C. Inside a cafe
D. Inside a library
E. Inside a museum
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 140/165 [05:24<01:09,  2.80s/it][32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = F2OhCCEIOcU.mp4[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/F2OhCCEIOcU.mp4[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: F2OhCCEIOcU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=280[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a woman with long black hair is sitting on the left, and a woman with yellow hair is sitting on the right. The woman with black hair is putting makeup on the woman with yellow hair. A man in yellow and white clothing is standing in the middle of the screen. After the subtitle 'Lisa is the female lead, replacing Polina. While getting ready, Lisa told her boyfriend, Alexey,', what does the woman with long black hair do?
A. Running
B. Leaving
C. Drinking water
D. Eating something
E. Fixing the yellow-haired woman's hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -PnG8Jp2gFw.mp4[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-PnG8Jp2gFw.mp4[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -PnG8Jp2gFw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=279[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, the man wearing red short sleeves and sunglasses is holding a phone in his right hand, and sitting outside with a few green plants in the background. In which other scene does this man appear?
A. By the seaside
B. Inside a room with a TV in the background
C. Inside a milk tea shop
D. Inside a fried chicken shop
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 141/165 [05:27<01:05,  2.72s/it][32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NexB4vj8_54.mp4[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NexB4vj8_54.mp4[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NexB4vj8_54.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=282[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a mustard-yellow wall hangs a television screen, which displays a webpage with black and white images and some document icons. A man with a yellow and black name tag is speaking. He is facing towards the right side of the screen, wearing a military green and black camouflaged uniform with a black and white accessory on the sleeve. What happens when he mentions: 'a gimbal now there's gimbals that stab'?
A. The man opens one hand and clenches the other into a fist
B. The man turns to face the screen
C. The man brushes his hair
D. The man takes a sip of water
E. The man changes his jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QpDL3mopnWM.mp4[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QpDL3mopnWM.mp4[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QpDL3mopnWM.mp4 | Selected 4 frames[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=281[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 13:18:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a group of people on the screen, with a hillside and some scattered grass in the background. Two smaller individuals wearing yellow helmets use weapons to knock down a man with a grey helmet and beard to the ground. Where else does the man with the grey helmet and beard appear in the video?
A. On the bed
B. On horseback
C. In the palace
D. In the office
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gJijNOktmoI.mp4[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gJijNOktmoI.mp4[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gJijNOktmoI.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=283[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a dark red table, there is a round white plate holding a yellow cake decorated with white powdered sugar. When a silver serrated knife appears above the cake, what is the video creator doing?
A. Eating the cake
B. Setting the table
C. Cutting the cake
D. Cleaning the utensils
E. Decorating the cake
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 142/165 [05:29<00:58,  2.54s/it][32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=284[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black background, there are two screens. On the left, there is a white car passing by on a road in front of a construction building. On the right, there are two people conversing on a red carpet stage. What objects are present in this screen?
A. helicopter
B. green stone lion
C. black car
D. traffic light
E. handgun
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 143/165 [05:31<00:54,  2.49s/it][32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5tN9hyfdkaE.mp4[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5tN9hyfdkaE.mp4[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5tN9hyfdkaE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=286[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a sea with jade-green water, a sky that is azure blue, small boats floating on the jade-green water, and a man with curly hair standing on the yellow sandy beach, wearing a grey short-sleeve shirt. In which of the following scenes has the man with curly hair, who is wearing a grey short-sleeve shirt, appeared before?
A. On the beach during a rainstorm
B. In front of an off-white wall with a hanging painting
C. In a peaceful park
D. In a pool with large turtles
E. In a restaurant with yellow curry
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = L-XGTMusZvc.mp4[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/L-XGTMusZvc.mp4[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: L-XGTMusZvc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=285[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What color pants is the woman, who is walking away from the camera on a street decorated with red lanterns, wearing when she says in the subtitles 'me to try the viral TikTok Foods in' while wearing a brown top and with long hair?
A. Gray
B. Black
C. Blue
D. White
E. Olive
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 144/165 [05:34<00:52,  2.50s/it][32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7318074908645264645.mp4[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7318074908645264645.mp4[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7318074908645264645.mp4 | Selected 8 frames[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=288[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a gray background, there are two lines of English sentences in white font on a red and black base in the upper left corner, and five white circular icons in the middle. What happened after the subtitle 'proper channels for requesting close air support' appeared?
A. A fighter jet crashes from the sky
B. A fighter jet crashes into the sea
C. A pilot jumps off the fighter jet
D. A fighter jet is engaging in ground combat
E. A fighter jet is hit by artillery
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kOZnpwI2hIM.mp4[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kOZnpwI2hIM.mp4[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kOZnpwI2hIM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=287[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A light-colored building is located on the left side of the screen, with exquisite carvings on its walls. At the entrance at the front of the building, a red UNIQLO sign is hanging. The entrance area is surrounded by a crowd of pedestrians. After the camera finishes filming the entrance of UNIQLO, what does it film next?
A. It films the scene inside the UNIQLO store.
B. It films the art museum next door.
C. It films the library next door.
D. It films the hotel next door.
E. It films the restaurant next door.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 145/165 [05:35<00:41,  2.09s/it][32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8hhcFRoR0mw.mp4[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8hhcFRoR0mw.mp4[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8hhcFRoR0mw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=290[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Outside a house in Yangguanmingyao, a man wearing a white short-sleeved shirt is sitting on a chair. Behind the man, there are green grass, trees, and a house. Next to the man, there is an empty chair. The man has a tattooed arm and is wearing a watch and a bracelet on one hand, while the other hand is wrapped with a white bandage. After the subtitle 'Music' appears, what characters show up on the screen?
A. A man with a black backpack
B. A man wearing a yellow short-sleeved shirt
C. A man wearing a red shirt and a man wearing a blue short-sleeved shirt
D. A shirtless man
E. A man wearing a blue shirt and a man wearing a black short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7rMgpExA4kM.mp4[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7rMgpExA4kM.mp4[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7rMgpExA4kM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=289[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a brown floor, a woman with black hair, wearing a white top and a green skirt, is kneeling on a white mat. On the leftmost side of the white table in front of her, there's a metal pot. What is this woman doing?
A. Making dumplings
B. Watching TV
C. Listening to music
D. Drinking water
E. Stir-frying vegetables
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 146/165 [05:37<00:41,  2.17s/it][32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lNReCCShKJQ.mp4[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lNReCCShKJQ.mp4[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lNReCCShKJQ.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=292[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:18:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Next to a large building, a tank is driving on a desolate street with signs of explosion in the background. In which of the following scenes has this tank appeared?
A. On a street with many pedestrians
B. On a square during a military parade
C. On a square during a rainy day
D. On a desolate grassland with dried grass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 147/165 [05:38<00:33,  1.84s/it][32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2zZSMnGLGao.mp4[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2zZSMnGLGao.mp4[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2zZSMnGLGao.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=294[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a white airplane is taxiing on the runway at the airport, with a backdrop of golden hills and an orange sky. What happens first on screen after the caption 'water on runway' appears?
A. Two men in work uniforms are manufacturing an airplane in a workshop.
B. At night, a man leans out from the front of a parked airplane to talk to the camera.
C. The airplane skids on a water puddle on the runway, splashing a huge spray of water.
D. A hand is drawing two buildings with a river flowing between them on white paper.
E. A person is working in a warehouse filled with boxes of paper.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = v0QLje6xYgA.mp4[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/v0QLje6xYgA.mp4[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: v0QLje6xYgA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=291[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a green plant in the background, a woman with long hair draped over her shoulders is holding a yellow book with a square cover featuring cartoon characters. What is this woman doing?
A. Throwing the book into the trash can
B. Turning the back of the book towards the camera
C. Picking up another book with a blue cover
D. Watering the plant
E. Holding the book facing the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 148/165 [05:41<00:34,  2.01s/it][32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yqejTvYILlA.mp4[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yqejTvYILlA.mp4[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yqejTvYILlA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=296[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a pink stage, there's a girl with long black hair wearing a white top, white short skirt, and white knee-high stockings. When she appears for the first time, what is she doing?
A. Touching her face with her palm
B. One leg kneeling on the ground
C. Kneeling with her right hand supporting her chin
D. Kneeling with both hands resting on her left leg
E. Both legs kneeling on the ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HQns-h_82qU.mp4[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HQns-h_82qU.mp4[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HQns-h_82qU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=293[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the street, in the distance are roadside houses and cars driving on the road. Nearby is a man in a black T-shirt talking to the camera. To the left behind the man are piles of filled black garbage bags. What did the man do after finishing speaking?
A. Touched his hair
B. Took a sip of iced coffee
C. Turned and walked towards the garbage bags
D. Waved his left hand
E. Stuck out his tongue at the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 149/165 [05:44<00:39,  2.46s/it][32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7109221563697876225.mp4[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7109221563697876225.mp4[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7109221563697876225.mp4 | Selected 15 frames[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=298[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 13:18:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the animated scene, the left side features a pitch-black sky, the middle shows a cliff face that is currently exploding, and the right side is a rock wall illuminated by a red light. What event occurred after the explosion?
A. A man lifted up a cane
B. A woman fell to the ground
C. A tiger fell to the ground
D. A panda took out a bamboo stick
E. A panda fell to the ground
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9S9i12n0TIw.mp4[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9S9i12n0TIw.mp4[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9S9i12n0TIw.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=295[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a wooden table, there is a wooden cutting board covered with a layer of white paper. There are six pieces of tofu on the cutting board with red sauce spread on top. On the right side of the screen, there is a pink brush. What happens in the screen at this moment?
A. The tofu pieces are being stir-fried
B. The brush is applying oil to the tofu pieces
C. The brush is applying sauce to the tofu pieces
D. The tofu pieces are being fried
E. The tofu pieces are being baked
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 150/165 [05:46<00:33,  2.26s/it][32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbNyMSwoT5A.mp4[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbNyMSwoT5A.mp4[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbNyMSwoT5A.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=300[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A group of people is advancing down the mountain. A person without a helmet is riding an elephant, followed by a group of people wearing helmets. A soldier is waving a long sword. Who is the person waving the long sword?
A. The person with a scabbard but without a helmet
B. The person wearing a helmet without a scabbard
C. The person without a helmet and without a shield
D. The person riding an elephant at the front
E. The person wearing a helmet without a shield
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 151/165 [05:48<00:31,  2.25s/it][32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mHARxee4EzQ.mp4[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mHARxee4EzQ.mp4[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mHARxee4EzQ.mp4 | Selected 6 frames[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=302[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the map with black lines on white paper first appears, what is the sweaty arm doing in the scene?
A. Spreading the map with open hands
B. Drawing on the map with a pen
C. Pointing at the map with a finger
D. Placing objects on the map
E. Painting the map black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RN2g9sRuJhA.mp4[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RN2g9sRuJhA.mp4[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RN2g9sRuJhA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=297[0m
[32m2025-11-29 13:18:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing glasses, puffing on a cigarette, dressed in a grey long-sleeve shirt with rolled-up sleeves, and holding a handful of red feed is feeding a fish with a big mouth. In which of the following places did he appear?
A. On a boat being blown by the wind
B. In a crowded talent show venue
C. On a flying airplane
D. In a quiet park
E. In a boxing ring
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 152/165 [05:49<00:23,  1.81s/it][32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0mEN5Jf2hU0.mp4[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0mEN5Jf2hU0.mp4[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0mEN5Jf2hU0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=304[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white tiles, there is a gray countertop. Next to the countertop stands a man wearing a blue checkered shirt, with tattoos on his arms. Beside him, there is a white bowl containing potatoes. What is he doing?
A. Washing the tomatoes
B. Peeling the potatoes
C. Cutting the potatoes
D. Washing the green peppers
E. Washing the potatoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rMXJOKhf_AA.mp4[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rMXJOKhf_AA.mp4[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rMXJOKhf_AA.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=299[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x4e5cd100] mmco: unref short failure
[32m2025-11-29 13:18:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The long-haired woman wearing a blue and white floral pattern long-sleeve shirt is speaking in the center of the screen. After the subtitle 'For question two, label each molecule as chiral or achiral' appears, what does she do with her hands?
A. Extends three fingers
B. Extends five fingers
C. Extends two fingers
D. Extends four fingers
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 153/165 [05:52<00:23,  1.99s/it][32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pJI5ZU6wxqg.mp4[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pJI5ZU6wxqg.mp4[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pJI5ZU6wxqg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=306[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man dressed as a clown is standing in front of a brick wall. The man has a red ball on his nose and is adorned with red decorations on his face. He is wearing a flowery ring and a purple coat. What did the man do the first time he appeared?
A. The man ran to the left side.
B. The man kept waving his hands.
C. The man wiggled his waist up and down.
D. The man spread his hands and climbed the wall.
E. The man's flowery ring fell on the ground.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mOiEOs3ZlT8.mp4[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mOiEOs3ZlT8.mp4[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mOiEOs3ZlT8.mp4 | Selected 6 frames[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=301[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 13:18:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a woman explaining a panel of a sacrificial altar painting is shown. Then, a painting with only two women appears. Finally, another panel depicting a sacrificial altar painting is shown.
B. First, a painting with only two women appears. Then, a panel depicting a sacrificial altar painting is shown. Finally, a woman explaining this panel appears.
C. First, a panel depicting a sacrificial altar painting is shown. Then, a woman explaining this panel appears. Finally, a painting with only two women appears.
D. First, a painting with only two women appears. Then, a woman explaining a panel of a sacrificial altar painting is shown. Finally, the video ends with another panel depicting a sacrificial altar painting.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UO_6TQnnOxM.mp4[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UO_6TQnnOxM.mp4[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UO_6TQnnOxM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=303[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a lush tree on the screen. Beside it, there is a small wooden house. A man wearing a hat and dressed in yellow and black clothing is looking towards the camera while riding an electric vehicle. Some people are chatting by the roadside. What happens after a white car passes through the screen?
A. A white car appears
B. An elderly person holding a palm fan appears
C. A little girl with a backpack appears
D. A large truck appears
E. A person wearing a helmet appears riding a motorcycle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 154/165 [05:55<00:25,  2.34s/it][32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7270058010888768770.mp4[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7270058010888768770.mp4[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7270058010888768770.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=308[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:18:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a phone, and the screen of the phone shows the number 911. When the subtitle "However, the girl used a disposable phone without a chip, making it impossible to locate her" appears, what change happens to the text in the middle of the phone screen?
A. Changes from the number 911 to the number 129
B. Changes from the number 911 to the blue text 'New Voicemail RAUL'
C. Changes from the number 911 to the number 119
D. Changes from the number 911 to the blue text 'save me'
E. Changes from the number 911 to the number 110
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 155/165 [05:56<00:20,  2.01s/it][32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7074483613273754882.mp4[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7074483613273754882.mp4[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7074483613273754882.mp4 | Selected 5 frames[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=310[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 13:18:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The video shows the interior of a museum with two white light fixtures. Many white cabinets containing different artifacts are placed on the dark-colored floor. On the right side of the screen, a woman is sitting in a room illuminated by white lights, shown in a small video frame. What material is the protective cover placed over the artifacts on the cabinet made of?
A. Ceramics
B. Plastic
C. Glass
D. Iron
E. Acrylic
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = k4jiEuZbN-4.mp4[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/k4jiEuZbN-4.mp4[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: k4jiEuZbN-4.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=305[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside a floor-to-ceiling window with a view of tall buildings there is a beauty room with pink walls and a white beauty bed. When the subtitle 'Okay, let's get started' appears, what objects are present in the scene?
A. false eyelashes
B. face mask
C. powder puff
D. lighting stand
E. mirror
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 156/165 [05:57<00:15,  1.69s/it][32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7302913253959617797.mp4[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7302913253959617797.mp4[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7302913253959617797.mp4 | Selected 3 frames[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=312[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 3 specific frames[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 3 custom frames[0m
[32m2025-11-29 13:18:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 3 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue sky and white clouds, there is a vast sea stretching to the horizon. On the sea's surface, there are two huge and oddly shaped rocks. A person is on the sandy shore; what is this person doing?
A. Building a sandcastle on the beach
B. Lying on the beach resting
C. Walking on the beach
D. Squatting on the beach catching crabs
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 157/165 [05:58<00:11,  1.38s/it][32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7269006883380399362.mp4[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7269006883380399362.mp4[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7269006883380399362.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=314[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a man wearing a black hoodie yawning; then, a man holding a white sign with the red text 'I HATE'; finally, two dark-skinned children lying at the doorway looking outside.
B. First, two dark-skinned children lying at the doorway looking outside; then, a man wearing a black hoodie yawning; finally, a man holding a white sign with the red text 'I HATE'.
C. First, a man holding a white sign with the red text 'I HATE'; then, a man wearing a black hoodie yawning; finally, two dark-skinned children lying at the doorway looking outside.
D. First, a man holding a white sign with the red text 'I HATE'; then, two dark-skinned children lying at the doorway looking outside; finally, a man wearing a black hoodie yawning.
E. First, two dark-skinned children lying at the doorway looking outside; then, a man holding a white sign with the red text 'I HATE'; finally, a man wearing a black hoodie yawning.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 158/165 [05:58<00:08,  1.25s/it][32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NMHmqgO04rU.mp4[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NMHmqgO04rU.mp4[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NMHmqgO04rU.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=316[0m
[32m2025-11-29 13:18:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides. Next, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel. Lastly, a person is washing a small knife covered in fresh blood at a sink.
B. First, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel. Next, a person is washing a small knife covered in fresh blood at a sink. Finally, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides.
C. First, a person is washing a small knife covered in fresh blood at a sink. Next, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel. Finally, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides.
D. First, a person is washing a small knife covered in fresh blood at a sink. Next, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides. Lastly, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel.
E. First, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides. Next, a person is washing a small knife covered in fresh blood at a sink. Finally, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSeq-nVSY_E.mp4[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSeq-nVSY_E.mp4[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSeq-nVSY_E.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=307[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man in a dark suit is handling food on a cutting board with a knife. He is wearing sunglasses, and behind him are various kitchen utensils and white cabinets. On the right side of the table, there is a bottle with green packaging containing cooking oil. In the lower left and right corners of the screen, there are images of two men from the waist up. When the subtitle 'Sheesh...' appears, what is the lighting on the ceiling like?
A. Round wall lamp
B. Triangular wall lamp
C. Square wall lamp
D. Gold pendant lamp
E. Silver pendant lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 159/165 [06:01<00:10,  1.72s/it][32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Msz128EJeWE.mp4[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Msz128EJeWE.mp4[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Msz128EJeWE.mp4 | Selected 9 frames[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=318[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white-background PPT, the top left corner is the black English text '1st Pass: Contrastive Loss'. Below the dashed box in the middle of the screen, which subtitles have appeared at the same time as a horizontal arrow pointing to the right?
A. "the same part this it's not a very good"
B. "you're going to get a very low value for"
C. "image so when you uh so they do not work"
D. "well for U detection at Region level"
E. "pi and then what you're going to do is"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7245035133688892714.mp4[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7245035133688892714.mp4[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7245035133688892714.mp4 | Selected 7 frames[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=309[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 13:18:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a bald man wearing a dark blue shirt and a suit, with a necklace, what did he do the first time he appeared?
A. He placed his hands behind his back
B. He made an X gesture with his hands
C. He placed his hands by his sides
D. He raised his hands above his head
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 160/165 [06:02<00:07,  1.51s/it][32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = x1FkhxMMIcg.mp4[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/x1FkhxMMIcg.mp4[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: x1FkhxMMIcg.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=320[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, two rows of sliced green onions are neatly arranged on a silver baking tray, with lemon slices placed on top of the green onions. Which of these ingredients appears first in the video?
A. Lemon slices
B. Neither of them appear
C. Both appear at the same time
D. Sliced white green onions
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i8TJ7RgimNM.mp4[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i8TJ7RgimNM.mp4[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i8TJ7RgimNM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=311[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, the male host speaks, then the female host and the teacher have an online discussion, and finally, the female host introduces the teacher.
B. First, the male host speaks, then the female host introduces the teacher, and finally, the female host and the teacher have an online discussion.
C. First, the female host introduces a teacher, then the female host and the teacher have an online discussion, and finally, a male host speaks.
D. First, the female host and the teacher have an online discussion, then the female host introduces the teacher, and finally, a male host speaks.
E. First, the female host and the teacher have an online discussion, then the male host speaks, and finally, the female host introduces the teacher.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 161/165 [06:05<00:07,  1.84s/it][32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0rWA-p4p5IM.mp4[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0rWA-p4p5IM.mp4[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0rWA-p4p5IM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=322[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a bright room, there is a woman wearing earrings and a necklace, dressed in green, sitting with an elderly woman wearing a gray sleeveless top with a necklace. When the woman in green, with her hands open and the backs of her hands facing outwards, naturally hangs them down, what is the elderly woman doing?
A. Raising hand
B. Standing up
C. Swaying left and right
D. Listening attentively
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6HTO2SOxUc.mp4[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6HTO2SOxUc.mp4[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6HTO2SOxUc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=313[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white surface, a hand places a transparent bowl on the table with an unpeeled egg inside. Where has the egg appeared?
A. In a cake
B. In a silver metal box
C. In a blue plastic container
D. In a black pot
E. In the refrigerator
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 162/165 [06:07<00:05,  1.95s/it][32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8_MG-E8QlBM.mp4[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8_MG-E8QlBM.mp4[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8_MG-E8QlBM.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=324[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There's a black surface on the table with a plate on it, inside the plate there's a multicolored dotted face mask, next to it there's a black and green cucumber model, and a yellow label with the word 'Blondies'. What other objects appear in the video?
A. Piano
B. Mobile phone
C. Television
D. Leaf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JASFwBtUK40.mp4[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JASFwBtUK40.mp4[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JASFwBtUK40.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=315[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white walls in the video, there are several brown experiment tables. A man wearing a blue and white shirt and black glasses is explaining. When the subtitle mentions 'I can. The higher I lift it, the faster the explanation goes,' which item is not present in the room at this time?
A. Some transparent tubes
B. Yellow pipes
C. Some white pipes
D. Black glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = IN0osLg-Mn8.mp4[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/IN0osLg-Mn8.mp4[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: IN0osLg-Mn8.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=317[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the scorching sun, a few people are standing on the yellow earth outside the home. On the right side of the screen, there is a parked yellow cart. In front of the camera, there are two men. The man on the left is wearing a black top with a distressed expression, while the man on the right is wearing a black and white striped top with rolled-up sleeves and has both hands placed on the man on the left. When the subtitle 'was being comforted by everyone who saw' appears, what is the man on the right doing?
A. Chatting with the man
B. Waving to the camera
C. Comforting the distressed man
D. Distributing food to the needy
E. Wiping the man's tears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 163/165 [06:11<00:04,  2.47s/it][32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d5JlCEDlHGE.mp4[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d5JlCEDlHGE.mp4[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d5JlCEDlHGE.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=326[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing a black jacket is pressing down another person wearing a checkered jacket on the ground. When the subtitle 'The prideful Frank refuses to cooperate, and is fatally stabbed and left for dead in the desert' appears, which of the following items is present?
A. hat
B. earring
C. computer
D. phone
E. watch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7275485247351901442.mp4[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7275485247351901442.mp4[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7275485247351901442.mp4 | Selected 9 frames[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=319[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 13:18:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white, square-patterned floor, there is a person with some white hair, wearing a black short-sleeve shirt with red designs. He also has a beard. What is this man doing?
A. Reading a book
B. Fishing
C. Drinking water
D. Playing piano
E. Talking
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 164/165 [06:14<00:02,  2.59s/it][32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7298820532466683142.mp4[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7298820532466683142.mp4[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7298820532466683142.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=328[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a building, a man wearing a green coat throws a punch towards a man in black clothes. The man in black dodges, and when the man in the green coat and the subtitle 'Accidentally, the eldest brother‚Äôs punch shattered everything about the sixth sibling.' appear simultaneously, what change occurs to him?
A. He takes off his outer coat.
B. He falls to the ground.
C. He holds his arm with his hand.
D. He looks to the side as he moves past.
E. He raises both hands above his head.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mFliMGufpwc.mp4[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mFliMGufpwc.mp4[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mFliMGufpwc.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=321[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the yellowish vast terrain, when the words 'TRY TO VIEW IT FROM' appear on the screen, and when it mentions 'Try to view it from space if you can', what object is present on the screen?
A. irregular structured object
B. circular structured object
C. square structured object
D. bead-like circular structured object
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [06:16<00:00,  2.38s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [06:16<00:00,  2.28s/it]
[32m2025-11-29 13:18:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a woman with short black hair on the screen, wearing glasses with purple-red frames, a green undershirt, and a white outer coat, with a black ornament on the collar. What items have appeared on the screen?
A. mobile phone
B. bracelet
C. ring
D. watch
E. earring
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8k6M0HD162k.mp4[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8k6M0HD162k.mp4[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8k6M0HD162k.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=323[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, some people are listening to a person on the podium explaining concepts related to projectiles. The concepts include sequences, red text in English, black text in English, and diagrams of red nets. What happens on the screen after the red net diagram appears?
A. Pie chart
B. Line chart
C. Bar chart
D. Circular diagram
E. Scatter plot
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7F9IrtSHmc0.mp4[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7F9IrtSHmc0.mp4[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7F9IrtSHmc0.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=325[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a wall tiger and a map on the wall, there is a man wearing a white shirt. What is he doing?
A. drinking water
B. playing with a cell phone
C. speaking
D. dancing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = N2mrK33gCYE.mp4[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/N2mrK33gCYE.mp4[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: N2mrK33gCYE.mp4 | Selected 10 frames[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=327[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 13:18:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:18:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a person wearing a shirt leaning over a desk with white paper on it. He dips one hand into the ink on the plate. What happens after Annc: IIc would talk about the things hc would do to try to achieve a heightened state of awareness?
A. A man wearing a shirt is holding a wooden object in one hand and a sculpture in the other. He places the sculpture in front of the wooden object and observes it. The background behind him is blue.
B. A man wearing a shirt is holding a wooden object in one hand and a sculpture in the other. He places the sculpture in front of the wooden object and observes it. The background behind him is black.
C. A man wearing a shirt is holding a wooden object in one hand and a sculpture in the other. He places the sculpture in front of the wooden object and observes it. The background behind him is purple.
D. A man wearing a shirt is holding a wooden object in one hand and a sculpture in the other. He places the sculpture in front of the wooden object and observes it. The background behind him is white.
E. A man wearing a shirt is holding a wooden object in one hand and a sculpture in the other. He places the sculpture in front of the wooden object and observes it. The background behind him is gray.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:18:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bwDfdTh0VYs.mp4[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bwDfdTh0VYs.mp4[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bwDfdTh0VYs.mp4 | Selected 16 frames[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=329[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 13:18:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 13:19:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the blue background PPT, there's a text style for 'Virtual and Real Attrition.' After mentioning 'real attrition because of every air attack,' what appears on the screen?
A. Three dark blue circular icons and two lines of English text in red font appear
B. Five yellow circular icons appear
C. Four square icons appear
D. A red airplane icon appears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 13:19:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Postprocessing:   0%|          | 0/165 [00:00<?, ?it/s][32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GdFMKGNFXaE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _EUDpS9UF9o_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7324498849857326341_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -eRimFrm6kQ_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DRIpznER-VQ_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LlqsCCa6y58_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KIf2fGmluhY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vVRC-0VKPrg_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mqtJErix0ss_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 66dwcQ1Y048_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: f0IbZGfTgUM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HeRS3nwySI8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fWNJmZAWRNg_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rwL_XPw46zQ_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _BDzMutoy6A_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7327779917989416197_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zTeDF7mQ88A_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fryyNwUCPWA_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1pxrIj9Xyps_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DVsw1brd_Yc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSeq-nVSY_E_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -0aM99dMu_4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eJr-y6UXnRE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fw1rirubXiU_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -PnG8Jp2gFw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _Y1pW77M3Pg_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8foMISZGiyw_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oddHY1vwcjo_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bjymxow3TVQ_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KIf2fGmluhY_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZGMGQsnSdLE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _qepWb_NVj4_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7324761016909188358_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JwoBdRC2fzE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UwlKYM2Sotg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zkmoxOKhpvk_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mFcEWmtn3ag_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7235995901477604635_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aqUisZS9Ruw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: W94Rth-aIkc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7269647281668852993_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Sn7JPKbG6tY_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lCvQtGVhUrc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: s49y2RP5C7E_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KWv8DJMEHsE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6Lb1PyJxVQM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iwXp1fT89-M_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qbA42wQoWAs_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6THwql5c6w_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8foMISZGiyw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kMryvefpcF8_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: acAWfzV__XI_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oCXKARwr6PA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 66dwcQ1Y048_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ErGYJ7kqIow_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: akoJDx23QWU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0WEnmqVVbHo_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7289528053112343814_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hg2Q_O5b9w4_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HAED3riiZkw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UN3ICsfqKEY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TMe7oXMJoSM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ezhafkxoRdo_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7280742496882134274_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7TljSpTBS9c_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TMe7oXMJoSM_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7XWqI121-Q4_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z9JSvDVMSm0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HvSEKzpSdzw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VGQ_djSR7zE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: brZugTJ0odg_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: j6beJTHUT_c_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-6940704678569053446_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Pm93D8CVlY8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: X29dPzJIMbA_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7200404243168415022_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bDpgz_2Piqg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z7Cox6lPW3c_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TFbGLEZ4qt0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qksR2Zvd-FM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: g7zuBUMBr2E_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ip8khYCMb8Y_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oI975O1BUu0_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VkNF0rXuDXw_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mqtJErix0ss_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kk-iRzLv81o_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jess.morg-7079970495499717934_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: O6UedmnRJc0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zda-T6wrEhs_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9aWPbYosJUw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3pTVbQilDqY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PbiTIR8N4Hc_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LAQRjgx_OY8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 4ouAf1ldH60_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VSZ8ywgGNGM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-7022693587703926022_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RQOdl64DtdI_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: xiK00WS0lkE_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aX_HgA5SNLQ_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7XWqI121-Q4_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tGiRbGGwRj8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LcZxjqtzXJI_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: BtaVRhoLpC0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GuEptwLiAvs_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PCPQToF10IM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i327DBSS_iE_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vEy6tcU6eLU_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XuQswmEPgxU_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: nWDNzv1Gk8Q_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7303594391850044678_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-7125042270381853995_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gtX_oRpLClY_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ip9DbdOtqF4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tWiGnu2BNsY_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAHsR02dUc0_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lzAESaVqix0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _kQXNFG664Y_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kOZnpwI2hIM_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GFg98TDqCpw_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -An3wZyoYe0_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pJI5ZU6wxqg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 61SYvhojGvg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jvkmcX47bKU_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TMe7oXMJoSM_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OmhVj_-cfH0_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7PqVVjEW0LM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mHccnoh9f5w_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jess.morg-7203120578537049386_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7282789187676294432_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 61SYvhojGvg_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oI975O1BUu0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7184160724715883781_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _hODR1cR9lo_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NS2V_OHYkvA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fWNJmZAWRNg_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lN3WnXMaE0o_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mld0TnA2jEs_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dCscvoOX2as_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 14ot4DrXdds_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: I-yg_3yx6iA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gJijNOktmoI_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rzIiQ4Vxlbk_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZaXpMou55lw_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fO7nwCix8xU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8ew0d0JmsfA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kN88RP3XWUU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -An3wZyoYe0_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pGEF7Tme3Tk_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XR3Ov2nQ39s_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dE5iWeCVpGI_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7359951777845775648_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tWiGnu2BNsY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XR3Ov2nQ39s_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: c6fuIEzOZ2E_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WaiGdRYD36k_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QJ6sjg7SXOQ_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GFg98TDqCpw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: xSzXFQPldJg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: a_8G0PzVFbc_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: BkCbbFn21LY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: M7YSCIkUaNw_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yz3lOAe32Tw_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gAgCnu82RHE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _BDzMutoy6A_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dCscvoOX2as_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-7097604725134118146_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: duxO1EZ650E_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: BktEeBeA7a8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 571nruSayeo_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -kaF6SnSEo8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: X29dPzJIMbA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: H2ksp6sRR-k_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mq6L8CnNJXc_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -0aM99dMu_4_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rP7sQe784k8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fWNJmZAWRNg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5tN9hyfdkaE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: u5NAcHhI_Uc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ze66pbJYr18_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bXRuqcmTIuk_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bwnkg6GbXwU_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 88LbBgZP1vQ_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAHsR02dUc0_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: J1IwKg2ufk8_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ozpGTw6DrXs_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qYnloYaeQA8_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: E7FSg22MdKE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -iCLYpeghJs_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yn7oTvw8QRY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7334544531490196741_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7277140989259599105_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qZVBFAtfp2A_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: e11Q4ThFu5A_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CGngv8vTQOs_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7257359603489443073_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: IGmuaY1jB1w_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i6C6r2g4Y7Q_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dxjKdnJFmLs_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: t48HXAjjDAU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: H2ksp6sRR-k_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6S_e34j6q9U_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZL07dkaoHOg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fxCRCMLJ0PU_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KFqlW0APKRA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qksR2Zvd-FM_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZfapKqwklG4_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8_MG-E8QlBM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7262938043315686664_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8Gl6iy7OEM4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bwnkg6GbXwU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: q3FAxTSENEw_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XYsCVqz3iug_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vEy6tcU6eLU_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XuQswmEPgxU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DRIpznER-VQ_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mkqgTAe2_O4_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KlZpZVphLrc_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fLn06p2HtAc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gAgCnu82RHE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Sy2unO22PUE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HeRS3nwySI8_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GawGUhl9zuQ_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mTn_C-SyW84_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hg2Q_O5b9w4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7XWqI121-Q4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qbA42wQoWAs_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NpYUxd1vUUE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bwnkg6GbXwU_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CdTijM0_es4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9PD3ciudpIE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zJ2uPZfkYMk_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mfS6gyP0mwo_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LAbtlJJhUlY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VFXJnbnN5ro_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: J1IwKg2ufk8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aVHAr8rc-Ks_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9dSkvxS2EB0_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAcbasjxljY_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: E7FSg22MdKE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RN2g9sRuJhA_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7rMgpExA4kM_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fvCrE5NCsts_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1R5uPaL0V-0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8905KCkLDYc_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iHNjWhx3EaI_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QPth_xqBXGY_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tdA5atpqaAc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eE5Z7gDbgVA_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7268936523481943297_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ydm72ftJStQ_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ysRFFN5nzqE_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: npLd4WTSQsM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wvfctNd-Aio_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WmrwQMFZLqI_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tdm72-vYxTs_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WM78_KqcrSY_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yz3lOAe32Tw_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _ZIa6SEJEyg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yFAuXmcGk2Y_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fySqsm5kNl4_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NexB4vj8_54_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _BDzMutoy6A_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7288701821369978144_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6d-EVupvWzU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AxciimuEZAc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F4bDyyEO4PU_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5zbV24vyO44_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JASFwBtUK40_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Aau-XoIebno_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0oALTLKRWBA_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: j6beJTHUT_c_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2W2ZkYARds4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -PnG8Jp2gFw_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: O6UedmnRJc0_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QpDL3mopnWM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: F2OhCCEIOcU_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gJijNOktmoI_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NexB4vj8_54_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: L-XGTMusZvc_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kOZnpwI2hIM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5tN9hyfdkaE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7rMgpExA4kM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7318074908645264645_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: v0QLje6xYgA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8hhcFRoR0mw_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HQns-h_82qU_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lNReCCShKJQ_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9S9i12n0TIw_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2zZSMnGLGao_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RN2g9sRuJhA_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yqejTvYILlA_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rMXJOKhf_AA_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @asianfoodrecipes-7109221563697876225_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mOiEOs3ZlT8_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbNyMSwoT5A_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UO_6TQnnOxM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mHARxee4EzQ_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: k4jiEuZbN-4_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0mEN5Jf2hU0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSeq-nVSY_E_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pJI5ZU6wxqg_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @thatrecipe.us-7245035133688892714_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7270058010888768770_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i8TJ7RgimNM_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-7074483613273754882_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6HTO2SOxUc_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7302913253959617797_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JASFwBtUK40_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7269006883380399362_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: IN0osLg-Mn8_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NMHmqgO04rU_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7275485247351901442_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Msz128EJeWE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mFliMGufpwc_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: x1FkhxMMIcg_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8k6M0HD162k_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0rWA-p4p5IM_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7F9IrtSHmc0_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8_MG-E8QlBM_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: N2mrK33gCYE_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d5JlCEDlHGE_1]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bwDfdTh0VYs_2]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7298820532466683142_0]:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 3307.32it/s]
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m631[0m - [1m================================================================================[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m632[0m - [1mLONGVIDEOBENCH CUSTOM RESULTS (with Frame Selection)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m633[0m - [1m================================================================================[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m641[0m - [1m
Accuracy by Duration Group:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m642[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  15s                           : 80.00% (40 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  60s                           : 57.50% (40 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  600s                          : 70.00% (100 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  3600s                         : 63.33% (150 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m650[0m - [1m
Accuracy by Question Category:[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m651[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E2O                           : 76.47% (17 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E3E                           : 76.19% (21 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O2E                           : 78.57% (28 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O3O                           : 28.57% (14 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2A                           : 75.00% (20 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2E                           : 84.61% (26 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2O                           : 83.33% (18 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SAA                           : 71.43% (14 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SOS                           : 77.27% (22 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SSS                           : 43.48% (23 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2A                           : 80.00% (15 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2E                           : 76.19% (21 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2O                           : 77.78% (18 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3E                           : 68.42% (19 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3O                           : 25.00% (16 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TAA                           : 50.00% (24 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TOS                           : 35.71% (14 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m658[0m - [1m
================================================================================[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m659[0m - [1mOVERALL ACCURACY: 66.67% (330 samples)[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m660[0m - [1m================================================================================[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2025-11-29 13:19:02[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m287[0m - [1mSaving samples to /home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_4.0_r60_6.0_r600_10.0_r3600_15.0_temporal_iter3_20251129_131216_results/..__LLaVA-NeXT-Video-7B-Qwen2/20251129_211222_samples_longvideobench_custom.jsonl[0m
llava_vid (pretrained=../LLaVA-NeXT-Video-7B-Qwen2,conv_template=chatml_direct,video_decode_backend=decord,max_frames_num=16,overwrite=False), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|        Tasks        |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|---------------------|------:|------|-----:|--------------|---|-----:|---|------|
|longvideobench_custom|      1|none  |     0|lvb_custom_acc|‚Üë  |0.6667|¬±  |   N/A|

[rank0]:[W1129 13:19:03.246465999 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
