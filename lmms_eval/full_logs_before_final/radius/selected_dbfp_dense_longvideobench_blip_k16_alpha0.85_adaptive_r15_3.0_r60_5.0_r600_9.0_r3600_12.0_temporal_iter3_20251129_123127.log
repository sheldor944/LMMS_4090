The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-11-29 12:31:32[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-29 12:31:32[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to DEBUG[0m
[32m2025-11-29 12:31:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-29 12:31:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m458[0m - [34m[1m`group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lmms-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the offical way to create groups with addition of group-wide configuations.[0m
[32m2025-11-29 12:31:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-29 12:31:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile _default_template.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/video-tt could not be loaded as a task or group[0m
[32m2025-11-29 12:31:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-29 12:31:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m484[0m - [34m[1mFile illusionvqa.yaml in /home/train01/miraj/lmms_eval/lmms_eval/tasks/illusionvqa could not be loaded as a task or group[0m
[32m2025-11-29 12:31:33[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_3.0_r60_5.0_r600_9.0_r3600_12.0_temporal_iter3_20251129_123127_results'}[0m
[32m2025-11-29 12:31:33[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-29 12:31:33[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-11-29 12:31:33[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': '/home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_3.0_r60_5.0_r600_9.0_r3600_12.0_temporal_iter3_20251129_123127_results'}[0m
[32m2025-11-29 12:31:33[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['longvideobench_custom'][0m
[32m2025-11-29 12:31:33[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m161[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
OpenCLIP not installed
OpenCLIP not installed
force sample: False
Rank 0:  Loaded LLaVA model: ../LLaVA-NeXT-Video-7B-Qwen2
force sample: False
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:07,  2.52s/it]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:02<00:08,  2.91s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:04,  2.30s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:05<00:05,  2.65s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:06<00:02,  2.25s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  1.80s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  1.99s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:07<00:02,  2.56s/it]Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 330 examples [00:00, 35258.82 examples/s]
[32m2025-11-29 12:31:46[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 1 (local rank 1)[0m
[32m2025-11-29 12:31:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank1-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-29 12:31:46[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 1...[0m
  0%|          | 0/165 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 7007.57it/s]
[32m2025-11-29 12:31:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 165[0m
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  1.97s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  2.22s/it]
Rank 0:  Model Class: LlavaQwenForCausalLM
[32m2025-11-29 12:31:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36m__init__[0m:[36m215[0m - [1mUsing 2 devices with data parallelism[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m402[0m - [1mRunning on rank 0 (local rank 0)[0m
[32m2025-11-29 12:31:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.caching.cache[0m:[36mload_from_cache[0m:[36m34[0m - [34m[1mrequests-longvideobench_custom-0shot-rank0-world_size2-tokenizer is not cached, generating...[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for longvideobench_custom on rank 0...[0m
  0%|          | 0/165 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 7149.16it/s]
[32m2025-11-29 12:31:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m460[0m - [34m[1mTask: longvideobench_custom; number of requests on this rank: 165[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m495[0m - [1mRunning generate_until requests[0m
Model Responding:   0%|          | 0/165 [00:00<?, ?it/s][32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6867204066108329221.mp4[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6867204066108329221.mp4[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6867204066108329221.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=1[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZoUsR8t8IxE.mp4[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZoUsR8t8IxE.mp4[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZoUsR8t8IxE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=0[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A lady with gray hair tied up is sitting on a sofa watching TV, holding a white bowl in one hand and a spoon in the other. There's a mirror on the white wall behind her reflecting the TV screen. When 'Who you gonna call?' is mentioned, what object is not present in the scene?
A. white socks
B. green pillow
C. blue pillow
D. black belt
E. black pillow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = I-yg_3yx6iA.mp4[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/I-yg_3yx6iA.mp4[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: I-yg_3yx6iA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=3[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a red house with a black roof, there is a woman wearing a light blue suit and holding a microphone. There is also a blue and white caption bar at the bottom of the screen. After the phrase 'court so this case is still really at' is mentioned, who appears on the screen?
A. A woman wearing a turquoise coat appears
B. A man wearing a black suit appears
C. A woman wearing headphones and a red coat appears
D. An elderly person wearing headphones and a black-gray coat appears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   1%|          | 1/165 [00:02<07:53,  2.89s/it][32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wvfctNd-Aio.mp4[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wvfctNd-Aio.mp4[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wvfctNd-Aio.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=2[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A green transport truck is parked on the roadside, with two groups of people fighting around the car. One group is in dark green uniforms holding axes, clubs and other weapons, while the other group is wearing white hats and uniforms with armbands. The highway is lined with greenery on both sides. When the subtitle 'there have been dozens of Border' appears, what shape is the decorative pattern on the rear of the car?
A. Circle
B. Square
C. Pentagon
D. Rectangle
E. Triangle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -eRimFrm6kQ.mp4[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-eRimFrm6kQ.mp4[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -eRimFrm6kQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=5[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left is black text in English with a red icon below, and on the right side of the screen is a stack of newspapers. Below the news headline, on a ticker tape, there is a black background with yellow text reading 'BREAKING NEWS'. Which subtitles have appeared at the same time as this icon?
A. ‚ÄúGPS and health workers insisting that‚Äù
B. ‚Äúand 37 and the polling station that have‚Äù
C. ‚Äúthe QR code you'll see on screen during‚Äù
D. ‚Äúopened in Russia their elections taking‚Äù
E. ‚Äústart with the times world uh Pages 36‚Äù
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   1%|          | 2/165 [00:05<07:28,  2.75s/it][32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JwoBdRC2fzE.mp4[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JwoBdRC2fzE.mp4[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JwoBdRC2fzE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=4[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which country's flag appears first in the video?
A. Singapore
B. Kiribati
C. India
D. St. Kitts
E. Barbados
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fPLjjr8w6DU.mp4[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fPLjjr8w6DU.mp4[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fPLjjr8w6DU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=7[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are two statues in the background, and a group of people raising their fists watching two shirtless men wearing white shorts. What are these two shirtless men in white shorts doing?
A. Running race
B. Long jump competition
C. Swimming competition
D. Wrestling match
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:   2%|‚ñè         | 3/165 [00:08<07:29,  2.77s/it][32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _BDzMutoy6A.mp4[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_BDzMutoy6A.mp4[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _BDzMutoy6A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=6[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the first character standing in front of the bathtub with flower petals in the video?
A. A lady wearing a white floral dress
B. A lady wearing a pink floral dress
C. A lady wearing a purple floral dress
D. A lady wearing a yellow floral dress
E. A lady wearing a green floral dress
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zVudr8cxHRE.mp4[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zVudr8cxHRE.mp4[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zVudr8cxHRE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=9[0m
[32m2025-11-29 12:31:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:31:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background features a white cabinet decorated with red lanterns. On the right side, there's a silver refrigerator with a red couplet sticker on it. A woman in a red short-sleeve top and apron is standing in front of a table holding a sesame ball. On the table, there are two glass containers and an iron plate. When the subtitle 'I fell like it's so refreshing' appears, what is this woman doing?
A. kneading a sesame ball
B. cutting a sesame ball
C. eating a sesame ball
D. deep-frying a sesame ball
E. making tangyuan
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:31:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   2%|‚ñè         | 4/165 [00:10<06:58,  2.60s/it][32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kLuqCtnKr_8.mp4[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kLuqCtnKr_8.mp4[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kLuqCtnKr_8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=8[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:31:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there are two men in a room. The man on the left is wearing a yellow shirt, a hat backwards, and a watch on his left hand. The man on the right is wearing a shirt with red flowers and green leaves and has a bracelet on his left hand. When the subtitle mentions "interested enough to join us but first," what change happens to the man wearing the shirt with red flowers and green leaves?
A. He takes off his bracelet
B. He changes into a black short-sleeved shirt
C. He changes into a white long-sleeved shirt
D. He changes into a black jacket
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MJYBHfYF8LI.mp4[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MJYBHfYF8LI.mp4[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MJYBHfYF8LI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=11[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a jade-green ocean, there is a huge rock with a hole standing in the ocean. Several people are standing on the rock, and one person is running forward. What did he do next?
A. Rushed towards another person standing on the rock
B. Jumped into someone's arms
C. Jumped into the jade-green sea
D. Hugged the person in front of him
E. Fell down on the rock
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   3%|‚ñé         | 5/165 [00:13<06:44,  2.53s/it][32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = c6fuIEzOZ2E.mp4[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/c6fuIEzOZ2E.mp4[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: c6fuIEzOZ2E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=10[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At a presentation with a black background, what action did a man wearing black clothing and glasses take while speaking towards the microphone when he mentioned 'stack and the higher memory. And it's the to die within the same'?
A. Put on a hat
B. Removed his glasses
C. Showed two GPU chips to the camera
D. Took a sip of water
E. Took off his outer garment
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kk-iRzLv81o.mp4[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kk-iRzLv81o.mp4[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kk-iRzLv81o.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=13[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a small room, a man and a woman are sitting on a white sofa. The man is wearing a dark gray jacket, and the woman is wearing a black dress. When the phrase 'people more a lot of things maybe how we' is mentioned, which objects are not present in the scene?
A. A painting with a black frame
B. A red poster
C. A black microphone with a white pattern
D. A beige pillow with blue design
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   4%|‚ñé         | 6/165 [00:15<06:54,  2.61s/it][32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Efuyl2Anehg.mp4[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Efuyl2Anehg.mp4[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Efuyl2Anehg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=12[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a plot of land surrounded by green trees. The land is brown, and there is a person wearing a yellow outfit with a cowboy hat and a mustache who is making a fire. There is also a person wearing white clothes and a gray skirt with a backpack behind him. Which one is carrying a gun?
A. The person wearing white clothes and a gray skirt
B. The person wearing white clothes and a gray skirt without a hat
C. The person wearing white clothes and a gray skirt with a hat
D. The person wearing yellow clothes and a hat making a fire
E. The person wearing white clothes, a gray skirt, and green shoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pFpZvRsEGZs.mp4[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pFpZvRsEGZs.mp4[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pFpZvRsEGZs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=15[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a gray coat and sporting short black hair is sitting upright on a cream-colored couch against a cream-colored background, eating from a green-white dessert bowl. What subtitle appeared at the same time as this man?
A. The next morning
B. And it comes with my own Arabic TV.
C. And if you can see, it's written in Arabic.
D. It's a little after 10 and I just made it to Bahrain.
E. You golta buy tulip bulbs.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:   4%|‚ñç         | 7/165 [00:18<06:59,  2.66s/it][32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7270058010888768770.mp4[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7270058010888768770.mp4[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7270058010888768770.mp4 | Selected 6 frames[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=14[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 12:32:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a phone, and the screen of the phone shows the number 911. When the subtitle "However, the girl used a disposable phone without a chip, making it impossible to locate her" appears, what change happens to the text in the middle of the phone screen?
A. Changes from the number 911 to the number 129
B. Changes from the number 911 to the blue text 'New Voicemail RAUL'
C. Changes from the number 911 to the number 119
D. Changes from the number 911 to the blue text 'save me'
E. Changes from the number 911 to the number 110
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   5%|‚ñç         | 8/165 [00:20<05:58,  2.28s/it][32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZaXpMou55lw.mp4[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZaXpMou55lw.mp4[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZaXpMou55lw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=16[0m
[32m2025-11-29 12:32:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bald person wearing a green coat is holding a phone to his ear. Behind him is a wall made of wooden blocks, and to his left-rear side, there is a white light bulb. What color is the phone?
A. black
B. blue
C. red
D. yellow
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7266555380925287723.mp4[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7266555380925287723.mp4[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7266555380925287723.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=17[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:32:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a wooden-colored table, there is a round transparent bowl with someone stirring the chocolate and butter inside it using a ladle. According to the video, which of these two stirred items appears first?
A. Butter
B. Chocolate and butter appear simultaneously
C. Neither of these items appears
D. Chocolate
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d8H7hgQY9ew.mp4[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d8H7hgQY9ew.mp4[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d8H7hgQY9ew.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=19[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the upper right corner of a white background, a middle-aged man wearing a gray short-sleeved shirt is explaining. Behind him are a piano keyboard and various objects. At the top of the screen are bold English letters, and in the center is a table with white data on a black background. What object is present in the scene?
A. A silver bracelet
B. A pair of glasses
C. There is a URL
D. There is a wristwatch
E. A yellow bracelet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   5%|‚ñå         | 9/165 [00:22<06:06,  2.35s/it][32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = i327DBSS_iE.mp4[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/i327DBSS_iE.mp4[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: i327DBSS_iE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=18[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a news scene, a woman with short hair wearing red clothes and a black inner shirt with earrings is smiling. Behind her, there's a large screen displaying the letters 'cna' and a red triangular line, along with some red and black characters. When the ticker below her scrolls to 'Australia's energy giants to face annual earnings slump on bleak,' what event occurred?
A. She shook hands with another man
B. She put on glasses
C. She nodded
D. She stood up from her chair
E. She hugged a man next to her
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z7Cox6lPW3c.mp4[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z7Cox6lPW3c.mp4[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z7Cox6lPW3c.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=21[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows some people pushing shopping carts in the vegetable section of a supermarket. What is the first product to appear on the screen after this?
A. Leek
B. Eraser
C. Cauliflower
D. Carrot
E. Mini Tomatoes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   6%|‚ñå         | 10/165 [00:25<06:42,  2.59s/it][32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LVFvRNRTEd4.mp4[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LVFvRNRTEd4.mp4[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LVFvRNRTEd4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=20[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing red clothes and a man wearing black clothes are in a video call, and a sentence starting with 'TSMC GETS' is gradually being revealed at the bottom. What kind of hair does the woman in the video call have?
A. She has short blonde hair.
B. She has black hair.
C. She has no hair.
D. She has long blonde hair.
E. She has black bob cut.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = M7YSCIkUaNw.mp4[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/M7YSCIkUaNw.mp4[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: M7YSCIkUaNw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=23[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Among the group of people in the video, there is a woman wearing a blue jacket with a white shirt underneath. She is raising her right hand, holding a large stuffed toy in her left hand, and carrying a white plastic bag filled with items. When the subtitle mentions 'those and the word balikbayan means,' what color is the stuffed toy?
A. purple
B. red
C. blue
D. green
E. yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   7%|‚ñã         | 11/165 [00:28<06:42,  2.61s/it][32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NSn78eNspwU.mp4[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NSn78eNspwU.mp4[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NSn78eNspwU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=22[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the black table, there is a white tray and bowl. The tray has a dark-colored bottle with a white paper label on it, and the bowl contains a white powder. A hand covered with a sleeve is mixing the contents with a kitchen utensil. After the subtitle 'basic muffin butter mixed with a cup of', what appears on the screen?
A. silver kitchen utensils
B. white bowl
C. red fruit
D. butterfly
E. white water bottle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7282789187676294432.mp4[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7282789187676294432.mp4[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7282789187676294432.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=25[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:32:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the kitchen, after a chef pours a yellow liquid into a wok with stir-fried vegetables, what happens on the screen?
A. The chef adds eggplant to the wok.
B. The chef transfers the vegetables from the wok into a rectangular white plate containing bread.
C. The chef adds scallions to the wok.
D. The chef transfers the vegetables from the wok into a rectangular white plate containing rice.
E. The chef transfers the vegetables from the wok into a round white plate containing rice.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kk-iRzLv81o.mp4[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kk-iRzLv81o.mp4[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kk-iRzLv81o.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=27[0m
[32m2025-11-29 12:32:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a scene appears with 'a white goose looking sideways at the gray-white sky and the blue-black sea', then a scene with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface', and finally a scene with 'a yellow box and some black objects floating on a blue-green water surface.'
B. First, a scene appears with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface', then a scene with 'a white goose looking sideways at the gray-white sky and the blue-black sea', and finally a scene with 'a yellow box and some black objects floating on a blue-green water surface.'
C. First, a scene appears with a 'yellow box and some black objects floating on a blue-green water surface', then a scene with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface', and finally a scene with 'a white goose looking sideways at the gray-white sky and the blue-black sea.'
D. First, a scene appears with a 'yellow box and some black objects floating on a blue-green water surface', then a scene with 'a white goose looking sideways at the gray-white sky and the blue-black sea', and finally a scene with 'on a white surface, a goose with a yellow crown lying on the ground next to several goose legs.'
E. First, a scene appears with 'a white goose looking sideways at the gray-white sky and the blue-black sea', then a scene with 'a yellow box and some black objects floating on a blue-green water surface', and finally a scene with 'a goose with a yellow crown lying on the ground next to several goose legs on a white surface.'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   7%|‚ñã         | 12/165 [00:31<07:03,  2.77s/it][32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9PD3ciudpIE.mp4[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9PD3ciudpIE.mp4[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9PD3ciudpIE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=24[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a light yellow wall, there is a woman wearing a pink hat sitting with another woman with long hair wearing a dark blue outfit. When the subtitle mentions 'the old people that can't work anymore,' what is the woman with the pink hat wearing?
A. red short sleeves
B. red long sleeves
C. black long sleeves
D. pink short sleeves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:   8%|‚ñä         | 13/165 [00:33<06:39,  2.63s/it][32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wSHPuI7wWIg.mp4[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wSHPuI7wWIg.mp4[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wSHPuI7wWIg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=26[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an animated building constructed with yellow and olive colors, the buildings on the left and center have white roofs. In front of the building, there are several people wearing yellow and black clothes and red and white clothes. The person wearing red and white clothes has a very tall grey hat and is holding a gun. One person, who is shirtless on the upper body and wearing yellow and black pants, is tied up with two sticks. There is another person swinging a bat and hitting him. Who is the character using the bat to hit the shirtless person?
A. The person wearing a white V-neck shirt, yellow pants, and has black hair
B. The person wearing yellow and black clothes with a double-eared hat
C. The person wearing yellow and black clothes with a round hat
D. The person wearing red and white clothes with a tall hat, holding a gun
E. The person wearing yellow and black clothes with olive-colored hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 571nruSayeo.mp4[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/571nruSayeo.mp4[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 571nruSayeo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=29[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the news footage, there is a man wearing green clothes in front of a virtual city background, speaking to the camera. The subtitles show 'the impression that uh the gangs were'. With which subtitles did this man in green clothes appear?
A. my parents gave me what I wanted
B. used in the past by politic S I mean for
C. Because he is so funny
D.  He has a big mouth
E. And we're getting on well with each other
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PQRyGacBRA4.mp4[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PQRyGacBRA4.mp4[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PQRyGacBRA4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=31[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A screen with a black frame is placed on the table. On the screen, a blue-haired girl is holding a small tile with a design. The girl is wearing a uniform with a red tie, and her eyes are white with circular patterns. When the subtitle 'Ah, are you kidding me' appears, what items are present in the scene?
A. A red heart tile
B. A white hat
C. A black peach tile
D. A plum blossom tile
E. A red hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:   8%|‚ñä         | 14/165 [00:36<06:43,  2.67s/it][32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8foMISZGiyw.mp4[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8foMISZGiyw.mp4[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8foMISZGiyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=28[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man wearing black clothes with curly hair is facing the camera. Behind him is a complex building with a clock tower. There are also some withered branches on the left side. In which of the following scenes does this man appear?
A. On top of a building with a lot of reporters, and the roof is red.
B. On a viewing platform without the Union Jack flag.
C. In front of a building with black rectangular tiles, a white carved door frame, black double doors, and surrounded by windows.
D. On a road surrounded by trees with cars around.
E. On a circular stage with many people below.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AjF13uKVQa0.mp4[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AjF13uKVQa0.mp4[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AjF13uKVQa0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=33[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a striped short-sleeve dress is sitting on a chair in front of a pink wall window. A white cloth bag is placed on her lap. What is she doing?
A. She is mending the cloth bag
B. She tore the cloth bag
C. She took a mask out of the cloth bag
D. She placed the cloth bag on the ground
E. She took a gun out of the cloth bag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:   9%|‚ñâ         | 15/165 [00:39<06:37,  2.65s/it][32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GFg98TDqCpw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=30[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the lower right corner of the screen, there is a man wearing a suit. His right hand is raised, and beside his right hand is the number 47. Behind this man, there is a white background with 10 lines of text. What color are these words?
A. The top line is yellow, the rest are black
B. The third line has some blue text, the rest are black
C. The top 8 lines of text are black, the bottom 2 lines are red
D. All are black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbNyMSwoT5A.mp4[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbNyMSwoT5A.mp4[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbNyMSwoT5A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=35[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a bald man wearing sunglasses in the bottom right corner of the video, he is dressed in black clothing, and there is a man in the screen wearing a white short-sleeve shirt with a beard. The man is holding a cigarette in his right hand. Which object does not appear in the video?
A. Hat
B. Sunglasses
C. Cigarette
D. White short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  10%|‚ñâ         | 16/165 [00:41<06:19,  2.55s/it][32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = FOMS_yqdN1o.mp4[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/FOMS_yqdN1o.mp4[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: FOMS_yqdN1o.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=32[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with warm lighting, a woman dressed in black is sitting on a chair holding a comb. What is she doing?
A. She is brushing her teeth
B. She is washing her face
C. She is putting on makeup
D. She is combing her hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  10%|‚ñà         | 17/165 [00:42<04:48,  1.95s/it][32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ro_8-CCORzk.mp4[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ro_8-CCORzk.mp4[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ro_8-CCORzk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=34[0m
[32m2025-11-29 12:32:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A group of people is advancing down the mountain. A person without a helmet is riding an elephant, followed by a group of people wearing helmets. A soldier is waving a long sword. Who is the person waving the long sword?
A. The person with a scabbard but without a helmet
B. The person wearing a helmet without a scabbard
C. The person without a helmet and without a shield
D. The person riding an elephant at the front
E. The person wearing a helmet without a shield
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pGEF7Tme3Tk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=37[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with short blonde hair and wearing earrings is speaking in front of a mirror. She is wearing black clothes, with a gray background wall behind her. In front of her is a white subtitle bar that reads 'BLANC:PENSIONS MARKETGROWING'. The subtitle bar changes to 'BLANC: CHANGETHROUGH AITO COMEIN WAVES', and a pop-up window appears on the right side of the screen that reads 'Amanda Blanc'. What change did this woman experience?
A. The woman shook hands with a person next to her
B. The woman got a haircut
C. The woman raised both hands
D. The woman stood up
E. The woman took a sip of water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  11%|‚ñà         | 18/165 [00:44<05:04,  2.07s/it][32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = k4jiEuZbN-4.mp4[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/k4jiEuZbN-4.mp4[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: k4jiEuZbN-4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=36[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a silver desktop, there is a wooden board. On the wooden board, there is an empty silver metal plate. A blond man wearing a black short-sleeved shirt is holding a spatula with his left hand and looking at the plate. When the plate and the subtitle 'uh and like I was saying at the start' appear simultaneously, what change occurs to the plate?
A. Yellow food material appears in the plate
B. Green food material appears in the plate
C. Eggs appear in the plate
D. Blue flowers appear in the plate
E. Eggs and beans appear in the plate
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Ytv-9RM4e0o.mp4[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Ytv-9RM4e0o.mp4[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Ytv-9RM4e0o.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=39[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides. Next, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel. Lastly, a person is washing a small knife covered in fresh blood at a sink.
B. First, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel. Next, a person is washing a small knife covered in fresh blood at a sink. Finally, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides.
C. First, a person is washing a small knife covered in fresh blood at a sink. Next, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel. Finally, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides.
D. First, a person is washing a small knife covered in fresh blood at a sink. Next, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides. Lastly, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel.
E. First, two people are hugging in a red room with a window behind them. The window has blue curtains on both sides. Next, a person is washing a small knife covered in fresh blood at a sink. Finally, a police officer is standing behind a person wearing a prison uniform, facing a door with a transparent glass panel.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  12%|‚ñà‚ñè        | 19/165 [00:47<05:27,  2.24s/it][32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YcbKamVxDzI.mp4[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YcbKamVxDzI.mp4[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YcbKamVxDzI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=38[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a spacious yellow room with many lights on, there is a man wearing a red and black checkered shirt. When the subtitle 'everyone you join me' appears, what change happens to the man wearing a red and black checkered shirt?
A. The man's shirt changes from a red and black checkered shirt to a white hoodie
B. The man's shirt changes from a red and black checkered shirt to a yellow short sleeve
C. The man's shirt changes from a red and black checkered shirt to a black short sleeve
D. The man's shirt changes from a red and black checkered shirt to a blue suit
E. The man's shirt changes from a red and black checkered shirt to a black hoodie
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PbiTIR8N4Hc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=41[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, the left side shows a dim yellow-lit beige room in the background, while the right side has a blurry white background. In the middle, there's a long-haired woman in purple clothing facing a mirror. Which characters appear after the subtitle 'concerns about the ending of the story' appears?
A. A man wearing white clothes and a yellow hat
B. A man wearing black clothes and a red hat
C. A woman wearing yellow clothes with blonde hair
D. A woman wearing a black hat and sunglasses
E. A man wearing white clothes with long hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  12%|‚ñà‚ñè        | 20/165 [00:49<05:50,  2.42s/it][32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sEiyR7-0FOA.mp4[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sEiyR7-0FOA.mp4[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sEiyR7-0FOA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=40[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a blurry screen, there are some soils of different colors. In the bottom right corner of the screen, there is also white text that reads 'Credit: AdventureON'. When the subtitle 'good specimens could be found near the' appears next to it, what is the first object that appears?
A. Grayish white crystal
B. Trilobite fossil
C. Fish fossil
D. Black crystal
E. Green quartz
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8k6M0HD162k.mp4[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8k6M0HD162k.mp4[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8k6M0HD162k.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=43[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two soldiers are standing next to a fallen tank, one soldier is holding a bucket, and there are 6 buckets on the ground next to the tank. When the subtitle 'misinformation is extremely effective in' appears, what color are the buckets on the ground?
A. orange
B. white
C. red
D. pink
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  13%|‚ñà‚ñé        | 21/165 [00:52<05:52,  2.45s/it][32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7269647281668852993.mp4[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7269647281668852993.mp4[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7269647281668852993.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=42[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:32:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a vast open area, there is a centipede formed by criminals dressed in orange uniforms. After the narration saying "In American prisons, the mouths and buttocks of 800 inmates are sewn together to form a long human centipede", what event happened in the video?
A. Criminals in orange clothes gather to gamble
B. Criminals in orange clothes gather to fight
C. A man in orange clothes is pushing his head against the person in front of him
D. Criminals in orange clothes go around killing people
E. A man in gray-green clothes is touching the brain of a dark-skinned man
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  13%|‚ñà‚ñé        | 22/165 [00:53<04:58,  2.09s/it][32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VSZ8ywgGNGM.mp4[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VSZ8ywgGNGM.mp4[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VSZ8ywgGNGM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=44[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, some people are listening to a person on stage explaining some English knowledge points on shooting. A man stands up from his seat and walks to the front of the woman on stage. After this man stands up, what happens on the screen?
A. The man walks out of the classroom
B. A person under the stage touches the back of their head with their hand
C. Everyone under the stage stands up
D. Everyone under the stage claps
E. The man walks onto the stage
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JDtVwz1R-kI.mp4[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JDtVwz1R-kI.mp4[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JDtVwz1R-kI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=45[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a lioness inside an iron mesh enclosure. Outside the iron mesh, someone is extending a pair of tongs through the mesh towards the lioness's nose. What is being clamped by the tongs that are reaching towards the lioness's nose?
A. A flower
B. Catnip
C. A piece of meat
D. A leaf
E. A chicken
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  14%|‚ñà‚ñç        | 23/165 [00:56<05:09,  2.18s/it][32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zkmoxOKhpvk.mp4[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zkmoxOKhpvk.mp4[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zkmoxOKhpvk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=46[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There are people resting in front of the flower bed in the spacious park. Not far from the flower bed, two people are standing. On the left is a man wearing gray clothes, and on the right is a woman wearing black clothes who is drinking a beverage. Where has this woman appeared before?
A. In the subway
B. In the convenience store
C. On the bridge
D. In the restroom
E. In the hotel room
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = il_wMYlDQ6I.mp4[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/il_wMYlDQ6I.mp4[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: il_wMYlDQ6I.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=47[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:32:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In daytime with the sun, the video shows the process of an airplane slowly taking off. At the beginning of the video, where does the airplane on the flat ground appear?
A. in the sky
B. remaining on the flat ground
C. in the ocean
D. on a hill
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ozpGTw6DrXs.mp4[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ozpGTw6DrXs.mp4[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ozpGTw6DrXs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=49[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The bridge with green railings is halfway in the air. Dense green forests are beside the bridge. The sunshine casts the railings' reflections. Who crossed this bridge?
A. The woman wearing a black corset
B. The curly-haired man wearing a green cat pattern onesie
C. The curly-haired man wearing a pink dog pattern onesie
D. The man wearing a black baseball cap
E. The curly-haired man wearing a pink cat pattern onesie
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
Model Responding:  15%|‚ñà‚ñç        | 24/165 [00:59<05:52,  2.50s/it][32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -iCLYpeghJs.mp4[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-iCLYpeghJs.mp4[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -iCLYpeghJs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=48[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A blonde man wearing a gray short sleeve shirt is in front of a mountain and an ocean in the scene. In which other scene does this man appear?
A. Appears on the road between the sea and the buildings
B. Appears on the beach
C. Appears on a boat
D. Appears in a restaurant
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bwDfdTh0VYs.mp4[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bwDfdTh0VYs.mp4[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bwDfdTh0VYs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=51[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white tiled wallpaper with icy and sweet candy circles, there are two men standing side by side, one wearing short sleeves and the other holding a remote control wearing long sleeves. When the phrase 'tlicking topping motion is that how you' is mentioned, how are their clothes described?
A. The man on the left is wearing light red short sleeves, and the man on the right is wearing a white long sleeve.
B. The man on the right is wearing light yellow short sleeves, and the man on the left is wearing a black long sleeve.
C. The man on the right is wearing light red short sleeves, and the man on the left is wearing a black long sleeve.
D. The man on the left is wearing light red short sleeves, and the man on the right is wearing a black long sleeve.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  15%|‚ñà‚ñå        | 25/165 [01:01<05:26,  2.34s/it][32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mq6L8CnNJXc.mp4[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mq6L8CnNJXc.mp4[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mq6L8CnNJXc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=50[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the blue background PPT, there's a text style for 'Virtual and Real Attrition.' After mentioning 'real attrition because of every air attack,' what appears on the screen?
A. Three dark blue circular icons and two lines of English text in red font appear
B. Five yellow circular icons appear
C. Four square icons appear
D. A red airplane icon appears
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = j6beJTHUT_c.mp4[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/j6beJTHUT_c.mp4[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: j6beJTHUT_c.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=53[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wall with blue ceramic tiles, there's a man with a mustache, carrying a backpack and wearing a short-sleeved shirt. What is the color of the straps on the backpack he's carrying in the video?
A. Olive
B. Black
C. White
D. Gray
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  16%|‚ñà‚ñå        | 26/165 [01:04<05:50,  2.52s/it][32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pGEF7Tme3Tk.mp4[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pGEF7Tme3Tk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=52[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a woman with long black hair is sitting on the left, and a woman with yellow hair is sitting on the right. The woman with black hair is putting makeup on the woman with yellow hair. A man in yellow and white clothing is standing in the middle of the screen. After the subtitle 'Lisa is the female lead, replacing Polina. While getting ready, Lisa told her boyfriend, Alexey,', what does the woman with long black hair do?
A. Running
B. Leaving
C. Drinking water
D. Eating something
E. Fixing the yellow-haired woman's hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NpYUxd1vUUE.mp4[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NpYUxd1vUUE.mp4[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NpYUxd1vUUE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=55[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the white cabinet, there is a man with short hair and wearing a black short-sleeved shirt. He is holding a chickpea in his left hand with both hands raised. When he appears alongside the subtitle 'pork ragu or i‚Äôm gonna do some romesco,' what changes occur to him?
A. The chickpea in his hand turns into pork.
B. The chickpea in his hand turns into an egg.
C. The chickpea in his hand turns into a glass of milk.
D. The chickpea in his hand turns into a bluebonnet.
E. The chickpea in his hand turns into a kitchen knife.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  16%|‚ñà‚ñã        | 27/165 [01:06<05:39,  2.46s/it][32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5tN9hyfdkaE.mp4[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5tN9hyfdkaE.mp4[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5tN9hyfdkaE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=54[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a pair of hands flips through a photo album, then a man embraces a child, followed by a pair of hands pouring a liquid with medicine into a sink, and finally a short-haired blonde woman points a gun at three people.
B. First, a short-haired blonde woman points a gun at three people, then a pair of hands pours a liquid with medicine into a sink, followed by a pair of hands flipping through a photo album, and finally a man embraces a child.
C. First, a man embraces a child, then a pair of hands pours a liquid with medicine into a sink, followed by a pair of hands flipping through a photo album, and finally a short-haired blonde woman points a gun at three people.
D. First, a short-haired blonde woman points a gun at three people, then a pair of hands pours a liquid with medicine into a sink, followed by a man embracing a child, and finally a pair of hands flipping through a photo album.
E. First, a man embraces a child, then a pair of hands flips through a photo album, followed by a pair of hands pouring a liquid with medicine into a sink, and finally a short-haired blonde woman points a gun at three people.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ze66pbJYr18.mp4[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ze66pbJYr18.mp4[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ze66pbJYr18.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=57[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a kitchen, there is a white plate with ingredients on the table. A person with an apron tied around their waist is cutting vegetables on a brown wooden board with a knife. What color top is the person wearing when the subtitle says 'Cuisines that extend well beyond Asia'?
A. red
B. white
C. blue
D. black
E. purple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  17%|‚ñà‚ñã        | 28/165 [01:08<05:33,  2.43s/it][32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=56[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the black background, there is a picture. The picture shows a blue sky and yellow stars. The color of the house on the left is yellow and gray. When the subtitle 'iconic works the quaint setting and use' appears, what object is on the screen?
A. Table and chair
B. Teapot
C. Bed
D. Table and stereo
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Oht0i1DACcA.mp4[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Oht0i1DACcA.mp4[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Oht0i1DACcA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=59[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:32:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:32:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black background, there are two screens. On the left, there is a white car passing by on a road in front of a construction building. On the right, there are two people conversing on a red carpet stage. What objects are present in this screen?
A. helicopter
B. green stone lion
C. black car
D. traffic light
E. handgun
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:32:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  18%|‚ñà‚ñä        | 29/165 [01:11<05:29,  2.42s/it][32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = npLd4WTSQsM.mp4[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/npLd4WTSQsM.mp4[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: npLd4WTSQsM.mp4 | Selected 6 frames[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=58[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 12:32:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On this yellow cutting board, two chicken breasts are placed side by side. After this person places the chicken breasts horizontally, what does he do next?
A. He throws the chicken breasts away.
B. He puts the chicken breasts into a pot.
C. He does nothing.
D. He uses a knife to cut the two whole chicken breasts into evenly sized small pieces.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  18%|‚ñà‚ñä        | 30/165 [01:12<04:35,  2.04s/it][32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = v-7zF3Y0yJs.mp4[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/v-7zF3Y0yJs.mp4[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: v-7zF3Y0yJs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=60[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the beginning of the video, a woman with a headband tied to her head, wearing a red top, carrying a black backpack, when the woman comes down from a hill with tall rocks, what changes occur to her backpack?
A. There is a dark red jacket hanging on her black backpack
B. Nothing changed
C. There is a white jacket hanging on her black backpack
D. There is a dark blue jacket hanging on her black backpack
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = X5v4nBo5y28.mp4[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/X5v4nBo5y28.mp4[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: X5v4nBo5y28.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=61[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a screen with a blue background and a turret-shaped building on the far right, what color suit is the man sitting in front of the phone booth wearing?
A. blue
B. pink
C. white
D. black
E. yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  19%|‚ñà‚ñâ        | 31/165 [01:14<04:43,  2.12s/it][32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = J_ZmaKRpyoU.mp4[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/J_ZmaKRpyoU.mp4[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: J_ZmaKRpyoU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=62[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a white house by the river, with various trees planted around it. Two people in long sleeves are walking towards the white house. When the subtitles mention 'They run into landlady and she tells them that Abigail disappeared one day and never ', which of the following items appears for the first time?
A. computer
B. snack
C. mobile phone
D. balloon
E. scissors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7308098412078025989.mp4[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7308098412078025989.mp4[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7308098412078025989.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=63[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:33:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there are three images on the PPT. One of the images has the word 'Image/Video' below it, another one has the word 'Where?' below it, and in the bottom right corner, there is a woman wearing a dark blue inner outfit, a black outer coat, and glasses. What objects have appeared on the screen?
A. A photo of a globe
B. A photo of a satellite
C. A photo of a road at night
D. A photo of a man in a black short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  19%|‚ñà‚ñâ        | 32/165 [01:17<04:59,  2.25s/it][32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fWNJmZAWRNg.mp4[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fWNJmZAWRNg.mp4[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fWNJmZAWRNg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=64[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a turquoise lake with a rocky pile at the side of the lake. In the middle of the screen, there are yellow letters stating 'FOR MULTIPLE.' After the subtitle 'This is the world's top-ranked beach for multiple reasons' is mentioned, what objects appear?
A. Seaweed
B. Ordinary green plants
C. Small fish
D. Coconuts on the coconut tree
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8_MG-E8QlBM.mp4[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8_MG-E8QlBM.mp4[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8_MG-E8QlBM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=65[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wooden platform with three potted plants, there is a person looking down with both legs raised on the table. Who is this person?
A. A woman with brown short hair
B. A woman with brown long hair
C. A woman with black short hair
D. A woman with black long hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  20%|‚ñà‚ñà        | 33/165 [01:19<04:52,  2.21s/it][32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PCPQToF10IM.mp4[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PCPQToF10IM.mp4[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PCPQToF10IM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=66[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Some women wearing headscarves are standing inside the hut, while the sunlight outside is dazzling. A man in a black and white striped short sleeve is holding a mobile phone. When the subtitle 'time news arrived of another body' appears, what is the woman in the middle with her hands covering her face and carrying a child on her back doing?
A. Sweeping the floor
B. Chatting with others
C. Waving to the camera
D. Taking care of the child
E. Covering her face with both hands, looking distressed
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AYMdAVxALP4.mp4[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AYMdAVxALP4.mp4[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AYMdAVxALP4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=67[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is only one woman with golden hair wearing a white dress, she is intently looking at her raised hand. After the subtitle mentions 'an immediate abduction impossible', who is the character that appears in the video?
A. A man with white hair wearing a white dress
B. A man wearing a white hat and a floral-patterned shirt
C. A man wearing an olive-colored jacket and a white shirt
D. A man with blonde hair and a bare upper body
E. A man wearing a black hat and an all-black suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  21%|‚ñà‚ñà        | 34/165 [01:22<05:08,  2.35s/it][32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UD5ifzOPzhc.mp4[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UD5ifzOPzhc.mp4[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UD5ifzOPzhc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=68[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
How many rectangular yellow metal blocks are on the table? There is a person with purple gloves in the background. When the subtitle mentions "eneficial way is difficult to say the," what changes occur on the table?
A. The number of rectangular yellow metal blocks increased by two
B. The number of rectangular yellow metal blocks increased by one
C. The number of rectangular yellow metal blocks decreased by two
D. The number of rectangular yellow metal blocks decreased by one
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NMHmqgO04rU.mp4[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NMHmqgO04rU.mp4[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NMHmqgO04rU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=69[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white background at the top with black English letters 'K-nearest neighbor' written on it, there is a man wearing glasses and a suit in the bottom right corner. The screen has some red error symbols. When the subtitles say 'okay because these might be some noise,' what is the shape of the green graphic on the screen?
A. rectangle
B. circle
C. triangle
D. star
E. square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  21%|‚ñà‚ñà        | 35/165 [01:24<04:59,  2.30s/it][32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7080578381569445125.mp4[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7080578381569445125.mp4[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7080578381569445125.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=70[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Someone is washing fresh green vegetables in a stainless steel basin on the screen. After mentioning 'back from a long road trip in the middle of the night. He had been driving for hours and I wanted,' what appears on the screen?
A. meat frying in the pan
B. white ceramic plate with yellow edges
C. dark liquid seasoning in a jar
D. raw red meat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 36/165 [01:25<03:57,  1.84s/it][32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wvfctNd-Aio.mp4[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wvfctNd-Aio.mp4[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wvfctNd-Aio.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=72[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man wearing a brown apron and blue jeans is sitting on a sofa, with flower-patterned white cushions and pillows. The man is holding a plate in one hand and chopsticks in the other. There is a dog with a collar in front of him. In the direction of his hand holding the plate, there is a kitchen full of utensils. When the subtitle 'You can't eat this' appears, what is the clothing like under the man's brown apron?
A. White shirt
B. Blue shirt
C. White chef uniform
D. Blue short sleeves
E. White short sleeves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = er1oRjH2iu8.mp4[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/er1oRjH2iu8.mp4[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: er1oRjH2iu8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=71[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the news screen is a bald man wearing a black suit with a white shirt, while on the right side of the news screen is a newspaper showing a picture of a woman with curly hair wearing a white shirt. Which subtitles appeared on the screen at the same time as this newspaper?
A. "politics totally so he's right there the"
B. "general election would somehow be a"
C. "Minister um in sunak government in what"
D. "accountability and there's be flights to"
E. "the sword having lovely nice thick gold"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  22%|‚ñà‚ñà‚ñè       | 37/165 [01:27<04:15,  2.00s/it][32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbgwG8fcIu0.mp4[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbgwG8fcIu0.mp4[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbgwG8fcIu0.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=74[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white wall with a hanging picture frame, a woman wearing a blue uniform, black shorts, and holding a green notebook did what while facing the camera?
A. She stuck out her tongue at the camera
B. She adjusted her long hair facing the camera
C. She made a funny face at the camera
D. She showed her notes to the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  23%|‚ñà‚ñà‚ñé       | 38/165 [01:28<03:21,  1.58s/it][32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = g7zuBUMBr2E.mp4[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/g7zuBUMBr2E.mp4[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: g7zuBUMBr2E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=76[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A white-framed black screen shows no image. When the caption mentions 'Fahlman posted this note, which would solve everything,' what changes occur on the black screen?
A. Blue English text appears on the screen
B. Green English text appears on the screen
C. Green numbers appear on the screen
D. Red English text appears on the screen
E. Yellow English text appears on the screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = O471uwTNx6k.mp4[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/O471uwTNx6k.mp4[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: O471uwTNx6k.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=73[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a space constructed with lines, featuring various colors, what objects are present when the subtitle 'they hear a mix of different sounds' appears?
A. A man with hands down, looking up
B. A woman with dark skin
C. A woman with tied hair, wearing a patterned shawl
D. A woman wearing a colorful headscarf
E. A man raising both hands with palms facing outward
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  24%|‚ñà‚ñà‚ñé       | 39/165 [01:29<03:32,  1.69s/it][32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=78[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two men are having a conflict in the woods. The man on the left side of the screen is holding a scarf in his right hand and sunglasses in his left hand. The man on the right side of the screen is wearing a gray hoodie and has long hair. When the scene changes to a Jeep, what change happens to the man sitting in the passenger seat?
A. He changed into a black short-sleeved shirt
B. He is now wearing a hat
C. His face has more scars
D. He became bald
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bgklOaBBmB8.mp4[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bgklOaBBmB8.mp4[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bgklOaBBmB8.mp4 | Selected 12 frames[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=75[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 12:33:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the brown wooden table, there is a transparent bowl filled with meat and broth. A pair of hands on either side of the bowl lifts it up. After lifting the bowl, what transition occurs in the scene?
A. From the floor to the microwave
B. From the table to the floor
C. From the table to the microwave
D. From the table to the chair
E. From the table to outside
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fo97qfO-9_g.mp4[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fo97qfO-9_g.mp4[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fo97qfO-9_g.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=77[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark car, there is a screen above, and a clock in front displaying 0:17. A man wearing glasses sitting in the front right seat is looking at the mirror. When the subtitle 'you guys to charity what's your name' appears, what action is this man with glasses doing?
A. Pointing at the mirror with his middle finger
B. Giving a thumbs-up
C. Stretching both hands towards the mirror
D. Pointing at the mirror with his index finger
E. Closing his eyes tightly
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  24%|‚ñà‚ñà‚ñç       | 40/165 [01:33<04:46,  2.29s/it][32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 59iv6EYWNn8.mp4[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/59iv6EYWNn8.mp4[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 59iv6EYWNn8.mp4 | Selected 13 frames[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=80[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-29 12:33:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When mentioning 'foreign', there's a Chinese flag in front of a dark blue background, and a man wearing a white shirt, black suit jacket, and a blue and white striped tie. What is his hairstyle like?
A. Long straight black hair
B. Big waves
C. Explosive hair
D. Black and white mixed short hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  25%|‚ñà‚ñà‚ñç       | 41/165 [01:35<04:11,  2.03s/it][32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7252661595875183874.mp4[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7252661595875183874.mp4[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7252661595875183874.mp4 | Selected 13 frames[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=82[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-29 12:33:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the live news broadcast set, there are three paintings made into window shapes, with black grids and some tall buildings inside the frames. Two men in suits and a woman in a black skirt are conversing. The woman is looking at a piece of paper in her hand, the man in the middle has his arms crossed, and another man is speaking. There is a round table with a coffee cup in front of them. What did the man in the middle do?
A. The man speaking picked up the coffee cup
B. The man sitting on the left stood up
C. The woman and the man in the middle shook hands
D. The man sitting in the middle placed his hands on his own legs
E. The woman stood up from her seat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = h4jIoMxZopU.mp4[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/h4jIoMxZopU.mp4[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: h4jIoMxZopU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=79[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man with black hair wearing a green coat sits with a boy who also has black hair. The man is saying something to the boy. In which subtitles have this man appeared before?
A. I am a photographer
B. I know
C. He buys the things and then returns to his son who was waiting for him
D. Help me
E. Don't do this
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  25%|‚ñà‚ñà‚ñå       | 42/165 [01:36<03:47,  1.85s/it][32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UwJTCg5fpXg.mp4[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UwJTCg5fpXg.mp4[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UwJTCg5fpXg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=84[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a blue background, a gentleman wearing a shirt with pink floral patterns is speaking. What did the gentleman do after becoming friends with the unicorn?
A. Put on a watch
B. Changed into a different shirt
C. Put on a mask
D. Put on a pair of sunglasses
E. Put on a unicorn headpiece
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = anrKq6HgPvs.mp4[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/anrKq6HgPvs.mp4[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: anrKq6HgPvs.mp4 | Selected 5 frames[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=81[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 12:33:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the picture, a woman is sitting on a chair holding two children beside her. Another child is standing behind her. A boy in a black woolen coat and another boy in a blue jacket are visible. The girl is wearing a red woolen coat and a checkered skirt. There is a white glass door in the background and green plants on the side. Who is the child sitting on the armrest of the chair in the picture?
A. The child wearing a red woolen coat
B. The child wearing a blue jacket
C. The child wearing a grey jacket
D. The child wearing a green woolen coat
E. The child wearing a checkered shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  26%|‚ñà‚ñà‚ñå       | 43/165 [01:38<03:42,  1.82s/it][32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bXRuqcmTIuk.mp4[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bXRuqcmTIuk.mp4[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bXRuqcmTIuk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=86[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A pair of hands holds a fresh yellow egg and places it on top of a cup with black spotted designs. When the subtitle says 'when the weather is dark and gloomy', what changes occur to the egg?
A. The eggshell turns white.
B. The eggshell shatters into small fragments.
C. The eggshell splits into two halves from an intact oval shape.
D. The eggshell does not change.
E. The eggshell turns red.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7003765189401185542.mp4[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7003765189401185542.mp4[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7003765189401185542.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=83[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:33:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the pot of rolling hot oil, there are many golden fried chicken pieces being deep-fried. Before the subtitle says 'Fry the chicken for four to five minutes,' which person first appears on the screen?
A. A blonde-haired woman wearing a black top
B. A red-haired woman wearing a black top
C. A black-haired woman wearing a green top
D. A black-haired woman wearing a white top
E. A black-haired woman wearing a black top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8MkL3W6wU3g.mp4[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8MkL3W6wU3g.mp4[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8MkL3W6wU3g.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=85[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two people are sitting on a screen, with a long-haired woman in a black long-sleeve dress on the left and a short-haired man in a black long-sleeve shirt on the right. Behind them, there are various types of trees. In front of them, there is a blue water cup. With which subtitles did this blue water cup appear together?
A. served at every single Chinese restaurant with the word 'dragon' in its name, because it's the
B. Here we learn that young Joe had a lot of enemies because he was a bully
C. a perp school called Evergreen Academy. which is a school Joe went to when he was younger.
D. by two loving parents, and seems to be thriving with the cello. this provides Joe with newfound
E. Right after, Joe manages to answer the first question about who he is
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 44/165 [01:41<04:26,  2.20s/it][32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = x4UBaEojM6U.mp4[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/x4UBaEojM6U.mp4[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: x4UBaEojM6U.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=88[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the wooden couch, there is a small red wooden scroll-shaped table with an open book on it, and the caption 'the little scroll table on the couch is' appears. What is the object that appears next?
A. beehive-shaped window in the courtyard
B. sign with Chinese characters
C. worker wearing a safety helmet with the Chinese flag
D. silver nail-shaped object
E. goldfish swimming in the pond
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gyV6EqgiPNg.mp4[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gyV6EqgiPNg.mp4[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gyV6EqgiPNg.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=87[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:33:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room with a gray-white curtain, there is a woman wearing a black short-sleeved shirt. What action does she make when she says 'old women so it just goes back to like'?
A. She raises both hands
B. She props up with both arms
C. She props up her right arm and raises her left hand
D. She props up her left arm and raises her right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  27%|‚ñà‚ñà‚ñã       | 45/165 [01:44<04:48,  2.40s/it][32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7234536361296940314.mp4[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7234536361296940314.mp4[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7234536361296940314.mp4 | Selected 11 frames[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=90[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 12:33:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen, a white plate is holding several buns, with a hand picking up one of the buns. When the subtitle 'the biggest change in the recipe was adding chocolate chips i did it for sake of my children' appears, what pattern is on the cloth under the plate?
A. white striped
B. black and white striped
C. black and white checkered
D. white checkered
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mbcvVYobCXI.mp4[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mbcvVYobCXI.mp4[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mbcvVYobCXI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=89[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the black pot with some broth, tomato sauce, and yellow vegetable pieces, what items are visible when the subtitle 'You still give me butterflies, my butterfly' appears?
A. Plate
B. Chopsticks
C. Lid
D. Garlic
E. Green vegetable
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 46/165 [01:45<04:19,  2.18s/it][32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -An3wZyoYe0.mp4[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-An3wZyoYe0.mp4[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -An3wZyoYe0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=92[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, a black egg-shaped stone on the left and a white egg-shaped stone on the right, then a pile of seaweed on the beach, and finally, two white egg-shaped stones on the beach.
B. First, two white egg-shaped stones on the beach, then a black egg-shaped stone on the left and a white egg-shaped stone on the right, and finally, a pile of seaweed on the beach.
C. First, a pile of seaweed on the beach, then a black egg-shaped stone on the left and a white egg-shaped stone on the right, and finally, two white egg-shaped stones on the beach.
D. First, two white egg-shaped stones on the beach, then a pile of seaweed on the beach, and finally, a black egg-shaped stone on the left and a white egg-shaped stone on the right.
E. First, a pile of seaweed on the beach, then two white egg-shaped stones on the beach, and finally, a black egg-shaped stone on the left and a white egg-shaped stone on the right.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = MJYBHfYF8LI.mp4[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/MJYBHfYF8LI.mp4[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: MJYBHfYF8LI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=91[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the blue seawater, there are coral reefs and seashells. On the screen, there is a person wearing a diving suit. When the subtitle 'beaches and plenty of drilling dive' appears, what is this person in the diving suit doing?
A. Diving in the seawater
B. Performing an underwater show
C. Playing with a sea turtle
D. Waving at the camera
E. Catching seafood
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  28%|‚ñà‚ñà‚ñä       | 47/165 [01:48<04:36,  2.35s/it][32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lojHyp1k0gE.mp4[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lojHyp1k0gE.mp4[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lojHyp1k0gE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=94[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the city streets, there is a white truck in the middle of the screen. In the distance, there is a yellow building, and nearby on the left, a woman in black clothes with short hair is talking to a man on the right who is also wearing black. When the subtitles mention 'you met with investors in Hong Kong and Kuala Lumpur in Singapore who are', what did the man do?
A. opened the car door
B. hugged the woman briefly
C. waved a few times to the woman
D. took out a phone
E. picked up a pair of scissors
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HRYlXC_ChzU.mp4[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HRYlXC_ChzU.mp4[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HRYlXC_ChzU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=93[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dim room, there is a glass window as the background. On the table in front of the window, there are many green plants and flowers. A woman is standing in front of the wooden table, lighting a fire stick. What is she doing?
A. Burning plants in a pot
B. Lighting incense
C. Lighting a candle
D. Burning a stick
E. Lighting a handheld incense stick
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  29%|‚ñà‚ñà‚ñâ       | 48/165 [01:50<04:15,  2.18s/it][32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hg2Q_O5b9w4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=96[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Sitting in the driver's seat of the car, a woman wearing blue jeans and a high ponytail mentioned in the subtitles 'really in depth car videos like those'. What color top was she wearing?
A. purple
B. white
C. blue
D. black
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UO_6TQnnOxM.mp4[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UO_6TQnnOxM.mp4[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UO_6TQnnOxM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=95[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the white-background PPT screen, there is black text at the bottom, yellow-highlighted text on the left, and in the middle, an illustration composed of a blue rectangle, a green circle, and a blue triangle. When the subtitle 'spaceship this and this and so right and' appears, what changes occur to the illustration?
A. Covered by a blue highlight
B. A star appeared in the middle
C. Got bigger
D. Got smaller
E. A red dot appeared in the middle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  30%|‚ñà‚ñà‚ñâ       | 49/165 [01:52<04:16,  2.21s/it][32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -0aM99dMu_4.mp4[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-0aM99dMu_4.mp4[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -0aM99dMu_4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=98[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The video shows the interior of a museum with two white light fixtures. Many white cabinets containing different artifacts are placed on the dark-colored floor. On the right side of the screen, a woman is sitting in a room illuminated by white lights, shown in a small video frame. What material is the protective cover placed over the artifacts on the cabinet made of?
A. Ceramics
B. Plastic
C. Glass
D. Iron
E. Acrylic
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/b__dUom9AcQ.mp4[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: b__dUom9AcQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=97[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an image with a white background and black English text, where the heading is styled as 'published as a conference paper at ICLR 2020,' the top row contains photos of six machines. When 'gradient so that's the outset let's' is mentioned, what changes occur to these six images?
A. There is a yellow circle annotation at the bottom of the images.
B. There is a red circle annotation at the top of the images.
C. There is a red circle annotation at the bottom of the images.
D. There is a yellow circle annotation at the top of the images.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  30%|‚ñà‚ñà‚ñà       | 50/165 [01:55<04:23,  2.29s/it][32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wFrztzzohJ8.mp4[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wFrztzzohJ8.mp4[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wFrztzzohJ8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=100[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the curtain, there is a transparent lectern with red text on it. Next to the lectern, a person wearing a blue coat is raising their right hand and speaking with their head lowered. What item is present in this scene?
A. Tie
B. Belt
C. Microphone
D. Display Screen
E. Mobile Phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KTY9bogonyw.mp4[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KTY9bogonyw.mp4[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KTY9bogonyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=99[0m
[32m2025-11-29 12:33:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a meadow with many animals, an old man dressed in blue clothes and wearing a red cape is talking to two naked people. Which animal appears on the screen?
A. Peacock
B. Tiger
C. Crow
D. Giraffe
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  31%|‚ñà‚ñà‚ñà       | 51/165 [01:57<04:35,  2.42s/it][32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TlaX2iIYZD4.mp4[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TlaX2iIYZD4.mp4[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TlaX2iIYZD4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=102[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the middle of the screen, there is a white-haired man dressed in a black suit with a dark blue tie, sitting in front of a white flag with a blue Star of David. What is this white-haired man doing?
A. Drinking water
B. Sleeping
C. Writing
D. Speaking into a microphone
E. Brewing tea
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dE5iWeCVpGI.mp4[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dE5iWeCVpGI.mp4[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dE5iWeCVpGI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=101[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a line of English text at the top of the PPT in the video, with some chemical formulas written below it. On the right side, there are two women in video frames. The woman in the lower right is sitting in front of a mirror with her head down, while the woman in the upper right with long black straight hair is wearing a black and white checkered coat and a dark red inner garment, facing the mirror. When the subtitle 'one and it‚Äòs not of that I what I want' appears, what is the color of the chair that the woman in the lower right is sitting on?
A. Black
B. Off-white
C. Yellow
D. Olive
E. Green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 52/165 [02:00<04:35,  2.44s/it][32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TlaX2iIYZD4.mp4[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TlaX2iIYZD4.mp4[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TlaX2iIYZD4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=104[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a slightly blurred background, what is a woman with long curly hair, wearing a long-sleeved top and a necklace, doing when the caption 'work you breathe it you live it and' appears?
A. Holding a blue pen and writing something
B. Holding a black pen and writing something
C. Holding a purple pen and writing something
D. Holding a white pen and writing something
E. Holding a red pen and writing something
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VGQ_djSR7zE.mp4[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VGQ_djSR7zE.mp4[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VGQ_djSR7zE.mp4 | Selected 6 frames[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=103[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 6 specific frames[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 6 custom frames[0m
[32m2025-11-29 12:33:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 6 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, a hand wearing a pair of white gloves is touching someone's neck, which shows signs of bruises. When the mention of 'The ME shows thetn an incision on the throat of one of the dead passengers. It is a deep,', what happens next?
A. A woman wearing glasses and dark clothes appears along with a man dressed in a white-gray coat.
B. A woman wearing glasses and dark clothes appears along with a man dressed in a black coat.
C. A woman wearing glasses and dark clothes appears along with a man dressed in a yellow coat.
D. A woman wearing glasses and dark clothes appears along with a man dressed in an olive coat.
E. A woman wearing glasses and dark clothes appears along with a man dressed in a gray coat.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LHXS0QR1ThA.mp4[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LHXS0QR1ThA.mp4[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LHXS0QR1ThA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=105[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The PPT on the screen has a three-line English title at the top, chemical formulas are filled below, and there are video screens of two women on the right; the woman at the bottom right is wearing a light-colored short-sleeve shirt, has long hair, black-frame glasses, and a wristwatch with a white strap. What kind of necklace is the woman at the bottom right wearing when the subtitle 'okay so what do we do now to find the' appears?
A. silver necklace
B. blue gemstone necklace
C. gold square necklace
D. pearl necklace
E. green gemstone necklace
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  32%|‚ñà‚ñà‚ñà‚ñè      | 53/165 [02:03<04:42,  2.52s/it][32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XJ6REZOXsvM.mp4[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XJ6REZOXsvM.mp4[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XJ6REZOXsvM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=106[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences is correct?
A. First appears Question1: How to detect key-points in the etc. below step1 etc., then Question1: How to detect key-points in the etc., followed by two red circles where the formula is circled, and finally Question2: Why use gaussian etc.
B. First appears Question1: How to detect key-points in the etc., followed by two red circles where the formula is circled, then Question1: How to detect key-points in the etc., below appears step1 etc., and finally appears Question2: Why use gaussian etc.
C. First appears Question1: How to detect key-points in the etc., followed by two red circles where the formula is circled, then Question2: Why use gaussian etc., and finally Question1: How to detect key-points in the etc. below step1 etc.
D. First appears Question2: Why use gaussian etc., then Question1: How to detect key-points in the etc. below step1 etc., and finally Question1: How to detect key-points in the etc., followed by two red circles where the formula is circled.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = T5bTeGzgJFs.mp4[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/T5bTeGzgJFs.mp4[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: T5bTeGzgJFs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=107[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with slightly dim lighting, there stands a woman with long hair, wearing blue clothes. She is looking at a square screen in front of her and is touching the screen with her hand. On the screen, there is a man. Not far from them, there is a lit lamp. What is the color of the man's clothes on the screen?
A. white
B. yellow
C. purple
D. olive
E. pink
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 54/165 [02:05<04:36,  2.49s/it][32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sKvvuo9Yxqk.mp4[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sKvvuo9Yxqk.mp4[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sKvvuo9Yxqk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=108[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a grassy field with a gentle breeze and beautiful sunshine, there is a withered tree on the right. In the middle, a group of people dressed in animal skins are standing. They are holding long spears, and the leader is placing stone heads with carved patterns together. Which of the following subtitles have appeared along with the stone heads with carved patterns?
A. The trip continues with only stops to hunt and rest. One evening,when they find a large and
B. men bring the sleds to carry the bison on,Tau stays by the edge of the diff,crying in denial.
C. Now that their hunt has been divided equally,Xi's party leaves on their own to return to their home
D. to give Kappa a memorial service that symbolizes the passing of one's spirit to the afterlife.
E. on a further ledge,where he breaks a leg and falls unconscious. Desperate to save his san,
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = BRiFXVCr1Ak.mp4[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/BRiFXVCr1Ak.mp4[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: BRiFXVCr1Ak.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=109[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with many yellow pages as the background, there is a blue-gray map. What changes occurred to the blue-gray map when the subtitle "subcontinent" appeared?
A. The entire map changed from blue-gray to red
B. The entire map changed from blue-gray to green
C. Different colors filled in the regions
D. The entire map changed from blue-gray to white
E. The entire map changed from blue-gray to purple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  33%|‚ñà‚ñà‚ñà‚ñé      | 55/165 [02:08<04:54,  2.68s/it][32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = h0OHi9uAcBo.mp4[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/h0OHi9uAcBo.mp4[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: h0OHi9uAcBo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=110[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First is a man seated in a gaming chair, with light strips on the wall behind him, wearing headphones. Next is a man in a brown long-sleeve shirt talking to a white microphone, with a blue curtain beside him. Finally, a scene with two women and a man wearing a hat standing above them, with a fan behind the man.
B. First is a scene with two women and a man wearing a hat standing above them, with a fan behind the man. Next is a man seated in a gaming chair, with light strips on the wall behind him, wearing headphones. Finally, a man in a brown long-sleeve shirt talking to a white microphone, with a blue curtain beside him.
C. First is a man in a brown long-sleeve shirt talking to a white microphone, with a blue curtain beside him. Next is a man seated in a gaming chair, with light strips on the wall behind him, wearing headphones. Finally, a scene with two women and a man wearing a hat standing above them, with a fan behind the man.
D. First is a scene with two women and a man wearing a hat standing above them, with a fan behind the man. Next is a man in a brown long-sleeve shirt talking to a white microphone, with a blue curtain beside him. Finally, a man wearing headphones is seated in a gaming chair, with light strips on the wall behind him.
E. First is a man in a brown long-sleeve shirt talking to a white microphone, with a blue curtain beside him. Next is a scene with two women and a man wearing a hat standing above them, with a fan behind the man. Finally, a man seated in a gaming chair, with light strips on the wall behind him, wearing headphones.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VL259eBJ68w.mp4[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VL259eBJ68w.mp4[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VL259eBJ68w.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=111[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a man wearing a green jacket and holding a green bag is talking to a long-haired woman in a white dress sitting at a desk. What did the long-haired woman in a white sleeveless top do after picking up a pen?
A. Retouched a photo
B. Drew a picture on paper
C. Drank water
D. Wrote
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  34%|‚ñà‚ñà‚ñà‚ñç      | 56/165 [02:10<04:39,  2.57s/it][32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bjymxow3TVQ.mp4[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bjymxow3TVQ.mp4[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bjymxow3TVQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=112[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:33:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a woman in a black dress in the kitchen. Behind her, there is a white cabinet with some items on it and a window with white curtains. The curtains are flanked by wooden shelves. In front of her, there is a large counter with a cast iron pot on it. Above the pot is a large stainless steel bowl which she is holding with both hands. Next to them, there is a large pink container with red liquid inside. What is the woman doing in the kitchen?
A. Turned the large bowl upside down
B. Put a lid on the large bowl
C. Moved the large bowl to the windowsill
D. Placed the large bowl on the counter
E. Put the large bowl on the pink container
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:33:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UbNyMSwoT5A.mp4[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UbNyMSwoT5A.mp4[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UbNyMSwoT5A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=113[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:33:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a large control panel, there is a man with short hair and glasses. Under the man's hand is a cream-colored paper. What style of clothing is the man with glasses wearing?
A. Black hooded jacket
B. Pink plaid shirt
C. Blue hooded jacket
D. Black suit
E. White T-shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñç      | 57/165 [02:13<04:32,  2.53s/it][32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = e6HwinLBK_Y.mp4[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/e6HwinLBK_Y.mp4[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: e6HwinLBK_Y.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=114[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the grass, six people are fighting two against two. One person wielding a long sword is slashing at a person holding a long spear. The person with the long spear is falling backward. Who is the person swinging the long sword?
A. The person without a helmet and without a shield
B. The person wearing a helmet and holding a shield
C. The person wearing a white headscarf
D. The person with golden hair and a shield
E. The person wearing a headscarf and with no hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eE5Z7gDbgVA.mp4[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eE5Z7gDbgVA.mp4[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eE5Z7gDbgVA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=115[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the background of the scene, there's a green plant. In the middle, there is a black man who is Kamala Khan's clone. Next to him, there is a woman wearing a white hat. Who is smiling in the scene at this moment?
A. The woman wearing a black hat
B. Kamala Khan's clone
C. The woman wearing a white hat
D. The man wearing a white hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  35%|‚ñà‚ñà‚ñà‚ñå      | 58/165 [02:15<04:27,  2.50s/it][32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7276598470151032066.mp4[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7276598470151032066.mp4[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7276598470151032066.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=116[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:34:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a black-and-white background, three men appear on the screen. The man on the right has his hands crossed in front of his chest, the man on the left is wearing a hat and his finger is pointing to the upper right. The other man is staring sharply at the man on the right. What is the style of the hat worn by the man on the left when the subtitle 'There's no way I'm going down' appears?
A. a beanie
B. a top hat
C. a denim cap
D. a baseball cap
E. a beret
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = FnKDgC9aNu0.mp4[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/FnKDgC9aNu0.mp4[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: FnKDgC9aNu0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=117[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a young man stands on the left side of the screen, and an elderly man with white hair, wearing a red plaid shirt, stands on the right side of the screen. The two face each other. What did this elderly man do the first time he appeared?
A. Was washing his hair
B. Held a knife towards himself
C. Looked in the mirror
D. Held a knife towards the person in front
E. Was cutting his hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñå      | 59/165 [02:17<03:53,  2.20s/it][32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PbiTIR8N4Hc.mp4[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PbiTIR8N4Hc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=118[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, three men are sitting. In the top right corner of the screen, there is a square picture. When the subtitle 'doomed doomed attempt ah they don't know' appears, what objects are present on the screen?
A. A blue shirt
B. A red arrow
C. A purple backpack
D. A black chair
E. A white short sleeve
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NpYUxd1vUUE.mp4[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NpYUxd1vUUE.mp4[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NpYUxd1vUUE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=119[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow ground, there is a fossil of a trilobite. After the narrator says "the Devonian era was an incredibly," which fossil appears next?
A. Shell fossil
B. Plant fossil
C. Insect fossil
D. Coral fossil
E. Fish fossil
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  36%|‚ñà‚ñà‚ñà‚ñã      | 60/165 [02:21<04:39,  2.66s/it][32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WTT7XZko3qk.mp4[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WTT7XZko3qk.mp4[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WTT7XZko3qk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=120[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of events is correct?
A. First, there is a painting showing a father, mother, a young boy, and a frightening old woman, then a short-haired blonde woman is embroidering, next, Lydia and Mrs. Mills are conversing in a room, and finally, the short-haired blonde woman uncovers a piece of furniture.
B. First, a short-haired blonde woman is embroidering, then Lydia and Mrs. Mills are conversing in a room, next, the short-haired blonde woman uncovers a piece of furniture, and finally, there is a painting showing a father, mother, a young boy, and a frightening old woman.
C. First, there is a painting showing a father, mother, a young boy, and a frightening old woman, then a short-haired blonde woman is dancing, next, Lydia and Mrs. Mills are conversing in a room, and finally, the short-haired blonde woman uncovers a piece of furniture.
D. First, Lydia and Mrs. Mills are conversing in a room, then a short-haired blonde woman is embroidering, next, the short-haired blonde woman uncovers a piece of furniture, and finally, there is a painting showing a father, mother, a young boy, and a frightening old woman.
E. First, there is a painting showing a father, mother, a young boy, and a frightening old woman, then a short-haired blonde woman is embroidering, next, the short-haired blonde woman uncovers a piece of furniture, and finally, Lydia and Mrs. Mills are conversing in a room.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5qMcDQd17Y4.mp4[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5qMcDQd17Y4.mp4[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5qMcDQd17Y4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=121[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a black coat and blue jeans is lying on his side in the trunk of a car with his hands and feet tied up with tape. What happens next?
A. Three men are practicing hand-tied drills on a deserted ground
B. The man in black clothes struggles free from the tape binding his hands and feet inside the trunk
C. Three men are listening to a professional in black short sleeves explaining something
D. Three men are singing inside a car
E. Three men are dining inside a restaurant
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  37%|‚ñà‚ñà‚ñà‚ñã      | 61/165 [02:23<04:24,  2.54s/it][32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _EUDpS9UF9o.mp4[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_EUDpS9UF9o.mp4[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _EUDpS9UF9o.mp4 | Selected 11 frames[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=122[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a black and white woven top, glasses, with long black hair is mentioned with the subtitle 'you're interested in.' What is behind her on the right?
A. door
B. computer
C. lamp
D. phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AxciimuEZAc.mp4[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AxciimuEZAc.mp4[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AxciimuEZAc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=123[0m
[32m2025-11-29 12:34:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there's a person cutting a green onion with a knife, and in the upper left corner, there's also a screen with burning wood. When the subtitle mentions 'Onion,' what other objects are present in the scene?
A. On the table, there's also a silver bowl containing a tomato and a pumpkin.
B. Oven
C. Bread
D. Watch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 62/165 [02:24<03:51,  2.24s/it][32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Bjymxow3TVQ.mp4[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Bjymxow3TVQ.mp4[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Bjymxow3TVQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=124[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a transparent glass building, surrounded by green trees and a few other trees, there are some black rectangular objects placed in front of the trees. The sunlight is shining on the marble surface. A man in white and a blonde woman walk past a black, prominently sculpted point structure. When the phrase 'what does that mean for others' is mentioned, what kind of shoes is the woman wearing?
A. White sneakers with black edges
B. White slippers with black edges
C. White high heels with black edges
D. White leather shoes with black edges
E. White straw shoes with black edges
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ixlQX7lV8dc.mp4[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ixlQX7lV8dc.mp4[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ixlQX7lV8dc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=125[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white table, there is a man wearing black pants and glasses standing. In front of the man, there is a gray wooden board. What hairstyle does the man with glasses have?
A. Brown short hair
B. Brown shoulder-length curls
C. Blue short hair
D. Black shoulder-length curls
E. Black buzz cut
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
Model Responding:  38%|‚ñà‚ñà‚ñà‚ñä      | 63/165 [02:26<03:42,  2.18s/it][32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pFtKaT3GF9I.mp4[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pFtKaT3GF9I.mp4[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pFtKaT3GF9I.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=126[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, a picture with the flag of Iraq is shown, followed by a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner, and lastly a man discussing a picture with a sheep and a desert is shown.
B. First, a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner is shown, followed by a picture with the flag of Iraq, and lastly a man discussing a picture with a sheep and a desert is shown.
C. First, a man discussing a picture with a sheep and a desert is shown, followed by a picture with the flag of Iraq, and lastly a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner is shown.
D. First, a man discussing a picture with a sheep and a desert is shown, followed by a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner, and lastly a picture with the flag of Iraq is shown.
E. First, a picture of a man in green clothes and a man in white clothes with a black background in the upper right corner is shown, followed by a man discussing a picture with a sheep and a desert, and lastly a picture with the flag of Iraq is shown.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 64/165 [02:29<03:46,  2.24s/it][32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qbA42wQoWAs.mp4[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qbA42wQoWAs.mp4[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qbA42wQoWAs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=128[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a picture featuring an animal with chameleon eyes, after the subtitle 'helped it seek out prey, primarily' appears, which animal is shown?
A. gecko
B. snake
C. chipmunk
D. frog
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = J_ZmaKRpyoU.mp4[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/J_ZmaKRpyoU.mp4[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: J_ZmaKRpyoU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=127[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the night-draped airport, four people are experiencing a ride in a vertical lift aircraft. Inside the aircraft, they are wearing earphones and fluorescent-patterned armor. Who among the following is participating?
A. A man with white hair
B. A woman with long hair
C. A child
D. An elderly man with white hair
E. A woman with green hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  39%|‚ñà‚ñà‚ñà‚ñâ      | 65/165 [02:31<03:44,  2.24s/it][32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yl-6-Yzt--A.mp4[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yl-6-Yzt--A.mp4[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yl-6-Yzt--A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=130[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen, there are 15 images on the PPT. On the right side of the images, there are several lines of English text, with the words 'Comparison: Qualitative Results' written on the images. In the bottom right corner, there is a woman wearing a dark blue inner coat with a black outer coat. Which images are highlighted on the screen?
A. The last image in the bottom right corner is highlighted with a green box
B. The last image in the top left corner is highlighted with a green box
C. The last image in the bottom right corner is highlighted with a red box
D. An image in the middle is highlighted
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zTeDF7mQ88A.mp4[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zTeDF7mQ88A.mp4[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zTeDF7mQ88A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=129[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top left corner of the screen, there is a globe with white English text displaying continents and oceans. To the right of the image, there's a man sitting and wearing a gray shirt. What is this man doing?
A. Raising both hands above his head
B. Crossing both arms in front of his chest
C. Clenching both hands into fists
D. Interlacing his fingers with both hands
E. Holding his chin with one hand then opening it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  40%|‚ñà‚ñà‚ñà‚ñà      | 66/165 [02:33<03:42,  2.25s/it][32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7275734357799652640.mp4[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7275734357799652640.mp4[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7275734357799652640.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=132[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:34:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of the palace, a man dressed in colorful underwear and a white cloak, wearing tree branch decorations on his head, is dragging a woman in a skirt whose eyes sparkle with pink hearts. What change happened the last time this woman with sparkling pink hearts in her eyes appeared?
A. Her eyes changed from pink heart shapes to black tears streaming.
B. Her glasses changed from black with tears to pink heart shapes.
C. The woman held a shield.
D. She went from standing to sitting.
E. She wore a woven grass headband.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PCPQToF10IM.mp4[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PCPQToF10IM.mp4[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PCPQToF10IM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=131[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a close-up of a purple flower. The entire petal of the flower is elongated. The stamen is yellow, and there are many similar purple flowers nearby. What happened when the flower first appeared?
A. Two bees landed on the flower.
B. A bee was flying over the flower.
C. Several bees were flying over the flower.
D. A bee landed on the flower.
E. Two bees were flying over the flower.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 67/165 [02:34<03:07,  1.91s/it][32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1vvYsirvA2I.mp4[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1vvYsirvA2I.mp4[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1vvYsirvA2I.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=134[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the desert, there are three mannequins. In front of the mannequins, there is a man wearing an olive-colored coat. Next to him, a person wearing a black hat and black clothes is holding a handgun. After the subtitle mentions 'off target by 0.5 mm sensing', what item appears in the video?
A. ÊâãË°®
B. È¶ôÁÉü
C. Ê£ãÁõò
D. Êú®Ê°å
E. ÊâãÊû™
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7267884432420277506.mp4[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7267884432420277506.mp4[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7267884432420277506.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=133[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:34:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with the white text 'to partner in the firm', there is a man wearing a blue shirt who is resting his hand on the shoulder of another man beside him. What kind of beard does the man in the blue shirt have?
A. Mountain goat beard
B. Connected beard
C. Eight-character beard
D. One-character beard
E. Shaving beard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fw1rirubXiU.mp4[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fw1rirubXiU.mp4[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fw1rirubXiU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=135[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, a white-ringed vegetable is being cut with a knife on a wooden cutting board. What is this vegetable that is being cut?
A. Apple
B. Yuzu
C. Leek
D. Radish
E. Pumpkin
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  41%|‚ñà‚ñà‚ñà‚ñà      | 68/165 [02:38<04:00,  2.48s/it][32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = wFrztzzohJ8.mp4[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/wFrztzzohJ8.mp4[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: wFrztzzohJ8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=136[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an oil painting depicting many people, there is a man in blue clothes holding an object and kneeling towards a man in black clothes. There are also many people standing behind them. Which character appears in this scene?
A. A person in black clothes leaning on a crutch
B. A person wearing a red robe
C. A person in gray clothes holding a musical instrument
D. A person wearing a purple robe
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 69/165 [02:40<03:53,  2.43s/it][32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CEZ9rbjK3P4.mp4[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CEZ9rbjK3P4.mp4[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CEZ9rbjK3P4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=138[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black background, there is a screen framed with a red line. On the screen, there's a man with short white hair and a pouting mouth. When this man appears next to the text 'THE WALL STREET JOURNAL', what change occurs to him?
A. He has an additional pair of gold-framed glasses on his face
B. He has an additional hat on his head
C. He has an additional pair of silver-framed glasses on his face
D. His hair changes to black
E. He has an additional pair of sunglasses on his face
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GdZYLAI0vpc.mp4[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GdZYLAI0vpc.mp4[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GdZYLAI0vpc.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=137[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:34:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing an overcoat, spreading her hands, and a woman wearing a white jacket with earrings are standing in front of the house. Who appears after the phrase 'back to' is mentioned?
A. A short-haired man wearing glasses, a brown shirt, and blue pants with his hands in his pockets
B. A woman wearing a purple shirt
C. An old man holding a cane
D. A student carrying a schoolbag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ZfapKqwklG4.mp4[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ZfapKqwklG4.mp4[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ZfapKqwklG4.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=139[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman in a black top is sitting in front of a table. Behind and beside her are white walls and a bookshelf filled with books. There is a wooden object in front of her, and there are drawings on the table in front of her. Where else has this woman appeared?
A. A room with a window
B. Under green trees outdoors
C. In front of a table with potted plants
D. In front of a table with a desk lamp
E. A bench in the park
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:30[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 70/165 [02:42<03:34,  2.26s/it][32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = n24n_20Kwe4.mp4[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/n24n_20Kwe4.mp4[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: n24n_20Kwe4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=140[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:30[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the phrase 'forbidden instead they were welcome to' was mentioned, what action did the man in the red and purple striped clothes do in the old, broken room?
A. Got up from the bed and ran
B. Ate
C. Covered his ears with both hands
D. Picked up a cup and drank water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iHzypa15yRA.mp4[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iHzypa15yRA.mp4[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iHzypa15yRA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=141[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there are two large trees with thick branches and dense foliage. Below the trees is a path with wooden railings, and a car is parked on the road. When the subtitle 'from her so after all that craziness Tom' appears, what happens?
A. A man holding a bag walks towards the camera with his head down.
B. A dog and a cat chase each other under the tree.
C. A woman holding a bag walks towards the camera with her head down.
D. A child runs with a toy in his arms.
E. A black car drives by.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 71/165 [02:45<03:37,  2.32s/it][32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = uWBh0meTg08.mp4[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/uWBh0meTg08.mp4[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: uWBh0meTg08.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=142[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman in a black coat is standing in front of a closed store inside a mall, with a 'cna' news ticker moving below. When the phrase 'assistance at about 4:50 p.m and uh' is mentioned, what does she do?
A. She looked down slightly at the manuscript on her phone
B. She ran her fingers through her hair
C. She switched the drink from her left hand to her right hand
D. She faced the camera and adjusted the lens position
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _ZIa6SEJEyg.mp4[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_ZIa6SEJEyg.mp4[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _ZIa6SEJEyg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=143[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white background, after a hand writes the words 'Neural Architecture Search' in blue ink and then writes 'YOLO-NAS' over it in black ink with a big bracket, what follows next?
A. Draws a cartoon figure with raised hands standing next to a board filled with sketches on the left of the English text
B. Draws a timeline
C. Draws a table composed of colored lines
D. Draws a square frame
E. Draws two gears, one blue and one black
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 72/165 [02:47<03:32,  2.28s/it][32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = sWfcgeDth_w.mp4[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/sWfcgeDth_w.mp4[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: sWfcgeDth_w.mp4 | Selected 5 frames[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=144[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against the white background, there are texts in both pink and black colors. In the bottom right corner of the screen, there is a woman with long black hair, wearing a pink outer garment and a black inner garment. She is raising both hands with palms facing inwards. Before the subtitle mentions 'see this topic on final exams so if you,' what number appears in the screen's bottom right corner?
A. 3
B. 4
C. 7
D. 6
E. 5
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7296863219178638594.mp4[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7296863219178638594.mp4[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7296863219178638594.mp4 | Selected 5 frames[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=145[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 12:34:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The scene shows a lady sitting in a yellow flower field looking ahead, with a mountain peak in the distance. Yellow flowers bloom on a hillside. The lady has brown hair and is wearing a long-sleeved outfit. When 'Not the least of which, is' is mentioned, what object is not present in the scene?
A. Snowy mountain
B. Green long-sleeved outfit
C. Blue sky
D. Brown long-sleeved outfit
E. Yellow flowers of yellow flower clusters
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 73/165 [02:48<02:51,  1.86s/it][32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = W8w09l_mmT4.mp4[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/W8w09l_mmT4.mp4[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: W8w09l_mmT4.mp4 | Selected 11 frames[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=146[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside the glass window that looks out onto the street, there are five cups with black straws on the wooden table. Who is the person holding one of the drinks in the video while tasting it?
A. The woman wearing a black top and sunglasses
B. The man wearing a black short-sleeved shirt
C. The woman wearing a white top and glasses
D. The woman with long black hair wearing a black short-sleeved shirt
E. The short-haired woman wearing a white top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _hODR1cR9lo.mp4[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_hODR1cR9lo.mp4[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _hODR1cR9lo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=147[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the kitchen, there is a man wearing a white short-sleeved patterned shirt cutting meat. In front of him, there are other side dishes, too. At the beginning, what happens to the meat being cut on the chopping board?
A. Thrown away
B. Lifted up
C. Fried in oil
D. Boiled in water
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 74/165 [02:49<02:31,  1.67s/it][32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = o2F-N42Ufo4.mp4[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/o2F-N42Ufo4.mp4[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: o2F-N42Ufo4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=148[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, there is a woman with yellow hair, wearing a brown coat, a pair of necklaces, and glasses. With which of the following subtitles did she appear together?
A. "I like to wear it when I sleep"
B. "which i am wearing right now and i have"
C. "This style is particularly comfortable to wear"
D. "There are a lot of people who like to wear this"
E. "I really like this style"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3JzhP8qfbqE.mp4[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3JzhP8qfbqE.mp4[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3JzhP8qfbqE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=149[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scenarios is in the correct sequence?
A. First, a scene of a man in a gray suit with a black and white tie holding a gun is shown, followed by a photo of a person in a black suit with a black and red tie against a white background, and finally a scene of two people sitting and five people standing in a conference room is shown.
B. First, a scene of a man in a gray suit with a black and white tie holding a gun is shown, followed by a scene of two people sitting and five people standing in a conference room, and finally a photo of a person in a black suit with a black and red tie against a white background is shown.
C. First, a scene of two people sitting and five people standing in a conference room is shown, followed by a photo of a person in a black suit with a black and red tie against a white background, and finally a scene of a man in a gray suit with a black and white tie holding a gun is shown.
D. First, a photo of a person in a black suit with a black and red tie against a white background is shown, followed by a scene of two people sitting and five people standing in a conference room, and finally a scene of a man in a gray suit with a black and white tie holding a gun is shown.
E. First, a photo of a person in a black suit with a black and red tie against a white background is shown, followed by a scene of a man in a gray suit with a black and white tie holding a gun, and finally a scene of two people sitting and five people standing in a conference room is shown.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 75/165 [02:52<03:02,  2.02s/it][32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Kz8_rwVn094.mp4[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Kz8_rwVn094.mp4[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Kz8_rwVn094.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=150[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a piece of white paper displaying various Earth plates, there is a blue line, below which there is a box with a red stripe, and below the box, there is a black horizontal stripe with white letters inside. What shape is the box with the red stripe?
A. Triangle
B. Rectangle
C. Square
D. Ellipse
E. Rounded Square
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7097604725134118146.mp4[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7097604725134118146.mp4[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7097604725134118146.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=151[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a hospital with blue walls, there are two doctors in white coats and several black-clothed patients resting in their beds. There are also three IV drips in the room. What did the gray-haired doctor without a mask do when 'fast the lack of money throughout the' was mentioned?
A. Gave an IV to a patient in bed
B. Listened to the patient lying in bed
C. Inserted his hand into the pocket of his coat while leaning against the wall
D. Talked with a patient in bed
E. Shook hands with another masked doctor
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 76/165 [02:53<02:39,  1.79s/it][32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = HAED3riiZkw.mp4[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/HAED3riiZkw.mp4[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: HAED3riiZkw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=152[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The background is a vibrant sky with sunlight above, featuring trees and a green meadow. A woman wearing an orange dress, a green shoulder bag, and green shoes is walking on stone steps with a handrail on the right side. In which other scenes does this woman appear?
A. On a green meadow with long shadows cast by the sun
B. In a coffee shop
C. Inside a clothing store in a shopping mall
D. Next to the dining table in a dining hall
E. By the swimming pool
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7rMgpExA4kM.mp4[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7rMgpExA4kM.mp4[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7rMgpExA4kM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=153[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
This is a piece of honeycomb taken from a box, placed in an iron tray. Below the iron tray is a table with a green tablecloth. There is also a pair of hands holding chopsticks, and next to it, there is a board of honeycomb. When this piece of honeycomb is placed in a large round stainless steel bowl and stirred with chopsticks, what changes occur?
A. Noodles were placed on the honeycomb
B. The honeycomb was poured out of the large bowl
C. Water was added to the honeycomb
D. The honeycomb was cut into pieces
E. The honeycomb was broken into pieces
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 77/165 [02:56<02:54,  1.98s/it][32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3t_Knk7FWT8.mp4[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3t_Knk7FWT8.mp4[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3t_Knk7FWT8.mp4 | Selected 12 frames[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=154[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 12:34:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What happens first on the screen after the subtitle 'and I am getting ready to go' appears, featuring a man wearing a black cold hat with an English letter logo, dressed in black clothes, carrying a black backpack, and sporting a stubbly mustache?
A. Manufacturing airplane wheels in a factory.
B. An airplane model suspended by several steel wires is displayed.
C. The man sits in a car looking out the window at the sunlit grass and trees.
D. Manufacturing the interior of an airplane fuselage.
E. Viewing the city from above.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Jaw7eWzgWr0.mp4[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Jaw7eWzgWr0.mp4[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Jaw7eWzgWr0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=155[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, two people are having a conversation. The woman on the left is sitting in a broadcasting room, while the man on the right is in a room having a discussion. When the man on the right says 'end not in a good place I mean I wish I', what accessory is the woman on the left wearing?
A. bracelet
B. ring
C. earrings
D. glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 78/165 [02:57<02:40,  1.85s/it][32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6976239624578419969.mp4[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6976239624578419969.mp4[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6976239624578419969.mp4 | Selected 15 frames[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=156[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 12:34:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with many musical instruments, there is a man wearing a dark green suit with a light blue shirt underneath, a blue tie, and glasses, holding a musical instrument. What is the color of the gloves worn by the man with glasses?
A. Black
B. Red
C. White
D. Yellow
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7309241426028596523.mp4[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7309241426028596523.mp4[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7309241426028596523.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=157[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A hand with manicured nails is placed near the shoulder of a reclining woman. The woman is wearing a black short sleeve shirt and is smiling. There is a toy figure behind her. What did the hand with manicured nails do after being placed on the reclining woman's shoulder?
A. Tapped the reclining woman's forehead
B. Tapped the reclining woman's face
C. Tapped the reclining woman's shoulder
D. Tapped the reclining woman's stomach
E. Tapped the reclining woman's buttocks
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 79/165 [02:59<02:44,  1.91s/it][32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VFXJnbnN5ro.mp4[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VFXJnbnN5ro.mp4[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VFXJnbnN5ro.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=158[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a space setting, there is a yellow sun design in the center with the word 'Emission' below. In which of the following scenarios has this sun design appeared?
A. In the starry sky from a side view, there is a glaring white light in the center, surrounded by a halo of white light.
B. In a red cloud-like background, there is a cluster of bright light spots emitting strong light in the center.
C. In a black night sky, there is a purple circular object emitting purple light, with the words 'Protoplanetary Nebula' inscribed on it.
D. In a space background, there is a yellow design on the left side with radiating lines around it, and on the right side, there is a circular design with light blocked by something, with a yellow line attached to the sun.
E. In a blue background, the center is sparkling with densely packed light dots.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 80/165 [03:02<02:52,  2.03s/it][32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mTn_C-SyW84.mp4[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mTn_C-SyW84.mp4[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mTn_C-SyW84.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=160[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a yellow table, there is a yellow cutting board with a piece of chicken breast on it. A person wearing a glove on the left hand has the left hand placed on the chicken breast, while holding a knife with the right hand on the chicken breast. When mentioning 'Only these ingredients and my family loves it,' what is this person doing?
A. This person is frying chicken breast
B. This person is frying a steak
C. This person is cutting chicken breast
D. This person is washing chicken breast
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:49[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8905KCkLDYc.mp4[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8905KCkLDYc.mp4[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8905KCkLDYc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=159[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:49[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the sunlight, the sea water reflects dazzling lights, and several men and women laugh heartily on the beach, raising their beer bottles to toast each other. What objects are present in this scene?
A. American flag
B. beach cart
C. watch
D. balloon
E. mobile phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7312063059160206597.mp4[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7312063059160206597.mp4[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7312063059160206597.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=161[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:34:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a wooden surface, a pair of hands is embroidering flowers on a cloth. There are already some yellow and white flowers embroidered on this cloth. What objects exist in this scene?
A. A flower basket
B. A knife
C. A wooden stick
D. A cup
E. A needle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 81/165 [03:04<02:57,  2.12s/it][32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6hBbXVkgxGE.mp4[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6hBbXVkgxGE.mp4[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6hBbXVkgxGE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=162[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Inside the subway station, on the left is the train and on the right are the waiting passengers. Some passengers are sitting with their phones, while others are standing. Screens and signs are suspended in the upper space of the subway station. After filming the subway station, what else did the camera capture?
A. a man wearing a hat
B. exit
C. a restaurant
D. subway car
E. a convenience store
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vEy6tcU6eLU.mp4[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vEy6tcU6eLU.mp4[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vEy6tcU6eLU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=163[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A person wearing a black coat is sitting, holding a document. Next to him is a table with a gun and a cell phone on it. There's a black lamp on the table. Who is holding the document?
A. Statham
B. Dougie
C. Jan
D. Mike
E. Bullet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 82/165 [03:06<03:05,  2.24s/it][32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mFliMGufpwc.mp4[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mFliMGufpwc.mp4[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mFliMGufpwc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=164[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing an orange shirt appears in front of a black background. The man rolls up his sleeves. The man is holding a plate of Indian specialty food in his hand. There is a food picture to the man's left, and when the subtitle 'These usually come to the Northern regions of India' appears, what is the shape of the plate in the picture to the right?
A. Rectangle
B. Circle
C. Square
D. Pentagon
E. Irregular Shape
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _uL3a3aMdMQ.mp4[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_uL3a3aMdMQ.mp4[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _uL3a3aMdMQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=165[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a woman with long hair dressed in yellow and a child. They are both sitting on a bed. What items are present in this room?
A. electric fan
B. parrot
C. refrigerator
D. dog
E. cat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 83/165 [03:09<03:06,  2.27s/it][32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2vVQo_GMA70.mp4[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2vVQo_GMA70.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=166[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a black background, two men are standing: one is wearing a white short-sleeve, and the other is wearing a blue long-sleeve coat. When the man in the white short-sleeve says "wouldn't be a monarch to like fantasize", what color is the inner wear of the man in the blue long-sleeve coat?
A. blue
B. purple
C. black
D. green
E. white
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GFg98TDqCpw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=167[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:34:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, after the yellow-bordered rectangular strip of paper is pasted, what appears next?
A. red strip of paper
B. pencil
C. notebook
D. mobile phone
E. white strip of paper with lines on it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:34:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 84/165 [03:11<03:15,  2.42s/it][32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VwZeSoYugZk.mp4[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VwZeSoYugZk.mp4[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VwZeSoYugZk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=168[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:34:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the lower right corner of the video, there is a bald person wearing sunglasses and dressed in black. There are also three boys on the screen: the one on the left is wearing a blue short-sleeve shirt, the one on the right is wearing a red long-sleeve shirt, and the one in the middle is wearing a gray short-sleeve shirt. Which of the following items does not appear in the video?
A. Black hat
B. White hat
C. Sunglasses
D. Blue short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = t48HXAjjDAU.mp4[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/t48HXAjjDAU.mp4[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: t48HXAjjDAU.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=169[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:35:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into two different characters' headshots on the left and right. The left headshot is of a person with glasses shouting. In the red frame at the bottom, it is written in white English text 'Hundreds rally in Tel Aviv for ceasefire in Gaza'. Whose hair is being blown messily by the strong wind in the screen?
A. A female reporter wearing a white coat
B. A male reporter wearing a grey coat
C. A female reporter wearing a black coat
D. A female reporter with glasses
E. A female reporter wearing a purple coat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NIxyQQfuVoc.mp4[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NIxyQQfuVoc.mp4[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NIxyQQfuVoc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=171[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Above a green lake, there is a small building by the shore. In the distance, there are some mountain peaks and a deep blue sky with clouds floating in it. The small building by the lake is light yellow with two windows. When it is mentioned that 'and only allowing a small group of people and animals, to survive and repopulate,' what is the shape of the roof of the small building?
A. Staircase
B. Square
C. Triangle
D. Rectangle
E. Semi-circle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 85/165 [03:14<03:08,  2.36s/it][32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qsH6q5wNso4.mp4[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qsH6q5wNso4.mp4[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qsH6q5wNso4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=170[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white house, surrounded by big trees, there is a woman wearing sunglasses, holding the hands of two little girls. What color is the top that the woman wearing sunglasses is wearing?
A. Blue
B. Yellow
C. Red
D. White
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LlqsCCa6y58.mp4[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LlqsCCa6y58.mp4[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LlqsCCa6y58.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=173[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which sequence of scenes in the video is correct?
A. A man wearing a green hooded coat is talking in front of a background wall with a picture of the Earth and some paintings hanging, four 3D demonstration images of the moon rover landing on the moon, and on his right, there is an English news webpage with some icons.
B. Four 3D demonstration images of the moon rover landing on the moon, on the right is an English news webpage with some icons, and a man wearing a green hooded coat is talking in front of a background wall with a picture of the Earth and some paintings hanging.
C. On the right is an English news webpage with some icons, four 3D demonstration images of the moon rover landing on the moon, and a man wearing a green hooded coat is talking in front of a background wall with a picture of the Earth and some paintings hanging.
D. A man wearing a green hooded coat is talking in front of a background wall with a picture of the Earth and some paintings hanging. On his right, there is an English news webpage with some icons, and four 3D demonstration images of the moon rover landing on the moon.
E. On the right is an English news webpage with some icons, a man wearing a green hooded coat is talking in front of a background wall with a picture of the Earth and some paintings hanging, and four 3D demonstration images of the moon rover landing on the moon.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 86/165 [03:16<03:01,  2.29s/it][32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7274542274997013761.mp4[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7274542274997013761.mp4[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7274542274997013761.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=172[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:35:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black and white scene, a person is bending over, with a white skull next to them. In the distance, there are many mounds of earth. When the subtitle mentions "American modernism her art reflects the diverse Landscapes of her homes from Wisconsin to New York", what does this person do?
A. Grabs a handful of sand
B. Picks up the skull from the ground
C. Dusts off the ash from their body
D. Picks up clothes from the ground
E. Raises their hand to block the wind and sand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 5KLSf7kwr7s.mp4[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/5KLSf7kwr7s.mp4[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 5KLSf7kwr7s.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=175[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a man and a woman. The woman is wearing a white nightgown, and the man is wearing a blue shirt. When the man in the blue shirt appears in an office with brown walls, what change occurs to his clothing?
A. Changes from a blue shirt to a red shirt
B. Changes from a blue shirt to a white T-shirt
C. Changes from a blue shirt to a purple shirt
D. Changes from a blue shirt to a black hoodie
E. Wears an additional black suit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 87/165 [03:17<02:39,  2.05s/it][32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dCscvoOX2as.mp4[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dCscvoOX2as.mp4[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dCscvoOX2as.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=174[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a machine next to the white wall. The machine's inlet has a gradually narrowing conical shape. At the outlet of the machine, there is a green plastic container. The engine of the machine is located on the left side. A person wearing jeans and a blue shirt is operating the machine. Who passes by from the right side of the machine?
A. A woman
B. A man
C. A child
D. A cat
E. A dog
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0rWA-p4p5IM.mp4[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0rWA-p4p5IM.mp4[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0rWA-p4p5IM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=177[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the shimmering lake, there is a bridge. A woman, wearing a gray headscarf and a black coat, is putting her phone into her handbag. Two other women are walking towards her. After this woman finishes putting her phone away, who is the first person to enter the scene?
A. A woman with a ponytail, wearing a floral dress
B. A woman with straight blonde hair, wearing white trousers
C. A woman with straight blonde hair, wearing a white coat
D. A woman with blonde hair, wearing a black coat
E. A woman wearing sunglasses and a black coat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 88/165 [03:20<03:00,  2.35s/it][32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = AnLMDMzO4QY.mp4[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/AnLMDMzO4QY.mp4[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: AnLMDMzO4QY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=176[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white surface, a hand places a transparent bowl on the table with an unpeeled egg inside. Where has the egg appeared?
A. In a cake
B. In a silver metal box
C. In a blue plastic container
D. In a black pot
E. In the refrigerator
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jbPR2SJuFHg.mp4[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jbPR2SJuFHg.mp4[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jbPR2SJuFHg.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=179[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which subtitles appear together with the woman wearing a white top, denim overalls, and round earrings in the beginning of the video?
A. we've got the cookies and the freezer and cooling for about maybe 10 minutes so appear together
B. love the fact they're sweet and
C. the a hint of salt

D. beath bars are mike chocolate covered
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 89/165 [03:22<02:53,  2.29s/it][32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = eDso3zHFxL8.mp4[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/eDso3zHFxL8.mp4[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: eDso3zHFxL8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=178[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a large marble table, there is a piece of baked food. A person wearing a ring is using chopsticks to apply sauce. What kind of ring is this person wearing?
A. Gold ring on the index finger
B. Diamond ring on the middle finger
C. Gold ring on the middle finger
D. Silver ring on the middle finger
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iHNjWhx3EaI.mp4[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iHNjWhx3EaI.mp4[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iHNjWhx3EaI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=181[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The individual on the screen is a man wearing a black hat and a white T-shirt. To his right, there is a photo that shows the back silhouette of a person looking at a sculpture. On the left side, there is also a yellow building. What is the man in the screen doing?
A. Raising both hands and facing away from a mirror while talking
B. Raising both hands and looking up while talking
C. Raising both hands and nodding while talking
D. Raising both hands and looking down while talking
E. Raising both hands and facing a mirror while talking
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 90/165 [03:25<02:53,  2.31s/it][32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = qksR2Zvd-FM.mp4[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/qksR2Zvd-FM.mp4[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: qksR2Zvd-FM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=180[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the curly-haired man wearing a gray hoodie picks up a box of pink-packaged tea leaves and the subtitle ‚Äòediting my video drinking some yamamoto‚Äô appears, which item is not present in the room behind him?
A. Black Overcoat
B. Coat Rack
C. Television
D. Tableware
E. Refrigerator
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = gURB1JwPfJw.mp4[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/gURB1JwPfJw.mp4[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: gURB1JwPfJw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=183[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A bullet hits the green tank and sparks fly. Who is the character that first appears after Bai mentions 'period in World War II'?
A. The soldier wearing a red headscarf
B. The soldier wearing a black headscarf and green camouflage uniform
C. The soldier without a helmet, with short blond hair, wearing a green camouflage uniform
D. The soldier wearing a green helmet, black scarf, and camouflage uniform
E. The soldier wearing a green helmet and gray clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 91/165 [03:27<02:56,  2.38s/it][32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DVsw1brd_Yc.mp4[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DVsw1brd_Yc.mp4[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DVsw1brd_Yc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=182[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white background PPT, there's a black English question at the top. In the middle of the screen, there's one black arrow and three blue arrows. At the bottom, there are chemical element symbols written inside a black lined border. In the lower right corner, within a circular frame, there's a video screen of a long-haired woman wearing a white coat with black inner clothing. What is this woman doing when the subtitle 'that's a good thing you get it now yeah' appears?
A. Yawning
B. Raising both hands and smiling with thumbs up
C. Resting her face on one hand
D. Making a peace sign at the camera
E. Tucking her hair behind her ear
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DoizYSYQRqU.mp4[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DoizYSYQRqU.mp4[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DoizYSYQRqU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=185[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white desk with an open book and a black keyboard, there is an orange-red book with the words 'LUCKY PLANET' on the cover. In which of the following scenes has this book appeared?
A. In the hands of a child wearing a black short-sleeve shirt
B. In the hands of a woman wearing black scrubs
C. In the hands of a man wearing black scrubs
D. In the hands of a man wearing a black short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 92/165 [03:30<03:01,  2.48s/it][32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -eRimFrm6kQ.mp4[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-eRimFrm6kQ.mp4[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -eRimFrm6kQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=184[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a car, a woman wearing a white coat is sitting with her eyes closed. She is holding a cup of coffee in her right hand and a mobile phone in her left hand. What objects are present in this scene?
A. transparent water cup
B. nose ring
C. earring
D. watch
E. earphone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7303594391850044678.mp4[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7303594391850044678.mp4[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7303594391850044678.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=187[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:35:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a small island on the blue sea, the island is full of green plants, and there are many boats docked along the shore. Among them, the largest boat in the middle, what color is the largest boat in the middle?
A. red
B. black
C. yellow
D. white
E. green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:20[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YcbKamVxDzI.mp4[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YcbKamVxDzI.mp4[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YcbKamVxDzI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=189[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:20[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The room filled with photographs has a white door, with a map next to it. Which character appears first in the room?
A. A man wearing a blue T-shirt with a crew cut
B. A man wearing a white T-shirt with short hair
C. A woman with long blonde hair wearing a pink top
D. A woman with long black hair wearing a white dress
E. A man wearing a black T-shirt with curly hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 93/165 [03:33<02:59,  2.50s/it][32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = athabNMGceo.mp4[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/athabNMGceo.mp4[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: athabNMGceo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=186[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, a man wearing a pair of black-rimmed glasses and a white short-sleeved shirt with a small bird pattern is explaining something. Which of the following animals can spray feces up to 40 cm?
A. Hamster
B. Whale
C. Ostrich
D. Rabbit
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 94/165 [03:35<02:49,  2.39s/it][32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kWUmHAzCp7s.mp4[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kWUmHAzCp7s.mp4[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kWUmHAzCp7s.mp4 | Selected 5 frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=188[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a park full of trees and plants, there is a winding path in the middle. On the path, there is a woman wearing a dark blue top and pink trousers, and a man wearing a white top. After the subtitle 'girlfriend who are having an argument' appears, which characters appear?
A. A woman wearing a yellow hat and sunglasses
B. A man wearing blue clothes
C. A girl wearing blue clothes
D. A man wearing black clothes and a red hat
E. A man wearing grey clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bqQTWdk1DAM.mp4[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bqQTWdk1DAM.mp4[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bqQTWdk1DAM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=191[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A group of people wearing uniforms are standing with their backs turned at a platform. On the platform are three people, all standing in a dimly lit building with light pouring in from a rectangular window behind them, casting long shadows. When it mentions 'the boys are put through a strict training regime by the Peacekeepers. They also have to', what objects are present in the scene?
A. yellow uniform
B. olive-colored uniform
C. gray uniform
D. green uniform
E. white and red uniform
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 95/165 [03:35<02:09,  1.85s/it][32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7m9XIXyT5_I.mp4[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7m9XIXyT5_I.mp4[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7m9XIXyT5_I.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=190[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen, there is a house with only its frame remaining. A man wearing a gray hat is extending half of his body out from the black middle section while holding a bucket. What is this man doing?
A. He filled the bucket with water.
B. He closed the door.
C. He took off his hat.
D. He is pouring the contents of the bucket outside.
E. He put down the bucket.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 96/165 [03:38<02:24,  2.09s/it][32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9S9i12n0TIw.mp4[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9S9i12n0TIw.mp4[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9S9i12n0TIw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=192[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a multi-colored shirt is sitting in the outdoor dining area of a restaurant. The man is holding a yellow package in his hand. Next to him are a white basket and green plants. Behind the man, there is an open umbrella and other diners. On the left side of the screen, there are colorful flags and the entrance of a shop. What is the first food the man eats?
A. Apple
B. Pie
C. Mooncake
D. Bread
E. Yogurt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 51dUUxFOjDE.mp4[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/51dUUxFOjDE.mp4[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 51dUUxFOjDE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=193[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen is divided into three parts: left, center, and right. The left side is all text, the center is a map, and the right side is a man in black clothing. After the man waves his hands to greet the camera, what does he do?
A. Put on a hat
B. Coughed
C. Took a sip of water
D. Tidied his clothes
E. Picked up a book
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = athabNMGceo.mp4[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/athabNMGceo.mp4[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: athabNMGceo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=195[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wall displaying a blue and white map, what is the man with white hair wearing a black short-sleeved shirt doing when he first appears?
A. Smiling at the camera
B. Making a mark on the map
C. Making a 'Yay' sign towards the camera
D. Raising his hand to greet
E. Talking to the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 97/165 [03:41<02:41,  2.37s/it][32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6880172230588894465.mp4[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6880172230588894465.mp4[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6880172230588894465.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=194[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:35:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Against a blue background, a man wearing black-framed glasses and a white short-sleeve shirt with a small bird pattern is explaining. Which of the following animals evolved hindgut fermentation?
A. Ostrich
B. Rabbit
C. Kangaroo
D. Whale
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GawGUhl9zuQ.mp4[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GawGUhl9zuQ.mp4[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GawGUhl9zuQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=197[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The upper left side of the screen shows a window overlooking the street below. When the yellow-green packaged snack first appears on the screen, what is happening in the scene?
A. The screen transitions from blurry to clear
B. Pouring the snacks out
C. Tearing open the snack package
D. The person in the video is eating the snacks
E. Showing the snack package to the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 98/165 [03:43<02:31,  2.26s/it][32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LfUsGv-ESbc.mp4[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LfUsGv-ESbc.mp4[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LfUsGv-ESbc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=196[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows a webpage. The top of the webpage has a sea-green background, the middle has a white background, and there's a black-and-white image on the right side. The middle contains some program code. In the black-and-white image, there is a man running with his hands raised. There are some icons connected with lines on his legs. In the lower right corner of the screen, there is a man wearing sunglasses and dressed in black, who is explaining something. The background behind him is grey. What is the shape of the icon connected by white lines on the screen?
A. Circle
B. Triangle
C. Square
D. Staircase shape
E. Rectangle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 99/165 [03:45<02:26,  2.23s/it][32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7305901654417706246.mp4[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7305901654417706246.mp4[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7305901654417706246.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=198[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Between two connected videos, there is a white notebook in the middle held by a female. The notebook has an additional paper attached with a figure on it. What changes happen to the notebook when the subtitle mentions 'there good and then'?
A. The additional paper on the notebook is gone
B. The notebook only has a blue figure drawn with a pen
C. The notebook has an additional paper and a black figure drawn with a pen
D. The notebook has an additional paper and a black figure drawn with a pen
E. The notebook has an additional paper and a blue figure drawn with a pen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = DoizYSYQRqU.mp4[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/DoizYSYQRqU.mp4[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: DoizYSYQRqU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=199[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, which of the following characters appears first?
A. A woman wearing a navy blue hooded jacket
B. A man wearing a gray coat, earphones, and with short black hair
C. A woman wearing a white T-shirt
D. A man wearing a white shirt
E. A woman wearing a dark orange coat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 100/165 [03:47<02:08,  1.97s/it][32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ixlQX7lV8dc.mp4[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ixlQX7lV8dc.mp4[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ixlQX7lV8dc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=200[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman in a red dress is singing on the screen, and behind her is a dancer wearing white clothing. The dancer has the word 'ICONIC' on their head. What objects are present in this scene?
A. Display screen
B. Microphone
C. Water cup
D. Car
E. Speaker
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NHIT9vq6mJU.mp4[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NHIT9vq6mJU.mp4[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NHIT9vq6mJU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=201[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a picture with a microscope, after the subtitle 'After completing a study about prehistoric insects' appears, what person appears?
A. A man in a yellow shirt
B. A man wearing glasses and smiling slightly
C. A man in a green shirt
D. A woman wearing glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 101/165 [03:49<02:19,  2.18s/it][32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fq3zbbp-lv4.mp4[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fq3zbbp-lv4.mp4[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fq3zbbp-lv4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=202[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a huge room with various exhibits on either side, there is a large pillar in the middle of the room. Next to the pillar, in the middle of the room, there is a long table. What is the color of the long table?
A. Green
B. Black
C. Blue
D. Gray
E. White
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:38[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = D7VYbsORD8k.mp4[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/D7VYbsORD8k.mp4[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: D7VYbsORD8k.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=203[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:38[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the grove of yellow leaves illuminated by sunlight, there is a woman with a checkered scarf, khaki-colored jacket, and jeans playing with a black Labrador beside her. Which of the following subtitles appeared simultaneously with the sight of this black dog?
A. "define who we are"
B. "slow down and recharge and communicate"
C. "in my case i wanted to be either a"
D. "my life is full of routines and"
E. ‚Äúthat puts me in a nostalgic mood it's‚Äù
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 102/165 [03:52<02:28,  2.36s/it][32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yU9fGAEcxJY.mp4[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yU9fGAEcxJY.mp4[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yU9fGAEcxJY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=204[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a car, a woman with long hair, wearing a white long-sleeve shirt, is holding a food container and showing it to the camera. When a white box with the text 'So I drive by this place' appears to her left, what happens to the object in her hand?
A. The object in her hand changes from a food container to a fork
B. The object in her hand changes from a food container to a phone with a pink case
C. The object in her hand changes from a food container to a black shoulder bag
D. The object in her hand changes from a food container to a phone with a black case
E. The object in her hand changes from a food container to a phone with a white case
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TXiX3NO5f5w.mp4[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TXiX3NO5f5w.mp4[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TXiX3NO5f5w.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=205[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After the female protagonist in the video adds melted butter into the blender containing chocolate cake mix, what happens next in the video?
A. Mix the two together
B. Pour them into a bowl
C. Add more chocolate cake mix
D. Add milk
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 103/165 [03:54<02:18,  2.24s/it][32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _uL3a3aMdMQ.mp4[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_uL3a3aMdMQ.mp4[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _uL3a3aMdMQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=206[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a green plant on the table, and someone is placing a pine cone on this green plant. Where else has this green plant appeared?
A. On the grass
B. On a yellow wooden board, which also has an olive-colored piece of clothing on it.
C. Inside a flower pot
D. On TV
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:43[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = acAWfzV__XI.mp4[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/acAWfzV__XI.mp4[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: acAWfzV__XI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=207[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:43[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a black background, there is a woman wearing a gray and white suspender dress. She is wearing a ring on her hand, and there is also a picture of a British flag beside her. When the subtitle "was there too okay this is gonna be a" appears, what kind of hairstyle does the woman in the gray and white suspender dress have?
A. Long black hair
B. Long silver hair
C. Short blonde hair
D. Long black curls
E. Long blonde curls
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 104/165 [03:56<02:18,  2.27s/it][32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Z-1lgAXOEc8.mp4[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Z-1lgAXOEc8.mp4[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Z-1lgAXOEc8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=208[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a white screen, many formulas are written, and at the top, there is a blue title. On the formula on the left side, there is a gray box. What happens to the gray box after the subtitle "complexity is Big O of V" appears?
A. Becomes more concise
B. Contents in the frame decrease
C. Just gets smaller
D. Moves down and gets larger
E. Moves down and gets smaller
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7267308320413797650.mp4[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7267308320413797650.mp4[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7267308320413797650.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=209[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:35:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there is a blonde woman wearing a black tank top and a man with curly hair wearing a black T-shirt. They are talking in front of a mirror, with a black column and a thick tree behind them. There are also two white cars parked by the roadside. In which scene does the woman in the gold tank top appear?
A. On the stairs in front of a red building with black handrails.
B. On the stairs in front of a red building with white handrails.
C. On the stairs in front of a red building with gray handrails.
D. On the stairs in front of a red building with yellow handrails.
E. On the stairs in front of a red building with orange handrails.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 105/165 [03:59<02:27,  2.46s/it][32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iwXp1fT89-M.mp4[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iwXp1fT89-M.mp4[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iwXp1fT89-M.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=210[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a person holding a phone taking a photo of their leg; then a pale-skinned woman and a dark-skinned man kissing; and finally, a woman wearing a green headband sliding down a hill being pulled back by someone.
B. First, a pale-skinned woman and a dark-skinned man kissing; then a person holding a phone taking a photo of their leg; and finally, a woman wearing a green headband sliding down a hill being pulled back by someone.
C. First, a pale-skinned woman and a dark-skinned man kissing; then a woman wearing a green headband sliding down a hill being pulled back by someone; and finally, a person holding a phone taking a photo of their leg.
D. First, a person holding a phone taking a photo of their leg; then a woman wearing a green headband sliding down a hill being pulled back by someone; and finally, a pale-skinned woman and a dark-skinned man kissing.
E. First, a woman wearing a green headband sliding down a hill being pulled back by someone; then a pale-skinned woman and a dark-skinned man kissing; and finally, a person holding a phone taking a photo of their leg.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GFg98TDqCpw.mp4[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GFg98TDqCpw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=211[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner of the video, there is a bald man wearing sunglasses and dressed in black. In the frame, there are two bloodshot eyeballs. Which object does not appear in the video?
A. sunglasses
B. microphone
C. a man wearing glasses and a suit
D. eyeballs
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = ErGYJ7kqIow.mp4[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/ErGYJ7kqIow.mp4[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: ErGYJ7kqIow.mp4 | Selected 15 frames[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=213[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, in a room with three white doors, the woman points to the word 'live' on her sleeve. Next, in the same room with three white doors, the woman stands under a green figurehead and lifts her left hand to touch her hair. Finally, in a room with green walls, a woman wearing a blue sleeveless knit top is drinking water with a straw while wearing earphones.
B. First, in a room with three white doors, the woman points to the word 'live' on her sleeve. Next, in a room with green walls, a woman wearing a blue sleeveless knit top is drinking water with a straw while wearing earphones. Finally, in the same room with three white doors, the woman stands under a green figurehead and lifts her left hand to touch her hair.
C. First, in a room with green walls, a woman wearing a blue sleeveless knit top is drinking water with a straw while wearing earphones. Next, in a room with three white doors, the woman points to the word 'live' on her sleeve. Finally, in the same room with three white doors, the woman stands under a green figurehead and lifts her left hand to touch her hair.
D. First, in a room with three white doors, the woman stands under a green figurehead and lifts her left hand to touch her hair. Next, in a room with green walls, a woman wearing a blue sleeveless knit top is drinking water with a straw while wearing earphones. Finally, in the same room with three white doors, the woman points to the word 'live' on her sleeve.
E. First, in a room with green walls, a woman wearing a blue sleeveless knit top is drinking water with a straw while wearing earphones. Next, in a room with three white doors, the woman stands under a green figurehead and lifts her left hand to touch her hair. Finally, in the same room with three white doors, the woman points to the word 'live' on her sleeve.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 106/165 [04:02<02:35,  2.64s/it][32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2W2ZkYARds4.mp4[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2W2ZkYARds4.mp4[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2W2ZkYARds4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=212[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the red video frame, after a man with a mustache lies down facing the left side, what event happens on the screen?
A. The man has a green ribbon tied over his eyes.
B. The man has a green ribbon tied around his neck.
C. The man has a white ribbon in his mouth.
D. The man has a red ribbon in his mouth.
E. The man's eyes are covered.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = UO_6TQnnOxM.mp4[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/UO_6TQnnOxM.mp4[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: UO_6TQnnOxM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=215[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a grassy field, there are many trees in the distance, a house at the back right, a yellow warning tape nearby, and 6 policemen walking forward. What happened when the yellow warning tape appeared?
A. A policeman with white hair bent down in the front right
B. A policeman cut the warning tape
C. A policeman wearing sunglasses at the back right raised his hand
D. A police dog ran out
E. A policeman in the back took a photo
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 107/165 [04:05<02:37,  2.71s/it][32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Q47I8AdRgzc.mp4[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Q47I8AdRgzc.mp4[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Q47I8AdRgzc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=214[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen shows two black men sitting and performing music and singing under the lights. The man towards the left-back is wearing an olive-colored suit, while the man on the right is holding a wooden guitar and wearing a blue patterned robe and singing into a microphone. In the top-right corner of the screen, there is a small video of a black man wearing a white shirt with a blue collar. What is the hairstyle of the man holding the guitar?
A. Long blonde hair
B. Short blonde hair
C. Black cornrows
D. Black afro
E. Short curly hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YebUIUOCo94.mp4[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YebUIUOCo94.mp4[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YebUIUOCo94.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=217[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A white hemisphere moves from left to right in a pitch-black space, along with some bright spots flashing in the space. Where have this hemisphere and which subtitles appeared together before?
A. the paths they previously simulated
B. like Venus
C. Earth's long-time neighbor - Mars
D. exhibited earth-like place tectonics
E. stagnant lid period align the simulation
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 108/165 [04:08<02:28,  2.60s/it][32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = N7RTTiHsSjI.mp4[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/N7RTTiHsSjI.mp4[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: N7RTTiHsSjI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=216[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a man wearing white pants lying on a blue-sheeted rack. There is another man watching him, and behind them, there is a person wearing a white skirt and an injured person leaning against the wall. When the caption mentions 'The operation went well. But the wound became infected, and Lannes died nine days later.', what is the condition of the lying man's leg?
A. Right leg amputated
B. Left leg amputated
C. Both legs intact
D. Both legs amputated
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OAcbasjxljY.mp4[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OAcbasjxljY.mp4[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OAcbasjxljY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=219[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a flat ground, the left side is the exterior wall of a building. There are two windows on the exterior wall, two outdoor units of air conditioners, and several plants at the bottom. In the middle, there are 7 people, 5 of whom are looking upward. There is a car in front of them, and there is a liquid on the car. Could you please tell me the color of the liquid on the car at this time?
A. Purple
B. Black
C. Blue
D. White
E. Blood Red
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 109/165 [04:10<02:25,  2.60s/it][32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = P0BSTjziVys.mp4[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/P0BSTjziVys.mp4[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: P0BSTjziVys.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=218[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:35:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:35:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with walls covered in pictures and a world map hanging, what is a man wearing a white beard and a gray shirt doing?
A. Holding a rabbit
B. Holding a squirrel
C. Holding a sheep
D. Holding a small dog
E. Holding a cat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:35:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mHARxee4EzQ.mp4[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mHARxee4EzQ.mp4[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mHARxee4EzQ.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=221[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:35:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing glasses, puffing on a cigarette, dressed in a grey long-sleeve shirt with rolled-up sleeves, and holding a handful of red feed is feeding a fish with a big mouth. In which of the following places did he appear?
A. On a boat being blown by the wind
B. In a crowded talent show venue
C. On a flying airplane
D. In a quiet park
E. In a boxing ring
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = cceTeD4JADU.mp4[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/cceTeD4JADU.mp4[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: cceTeD4JADU.mp4 | Selected 14 frames[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=223[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 14 specific frames[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 14 custom frames[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 14 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the opening of the video, Melissa Maribel with dark brown hair and wearing a white V-neck top appears. In which of the following scenes does Melissa Maribel appear?
A. In an orange background with a green paper showing a hint in the middle.
B. On the left side with an orange background containing white text 'SUBSCRIBE', and on the right side, a green horizontal line, a red vertical line, and some black text.
C. In an orange background with a green plant pot in the upper right corner and some curved needles on the left.
D. On the right side with an orange background containing white text 'SUBSCRIBE', and on the left, a green horizontal line, a red vertical line, and some black text.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 110/165 [04:12<02:14,  2.44s/it][32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = dxjKdnJFmLs.mp4[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/dxjKdnJFmLs.mp4[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: dxjKdnJFmLs.mp4 | Selected 11 frames[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=220[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 11 specific frames[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 11 custom frames[0m
[32m2025-11-29 12:36:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 11 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a small road, a man wearing a dark red short-sleeved T-shirt and a green hat is chatting with a man wearing a black short-sleeved T-shirt and a red hat. When the man wearing the green hat holds a shoe in his right hand, what action does the man wearing the black short-sleeved T-shirt and red hat do with his left hand?
A. Throwing the shoe away
B. Holding a red teacup
C. Holding a red teacup and drinking tea
D. Point with his thumb and index finger at the man wearing the green hat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 111/165 [04:14<01:57,  2.17s/it][32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/0t1vtW0cT1E.mp4[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 0t1vtW0cT1E.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=222[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the screen, there is a woman with green and black hair wearing glasses. She is in a room covered with drawings. In front of her is a computer desk, which besides the computer also has some cluttered items. She is wearing a sweater that matches the color of her green hair. When she mentions 'graded for it my exam,' what object is not present in the scene?
A. An orange string
B. A blue painting
C. A golden lamp
D. A white bookshelf
E. A white keyboard
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = tdA5atpqaAc.mp4[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/tdA5atpqaAc.mp4[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: tdA5atpqaAc.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=225[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top-right corner of the brown cutting board, there are several pieces of already-cut meat. On the left side of the cutting board, there is uncut meat on a metal plate. In the middle of the screen, a person is holding a pair of tongs. What is this person doing?
A. Placing the tongs on the cutting board
B. Placing the meat from the metal plate onto the cutting board
C. Using the tongs to grab vegetables
D. Placing the cut meat from the cutting board onto the metal plate
E. Putting the tongs into a bowl
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _kQXNFG664Y.mp4[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_kQXNFG664Y.mp4[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _kQXNFG664Y.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=227[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:36:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a corner of a bedroom, a short-haired woman wearing an olive green tank top is sitting in front of a bed. To the right is a bookshelf filled with books. What color is the bookshelf in the screen?
A. A three-layer pink bookshelf
B. A three-layer blue bookshelf
C. A four-layer red bookshelf
D. A five-layer orange bookshelf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:04[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = yqejTvYILlA.mp4[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/yqejTvYILlA.mp4[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: yqejTvYILlA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=229[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:04[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a canyon, the walls on both sides are covered with green plants. There is a small stream below, with several stones on the left side and a golden-haired person on the right. In front of the camera is a man wearing a red headscarf and holding a black backpack. When the subtitle 'gonna weather proof my stuff like this' appears, what action does this man take?
A. Pats the black backpack
B. Raises his thumb
C. Opens the backpack
D. Puts down the backpack
E. Take off the headscarf
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 112/165 [04:18<02:22,  2.69s/it][32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7194857776877817094.mp4[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7194857776877817094.mp4[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7194857776877817094.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=224[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:36:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Who is the person, in a room with green plants, holding chopsticks and picking up food from the round plate on the table in front, and then putting it into their mouth?
A. A black-haired woman wearing a black top
B. A black-haired man wearing a white top
C. A black-haired woman wearing a white top
D. A white-haired woman wearing a black top
E. A black-haired woman wearing a purple top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 113/165 [04:18<01:47,  2.07s/it][32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = FnKDgC9aNu0.mp4[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/FnKDgC9aNu0.mp4[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: FnKDgC9aNu0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=226[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the street, in the distance are roadside houses and cars driving on the road. Nearby is a man in a black T-shirt talking to the camera. To the left behind the man are piles of filled black garbage bags. What did the man do after finishing speaking?
A. Touched his hair
B. Took a sip of iced coffee
C. Turned and walked towards the garbage bags
D. Waved his left hand
E. Stuck out his tongue at the camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = a_hkRXc_bYg.mp4[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/a_hkRXc_bYg.mp4[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: a_hkRXc_bYg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=231[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, there are three men sitting. One is wearing a black short-sleeve shirt, another is wearing a dark grey short-sleeve shirt, and the third is wearing a grey-and-white dress shirt. When the subtitle 'Sicily to Libya and some technical' appears, what objects can be seen in the frame?
A. red arrow
B. white chair
C. blue water tank
D. black camera
E. black phone
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:09[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 114/165 [04:21<01:55,  2.26s/it][32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = QJ6sjg7SXOQ.mp4[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/QJ6sjg7SXOQ.mp4[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: QJ6sjg7SXOQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=228[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:09[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a broadcast room, there is a man with short blond hair wearing a black suit and a white shirt. What action does this man take immediately after the subtitle mentions 'something where conservatives can say'?
A. He raises both hands with palms facing inward
B. He only raises his left hand
C. He places his hand over his chest
D. He only raises his right hand
E. He raises both hands with palms facing outward
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = otaJfBSlsG8.mp4[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/otaJfBSlsG8.mp4[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: otaJfBSlsG8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=233[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The screen switches to a split-screen view with two sections, left and right. At the bottom of the screen, there is a red rectangle with white text that reads 'Israel's renewed bombardment of Gaza.' In the video on the left side of the screen, amidst scattered debris and items on the ground, a person dressed in a black shirt and black pants is holding a large round metal bucket. What is this man doing?
A. Throwing the metal bucket into the sea
B. Burning the metal bucket
C. Throwing the metal bucket on the ground
D. Dumping garbage into the metal bucket
E. Placing the metal bucket in a vehicle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:11[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 115/165 [04:23<01:53,  2.26s/it][32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rwL_XPw46zQ.mp4[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rwL_XPw46zQ.mp4[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rwL_XPw46zQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=230[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:11[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a white cabinet, there is a green potted plant on the side. In front, there is a woman with long black hair holding an illustrated book. Which of the following subtitles appeared with this illustrated book?
A. that afternoon stella and her clay
B. let's find a cozy spot and let's get
C. let's begin with our welcome song just
D. started
E. story time and activity now
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XVXczyheik0.mp4[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XVXczyheik0.mp4[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XVXczyheik0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=235[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of events is correct?
A. First, a soldier wearing a hat with an eagle insignia stands on a platform with his hand on his hip, then three soldiers with rifles appear on the battlefield, and finally a Japanese soldier is holding a handgun with both hands raised.
B. First, a Japanese soldier is holding a handgun with both hands raised, then three soldiers with rifles appear on the battlefield, and finally a soldier wearing a hat with an eagle insignia stands on a platform with his hand on his hip.
C. First, three soldiers with rifles appear on the battlefield, then a soldier wearing a hat with an eagle insignia stands on a platform with his hand on his hip, and finally a Japanese soldier is holding a handgun with both hands raised.
D. First, a soldier wearing a hat with an eagle insignia stands on a platform with his hand on his hip, then a Japanese soldier is holding a handgun with both hands raised, and finally three soldiers with rifles appear on the battlefield.
E. First, a Japanese soldier is holding a handgun with both hands raised, then a soldier wearing a hat with an eagle insignia stands on a platform with his hand on his hip, and finally three soldiers with rifles appear on the battlefield.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 116/165 [04:26<01:52,  2.30s/it][32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=232[0m
[32m2025-11-29 12:36:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a white room, there is a man wearing a dark blue jacket speaking on the screen. In front of him is a black microphone. He has dark skin and a mustache. On the wall behind him, there's a black map. To the left of the frame, there is a whiteboard, and to the right, there is also a wall with a piece of paper in a black frame. While this man is writing on a black background with white text that says 'How much data do we need?', what change occurs?
A. He puts on glasses
B. He changes to a grey microphone
C. He puts on a hat
D. He changes to black clothes
E. He changes to white clothes
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = s5edwp0PEqk.mp4[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/s5edwp0PEqk.mp4[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: s5edwp0PEqk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=237[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing an off-shoulder top is sitting on a white sofa. She has orange nail polish and is wearing a necklace. Behind her is a white wall and a black armrest. Two books are on either side of her. When the subtitle 'honeymooners is one of my favorites and' appears, what is the woman doing?
A. The woman is holding a book in each hand
B. The woman is holding a pen in both hands
C. The woman is holding a book in her right hand and a pen in her left hand
D. The woman is holding a book in her left hand and a paper in her right hand
E. The woman is holding a book in her left hand and a pen in her right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 117/165 [04:28<01:54,  2.39s/it][32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = YehqA9xoGTY.mp4[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/YehqA9xoGTY.mp4[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: YehqA9xoGTY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=234[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences in the video are correct?
A. First, inside a museum, many colorful crystals are displayed under a glass cover, then some people are sitting around a wooden table wrapping dumplings, and finally, a girl with short, pink-dyed hair wearing a black bikini sits on the beach spraying sunscreen mist.
B. First, some people are sitting around a wooden table wrapping dumplings, then inside a museum, many colorful crystals are displayed under a glass cover, and finally, a girl with short, pink-dyed hair wearing a black bikini sits on the beach spraying sunscreen mist.
C. First, a girl with short, pink-dyed hair wearing a black bikini sits on the beach spraying sunscreen mist, then some people are sitting around a wooden table wrapping dumplings, and finally, inside a museum, many colorful crystals are displayed under a glass cover.
D. First, a girl with short, pink-dyed hair wearing a black bikini sits on the beach spraying sunscreen mist, then inside a museum, many colorful crystals are displayed under a glass cover, and finally, some people are sitting around a wooden table wrapping dumplings.
E. First, inside a museum, many colorful crystals are displayed under a glass cover, then a girl with short, pink-dyed hair wearing a black bikini sits on the beach spraying sunscreen mist, and finally, some people are sitting around a wooden table wrapping dumplings.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OUeE8nCKWGA.mp4[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OUeE8nCKWGA.mp4[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OUeE8nCKWGA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=239[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a vague background, there is a man with short black hair wearing a dark blue suit. What was the man in the dark blue suit doing when he first appeared?
A. Talking to the camera
B. Smiling and clapping
C. Supporting his chin with his left hand
D. Supporting his forehead with his left hand
E. Crossing his arms in front of his chest
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 118/165 [04:31<01:52,  2.39s/it][32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2edlqFUTDVc.mp4[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2edlqFUTDVc.mp4[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2edlqFUTDVc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=236[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white background, there is a man with short hair wearing a short-sleeved T-shirt, sitting in front of a mirror. What is he doing at this moment?
A. Raised both hands upwards
B. Shaking head
C. Stood up
D. Crying
E. Hands clasped together
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 6948509102305791238.mp4[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/6948509102305791238.mp4[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 6948509102305791238.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=241[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue and white sky, in front of a short house backdrop, on the far right side stand two figures wearing olive-colored clothes and belts, one of whom is holding a scythe. Which of the figures on the grass in the bottom left corner is simultaneously opening a scroll?
A. Two small figures wearing black helmets
B. Two small figures wearing white helmets
C. Two small figures wearing green helmets
D. Two small figures wearing black helmets
E. Two small figures wearing yellow helmets
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 119/165 [04:33<01:47,  2.34s/it][32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = E7FSg22MdKE.mp4[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/E7FSg22MdKE.mp4[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: E7FSg22MdKE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=238[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
When the subtitle: 'First, you're going to want to heat your tortillas on a pan for a little bit so that they're more flexible.' appears at the bottom of the screen, what color sauce is spread on the tortilla placed in the white speckled round plate on the gray marble countertop?
A. Green
B. Red
C. Yellow
D. White
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:22[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Oht0i1DACcA.mp4[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Oht0i1DACcA.mp4[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Oht0i1DACcA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=243[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:22[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, blue curtains are hanging in the middle, and below the curtains is a parquet floor. After the subtitle mentions 'timeschedhereattheinem,' what is the first glowing object that appears?
A. lamp
B. flashlight
C. fire
D. firefly
E. torch
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 120/165 [04:36<01:50,  2.46s/it][32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7265680288636767520.mp4[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7265680288636767520.mp4[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7265680288636767520.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=240[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:36:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What changes occur to the clothing of the woman, who appears at the beginning of the video with short hair, wearing a blue jacket, carrying shoes in her hand, and walking barefoot on a path between fields, when she walks down a path lined with brightly decorated shops?
A. No changes
B. She changed to a red jacket
C. She took off the blue jacket and tied it around her waist, wearing a black short-sleeved top
D. She took off the blue jacket and tied it around her waist, wearing a white short-sleeved top
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:24[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mq6L8CnNJXc.mp4[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mq6L8CnNJXc.mp4[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mq6L8CnNJXc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=245[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:24[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top left corner of the screen, there's a person wearing jeans and white sneakers holding a white teddy dog standing on a gray floor. Sunlight is shining in from the top right corner. After the subtitle 'Such beautiful day, so I'm gonna start it at a cafe and I'm gonna be productive and that's my ride' appears, what is the object shown in the middle of the screen?
A. A train running on the railway
B. A flowing river below the railway
C. A green sandwich placed on a black plate
D. Coffee inside a red polka dot mug
E. A building surrounded by green trees
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 121/165 [04:39<01:56,  2.64s/it][32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3b_v1KO_U8A.mp4[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3b_v1KO_U8A.mp4[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3b_v1KO_U8A.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=242[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene, there are two characters made to look like maps with eyes. The one on the left is holding a cup, and the one on the right is holding a fish. What kind of cup is the one in the scene?
A. A glass tea cup containing red tea
B. A ceramic cup containing red tea
C. A ceramic cup containing green tea
D. A glass tea cup containing coffee
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lzAESaVqix0.mp4[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lzAESaVqix0.mp4[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lzAESaVqix0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=247[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What event occurred on the video screen just before the phrase 'wilderness and the open skies' was mentioned?
A. A host was explaining a map of the western region.
B. A map with the word 'city' appeared.
C. A map of China appeared.
D. A picture of the sea appeared.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 122/165 [04:40<01:36,  2.25s/it][32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = iwXp1fT89-M.mp4[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/iwXp1fT89-M.mp4[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: iwXp1fT89-M.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=244[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
After a man wearing a red short-sleeved shirt and a black hat finished speaking in front of a black background, what did this man do?
A. picked up a basketball
B. picked up a stick
C. picked up a soccer ball
D. picked up a painting
E. picked up a pot of flowers
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=249[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequence of scenes is correct?
A. First, in a small frame on a pure yellow background, a green straightener is displayed. Next, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Finally, on a pure yellow background, there is green text 'BEAUTY'.
B. First, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Next, on a pure yellow background, there is green text 'BEAUTY'. Finally, on the yellow background, a small frame displays a green straightener.
C. First, on a pure yellow background, there is green text 'BEAUTY'. Next, in a small frame on a pure yellow background, a green straightener is displayed. Finally, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern.
D. First, on a pure yellow background, there is green text 'BEAUTY'. Next, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Finally, in a small frame on a pure yellow background, a green straightener is displayed.
E. First, in a room with green walls, a woman in a blue sleeveless knit shirt lifts a pair of shoes with an 'N' pattern. Next, in a small frame on a pure yellow background, a green straightener is displayed. Finally, on the yellow background, there is green text 'BEAUTY'.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 123/165 [04:43<01:46,  2.53s/it][32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WaiGdRYD36k.mp4[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WaiGdRYD36k.mp4[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WaiGdRYD36k.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=246[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman dressed in an off-shoulder top is sitting on a white sofa, wearing a necklace and a ring. Behind her, there's a black railing and a white wall with a plant on the railing. To her right is the cover of a book, and to her left is a book. What is the woman doing when the subtitle 'colleen hooper you did it again' appears?
A. The woman is holding a pen with one hand.
B. The woman is holding a book with one hand.
C. The woman is holding a book with one hand.
D. The woman is lifting the book above her head.
E. The woman is holding a book with both hands.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WM78_KqcrSY.mp4[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WM78_KqcrSY.mp4[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WM78_KqcrSY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=251[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a long-haired woman wearing a checkered coat with a black shirt underneath. On the wall behind her, there is a bright lamp. After the subtitle mentions 'reputational damage um how the IDF is', what object appears in the woman's hand?
A. ball
B. phone
C. apple
D. camera
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:33[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 124/165 [04:45<01:39,  2.42s/it][32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = L-XGTMusZvc.mp4[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/L-XGTMusZvc.mp4[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: L-XGTMusZvc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=248[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:33[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a few small planes appear on the left, top right, and bottom right, with a big plane in the middle right, then some lines of yellow and white subtitles appear, and finally, ends with a white bear.
B. First, a white bear appears, then a few small planes appear on the left, top right, and bottom right, with a big plane in the middle right, and finally, ends with some lines of yellow and white subtitles.
C. First, some lines of yellow and white subtitles appear, then a white bear appears, and finally, ends with a few small planes on the left, top right, and bottom right, with a big plane in the middle right.
D. First, a white bear appears, then some lines of yellow and white subtitles appear, and finally, the sequence ends with a screen showing a few small planes on the left, a few small planes on the top right and bottom right, and a big plane in the middle right.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7268213090708245761.mp4[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7268213090708245761.mp4[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7268213090708245761.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=253[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:36:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the gray background, there is a paragraph made up of black and white English words in the middle. There are four circular white icons on the top and bottom of the screen respectively. What happens after the subtitle 'close air support force, the 8th Air Corps' appears?
A. Explosion occurs around the ship
B. Explosion occurs on the ground
C. Fighter jet is hit by artillery
D. Fighter jet crashes into the sea
E. Personnel on the tank are injured by explosion
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 125/165 [04:47<01:33,  2.34s/it][32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PE32sjfN-uM.mp4[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PE32sjfN-uM.mp4[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PE32sjfN-uM.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=250[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:36:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with white text 'Tom used his eyes to signal Mike to take action', there is a table with many codes on it, and beside the table, there is a woman with short white hair wearing a red blouse. What is the woman in the red blouse doing when she first appears?
A. Covering her face with both hands
B. Putting both hands on the table with many codes
C. Drinking a glass of red wine
D. Brushing her hair with her right hand
E. Brushing her hair with her left hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kj3Po7zUeyw.mp4[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kj3Po7zUeyw.mp4[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kj3Po7zUeyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=255[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a hall with a half-body statue and two national flags in the background, two rows of people are sitting on the left and right sides, and two country representatives are seated in the middle. After mentioning 'remain on good terms with both the', what changes occur on the screen?
A. The screen focuses on the original representative on the left side.
B. The screen focuses on the original representative on the right side.
C. The screen focuses on the two national flags in the background.
D. The screen cuts to the two rows of people on both sides.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:36[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 126/165 [04:49<01:16,  1.95s/it][32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6HTO2SOxUc.mp4[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6HTO2SOxUc.mp4[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6HTO2SOxUc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=252[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:36[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, two men and a woman with straight hair wearing a black and white striped outfit appear, they are facing the camera and waving. There are also many objects on the table with the word JELL-O on them. Besides this, what else appears in the room?
A. Mobile phone
B. Television
C. Flower pot
D. Piano
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 127/165 [04:51<01:17,  2.03s/it][32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 22iOyzE8Ec0.mp4[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/22iOyzE8Ec0.mp4[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 22iOyzE8Ec0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=254[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What is the ethnicity of the first person to appear in the video?
A. White
B. Black
C. Asian
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = mfS6gyP0mwo.mp4[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/mfS6gyP0mwo.mp4[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: mfS6gyP0mwo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=257[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a purple background, there is a man with long black hair standing. He has his hands clenched into fists in front of him. In the top left corner of the screen, there are bold white and blue captions. What did he do after this?
A. He styled his hair facing the mirror
B. He made a victory gesture
C. He touched his beard
D. He closed his eyes and clasped his hands in front of him
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 128/165 [04:53<01:20,  2.17s/it][32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_g3Y_mk64Wc.mp4[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _g3Y_mk64Wc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=256[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman with long hair, wearing a purple top and a necklace, is giving an introduction at the beginning of the video and later gives a lecture. What changes occur in the color of the wall behind her at these times?
A. White changes to blue
B. Olive green changes to white
C. White changes to olive green
D. Olive green changes to blue
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GuEptwLiAvs.mp4[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GuEptwLiAvs.mp4[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GuEptwLiAvs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=259[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A woman wearing a shoulder-baring top is sitting on a white sofa. She is wearing a wristwatch and a ring. Behind her are a black railing and a white wall. When the subtitle 'blackford' appears, what is the woman doing?
A. The woman is holding a book
B. The woman is holding a cat
C. The woman is holding two pieces of paper
D. The woman is holding two books
E. The woman is holding a pen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 129/165 [04:56<01:22,  2.29s/it][32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = td35F9LNazA.mp4[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/td35F9LNazA.mp4[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: td35F9LNazA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=258[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. A man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt, a man wearing gray sportswear and black earphones running outdoors.
B. A man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf, a man wearing gray sportswear and black earphones running outdoors, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt.
C. A man wearing gray sportswear and black earphones running outdoors, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt, a man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf.
D. A man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt, a man wearing gray sportswear and black earphones running outdoors, a man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf.
E. A man wearing gray sportswear and black earphones running outdoors, a man wearing an orange hooded sweatshirt with a red and white logo design on the top right corner sitting in front of a bookshelf, a man wearing a blue-gray jacket with white hair sitting in a car while buckled up with a seatbelt.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d-GKQeu4S6M.mp4[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d-GKQeu4S6M.mp4[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d-GKQeu4S6M.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=261[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the upper right corner, there are two minimized screens of two women. At the top of the white background, there's a line of black English text. In the middle, there are four rectangles with some formulas on them. What happens on the screen after the caption 'of questions cool that's not bad at all' appears?
A. The video screen of the two women moves from the right side to the left side.
B. Two women explain the content of the PPT composed of four differently colored rectangles on a white background.
C. The video screen of the two women moves from the top to the bottom.
D. The video screen of the two women disappears.
E. The video screen of the two women enlarges.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CEZ9rbjK3P4.mp4[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CEZ9rbjK3P4.mp4[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CEZ9rbjK3P4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=263[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[h264 @ 0x4f6642c0] mmco: unref short failure
[32m2025-11-29 12:36:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man holding a laptop stands in front of a glass window. He is wearing a black short-sleeved shirt, has short black hair, and is wearing jeans. What changes occur to him when a woman wearing a grey long-sleeved shirt appears next to him?
A. He changed into a grey short-sleeved shirt
B. He changed into a grey and white long-sleeved shirt
C. He changed into a grey and white short-sleeved shirt
D. He changed into a green long-sleeved shirt
E. He changed into a white short-sleeved shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 130/165 [04:59<01:24,  2.42s/it][32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = g_kziK-UOSU.mp4[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/g_kziK-UOSU.mp4[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: g_kziK-UOSU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=260[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the center of the screen is a drawing, depicting a person resting their hand on their forehead on a yellowish paper. The drawing is composed of lines and lacks colors. Where else has this artwork appeared?
A. In a room with a bookshelf
B. On a bench outside
C. In front of a table holding a vase
D. On the glass of a transparent window
E. In front of a table with a desk lamp
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lN3WnXMaE0o.mp4[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lN3WnXMaE0o.mp4[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lN3WnXMaE0o.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=265[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A car is stuck in a crevice between mountain rocks, severely damaged and emitting white smoke upwards. A person wearing blue clothing approaches the accident scene. What did this person in blue do afterwards?
A. Hold a fire extinguisher in their left hand
B. Hold a fire extinguisher in their right hand
C. Climb the mountain holding something in their left hand
D. Climb the mountain holding something in their right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:48[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 131/165 [05:00<01:16,  2.26s/it][32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Dkm35G5kkcc.mp4[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Dkm35G5kkcc.mp4[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Dkm35G5kkcc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=262[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:48[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A soldier wearing a golden helmet is standing on a grassy field near a wooden fence. Holding a water bag, three drops fall from it. After the subtitle 'you will have to pay for it in blood' appears, what is the first object that appears on the screen?
A. A person with white hair holding a green shield
B. A person wearing a red robe with black hair
C. Three shields
D. A person with yellow hair holding a water bag
E. A soldier holding a red shield and wearing a helmet
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VkNF0rXuDXw.mp4[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VkNF0rXuDXw.mp4[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VkNF0rXuDXw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=267[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following sequences of scenes is correct?
A. First, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face. Next, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Finally, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping.
B. First, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping. Next, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face. Finally, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine.
C. First, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping. Next, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Finally, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face.
D. First, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Then, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping. Finally, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face.
E. First, in a laundry room with three washing machines, a man in black clothes puts clothes into a washing machine. Next, outside, two women walk side by side, the one on the left with her eyes closed and fingers touching her face. Finally, on the left side of a corridor with a green billboard, a woman in red clothes is skipping and jumping.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:51[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 132/165 [05:03<01:18,  2.39s/it][32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/8Gl6iy7OEM4.mp4[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 8Gl6iy7OEM4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=264[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:51[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a piece of white paper, the words 'not useful' are written, and there is a downward-curving arrow. Someone is holding a white and blue pen. What are they doing?
A. Coloring the roof in the drawing
B. Drawing sweat on the little person in the drawing
C. Coloring the sky in the drawing
D. Coloring the flowers in the drawing
E. Putting clothes on the little person in the drawing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = I-yg_3yx6iA.mp4[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/I-yg_3yx6iA.mp4[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: I-yg_3yx6iA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=269[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with pictures, two men are discussing some topics. There's a picture with a river at the bottom left corner of the screen. One of the men is saying 'a pew river the whole'. Which man is saying 'a pew river the whole'?
A. The man with fair skin
B. The man wearing a black short-sleeve shirt
C. The man wearing an olive hat
D. The man wearing a white short-sleeve shirt
E. The man wearing a yellow short-sleeve shirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:53[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 133/165 [05:05<01:15,  2.37s/it][32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = z6THwql5c6w.mp4[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/z6THwql5c6w.mp4[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: z6THwql5c6w.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=266[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:53[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under a gray sky, a bullet-riddled airplane is flying with red and white stripes on its tail wings. There is a red pattern dot on the back of the fuselage, and the rest of the plane is silver. When the subtitle 'the aircraft falling away after being' appears, what is the shape of the red pattern on the tail of the fuselage?
A. A star
B. A square
C. A triangle
D. A pattern composed of a rectangle and a star
E. A rectangle
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KTY9bogonyw.mp4[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KTY9bogonyw.mp4[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KTY9bogonyw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=271[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black and white scene, a group of people are charging up a hill with guns. One person is holding a flag with a five-starred red emblem. After the subtitle 'spot where t e Ah,this qv who konws it', what appears on the screen?
A. French Flag
B. American Flag
C. British Flag
D. German Flag
E. Chinese Flag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:56[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 134/165 [05:08<01:13,  2.39s/it][32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7m9XIXyT5_I.mp4[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7m9XIXyT5_I.mp4[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7m9XIXyT5_I.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=268[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:56[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene where red ribbons are floating in the air, what is the woman with black hair, dressed in a white coat and wearing a watch, doing?
A. Putting her hand on her temple
B. Raising both hands
C. Facing away from the mirror
D. Raising one hand
E. Covering her nose with her hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fryyNwUCPWA.mp4[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fryyNwUCPWA.mp4[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fryyNwUCPWA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=273[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:36:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top left corner of the screen, there is the red text 'WEAPONRY'. Inside an operation room outlined with a red line, there is a soldier wearing an olive-colored hat. What did this soldier do?
A. He removed the shell from the cannon
B. He collapsed onto the ground
C. He left the operation room
D. He loaded a shell into the cannon and fired it
E. He disassembled the cannon
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:36:58[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 135/165 [05:11<01:14,  2.48s/it][32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = NAJOZTNkhlI.mp4[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/NAJOZTNkhlI.mp4[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: NAJOZTNkhlI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=270[0m
[32m2025-11-29 12:36:58[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:36:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:36:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with various instruments and control panels, there is a man with short hair wearing a white lab coat. When the subtitle 'think you'll see this technology be used' appears, what objects are present in the scene?
A. a gold chain
B. a red button
C. a white button
D. a black remote
E. a black steering wheel
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:00[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zVudr8cxHRE.mp4[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zVudr8cxHRE.mp4[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zVudr8cxHRE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=275[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:00[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
This is a document with the words 'Preprint. Under review.' at the top. There is a table below with the word 'Method' in the header. What happened when this document first appeared?
A. There was a black line drawn across the document.
B. There was a yellow line drawn across the document.
C. The text in the document was highlighted in yellow.
D. The text in the document was highlighted in green.
E. There was a red line drawn across the document.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:01[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 136/165 [05:13<01:13,  2.53s/it][32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = LB1qPExHQY8.mp4[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/LB1qPExHQY8.mp4[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: LB1qPExHQY8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=272[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:01[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a confined space, on the right side, there is a man wearing a yellow shirt, with earphones around his neck, and a watch on his left hand. In the middle, there is a man wearing a white shirt and a visor, sitting on a black chair. On the left side, there is a person wearing black clothes, carrying a white bag. What change did the man in the yellow shirt undergo when the subtitles mentioned 'yourself feel terrible and like flirty'?
A. He took off his watch
B. He changed into a black shirt
C. He changed into a black jacket
D. He took off his earphones
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = bAGhXcYc0o4.mp4[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/bAGhXcYc0o4.mp4[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: bAGhXcYc0o4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=277[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the bottom right corner with a black tank in the background, what change occurred to the white word 'Plans' located at the bottom left of the screen when the subtitle said 'upcoming plans next steps are'?
A. The text got bigger
B. The text turned black
C. The text turned red
D. The text got smaller
E. The text turned purple
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:03[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 137/165 [05:15<01:08,  2.45s/it][32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = lNReCCShKJQ.mp4[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/lNReCCShKJQ.mp4[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: lNReCCShKJQ.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=274[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:37:03[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Next to a large building, a tank is driving on a desolate street with signs of explosion in the background. In which of the following scenes has this tank appeared?
A. On a street with many pedestrians
B. On a square during a military parade
C. On a square during a rainy day
D. On a desolate grassland with dried grass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 138/165 [05:17<00:57,  2.13s/it][32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Sy2unO22PUE.mp4[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Sy2unO22PUE.mp4[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Sy2unO22PUE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=276[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a wooden wall decorated with a face flag, a man wearing a blue striped short sleeve shirt is sitting on a grey sofa. When 'Norwegian Geograpeeps explaining' is mentioned, what objects are present on the screen?
A. A black hat
B. A blue hat
C. A yellow small flag
D. A black small flag
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = kbRtl58u_kk.mp4[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/kbRtl58u_kk.mp4[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: kbRtl58u_kk.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=279[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:37:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a dark room, there is a rotating fan hanging. When the screen displays white subtitles saying 'i watch all ur vedeo', what is a short-haired man wearing a green short-sleeved shirt doing?
A. He is preparing to change clothes.
B. He is preparing to turn off the fan.
C. He is touching his own hair.
D. He is looking at the electric fan.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = PQRyGacBRA4.mp4[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/PQRyGacBRA4.mp4[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: PQRyGacBRA4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=281[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:06[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A cartoon character is standing at the end of a corridor in a room. The cartoon character is wearing a green uniform, a green hat, and black shoes. The corridor has doors on both sides arranged in an orderly manner. When the subtitle 'around a corner he was suddenly within' appears, what change occurs in the posture of this character in the green uniform?
A. From standing to leaning back
B. From standing to kneeling
C. From standing to bending over
D. From standing to crawling
E. From standing to lying on the side
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:07[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 139/165 [05:19<00:57,  2.21s/it][32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d8H7hgQY9ew.mp4[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d8H7hgQY9ew.mp4[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d8H7hgQY9ew.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=278[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:07[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man wearing a suit and a purple tie is walking on a concrete road surrounded by trees and parked cars. He has short hair and is holding a piece of white paper in his hand. What other scenes did this man appear in?
A. On a stage with British flags displayed
B. In a library with a brown bookshelf full of books, in front of a green desk
C. In front of a blue backdrop with the British flag
D. In front of a complex building with a bell tower and some withered branches on the left
E. In front of a green backdrop painted with various colorful buildings
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:08[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = jvkmcX47bKU.mp4[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/jvkmcX47bKU.mp4[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: jvkmcX47bKU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=283[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:08[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In an interview setting, a man in a suit and a woman are having a conversation. Behind them on the left is a model made of red lines, and on the right is a screen with red and black letters. Both the man and the woman are sitting on stools. In front of them is a round table, which also has red triangular lines with the letters cna printed on it. When the letters 'Rahm and Hovland' in the bottom scrolling black area moved to the left, what event occurred?
A. The man smoothed his clothes
B. The man stood up
C. The man picked up a piece of paper from the table
D. The man took a sip of water
E. The woman adjusted her hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:10[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 140/165 [05:22<00:59,  2.38s/it][32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = XuQswmEPgxU.mp4[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/XuQswmEPgxU.mp4[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: XuQswmEPgxU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=280[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:10[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A girl is sitting in a room lit by colorful lights, with green plants behind her and a white curtain on the left side of the screen. Her hair is yellow and black, she is wearing glasses, and she has on a gray T-shirt along with gloves. She is speaking to the camera and after mentioning 'and she has this series of artwork named', what happened?
A. A transparent pen holder with blue sticky notes on it appeared to the right of the camera.
B. A transparent pen holder with purple sticky notes on it appeared to the right of the camera.
C. A transparent pen holder with olive sticky notes on it appeared to the right of the camera.
D. A transparent pen holder with yellow sticky notes on it appeared to the right of the camera.
E. A transparent pen holder with green sticky notes on it appeared to the right of the camera.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:12[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = Fw1rirubXiU.mp4[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/Fw1rirubXiU.mp4[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: Fw1rirubXiU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=285[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:12[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the very beginning of the video, a woman wearing a hat and a fur coat is standing in front of a car. In the car, in the driver's seat, there is a man also wearing a fur coat. In the upper left corner of the screen, the white text 'HARLEM IS EVERY WHERE' appears. Where else does this white text appear?
A. In the purple background on the left side, there is a group of English words, and on the right side, there is a picture of a nude woman sitting with her hands hugging her knees, staring at the stove
B. In a black background on the left side, there is a picture of a person wearing a purple skirt sitting on the grass
C. In a green background on the right side, there is a picture of a person wearing a red skirt sitting in front of a stove
D. In a red background on the right side, there is a picture of a nude person sitting in front of a stove
E. In a purple background on the right side, there is a picture of a person wearing a white short-sleeve shirt sitting in front of a stove
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:13[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 141/165 [05:25<00:59,  2.47s/it][32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = oI975O1BUu0.mp4[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/oI975O1BUu0.mp4[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: oI975O1BUu0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=282[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:13[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the broadcast room, there is a man wearing a black suit and a white shirt. His right hand is on the table, and his left hand is slightly raised. On the screen next to his right hand, the text 'DYING FOR AID' appears. What change occurs to his right hand when the text on the screen changes to 'GLOBAL WATCH'?
A. He places his right hand on a mouse
B. He places his right hand on his forehead
C. He places his right hand on his chin
D. He is holding a piece of paper with his right hand
E. He is holding a phone with his right hand
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:14[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aX_HgA5SNLQ.mp4[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aX_HgA5SNLQ.mp4[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aX_HgA5SNLQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=287[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:14[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a man wearing a red shirt with a beard in the middle of the screen, and there is a logo in the bottom right corner. What clothing does this man change into when the subtitle mentions 'as Caitlyn will tell you that might not'?
A. Black shirt changes to patterned short sleeves
B. White shirt changes to patterned short sleeves
C. Red shirt changes to patterned short sleeves
D. Yellow shirt changes to patterned short sleeves
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:15[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 142/165 [05:27<00:54,  2.38s/it][32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7153617149041446150.mp4[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7153617149041446150.mp4[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7153617149041446150.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=284[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:37:15[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a white rectangular bowl on a white table. The bowl contains white cream cheese cubes. A hand is holding a piece of cream cheese. What does the hand do when the white cream cheese first appears?
A. Spread the cream cheese evenly
B. Use a torch to melt the cream cheese
C. Break the cream cheese into pieces
D. Season the cream cheese
E. Take the cream cheese off
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:16[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 143/165 [05:28<00:44,  2.00s/it][32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7254238802577820929.mp4[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7254238802577820929.mp4[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7254238802577820929.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=286[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:37:16[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a glass door with a black frame, there is a man sitting who is wearing a green jacket, has a goatee, and is wearing white earphones. After he says "spaces," who is the first person to appear?
A. A woman with black long hair wearing black top
B. A man with short hair wearing black top
C. A man wearing black glasses
D. A woman wearing black glasses
E. A woman wearing a blue top and tying her hair back with a black band
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:17[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = CdTijM0_es4.mp4[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/CdTijM0_es4.mp4[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: CdTijM0_es4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=289[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:17[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Outside a bright window, there is a boy wearing a white shirt and a boy holding a basketball. At the bottom of the screen, there is white text that says 'Tom is really a pair of'. What is the boy in the white shirt doing in the scene?
A. Holding his head and crying
B. Crouching on the boy holding the basketball
C. Fighting with the boy holding the basketball
D. Kneeling on the ground tying his shoelaces
E. Putting his arm around the boy holding the basketball
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:18[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 144/165 [05:30<00:43,  2.05s/it][32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=288[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:18[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Under the blue sky and white clouds, there is an endless stretch of mountain ranges. In front of the mountain ranges, there are some brown tents with two soldiers standing beside them. The soldiers are wearing gray helmets and holding crescent-shaped shields. In which of the following scenes have soldiers wearing gray helmets appeared?
A. Inside a dense forest
B. In a desert with swirling sandstorms
C. On a high mountain covered with white snow
D. In a scene with an olive tree and numerous arrows flying in the sky
E. On a grassland during rain
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:19[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fLn06p2HtAc.mp4[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fLn06p2HtAc.mp4[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fLn06p2HtAc.mp4 | Selected 15 frames[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=291[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 15 specific frames[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 15 custom frames[0m
[32m2025-11-29 12:37:19[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 15 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room, a man with short black hair, wearing black clothes, is holding a gun. He is pointing the gun at another man with short black hair, wearing black clothes with a belt. The question is, in which of the following scenes does this gun appear?
A. In the hand of the man with red hair
B. In the hand of the man with green hair
C. In the hand of the man with white hair
D. In the hand of the man with blue hair
E. In the hand of the man with purple hair
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 145/165 [05:33<00:44,  2.23s/it][32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 3hyPwjkdHEA.mp4[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/3hyPwjkdHEA.mp4[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 3hyPwjkdHEA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=290[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the video, there is a small person figure wearing a blue duckbill cap and dressed in blue clothes. Where has this blue-clothed character appeared before?
A. A room with a map in front, including 3 guitars of different colors, a computer, an olive-colored sofa, and a bookshelf.
B. A room with a map in front, including 2 guitars of different colors and a computer.
C. A room with a map in front, including an olive-colored sofa, a computer, and a bookshelf.
D. A room with a map in front, including an olive-colored sofa and a bookshelf.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:21[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TFbGLEZ4qt0.mp4[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TFbGLEZ4qt0.mp4[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TFbGLEZ4qt0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=293[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:21[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a ground covered with dry grass, there is a woman standing in a yellow floral dress. Behind the woman is a black dog. The woman is holding a hat in her hand. Which of the following subtitles appeared along with the black dog following the woman?
A. "you can give yourself than a homemade"
B. "of care"
C. "meal"
D. "after a long day i find no greater gift"
E. "and faith that anything is possible and"
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 146/165 [05:35<00:44,  2.33s/it][32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = VkNF0rXuDXw.mp4[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/VkNF0rXuDXw.mp4[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: VkNF0rXuDXw.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=292[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A lady with long black straight hair is in a white room. She is wearing a white coat and a pink top. To her right is the door of the room, and to her left is a white display shelf with a table lamp, vase, and some pictures on it. She is sitting in front of a table, talking. There is also a bucket with many colored pencils and a bunch of flowers to the left of the table. What action did this lady do?
A. She used a purple colored pencil
B. She moved her hand to the right
C. She got up and opened the room door
D. She picked up the bunch of flowers
E. She got up and walked out of the room
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:23[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = f0IbZGfTgUM.mp4[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/f0IbZGfTgUM.mp4[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: f0IbZGfTgUM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=295[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:23[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a piece of white paper, there is a black frame drawn on it, filled with blue water. Someone is holding a yellow pen. What is he doing?
A. Coloring the roof in the drawing
B. Coloring the flowers in the drawing
C. Coloring the radish in the drawing
D. Coloring the sun in the drawing
E. Coloring the western red cedar in the drawing
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:25[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 147/165 [05:37<00:40,  2.25s/it][32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7197781091162279169.mp4[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7197781091162279169.mp4[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7197781091162279169.mp4 | Selected 4 frames[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=294[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 4 specific frames[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 4 custom frames[0m
[32m2025-11-29 12:37:25[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 4 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the top-left corner of a black background with white English text 'Explosive Reactive Armor', what happens on the screen after a gray circle with a white Star of David appears on the left side of the screen?
A. A line of white English text appears at the bottom of the black screen
B. A line of green English text appears in the middle of the black screen
C. A line of white English text appears in the middle of the black screen
D. A line of red English text appears in the top right corner of the black screen
E. A line of white Chinese text appears in the middle of the black screen
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7194500194648476933.mp4[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7194500194648476933.mp4[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7194500194648476933.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=297[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
At the beginning of the video, a woman wearing a white short-sleeved top and gray shorts is standing barefoot on a wooden platform, holding black and pink clothes. When the subtitle 'Ever since I left the city, you' appears, what change happens to this woman?
A. The gray shorts change to black shorts.
B. She goes from not wearing sunglasses to wearing sunglasses.
C. The white short-sleeved top changes to a pink plaid long-sleeved top.
D. She goes from not wearing a hat to wearing a hat.
E. Her hair changes from black to yellow.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:26[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 148/165 [05:38<00:29,  1.76s/it][32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fZBC3nmvJb8.mp4[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fZBC3nmvJb8.mp4[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fZBC3nmvJb8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=296[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:26[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man appears on the screen wearing a grey shirt and black pants, holding a black long strip in his hand. After the subtitle 'I got the chronic by the tree' appears, what does the man in the grey shirt do?
A. Holds both hands in front of his chest
B. Presses the black long strip against his chest with both hands
C. Inserts both hands into his pockets
D. Inserts both hands into his coat pockets
E. Crosses his hands at his waist
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:27[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = JASFwBtUK40.mp4[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/JASFwBtUK40.mp4[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: JASFwBtUK40.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=299[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:27[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a black drawing board in the screen, there is a white design. In the distance, a plastic box filled with items is placed on the desk. In the lower right corner, a hand is holding a drawing pen and adjusting a color palette. What object is sliding down at this moment?
A. black canvas
B. white pigment
C. drawing pen
D. color palette
E. easel
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:28[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 149/165 [05:41<00:31,  1.99s/it][32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = rP7sQe784k8.mp4[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/rP7sQe784k8.mp4[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: rP7sQe784k8.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=298[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:28[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white walls in the video, there are several brown experiment tables. A man wearing a blue and white shirt and black glasses is explaining. When the subtitle mentions 'I can. The higher I lift it, the faster the explanation goes,' which item is not present in the room at this time?
A. Some transparent tubes
B. Yellow pipes
C. Some white pipes
D. Black glasses
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:29[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7231929658869107994.mp4[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7231929658869107994.mp4[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7231929658869107994.mp4 | Selected 8 frames[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=301[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 8 specific frames[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 8 custom frames[0m
[32m2025-11-29 12:37:29[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 8 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a rectangular table with food ingredients, there are some green onions on the wooden tray on the far left side. What change occurred to the green onions when the subtitle says 'Onion'?
A. The green onions were cut into chunks
B. The green onions were put into a bottle
C. The green onions were placed on a rack
D. The green onions were put into a pot
E. The green onions were cut into pieces
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:31[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 150/165 [05:44<00:34,  2.32s/it][32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 9yQV0t5meo4.mp4[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/9yQV0t5meo4.mp4[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 9yQV0t5meo4.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=300[0m
[32m2025-11-29 12:37:31[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a glass bowl containing some white and green foods, there is some brown powder. There are some fruits beside the glass bowl. A person is holding a wooden spoon, stirring inside the glass bowl. What objects are present in the scene?
A. Yellow plums
B. Yellow bananas
C. Yellow pineapple
D. Green mangoes
E. Pink peaches
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = zk6fgbXI5AE.mp4[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/zk6fgbXI5AE.mp4[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: zk6fgbXI5AE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=303[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the scene on the wide street, there are a few cars and a few buildings in the background. What change occurred to the bird after it was on the ground?
A. Stayed in the same place
B. Walked on the ground
C. Flew onto a tree
D. Flew into the sky
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:32[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 151/165 [05:45<00:26,  1.90s/it][32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7270058445577948418.mp4[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7270058445577948418.mp4[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7270058445577948418.mp4 | Selected 13 frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=302[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 13 specific frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 13 custom frames[0m
[32m2025-11-29 12:37:32[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 13 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scenario sequences is correct?
A. First, flames engulf a person, then a woman in yellow clothing and a person in a black outfit lie together, and finally, a man wearing a grey outfit lights a lighter.
B. First, a man wearing a grey outfit lights a lighter, then flames engulf a person, and finally, a woman in yellow clothing and a person in a black outfit lie together.
C. First, a man wearing a grey outfit lights a lighter, then a woman in yellow clothing and a person in a black outfit lie together, and finally, flames engulf a person.
D. First, flames engulf a person, then a man wearing a grey outfit lights a lighter, and finally, a woman in yellow clothing and a person in a black outfit lie together.
E. First, a woman in yellow clothing and a person in a black outfit lie together, then a man wearing a grey outfit lights a lighter, and finally, flames engulf a person.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:34[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 152/165 [05:46<00:23,  1.81s/it][32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = fO7nwCix8xU.mp4[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/fO7nwCix8xU.mp4[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: fO7nwCix8xU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=304[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:34[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
What object appeared before the subtitle saying 'but you have to pay for your bed' in a dark airplane cabin with a person wearing a black shirt without a scarf holding a round yellow paper cup containing ice and coffee-colored liquid?
A. A red backpack
B. A bed
C. An air conditioner
D. A magazine with a woman with long hair on the cover
E. A flower pot
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:35[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = T57jVsvVVR0.mp4[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/T57jVsvVVR0.mp4[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: T57jVsvVVR0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=305[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:35[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with white walls and a decorative object hanging on the wall, there is a table and chairs. Two people are sitting at the table, which is cluttered with various items. On the left is a short-haired man in a white long-sleeved shirt, and on the right is a long-haired woman in a white long-sleeved shirt. Which of the following items has appeared on the table?
A. Lamp
B. Red cup
C. Snacks
D. Jump rope
E. Beverage
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 153/165 [05:49<00:25,  2.09s/it][32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = a_8G0PzVFbc.mp4[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/a_8G0PzVFbc.mp4[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: a_8G0PzVFbc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=306[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the left side of the screen, there is a large white board with black text saying 'NO EXTRADITION Free Julian Assange'. On the right side, there is a person holding a rectangular board with the text 'PRESS FREEDOM IS MY FREEDOM'. What style of shoes is the person on the right wearing when the subtitles say 'well I think the Australian government'?
A. skate shoes
B. black boots
C. black loafers
D. black sneakers
E. black high heels
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:37[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = brZugTJ0odg.mp4[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/brZugTJ0odg.mp4[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: brZugTJ0odg.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=307[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:37[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room filled with all kinds of items, with a yellow floor, there is a woman wearing a blue long-sleeved top pushing a cart. After the subtitle 'The St. Mark's Tower is one of Frank Lloyd Wright's earliest designs for a' appears, what does she do?
A. Walks around the cart in a circle
B. Speaks into the mirror
C. Brushes something on the cart with a small brush
D. Lifts the bottom of the cart
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7269006883380399362.mp4[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7269006883380399362.mp4[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7269006883380399362.mp4 | Selected 7 frames[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=309[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 7 specific frames[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 7 custom frames[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 7 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a scene with a big tree as the background, a black and yellow long-haired cat is walking on a horizontal wooden beam, and in a scene with a big tree as the background, a black dog is holding its front legs on a horizontal wooden beam. Which of these two animals appeared first?
A. Neither appeared
B. Black dog
C. Both appeared at the same time
D. Black and yellow long-haired cat
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:39[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 154/165 [05:51<00:24,  2.21s/it][32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = OMJc43wUPLM.mp4[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/OMJc43wUPLM.mp4[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: OMJc43wUPLM.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=308[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:39[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, a man wearing a black hoodie yawning; then, a man holding a white sign with the red text 'I HATE'; finally, two dark-skinned children lying at the doorway looking outside.
B. First, two dark-skinned children lying at the doorway looking outside; then, a man wearing a black hoodie yawning; finally, a man holding a white sign with the red text 'I HATE'.
C. First, a man holding a white sign with the red text 'I HATE'; then, a man wearing a black hoodie yawning; finally, two dark-skinned children lying at the doorway looking outside.
D. First, a man holding a white sign with the red text 'I HATE'; then, two dark-skinned children lying at the doorway looking outside; finally, a man wearing a black hoodie yawning.
E. First, two dark-skinned children lying at the doorway looking outside; then, a man holding a white sign with the red text 'I HATE'; finally, a man wearing a black hoodie yawning.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:40[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aX_HgA5SNLQ.mp4[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aX_HgA5SNLQ.mp4[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aX_HgA5SNLQ.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=311[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:40[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a red background, there is a white box containing a small red square. Next to the red square, there are white letters reading '26√ó.' Inside the red square, there are two small black X's and one large black X. What changes occur to the red square when it appears on a red background with white letters reading 'Lwow - Lviv - Lemberg'?
A. It changes from red to green, and the number of small X's inside the box changes from two to one.
B. It changes from red to green, and the number of small X's inside the box changes from two to four.
C. It changes from red to green, and the number of small X's inside the box changes from two to three.
D. It changes from red to green, and the number of small X's inside the box changes from two to six.
E. It changes from red to green, and the number of small X's inside the box changes from two to five.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:41[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 155/165 [05:54<00:22,  2.20s/it][32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = d5JlCEDlHGE.mp4[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/d5JlCEDlHGE.mp4[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: d5JlCEDlHGE.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=310[0m
[32m2025-11-29 12:37:41[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a bookshelf filled with many books, a man wearing black glasses, with short hair and dressed in a black top, is talking. After he says "that really took away the waste scene so", what is the first item that appears?
A. gold necklace
B. green coat
C. white necklace
D. white earphones
E. black and gray long tail skirt
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:42[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = L-XGTMusZvc.mp4[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/L-XGTMusZvc.mp4[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: L-XGTMusZvc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=313[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:42[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a room with a white, square-patterned floor, there is a person with some white hair, wearing a black short-sleeve shirt with red designs. He also has a beard. What is this man doing?
A. Reading a book
B. Fishing
C. Drinking water
D. Playing piano
E. Talking
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:44[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 156/165 [05:56<00:21,  2.39s/it][32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 1R5uPaL0V-0.mp4[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/1R5uPaL0V-0.mp4[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 1R5uPaL0V-0.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=312[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:44[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a gray background, there are two lines of English sentences in white font on a red and black base in the upper left corner, and five white circular icons in the middle. What happened after the subtitle 'proper channels for requesting close air support' appeared?
A. A fighter jet crashes from the sky
B. A fighter jet crashes into the sea
C. A pilot jumps off the fighter jet
D. A fighter jet is engaging in ground combat
E. A fighter jet is hit by artillery
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:45[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = GZFL58_pXPg.mp4[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/GZFL58_pXPg.mp4[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: GZFL58_pXPg.mp4 | Selected 12 frames[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=315[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 12 specific frames[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 12 custom frames[0m
[32m2025-11-29 12:37:45[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 12 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On the screen, there are many advanced math problems on a piece of white paper. Among the problems, there is also a complete brain diagram. When the subtitle mentions 'an extraordinary brain that lacked the,' what color appears on the right side of the brain diagram?
A. The left side of the brain diagram is gray with stained patterns.
B. The right side of the brain is blue with stains.
C. The right side of the brain diagram is gray, resembling stains.
D. The left side of the brain is blue with stains.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:46[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: C.[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7171182579058511110.mp4[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7171182579058511110.mp4[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7171182579058511110.mp4 | Selected 5 frames[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=317[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 5 specific frames[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 5 custom frames[0m
[32m2025-11-29 12:37:46[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 5 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The person on the screen is a black-haired man wearing a T-shirt and a black scarf. He is in a white kitchen, with a stove behind him. On the stove, there are some cylinders and tools, as well as transparent bottles and various other items. In front of the man, there is a countertop with a cutting board and a metal tray containing a large sushi roll. The man is holding a yellow model of a boat. What material is this boat made of?
A. plastic
B. wood
C. ceramic
D. stainless steel
E. glass
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 157/165 [05:59<00:19,  2.43s/it][32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RTUFPjliMCU.mp4[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RTUFPjliMCU.mp4[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RTUFPjliMCU.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=314[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a row of black glass doors of a freezer, a woman wearing a beige wool coat and a black mask is holding a box of food, standing in front of a glass cabinet. What did she do next?
A. She was sleeping in the bedroom
B. She was eating chicken wings from a plate
C. She was reading a book in the library
D. She was cleaning the room in the bedroom
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:47[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = WpbB_swXHkc.mp4[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/WpbB_swXHkc.mp4[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: WpbB_swXHkc.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=319[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:47[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In front of a ruin of a building with two stone pillars standing at the entrance, there is a woman sitting. She has black curly hair and is wearing a blue long-sleeved garment, covering her face with both hands. Which subtitles have appeared together with this woman?
A. all right that‚Äôs the fun part of the day
B. is just bam it‚Äôs kind of slaps
C. Is this a special treatment for members?
D. It‚Äôs seven o‚Äôclock, did you hear?
E. if you take a deep breath and keep it
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = _BDzMutoy6A.mp4[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/_BDzMutoy6A.mp4[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: _BDzMutoy6A.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=321[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Two women on the screen are explaining a question. In the problem, there is a number crossing a pink bar at the bottom and a slanted line. When the subtitle 'figs but I still would round up so I' appears, what color is the slanted line?
A. Olive Yellow
B. Light Yellow
C. Light Blue
D. Grass Green
E. Ink Green
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:50[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 158/165 [06:02<00:18,  2.58s/it][32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = vJ9hYCUDHTo.mp4[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/vJ9hYCUDHTo.mp4[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: vJ9hYCUDHTo.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=316[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:50[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A lady with brown hair is explaining in front of a mirror. She is wearing light brown clothes, with a white wall behind her decorated with long wooden planks. In the top left corner behind her, there is a display screen showing various times. When the phrase 'best of Malaysia Airline and people who' is mentioned, what objects are present?
A. A hanging picture with timestamps
B. Earrings
C. Glasses
D. A blue robe
E. A necklace
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
Model Responding:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 159/165 [06:04<00:14,  2.42s/it][32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = u1D4ArcBjLI.mp4[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/u1D4ArcBjLI.mp4[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: u1D4ArcBjLI.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=318[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the upper left side of the wooden table, there's a plate of white and pink tangyuan. In the lower left, there's ice water with ice cubes in a glass container. On the right, there are six tangyuan in a blue pot on a black gas stove. When the subtitle 'It'll stick to the bottom of your pan' appears, what is the hand holding a green slotted spoon doing?
A. Boiling tangyuan
B. Stir-frying tangyuan
C. Kneading tangyuan
D. Deep-frying tangyuan
E. Pan-frying tangyuan
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:52[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = -0aM99dMu_4.mp4[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/-0aM99dMu_4.mp4[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: -0aM99dMu_4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=323[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:52[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In a black-bordered, white-background image, there are three equally sized video windows labeled 'timesteps'. When 'the unsupervised method will discover' is mentioned, what change occurs in the first video window?
A. It shows one segment of a black-and-white grid with two green objects.
B. It shows two segments of a black-and-white grid with two green objects.
C. It shows two segments of a pure black screen with two green objects.
D. It shows one segment of a pure black screen with two green objects.
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:54[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = KIf2fGmluhY.mp4[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/KIf2fGmluhY.mp4[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: KIf2fGmluhY.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=325[0m
[32m2025-11-29 12:37:54[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
Which of the following scene sequences is correct?
A. First, the scene shows 'a corner of a wall with a wine-red background, where a blonde woman in a black suit is speaking with her hands spread apart', followed by 'the video screen focuses on the projector screen, with a white background and multiple pictures on the projector screen. The top right shows a picture of a person's head with their hand raised, and the bottom right shows a hand wearing a blue glove', and finally, 'the video screen focuses on the projector screen, displaying a white box filled with small items of different colors.'
B. First, the scene shows 'the video screen focuses on the projector screen, displaying a white box filled with small items of different colors', followed by 'a corner of a wall with a wine-red background, where a blonde woman in a black suit is speaking with her hands spread apart', and finally, 'the video screen focuses on the projector screen, with a white background and multiple pictures on the projector screen. The top right shows a picture of a person's head with their hand raised, and the bottom right shows a hand wearing a blue glove.'
C. First, the scene shows 'the video screen focuses on the projector screen, with a white background and multiple pictures on the projector screen. The top right shows a picture of a person's head with their hand raised, and the bottom right shows a hand wearing a blue glove', followed by 'the video screen focuses on the projector screen, displaying a white box filled with small items of different colors', and finally, 'a corner of a wall with a wine-red background, where a blonde woman in a black suit is speaking with her hands spread apart.'
D. First, the scene shows 'the video screen focuses on the projector screen, with a white background and multiple pictures on the projector screen. The top right shows a picture of a person's head with their hand raised, and the bottom right shows a hand wearing a blue glove', followed by 'the scene shows a corner of a wall with a wine-red background, where a blonde woman in a black suit is speaking with her hands spread apart', and finally, 'the video screen focuses on the projector screen, displaying a white box filled with small items of different colors.'
E. First, the scene shows 'the video screen focuses on the projector screen, displaying a white box filled with small items of different colors', followed by 'the video screen focuses on the projector screen, with a white background and multiple pictures on the projector screen. The top right shows a picture of a person's head with their hand raised, and the bottom right shows a hand wearing a blue glove', and finally, 'a corner of a wall with a wine-red background, where a blonde woman in a black suit is speaking with her hands spread apart.'
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:55[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: E.[0m
Model Responding:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 160/165 [06:07<00:13,  2.68s/it][32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 2ekjGl8yWZk.mp4[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/2ekjGl8yWZk.mp4[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 2ekjGl8yWZk.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=320[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:55[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
During the appearance of the black arrow between the English text on the white background PPT with two lines at the top, what happens on the screen?
A. The arrow moves from top to bottom
B. The arrow moves from right to left
C. The arrow changes from large to small
D. The arrow moves from left to right
E. The arrow changes from small to large
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D.[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 161/165 [06:09<00:09,  2.49s/it][32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/hg2Q_O5b9w4.mp4[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: hg2Q_O5b9w4.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=322[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The title on the screen is 'Datasets', below it are inference formulas, and a dynamic graph appears in the middle. In the top right corner, there is a man with glasses explaining. What did the boy holding the ball do when he appeared for the first time?
A. Threw the ball into the distance
B. Shot the ball towards the basket
C. Dribbled the ball
D. Stepped on the ball with his foot
E. Passed the ball to someone else
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:57[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = 7184469162956246277.mp4[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/7184469162956246277.mp4[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: 7184469162956246277.mp4 | Selected 10 frames[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=327[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 10 specific frames[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 10 custom frames[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 10 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:57[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
The man wearing a black shirt appears in the center of the screen, he's wearing sunglasses, his hair is parted in the middle, and he has a white accessory at the collar. Behind him is a green field, trees, and a white sky, with people resting on the grass. In which other locations has this man wearing sunglasses appeared?
A. White sofa
B. Path by the water
C. Spacious theater
D. Hill in the grass field
E. Bench in the grass field
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = TxS1JnfuG34.mp4[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/TxS1JnfuG34.mp4[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: TxS1JnfuG34.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=329[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:37:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
In the PPT slide with white background and black text, on the left side, there are three shapes made up of three overlapping blue squares each, and the rest of the screen is text. When the caption 'here somewhere the anchor is cropped' appears, what changes occur to the shapes?
A. Turned green
B. Covered by a yellow overlay
C. Got bigger
D. Turned yellow
E. Got smaller
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:37:59[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A.[0m
Model Responding:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 162/165 [06:11<00:07,  2.41s/it][32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = RN2g9sRuJhA.mp4[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/RN2g9sRuJhA.mp4[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: RN2g9sRuJhA.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=324[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:37:59[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:38:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a street at night, there are two people. Among them, a woman with long black hair wearing a red coat is sitting on the ground. In front of her, a short-haired man wearing an olive-colored outfit is kneeling. In which of the following scenes did this woman appear?
A. In the woods
B. Inside a room
C. In the desert
D. In the sea
E. On a plane
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:38:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: B.[0m
[32m2025-11-29 12:38:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
On a natural wood-colored floor, there is a man standing who is wearing a blue shirt and has tattoos on his arms. In front of him, there are cut tofu strips, and to the left, there is a white plate. To his right, there is an orange object. What is he doing?
A. Sprinkling salt on tofu
B. Cutting green peppers
C. Washing tofu strips
D. Frying tofu strips
E. Cutting tofu strips
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:38:02[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 163/165 [06:14<00:05,  2.54s/it][32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = pFpZvRsEGZs.mp4[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/pFpZvRsEGZs.mp4[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: pFpZvRsEGZs.mp4 | Selected 16 frames[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=326[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 16 specific frames[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 16 custom frames[0m
[32m2025-11-29 12:38:02[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 16 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:38:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
A man in a white coat and a long-haired woman are standing face to face next to a shelf. The man is holding a bottle with liquid in one hand and resting the other hand on the shelf. What is the color of the liquid in the bottle?
A. Black
B. Yellow
C. White
D. Red
E. Blue
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:38:05[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: D[0m
Model Responding:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 164/165 [06:17<00:02,  2.51s/it][32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m408[0m - [1mDEBUG: base_cache_dir = /home/train01/.cache/huggingface/[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m417[0m - [1mDEBUG: cache_name from YAML = longvideobench_custom_cache[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m425[0m - [1mDEBUG: final cache_dir = /home/train01/.cache/huggingface/longvideobench_custom_cache[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m429[0m - [1mDEBUG: video_filename from doc = aCPNlZ7bvRc.mp4[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m445[0m - [1mDEBUG: constructed video_path = /home/train01/.cache/huggingface/longvideobench_custom_cache/videos/aCPNlZ7bvRc.mp4[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m446[0m - [1mDEBUG: video_path exists? True[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_doc_to_visual[0m:[36m484[0m - [1m[longvideobench_custom] Video: aCPNlZ7bvRc.mp4 | Selected 9 frames[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m626[0m - [1m[CUSTOM_FRAMES] Detected custom frame selection for doc_id=328[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m629[0m - [1m[CUSTOM_FRAMES] Will load 9 specific frames[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m375[0m - [1m[CUSTOM_FRAMES] Received 9 custom frames[0m
[32m2025-11-29 12:38:05[0m | [1mINFO    [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mload_video[0m:[36m386[0m - [1m[CUSTOM_FRAMES] Using 9 custom frames instead of uniform sampling[0m
[32m2025-11-29 12:38:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m742[0m - [34m[1mQuestion: <image>
There is a man in the screen wearing a green military uniform, raising his hands. There are guns on both sides of him. Who is being held at gunpoint in the video?
A. Commander Jeremiah Denton
B. Tom
C. Nancy
D. Lhcy
Answer with the option's letter from the given choices directly.[0m
[32m2025-11-29 12:38:06[0m | [34m[1mDEBUG   [0m | [36mlmms_eval.models.simple.llava_vid[0m:[36mgenerate_until[0m:[36m743[0m - [34m[1mAnswer: A[0m
Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [06:18<00:00,  2.22s/it]Model Responding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [06:18<00:00,  2.30s/it]
Postprocessing:   0%|          | 0/165 [00:00<?, ?it/s][32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZoUsR8t8IxE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-6867204066108329221_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: I-yg_3yx6iA_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wvfctNd-Aio_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -eRimFrm6kQ_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JwoBdRC2fzE_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _BDzMutoy6A_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fPLjjr8w6DU_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kLuqCtnKr_8_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zVudr8cxHRE_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MJYBHfYF8LI_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: c6fuIEzOZ2E_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Efuyl2Anehg_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kk-iRzLv81o_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7270058010888768770_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pFpZvRsEGZs_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZaXpMou55lw_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @thatrecipe.us-7266555380925287723_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: i327DBSS_iE_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d8H7hgQY9ew_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LVFvRNRTEd4_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z7Cox6lPW3c_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NSn78eNspwU_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: M7YSCIkUaNw_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9PD3ciudpIE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7282789187676294432_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kk-iRzLv81o_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wSHPuI7wWIg_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 571nruSayeo_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8foMISZGiyw_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PQRyGacBRA4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GFg98TDqCpw_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AjF13uKVQa0_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: FOMS_yqdN1o_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbNyMSwoT5A_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ro_8-CCORzk_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: k4jiEuZbN-4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pGEF7Tme3Tk_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YcbKamVxDzI_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Ytv-9RM4e0o_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sEiyR7-0FOA_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PbiTIR8N4Hc_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8k6M0HD162k_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7269647281668852993_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JDtVwz1R-kI_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VSZ8ywgGNGM_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: il_wMYlDQ6I_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zkmoxOKhpvk_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -iCLYpeghJs_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ozpGTw6DrXs_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mq6L8CnNJXc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bwDfdTh0VYs_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: j6beJTHUT_c_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pGEF7Tme3Tk_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NpYUxd1vUUE_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5tN9hyfdkaE_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ze66pbJYr18_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Oht0i1DACcA_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: npLd4WTSQsM_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: X5v4nBo5y28_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: v-7zF3Y0yJs_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7308098412078025989_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: J_ZmaKRpyoU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8_MG-E8QlBM_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fWNJmZAWRNg_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AYMdAVxALP4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PCPQToF10IM_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NMHmqgO04rU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UD5ifzOPzhc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: er1oRjH2iu8_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-7080578381569445125_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: O471uwTNx6k_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wvfctNd-Aio_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbgwG8fcIu0_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bgklOaBBmB8_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: g7zuBUMBr2E_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fo97qfO-9_g_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: h4jIoMxZopU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: anrKq6HgPvs_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 59iv6EYWNn8_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7252661595875183874_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-7003765189401185542_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UwJTCg5fpXg_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8MkL3W6wU3g_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bXRuqcmTIuk_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gyV6EqgiPNg_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: x4UBaEojM6U_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mbcvVYobCXI_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7234536361296940314_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: MJYBHfYF8LI_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -An3wZyoYe0_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HRYlXC_ChzU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lojHyp1k0gE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UO_6TQnnOxM_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hg2Q_O5b9w4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: b__dUom9AcQ_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -0aM99dMu_4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KTY9bogonyw_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wFrztzzohJ8_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dE5iWeCVpGI_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TlaX2iIYZD4_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VGQ_djSR7zE_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LHXS0QR1ThA_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TlaX2iIYZD4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XJ6REZOXsvM_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: T5bTeGzgJFs_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sKvvuo9Yxqk_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: BRiFXVCr1Ak_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VL259eBJ68w_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: h0OHi9uAcBo_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bjymxow3TVQ_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UbNyMSwoT5A_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eE5Z7gDbgVA_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: e6HwinLBK_Y_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: FnKDgC9aNu0_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7276598470151032066_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NpYUxd1vUUE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PbiTIR8N4Hc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5qMcDQd17Y4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WTT7XZko3qk_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AxciimuEZAc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _EUDpS9UF9o_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ixlQX7lV8dc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Bjymxow3TVQ_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pFtKaT3GF9I_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: J_ZmaKRpyoU_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qbA42wQoWAs_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zTeDF7mQ88A_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PCPQToF10IM_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yl-6-Yzt--A_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7267884432420277506_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @_eat_sleep_travel_repeat-7275734357799652640_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fw1rirubXiU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1vvYsirvA2I_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GdZYLAI0vpc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: wFrztzzohJ8_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ZfapKqwklG4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CEZ9rbjK3P4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iHzypa15yRA_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: n24n_20Kwe4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _ZIa6SEJEyg_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: uWBh0meTg08_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @emsiiees-7296863219178638594_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: sWfcgeDth_w_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _hODR1cR9lo_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: W8w09l_mmT4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3JzhP8qfbqE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: o2F-N42Ufo4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-7097604725134118146_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Kz8_rwVn094_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7rMgpExA4kM_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: HAED3riiZkw_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Jaw7eWzgWr0_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3t_Knk7FWT8_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @thatrecipe.us-7309241426028596523_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-6976239624578419969_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8905KCkLDYc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VFXJnbnN5ro_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7312063059160206597_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mTn_C-SyW84_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vEy6tcU6eLU_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 6hBbXVkgxGE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _uL3a3aMdMQ_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mFliMGufpwc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GFg98TDqCpw_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2vVQo_GMA70_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: t48HXAjjDAU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VwZeSoYugZk_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NIxyQQfuVoc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qsH6q5wNso4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LlqsCCa6y58_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7274542274997013761_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 5KLSf7kwr7s_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dCscvoOX2as_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0rWA-p4p5IM_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: AnLMDMzO4QY_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jbPR2SJuFHg_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: eDso3zHFxL8_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iHNjWhx3EaI_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: qksR2Zvd-FM_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: gURB1JwPfJw_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DVsw1brd_Yc_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DoizYSYQRqU_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -eRimFrm6kQ_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @placesunleashed-7303594391850044678_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: athabNMGceo_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YcbKamVxDzI_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kWUmHAzCp7s_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bqQTWdk1DAM_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7m9XIXyT5_I_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 51dUUxFOjDE_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9S9i12n0TIw_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: athabNMGceo_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-6880172230588894465_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GawGUhl9zuQ_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LfUsGv-ESbc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: DoizYSYQRqU_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7305901654417706246_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NHIT9vq6mJU_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ixlQX7lV8dc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: D7VYbsORD8k_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fq3zbbp-lv4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TXiX3NO5f5w_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yU9fGAEcxJY_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: acAWfzV__XI_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _uL3a3aMdMQ_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7267308320413797650_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Z-1lgAXOEc8_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GFg98TDqCpw_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iwXp1fT89-M_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: ErGYJ7kqIow_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2W2ZkYARds4_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: UO_6TQnnOxM_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Q47I8AdRgzc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YebUIUOCo94_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: N7RTTiHsSjI_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OAcbasjxljY_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: P0BSTjziVys_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mHARxee4EzQ_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: dxjKdnJFmLs_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: cceTeD4JADU_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 0t1vtW0cT1E_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: tdA5atpqaAc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-7194857776877817094_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _kQXNFG664Y_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: FnKDgC9aNu0_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: yqejTvYILlA_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: QJ6sjg7SXOQ_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: a_hkRXc_bYg_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rwL_XPw46zQ_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: otaJfBSlsG8_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XVXczyheik0_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: YehqA9xoGTY_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: s5edwp0PEqk_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2edlqFUTDVc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OUeE8nCKWGA_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: E7FSg22MdKE_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @healthfood-6948509102305791238_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7265680288636767520_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Oht0i1DACcA_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3b_v1KO_U8A_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mq6L8CnNJXc_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: iwXp1fT89-M_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lzAESaVqix0_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WaiGdRYD36k_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: L-XGTMusZvc_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WM78_KqcrSY_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PE32sjfN-uM_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7268213090708245761_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6HTO2SOxUc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kj3Po7zUeyw_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 22iOyzE8Ec0_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: mfS6gyP0mwo_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _g3Y_mk64Wc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GuEptwLiAvs_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: td35F9LNazA_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d-GKQeu4S6M_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: g_kziK-UOSU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CEZ9rbjK3P4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Dkm35G5kkcc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lN3WnXMaE0o_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 8Gl6iy7OEM4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VkNF0rXuDXw_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: z6THwql5c6w_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: I-yg_3yx6iA_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 7m9XIXyT5_I_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KTY9bogonyw_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: NAJOZTNkhlI_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fryyNwUCPWA_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: LB1qPExHQY8_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zVudr8cxHRE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: lNReCCShKJQ_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: bAGhXcYc0o4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Sy2unO22PUE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: kbRtl58u_kk_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d8H7hgQY9ew_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: PQRyGacBRA4_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: XuQswmEPgxU_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: jvkmcX47bKU_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: oI975O1BUu0_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: Fw1rirubXiU_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @recipesbyanne-7153617149041446150_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aX_HgA5SNLQ_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7254238802577820929_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: CdTijM0_es4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fLn06p2HtAc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 3hyPwjkdHEA_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TFbGLEZ4qt0_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: VkNF0rXuDXw_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: f0IbZGfTgUM_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @kerstinong-7197781091162279169_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7194500194648476933_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fZBC3nmvJb8_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: JASFwBtUK40_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: rP7sQe784k8_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @lisolna-7231929658869107994_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 9yQV0t5meo4_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: zk6fgbXI5AE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7270058445577948418_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: T57jVsvVVR0_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: fO7nwCix8xU_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: brZugTJ0odg_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: a_8G0PzVFbc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @movie.explained6-7269006883380399362_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: OMJc43wUPLM_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aX_HgA5SNLQ_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: d5JlCEDlHGE_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: L-XGTMusZvc_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 1R5uPaL0V-0_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: GZFL58_pXPg_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'C.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RTUFPjliMCU_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @tiffycooks-7171182579058511110_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: vJ9hYCUDHTo_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: WpbB_swXHkc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: u1D4ArcBjLI_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'E.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'E'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: _BDzMutoy6A_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: 2ekjGl8yWZk_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: -0aM99dMu_4_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: hg2Q_O5b9w4_2]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: KIf2fGmluhY_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'C'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: False[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: RN2g9sRuJhA_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: @jonijawne-7184469162956246277_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: pFpZvRsEGZs_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'D'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: TxS1JnfuG34_1]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'B.'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'B'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m557[0m - [1mDEBUG [ID: aCPNlZ7bvRc_0]:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m558[0m - [1m  Raw prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m559[0m - [1m  Parsed prediction: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m560[0m - [1m  Correct answer: 'A'[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_process_results[0m:[36m561[0m - [1m  Match: True[0m
Postprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [00:00<00:00, 3337.96it/s]
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m631[0m - [1m================================================================================[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m632[0m - [1mLONGVIDEOBENCH CUSTOM RESULTS (with Frame Selection)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m633[0m - [1m================================================================================[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m641[0m - [1m
Accuracy by Duration Group:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m642[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  15s                           : 77.50% (40 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  60s                           : 67.50% (40 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  600s                          : 67.00% (100 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m645[0m - [1m  3600s                         : 60.00% (150 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m650[0m - [1m
Accuracy by Question Category:[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m651[0m - [1m--------------------------------------------------------------------------------[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E2O                           : 72.73% (22 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  E3E                           : 77.78% (18 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O2E                           : 56.25% (16 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  O3O                           : 54.55% (11 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2A                           : 77.27% (22 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2E                           : 82.61% (23 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  S2O                           : 88.89% (18 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SAA                           : 62.50% (16 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SOS                           : 72.73% (22 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  SSS                           : 47.62% (21 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2A                           : 74.07% (27 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2E                           : 75.00% (20 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T2O                           : 57.89% (19 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3E                           : 57.14% (14 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  T3O                           : 40.74% (27 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TAA                           : 47.62% (21 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m654[0m - [1m  TOS                           : 53.85% (13 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m658[0m - [1m
================================================================================[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m659[0m - [1mOVERALL ACCURACY: 65.15% (330 samples)[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mutils[0m:[36mlongvideobench_custom_aggregate_results[0m:[36m660[0m - [1m================================================================================[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
[32m2025-11-29 12:38:06[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_samples[0m:[36m287[0m - [1mSaving samples to /home/train01/miraj/lmms_eval/results/full_logs/radius/selected_dbfp_dense_longvideobench_blip_k16_alpha0.85_adaptive_r15_3.0_r60_5.0_r600_9.0_r3600_12.0_temporal_iter3_20251129_123127_results/..__LLaVA-NeXT-Video-7B-Qwen2/20251129_203133_samples_longvideobench_custom.jsonl[0m
llava_vid (pretrained=../LLaVA-NeXT-Video-7B-Qwen2,conv_template=chatml_direct,video_decode_backend=decord,max_frames_num=16,overwrite=False), gen_kwargs: (), limit: None, num_fewshot: None, batch_size: 1
|        Tasks        |Version|Filter|n-shot|    Metric    |   |Value |   |Stderr|
|---------------------|------:|------|-----:|--------------|---|-----:|---|------|
|longvideobench_custom|      1|none  |     0|lvb_custom_acc|‚Üë  |0.6515|¬±  |   N/A|

[rank0]:[W1129 12:38:07.705247510 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
